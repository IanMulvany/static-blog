<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
 
 <title>Partially Attended</title>
 <link href="http://partiallyattended.com/atom.xml" rel="self"/>
 <link href="http://partiallyattended.com/"/>
 <updated>2014-11-09T22:14:06+00:00</updated>
 <id>http://partiallyattended.com/</id>
 <author>
   <name>Ian Mulvany</name>
   <email>ian@mulvany.net</email>
 </author>

 
 <entry>
   <title>synthesis of breakout session from day 1 - institutions and metrics</title>
   <link href="http://partiallyattended.com/2014/09/26/1am-session-synthasis-institutes-and-metrics"/>
   <updated>2014-09-26T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/09/26/1am-session-synthasis-institutes-and-metrics</id>
   <content type="html">&lt;p&gt;Thanks to – Kevin Dolby, Martijn Roelandse, Mike Taylor and Andrea Michalek for taking the notes from each of the breakout sessions, I have synthesised them here. &lt;/p&gt;

&lt;p&gt;Altmetrics could be used as a way to indicate the pathway of impact&lt;/p&gt;

&lt;p&gt;Institutions should define their game plan, what do we want to achieve, what metrics can help get us there
they could give guidance to researchers on what platforms to adopt (the landscape is cluttered, but at the same
time Institutions probably don’t know), that said funders are behind the principle that universities drive what metrics they want to collect, and the set of standards, instead of prescribing metrics (don’t get led by what gets measured, define the
change you want to affect first).&lt;/p&gt;

&lt;p&gt;Researchers still don’t know about these metrics, there are some routes to education, in particular via the library 
(a course exists in Sheffield),
but there is a general sense of “it’s not worth the time”. A key is going to be to get the younger researchers to adopt. 
We need to find incentives (I’m not going to mention what form those incentives could take)&lt;/p&gt;

&lt;p&gt;On the topic of adoption, it’s clearly discipline dependent (there is a first mover problem in a field, if 
others are doing it, it can be seen as more acceptable)&lt;/p&gt;

&lt;p&gt;one university had faculty need to to spend “two points” on community outreach, managing the department 
twitter account allowed them to tick this requirements. &lt;/p&gt;

&lt;p&gt;In contrast to what one group reported, another reported that younger researchers more engaged, those at the top - no interest &lt;/p&gt;

&lt;p&gt;Making them personal was considered appealing &lt;/p&gt;

&lt;p&gt;It’s clear we can’t mandate participation.&lt;/p&gt;

&lt;p&gt;Can there be a standard? No, for reasons above (mainly around participation). So if there isn’t, then anyone who provides altmetric data will inevitably curate them, favourably. When does this become cheating? How do we learn how to read altmetric data as funders? What other evidence might be provided?&lt;/p&gt;

&lt;p&gt;Gaming will happen, perhaps we could embrace that Altmetrics can incentivise researchers to make their research available in open access. In addition don’t forget the Humanities!! &lt;/p&gt;

&lt;p&gt;Could be used to Raise the institutional profile, even help with track public engagement, however …&lt;/p&gt;

&lt;p&gt;Metrics (both new metrics and traditional citations count “hits” so both negative and positive hits are counted equally. This leaves the “quality” problem there&lt;/p&gt;

&lt;p&gt;Looking at what metrics are valuable around a discipline-level vs institution-level could also be interesting&lt;/p&gt;

&lt;p&gt;Looking at late adopters of social media use, using social media metrics about their work could be helpful in showing the value of social media to them&lt;/p&gt;

&lt;p&gt;Do please use standards, DOIs, ORCIDs etc.&lt;/p&gt;

&lt;p&gt;Where artefacts live in different plances (when content is promiscuous), find a way to have usage data 
flow between different object silos. &lt;/p&gt;

&lt;p&gt;How do we stop altmetrics being misused, a la JIF. Since there is no safety catch on altmetrics, people are free to mis-use them! Openness and communication and conferences like this one will help&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>FuturePub3 - September 2014 event</title>
   <link href="http://partiallyattended.com/2014/09/24/futurepub3"/>
   <updated>2014-09-24T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/09/24/futurepub3</id>
   <content type="html">&lt;p&gt;Welcome back for the next installment of FuturePub. There are tons of people at the meeting tonight, pizza and beers care of WriteLaTeX!! &lt;/p&gt;

&lt;h1 id=&quot;sumika-sakanishi---product-manager---odi&quot;&gt; Sumika Sakanishi - Product Manager - ODI&lt;/h1&gt;

&lt;p&gt;They aim to encourage organisations to unlock data. They also work with individuals to help them unlock the value of open data. &lt;/p&gt;

&lt;p&gt;Open data is free to use, reuse and redistribute it, e.g. CC-BY. &lt;/p&gt;

&lt;p&gt;The open data instutute have created the open data certificate, an online tool to help open data owners publish their data. It’s a questionairre. At the end you get a certifciation telling you how open your data is.&lt;/p&gt;

&lt;p&gt;You get a badge that you can put on your website. I remain bearish on the topic of badges on websites. &lt;/p&gt;

&lt;p&gt;They have issued about 1k certificates in either draft of publised form. About 100 are fully published. &lt;/p&gt;

&lt;p&gt;Tool is available here: &lt;a href=&quot;certificates.theoid.org&quot;&gt;certificates.theoid.org&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;For more thoughts on openening data within research see my recent posts &lt;a href=&quot;&quot;&gt;here&lt;/a&gt;, &lt;a href=&quot;&quot;&gt;here&lt;/a&gt; and a summary &lt;a href=&quot;&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;walacea---back-sciecne-you-believe-in&quot;&gt; Walacea - back sciecne you believe in&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;walacea.com]&quot;&gt;walacea.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This is a crowd funding site for researchers. &lt;/p&gt;

&lt;p&gt;Name inspired by alfred russell wallace, who crowd-funded his work in early 19th century terms. &lt;/p&gt;

&lt;p&gt;They launced today with their first two proejcts. &lt;/p&gt;

&lt;p&gt;Walacea receives a 5% comission on all projects. &lt;/p&gt;

&lt;p&gt;It’s interesting that they put their comission up front. &lt;/p&gt;

&lt;p&gt;They are hoping to be able to raise on the order of about 50k per project, or thereabouts. The inital two projects are aiming for about 15k. On the question of the addressable market, in the UK 9B is given by the public to charity every year, so that’s an indication of one way to measure possible addressable market. They contrast to experiment.com by providing a rewards program to donors. &lt;/p&gt;

&lt;p&gt;(lot’s of interest in this talk, lots of questions). &lt;/p&gt;

&lt;h1 id=&quot;anna-sharman---cofactor-and-the-journal-selector-tools&quot;&gt;Anna Sharman - cofactor, and the journal selector tools.&lt;/h1&gt;

&lt;p&gt;Other tools that exist - &lt;a href=&quot;jane&quot;&gt;Journal/Author Name Estimator&lt;/a&gt;&lt;br /&gt;
Edanz Journal Selector - []  &lt;/p&gt;

&lt;p&gt;Cofactor is a complimentary tool that might be useful. It’s about broad scope journals, there are many options and it’s manually curated. &lt;/p&gt;

&lt;p&gt;Includes queries aroud options such as
- type of peer review
- licence
- gold v hybrid
- APC
- non profit vs profit
- length limits
- copyediting or not &lt;/p&gt;

&lt;p&gt;The current focus is on broad scope open access journals. &lt;/p&gt;

&lt;p&gt;Looks nice! &lt;/p&gt;

&lt;p&gt;How are they going to tackle issues around scalability? 
Currently they are checking the data against the journal website. The issue of scalablilty needs to considered carefully. &lt;/p&gt;

&lt;p&gt;The aim of the tool is to use it to bring people to the website in the hope that &lt;/p&gt;

&lt;h1 id=&quot;bookgenie-451---andrew-mcfarland&quot;&gt;BookGenie 451 - Andrew Mcfarland&lt;/h1&gt;

&lt;p&gt;Their mission is to improve research outcomes in higher education. They match a profile of the researcher against content coming from a publisher’s repository. They have very clever tools that do this. &lt;/p&gt;

&lt;p&gt;They produce snips of content based on keyword search. &lt;/p&gt;

&lt;p&gt;Their co-founder was a CTO at Amazon and was one of the people based on working on the Kindle. &lt;/p&gt;

&lt;p&gt;They aim to sell micro-pieces of content for micro-prices, they take a 40% cut on sales of content to consumers. They have 4 publishers setup for a proof of concept. &lt;/p&gt;

&lt;p&gt;There is a “textbook cirses”, too many unafordable textbooks in the higher education market. &lt;/p&gt;

&lt;p&gt;The impact of Open Access is going to adversly affect publisher incomes (yay!! – my comment). &lt;/p&gt;

&lt;p&gt;Search engines for academic content are poor, institutinoal based repository specific search indexes preofrm better than MS academic search or google scholar. The big question is how do you move the user behaviour. If you can get the user to search in an app, or in their book, that might be an option. &lt;/p&gt;

&lt;p&gt;They are expecting BookGenie 451 to become the iTunes for academic search. &lt;/p&gt;

&lt;p&gt;(There are soooooo many questions about this product, but I don’t have to ask any questions at this stage, becuase they are at such an early stage the the reality of creating a real product will iron out many of these questions, so I’ll come back and ask my questions in 18 months, if they are still around). &lt;/p&gt;

&lt;h1 id=&quot;alan-hyndman---the-latest-from-planet-figshare&quot;&gt; Alan Hyndman - the latest from planet figshare&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;they have a figshare for publishers - suite of products   &lt;/li&gt;
  &lt;li&gt;figshare portal is a library of supp data for a publiser  &lt;/li&gt;
  &lt;li&gt;figshare datastore can handly up to 200GB file types  &lt;/li&gt;
  &lt;li&gt;figshare innovations - any cool data realted prodcuts - related content engine on plos is driven by this tool, will do relatedness at the individual file level (sounds a little like the source data proejct that EMBO is working on).  &lt;/li&gt;
  &lt;li&gt;HGV database - human genome variation database   &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;mattias-priparri---new-developments-from-papers-the-citation-tool-of-the-future&quot;&gt; Mattias Priparri - new developments from papers, the citation tool of the future?&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;their citation tool is a stand alone tool, it can insert citations into almost any app on your mac. &lt;/li&gt;
  &lt;li&gt;it’s inspired by applications like Alfred and other quick launcer applications &lt;/li&gt;
  &lt;li&gt;they want their citation tool to be like a quick launcher for scientific content &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;wrapup&quot;&gt; Wrapup&lt;/h1&gt;

&lt;p&gt;It’s a wrap, time for the pub!! The next futurepub event will be in January in Oxford, I’m going to try to make it. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>thoughts on the ERC data workshop</title>
   <link href="http://partiallyattended.com/2014/09/24/erc-workshop-thought"/>
   <updated>2014-09-24T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/09/24/erc-workshop-thought</id>
   <content type="html">&lt;p&gt;On Thursday and Friday of last week I attended a European Research Council workshop on managing research data. It was well attended with about 130 participants brining views from across the academic disciplines. I’ve blogged my raw notes from &lt;a href=&quot;http://partiallyattended.com/2014/09/21/erc-workshop-day1&quot;&gt;day one&lt;/a&gt; and &lt;a href=&quot;http://partiallyattended.com/2014/09/21/erc-workshop-day2&quot;&gt;day two&lt;/a&gt;. In this post I reflect on the points I noticed that were raised over the two days. People have been talking about the increasing importance of research information for many years now, and a hope was raised in the opening comments that we might be able to provide solutions to the problems posed by the issues of research data, by the end of the workshop. I was skeptical about our chances of doing that. The risk at a meeting like this is that the same points and problems get regurgitated, problems are listed at too high a level, everyone calls on everyone else, or at least someone else, to step in and solve the problem. There were aspects of all of these issues, but there were also highly encouraging signs too, and signs of real progress in solving some of the perennial existential questions of research data. Over the course of the two days I made a note, when I noticed it, of when specific named issues, potential solutions, or novel points, were made.&lt;/p&gt;

&lt;p&gt;By the end of the first day the problems list far outweighed the solutions list, but by the end of the second day that ratio had reversed. I’m going to briefly drill into each one in a moment, but before doing that I’ll touch on the highlights coming out of the meeting.&lt;/p&gt;

&lt;p&gt;By the end of the meeting the chair put it well when he said that overall the feeling coming out of the meeting was one of unity, a shared desire and understanding that data should be open, and a shared understanding that some culture change is necessary. We have many parties interested in this issue, and we all want to move faster on the issue.&lt;/p&gt;

&lt;p&gt;There were signs of real progress too. LERU have a working paper on research data, and the take home message is that university chancellors almost universally think that research data should be made open, and that this will be a high priority issue for them - once they figure out what they are doing about open access.&lt;/p&gt;

&lt;p&gt;How to cite data is now solved, in principle. The FROCE 11 data citation principles solve this, what remains is implementation (already in progress in the life sciences), and then adoption. Adoption is going to be where the largest challenges lie, because if we have a mechanism for citing data, and researchers continue to turn up to meetings like this say &lt;em&gt;how do I cite data&lt;/em&gt;, then obviously there is work to do. We have to continue this work until researchers turn up to meetings like this one and say &lt;em&gt;this is how I cite data&lt;/em&gt;. We want data citations everywhere.&lt;/p&gt;

&lt;p&gt;A working solution to how researchers can make claims on what data they have produced was demonstrated by Sünje Dallmeier‐Tiessen with the The &lt;a href=&quot;http://odin-project.eu&quot;&gt;ODIN&lt;/a&gt; project. Again there is work needed here to promote adoption, and work to do on usability and interoperability.&lt;/p&gt;

&lt;p&gt;It wasn’t all light and harmonious music though, there were a few telling shadows, a few indicators that the problem remains a deep and challenging one. It was notable that no LERU university has any reward system or prize system in place for good use or reuse of research data, or any mechanism in place for rewarding excellence in the support systems for research data. There is a Dutch prize on this topic, but it’s clear that more can be done.&lt;/p&gt;

&lt;p&gt;In fact, often a need in culture change was mentioned. It should be obvious where this change can best be affected - in the grant rewarding process and in the hiring process. The EU, indeed all funders, are wary of sticks, but let’s sow the fields of Europe’s rich plots of data with an abundance of carrots. Let’s make available specific funding to support bottom up approaches to training for data management. There is already an appetite with initiatives like software carpentry, the creation of figshare, the growth of data dryad. Goodness, we could even invest in library infrastructure for this purpose. Let’s set up a research track for pure data re-use with grants awarded to those who have projects that reuse the data of others, and give them the time and resources to clean up that data. Let’s make clear that data are a real research output that counts in assessment. There would be no requirement to do this, but researchers who did would have their work recognised where it matters most. There were a few calls that anywhere between 5% or 15% of all research funding should go to data management, but I think it would be better to look at how we can alter behaviours on the ground from the bottom up. Data is important. After all, the data is the science, or at the very least it is the embodiment of our articulation of how we have grappled with reality, and it is the trail that shows our direct engagement with nature.&lt;/p&gt;

&lt;p&gt;Having real options for data management careers in research could also help in the short term, and in the medium term could help create a workforce that is skilled in the management of big data.&lt;/p&gt;

&lt;p&gt;OK, so let’s now look at each of the points that I captured from the two days at the meeting. I’ll list these as either questions, problems or solutions. I’m grouping them into topics that seem to make sense to me, so my groupings don’t reflect the order in which these topics arose, but I hope by doing this I can provide a horizontal view across the breakout sessions from the meeting to get the common themes that emerged. I’ll list the solutions as they were proposed. They stand here for your consideration. I add my own commentary at the bottom of each section. &lt;/p&gt;

&lt;h1 id=&quot;moolah-money-cash&quot;&gt;Moolah, money, cash,&lt;/h1&gt;
&lt;p&gt;### Problems or questions raised
	- Question: who pays, what do they pay for?&lt;/p&gt;

&lt;h3 id=&quot;solutions-proposed&quot;&gt;Solutions proposed&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- Solution: provide funding for data sharing.  
- Solution: take a percent, say 15%, and set that aside in every grant for data sharing, curation and storage . 
- Solution: do bulk purchasing from providers, and distribute compute and storage credits to researchers.  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;my-comments&quot;&gt;My comments&lt;/h3&gt;

&lt;p&gt;The inference seemed to be that it should mostly be funders supplying the cash through some mechanism. The idea of doing bulk purchasing for infrastructure, and then giving researchers credits is an appealing one. Such approaches will be good for big data, but will have little impact on the majority of instances of data that is created, things like individual excel files on an individuals computer. &lt;/p&gt;

&lt;h2 id=&quot;infrastructure-and-support&quot;&gt;Infrastructure and support&lt;/h2&gt;
&lt;p&gt;### Problems or questions raised&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- Problem: hiring domain experts, e.g. DBAs, on a temporary basis is hard.  
- Problem: formats need to be updated, needs to work in the long-term, needs intelligent curation, structures to support this does not exist.   
- Problem: manual labour is required, the current credit system does not support that.   
- Question: how might we provide more training.   
- Problem: data is useless without the computational infrastructure behind the data.  
- Question: how might we provide better infrastructure for data.     
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;solutions-proposed-1&quot;&gt;Solutions proposed&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Solution: have a bank of data domain experts ready in the library/institution that can be seconded out or hired on short term contracts by researchers  
Solution: create a profession of data curators  
Solution: The EU should take care of infrastructure EU-wide to promote a level playing field.  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;my-comments-1&quot;&gt;My comments&lt;/h3&gt;

&lt;p&gt;All of these solutions are good in principle, however they will require real will to create these kinds of incentives. It was often mentioned throughout the meeting that these kinds of skills could be provided through the private sector, and there was real concern that such an approach might lead to restrictions on the data if that data becomes controlled by a private company. Academic publishers were mentioned. I find it hard to see an EU-wide rolling out of an army of data curators, I think that has to come bottom up, from within disciplines. I could see libraries making a case to equip themselves for this task, but I don’t see them as being the natural inheritors of that task. It seems that institution-wide facilities, or national facilities might be good places for these kinds of roles to reside. &lt;/p&gt;

&lt;h2 id=&quot;fundamental-definitions&quot;&gt;Fundamental definitions&lt;/h2&gt;
&lt;p&gt;### Problems or questions raised&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Problem: open data has been defined by rich labs, it&#39;s ambiguous, and currently non-inclusive.   
Question: how can we get to an agreed understanding of what Open Data is, and what currency it has in research communication.    
Question: how might we define data, per discipline.    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;my-comments-2&quot;&gt;My comments&lt;/h3&gt;
&lt;p&gt;No solutions were proposed for this topic, but a great point was made that what we are calling data sharing is really effectively data dissemination, as those making their data available are not usually waiting for some reciprocal piece of data (although to be fair that was the example for the motivation behind sharing geneomic data).  &lt;/p&gt;

&lt;h2 id=&quot;management-and-interoperability&quot;&gt;Management and interoperability&lt;/h2&gt;

&lt;h3 id=&quot;problems-or-questions-raised&quot;&gt;Problems or questions raised&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Question: how do we combine heterogeneous data from within one discipline or study.   
Question: how do you deal with large unstructured data sets?    
Question: who sets the metadata structures in different communities? 
Question: where do we put our data?  
Problem: need coordination between different data repositories and related services.    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;solutions-proposed-2&quot;&gt;Solutions proposed&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Solution: deposit you data into existing structured DBs where they are available.  
Solution: convince people to copy good data management plans (and follow them).    
Solution: create an open marketplace of good data management plans.    
Solution: make data management plans be a living document.    
Solution: include the data scientist at the point of experimental design.    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;my-comments-3&quot;&gt;My comments&lt;/h3&gt;

&lt;p&gt;So these topics, where do I put my data, how, how does it interoperate. To make anything happen we &lt;strong&gt;have&lt;/strong&gt; to look at things on a discipline by discipline level. Many disciplines have this nailed, and we must must must must must work as hard as we can to get appropriate data into it’s appropriate repository. If it goes anywhere else that piece of data might as well not exist. I had a detailed conversation about the feasibility of federating computation over these kinds of data sets across repositories, but at the moment there is no infrastructure or will to support an approach like that, however we don’t have to, because the primary home for that data exists. &lt;/p&gt;

&lt;p&gt;For small scale - one off files- data that is important on a paper by paper basis, there are now stable DOI coining repositories. If we can get people to use them then the question of where this data should go seems to have a clear answer. &lt;/p&gt;

&lt;p&gt;Two areas that represent significant challenges are domains that are just now stumbling into the era of unmanageably large data owing to tooling or data sources suddenly being able to produce more data than these domains had previously needed to work with. Domains that look at web scale data, and domains whose experimental equipment has vastly increased it’s output volume are examples, such as the digital humanities and microscopy. These research fields need to work hard on building up a shared infrastructure and data formats, and those efforts need to be supported. &lt;/p&gt;

&lt;p&gt;The other area that represents a challenge is data which is heterogeneous, but needs to be integrated in order to tell a story. Before this workshop I’d not appreciated that this kind of complexity can live even within one experiment. Perhaps a research objects like approach, or an approach of adopting tools and methods from schema-less data stores and key-value stores in web applications, could be applied to these problems, I just don’t know enough to have a solid opinion on this yet. &lt;/p&gt;

&lt;h2 id=&quot;incentives-trust-and-ethics&quot;&gt;Incentives, trust and ethics&lt;/h2&gt;

&lt;h3 id=&quot;problems-or-questions-raised-1&quot;&gt;Problems or questions raised&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;Question: how do you reward data dissemination? how do you provide incentives.  
Question: how do we deal with data fraud.  
Question: can you trust the data in a repository?
Question: how might we provide a proper citation and reward system.  
Question: how do we make data donation habitual?
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;solutions-proposed-3&quot;&gt;Solutions proposed&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Solution: give DOIs, or similar, to data.  
Solution: cite data in reference lists, use the [FORCE 11 data citation principles](https://www.force11.org/datacitation).  
Solution: reward data contributions .   
Solution: appropriately label datasets to support fine-grained attribution.  
Solution: develop a culture of acknowledgement.  
Solution: use embargoes as a mechanism to incentivise researcher to make timely use of their own data.  
Solution: give a prize for examples of good use of data (it&#39;s mention that there is a data prize in The Netherlands).  
Solution: provide certification for digital repositories.  
Solution: Funders should mandate open data.  
Solution: enforce data policies.  
Solution: create a code of conduct teaching young researchers about the ethical issues around data.  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;my-comments-4&quot;&gt;My comments&lt;/h3&gt;

&lt;p&gt;A lot of people talked about how we can cite the data. Yo, HELLO!!, we already have a solution to this, you just have to cite the data. A functioning example of how a researcher had connected a data output from one paper to their ORCID profile was even demonstrated during the meeting. For the vast majority of use cases, this is technically solved, we just need to let people know that it’s solved. Indeed the following blog post from CrossRef describes how to &lt;a href=&quot;http://crosstech.crossref.org/2014/09/linking-data-and-publications.html&quot;&gt;intertwine data and literature citations&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are, of course, some subtitles, what do you do with a data source or DB that has multiple contributors, what if your data source is evolving over time. There are potential solutions to these issues on the horizon, I’m excited to see where the &lt;a href=&quot;http://dat-data.com&quot;&gt;DAT&lt;/a&gt; project gets to. The aim of this project is to allow the creation of fine-grained identifiers (along with contributor info) for every record in a DB. It’s basically git for data. &lt;/p&gt;

&lt;p&gt;On the broader topic of giving credit for data outputs where those outputs can be identified, that is where the cultural change needs to come, and ideas such as setting up prizes or named chairs for data reuse are really good ones. In fact looking over the proposed solutions, most are indeed carrot-like rather than stick-like. &lt;/p&gt;

&lt;p&gt;On the topic of ethical responsibility and data fraud, I love the idea that by making your data available, that is a huge dis-incentive to fraud. Reproducing experiments is hard, so even if your data is made available, your experiment might not be that easy to reproduce, but fake data tends to have a statistically significantly different signature to real data, and so the act of making your data available is an act of ethical responsibility. &lt;/p&gt;

&lt;h2 id=&quot;legal-and-commercial-issues&quot;&gt;Legal and commercial issues&lt;/h2&gt;

&lt;h3 id=&quot;problems-or-questions-raised-2&quot;&gt;Problems or questions raised&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Question: how does the distance to the commercial market affect acceptance of and practices in data sharing.  
Question: can we introduce licences that can be interoperable for data?  
Question: who owns the data/a bacterium?  
Question: legal and ethical issues affect the use of such data.  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;solutions-proposed-4&quot;&gt;Solutions proposed&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Solution: move towards an internationally level playing field on ethics for research.  
Solution: update the EU copyright directive.  
Solution: create an EU-wide directive on data policy for scientific research.  
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;my-comments-5&quot;&gt;My comments&lt;/h3&gt;

&lt;p&gt;It seems there are movements within the vast machine of EU legality to try to get to some state of normalisation on these issues, and I wish them the very best. One response that was clear from the floor of the conference around commerical involvement was the clear call to not give ownership of the data away to the private sector in the same way that ownership of the literature has been ceded to commerical publishers. In contrast to this the fact that data that is currently commercially held can be of high value to research was mentioned eloquently by the speaker who is building climate change models, and I think that position strengthens the arguments of the Open Data movement – even commerical data providers should be encouraged EU-wide to move to thinking about getting open data certification for their data. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>ERC data management workshop, day 2</title>
   <link href="http://partiallyattended.com/2014/09/21/erc-workshop-day2"/>
   <updated>2014-09-21T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/09/21/erc-workshop-day2</id>
   <content type="html">&lt;!-- toc --&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#life-sciences-breakout-key-points&quot;&gt;Life sciences breakout - key points.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#physical-sciences-breakout-key-points&quot;&gt;Physical sciences breakout - key points.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#humanities-breakout-key-points&quot;&gt;Humanities breakout - key points.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#open-discussion-on-morning-presentations&quot;&gt;Open discussion on morning presentations.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#breakout-session-on-incentives&quot;&gt;Breakout session on incentives.&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#paul-ayris-implementing-the-future-the-leruhttpleruorg-roadmap-for-research-data&quot;&gt;Paul Ayris - Implementing the Future: the [LERU](http://leru.org) roadmap for research data.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#sünje-dallmeiertiessen-incentives-for-open-science-attribution-recognition-collaboration&quot;&gt;Sünje Dallmeier‐Tiessen - Incentives for Open Science Attribution, Recognition, Collaboration.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#veerle-van-den-eynden-and-libby-bishop-incentives-for-sharing-research-data-evidence-from-an-eu-study&quot;&gt;Veerle Van den Eynden and Libby Bishop - Incentives for sharing research data, evidence from an EU study.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#open-discussion-after-breakout-session&quot;&gt;Open discussion after breakout session.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#reporting-session-from-working-groups&quot;&gt;Reporting session from working groups.&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#data-management-and-sharing&quot;&gt;Data management and sharing.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#storage-curation-and-interoperability&quot;&gt;Storage, curation and interoperability.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#data-discoverability-access-and-reuse&quot;&gt;Data discoverability access and reuse.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#rewards-and-incentives-for-good-data-management-the-carrot-session&quot;&gt;Rewards and incentives for good data management (the carrot session).&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#breakout-session-post-summing-discussion&quot;&gt;Breakout session - post summing - discussion.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#concluding-discussion-session&quot;&gt;Concluding discussion session.&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#closing-remarks&quot;&gt;Closing remarks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#issues-and-questions-that-came-up-today&quot;&gt;Issues and questions that came up today.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#suggested-solutions-to-issues-that-came-up-today&quot;&gt;Suggested solutions to issues that came up today.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- toc stop --&gt;

&lt;p&gt;Well, here we are at day two. My notes on the first day are &lt;a href=&quot;http://partiallyattended.com/2014/09/21/erc-workshop-day1/&quot;&gt;here&lt;/a&gt;.
We will open up with a short overview of the breakout sessions yesterday.&lt;/p&gt;

&lt;h3 id=&quot;life-sciences-breakout---key-points&quot;&gt;Life sciences breakout - key points.&lt;/h3&gt;

&lt;p&gt;The only point that came up that I hadn’t really covered in my notes from yesterday was that the view was that scientists should not become experts in data management, but some training should help.&lt;/p&gt;

&lt;h3 id=&quot;physical-sciences-breakout---key-points&quot;&gt;Physical sciences breakout - key points.&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;open access to data shows the true richness of the data&lt;/li&gt;
  &lt;li&gt;can validate the ownership of data&lt;/li&gt;
  &lt;li&gt;can attract collaborators from other fields&lt;/li&gt;
  &lt;li&gt;advantages of data sharing outweigh the disadvantages&lt;/li&gt;
  &lt;li&gt;process of data sharing starts at the level of instrumentation and common data formats&lt;/li&gt;
  &lt;li&gt;there should be the possibility of DOI-type labelling of data packages&lt;/li&gt;
  &lt;li&gt;how do you deal with large unstructured data sets?&lt;/li&gt;
  &lt;li&gt;legal and ethical issues affect the use of such data&lt;/li&gt;
  &lt;li&gt;there is a difference between observational and experimental data sets&lt;/li&gt;
  &lt;li&gt;how does the distance to the commercial market affect acceptance of and practices in data sharing&lt;/li&gt;
  &lt;li&gt;who makes the first move? – researchers, institutions, funders, societies?&lt;/li&gt;
  &lt;li&gt;do we need a new profession of data curator?&lt;/li&gt;
  &lt;li&gt;appropriately label datasets to support fine-grained attribution&lt;/li&gt;
  &lt;li&gt;develop a culture of acknowledgement&lt;/li&gt;
  &lt;li&gt;provide funding for data sharing&lt;/li&gt;
  &lt;li&gt;Embargoes are complex, different embargoes are needed for different levels, PI’s need some time to work with the data, data collected at the national level should be made open immediately.
    &lt;ul&gt;
      &lt;li&gt;an embargo can act as an incentive for the timely use of the data for researchers (they need to get that paper out before their data is released)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;set aside 15% of each grant for data curation and storage&lt;/li&gt;
  &lt;li&gt;that old chestnut “standardisation vs interoperability”&lt;/li&gt;
  &lt;li&gt;update the EU copyright directive&lt;/li&gt;
  &lt;li&gt;who sets the metadata structures in different communities?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;humanities-breakout---key-points&quot;&gt;Humanities breakout - key points.&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;&quot;&gt;DigiPal&lt;/a&gt; was mentioned.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;management must be done at the discipline level, not at domain level&lt;/li&gt;
  &lt;li&gt;needs to be done above the institutional level&lt;/li&gt;
  &lt;li&gt;sustainability is crucial for SSH&lt;/li&gt;
  &lt;li&gt;could SSH learn how to deal with Ethical issues from the life sciences?
    &lt;ul&gt;
      &lt;li&gt;need flexible sciences&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ownership of data is discipline depended, one rule does not fit all&lt;/li&gt;
  &lt;li&gt;creation of infrastructures in not an ERC mandate (it makes one wonder why we might be here today)&lt;/li&gt;
  &lt;li&gt;need career recognition&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;open-discussion-on-morning-presentations&quot;&gt; Open discussion on morning presentations.&lt;/h3&gt;

&lt;p&gt;Data management starts before the first data point is acquired.&lt;/p&gt;

&lt;p&gt;Data and publications need to be tied together.&lt;/p&gt;

&lt;p&gt;We need to get the right tools to researchers.&lt;/p&gt;

&lt;p&gt;Representation of data is as important as data itself.&lt;/p&gt;

&lt;p&gt;I remind researcher to cite data in their reference lists.&lt;/p&gt;

&lt;p&gt;There is a discussion around whether raw data should be stored, of if
it’s possible to derive the data from code, could that be sufficient,
it seems agreed that this needs to be decided by the community to find
their own norms.&lt;/p&gt;

&lt;p&gt;Roles and responsibilities around costs are one of the main issues that
universities are currently discussing.&lt;/p&gt;

&lt;p&gt;(Today I learnt about the &lt;a href=&quot;http://www.dcc.ac.uk&quot;&gt;Digital Curation Centre&lt;/a&gt; in the UK, I feel
a little bad that I’d not totally been on top of that before).&lt;/p&gt;

&lt;p&gt;There is a discussion on data journals and data articles. (I’m not entirely sure that
this conversation gets us anywhere further than describing the world as we find it).&lt;/p&gt;

&lt;p&gt;There is a discussion around funding, it’s asked whether data management and storage for
research data represents a new market for the private sector. Strong reservations are expressed
by multiple people, and the idea is compared to what has happened with scientific publications.&lt;/p&gt;

&lt;h2 id=&quot;breakout-session-on-incentives&quot;&gt;Breakout session on incentives.&lt;/h2&gt;

&lt;h3 id=&quot;paul-ayris---implementing-the-future-the-leruhttpleruorg-roadmap-for-research-data&quot;&gt;Paul Ayris - Implementing the Future: the &lt;a href=&quot;http://leru.org&quot;&gt;LERU&lt;/a&gt; roadmap for research data.&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;each university needs a research data management plan&lt;/li&gt;
  &lt;li&gt;researchers should have data management plans&lt;/li&gt;
  &lt;li&gt;LERU recognises that data should be open by default&lt;/li&gt;
  &lt;li&gt;rewards and incentives for researchers need further development&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Excitingly the rectors of the universities that comprise the LERU group were
very positive about adopting an open data policy.&lt;/p&gt;

&lt;p&gt;The point in the roadmap about incentives for researchers has the optimistic view
that there will be real economic benefit from opening up data early, and that
will lead to the creation of more resources downstream that researchers can
later benefit from.&lt;/p&gt;

&lt;p&gt;A significant barrier is that data is not part of the way that research evaluation
is done. Everything still hinges on the research article.&lt;/p&gt;

&lt;p&gt;Not all journals require data to be deposited. Researchers are not going to deposit
data out of the goodness of their heart. There are few rewards for data sharing,
even concrete rewards and prizes. No LERU universities have any such prize.&lt;/p&gt;

&lt;p&gt;The recommendations on how to improve the situation include the common themes&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- cite the data
- enforce data policies
- reward data contributions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Currently a good number of institutions have not developed a good research data policy,
or data curation systems or policies.
It’s not that it’s not important, it’s just too early in the process. Institutions are
currently more involved with looking at open access, open data has just not made
to to the top of the pile yet.&lt;/p&gt;

&lt;p&gt;Most are planning to do something, they just haven’t started yet.&lt;/p&gt;

&lt;h3 id=&quot;sunje-dallmeiertiessen---incentives-for-open-science-attribution-recognition-collaboration&quot;&gt; Sünje Dallmeier‐Tiessen - Incentives for Open Science Attribution, Recognition, Collaboration.&lt;/h3&gt;

&lt;p&gt;Questions that come up from researchers&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;How do I find data referenced in this paper.

This dataset is great! Has the author shared more?

Why should I bother to share my data, no one will see it anyway.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sünje is working with &lt;a href=&quot;http://www.datacite.org&quot;&gt;DataCite&lt;/a&gt; and &lt;a href=&quot;http://orcid.org&quot;&gt;ORCID&lt;/a&gt; on &lt;a href=&quot;http://odin-project.eu&quot;&gt;ODIN&lt;/a&gt;, a way
to link data, papers and people. This kind of infrastructure can help answer many of
the questions that people have today about data.&lt;/p&gt;

&lt;p&gt;Again The Data Citation principles are mentioned.&lt;/p&gt;

&lt;p&gt;She gives a great example of how &lt;a href=&quot;http://orcid.org/0000-0002-5769-7094&quot;&gt;Kyle Cranmer&lt;/a&gt; uses his ORCID profile to show how he has contributed
to data creation on the ATLAS experiment.&lt;/p&gt;

&lt;p&gt;(It looks to me that this question of data citation is now well within the realm of having been technically solved, so we need to move
to advocacy, and we need to teach researchers how to do this. The question of “how can I cite data” has a clear answer. Getting people
to find out about the answer is the next challenge).&lt;/p&gt;

&lt;h3 id=&quot;veerle-van-den-eynden-and-libby-bishop---incentives-for-sharing-research-data-evidence-from-an-eu-study&quot;&gt;Veerle Van den Eynden and Libby Bishop - Incentives for sharing research data, evidence from an EU study.&lt;/h3&gt;

&lt;p&gt;They looked at case studies from a number of EU countries across a number of different disciplines. There are a diverse range of methods for data sharing.
The report will be online next week and the interviews will go into their university repository and will also be available (Open Data FTW!!).&lt;/p&gt;

&lt;p&gt;The incentives that these researchers identified were:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- direct benefit
    - collaborations are more robust
    - career visibility
    - get wiser
    - is better for science

- norms
    - default in the research group
    - hierarchical sharing throughout their research career
    - conservative non-sharing cultures represent a challenge
    - openness benefits research, but individual researchers reluctant to take lead

- external drivers
    - funders
    - data support services
    - publishers
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;These external drivers are not the main drivers, but they do help to shift the landscape.&lt;/p&gt;

&lt;p&gt;The big fear remains being scooped. We need to create a level playing field for sharing. Sharing failed experiments were mentioned in biology and chemistry
was mentioned as being very important (but still people do not do this yet).&lt;/p&gt;

&lt;p&gt;Data citation didn’t feel that they had to be able to track reuse of their data, but they were expecting citation for reuse.&lt;/p&gt;

&lt;p&gt;Micro-publishing and micro-citation were mentioned as important, especially in the life sciences. You need to be able to provide atomic level identifiers.&lt;/p&gt;

&lt;p&gt;The report and full recommendations will be available at &lt;a href=&quot;http://knowledge-exchange.info&quot;&gt;http://knowledge-exchange.info&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;open-discussion-after-breakout-session&quot;&gt;Open discussion after breakout session.&lt;/h3&gt;

&lt;p&gt;It’s mentioned that there is an error in equating data publication with formal publication. It should be reported as a separate output. It’s also mentioned
that in the humanities when data is cited the compilers of the data is currently not included in that data citation. (I have to say that I think that the commenters
full comment is not inconsistent with the idea of actually including names in citations, even if they are not being used right now).&lt;/p&gt;

&lt;p&gt;Someone asks for a data repository with an embargo for the period of when a paper is under review. Sünje mentions that &lt;a href=&quot;http://zenodo.org&quot;&gt;Zenodo&lt;/a&gt; can support this.&lt;/p&gt;

&lt;p&gt;There is a very interesting discussion around aggregation of data, vs the original collection of the data. A specific paper is mentioned where there are about
40 authors of an aggregation paper. The data that they aggregated were not in a state to be cited, they are not, at this point in time, citable. It’s put to
one of the commenters that he could make a comment in the article on the journal platform to ask the authors to correctly cite the original data that they aggregated,
and he said that he would be worried of making a comment like that, for fear of a negative impact on his future funding prospects.&lt;/p&gt;

&lt;p&gt;I mention that research assessment needs to improve to seriously look at non-article contributions. I mention that researchers may need to look past the impact factor.
There is an uncomfortable titter of polite laughter at the recommendation in the room, and we pass quickly over the point.&lt;/p&gt;

&lt;p&gt;We do talk about the concrete steps that are out there to reward this kind of behaviour, and there are no institutions that formally recognise and reward these practices.
That’s a bit of a red flag there.&lt;/p&gt;

&lt;p&gt;We ask what is the kind of reward that would make a difference. It’s thought that money would be counter-productive. Research money would be nice. Researchers want
help to do their work. They want good services. If they can find people to work with who are professionals in managing data, that would be helpful.&lt;/p&gt;

&lt;p&gt;Tim Hunt mentions that the ORCID interface is terrible. Work on that would be very valuable. “if you don’t make a good interface, you might as well not get out of bed”.&lt;/p&gt;

&lt;p&gt;We talk about whether software should be usable, would that increase the uptake of good behaviour, but there is no conclusion from the group on this point.&lt;/p&gt;

&lt;p&gt;We come back to to the issue of what kind of a thing the data contribution is. Do we want databases to count as patents or publications? Do we not want them to
count as databases?, actually the point is more about what kind of IP we want for the data, which actually makes a lot of sense as a question. There is a strong
call to make the data open. I have some thoughts on &lt;a href=&quot;http://partiallyattended.com/2008/07/14/patents-and-peer-review/&quot;&gt;the differences between patents and papers&lt;/a&gt;.
This also touches on the question of who is the owner of the data?&lt;/p&gt;

&lt;h2 id=&quot;reporting-session-from-working-groups&quot;&gt;Reporting session from working groups.&lt;/h2&gt;

&lt;h3 id=&quot;data-management-and-sharing&quot;&gt;Data management and sharing.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- Issue: need coordination between different data repositories and related services
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The key message is that a cultural change is needed when it comes to dealing with data.&lt;/p&gt;

&lt;p&gt;Collection of personal data for scientific research is considered legitimate subject to safeguards, under the view of&lt;br /&gt;
EU data and privacy policies. They are moving towards a one stop shop model for these kinds of data use cases.&lt;/p&gt;

&lt;p&gt;It is considered that data protection laws will not require additional resources from institutes (though that’s an opinion
that flies in the face of common sense, so it will be interesting to see if it holds up).&lt;/p&gt;

&lt;h3 id=&quot;storage-curation-and-interoperability&quot;&gt;Storage, curation and interoperability.&lt;/h3&gt;

&lt;p&gt;There was a speaker from &lt;a href=&quot;http://www.dans.knaw.nl&quot;&gt;Data Archiving and Networked Services&lt;/a&gt;.
It was put that it would be good to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- provide certification for digital repositories  
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;A lot of technology is working now for managing data, but people don’t know about it, so we need to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- improve advocacy around existing solutions
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Key points from this discussion were&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- can you trust the data in a repository?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To get to that we need to understand the appropriate level of curation for the data. Metadata is critical. Scientific quality
is the responsibility of both the researcher and the institute.&lt;/p&gt;

&lt;p&gt;On fraud, who is responsible for it. If it’s found, who owns it?&lt;/p&gt;

&lt;p&gt;How do you create a level playing field. It’s mentioned that the UK and the Netherlands are paying for repositories, but
that might lead to less open access, as those bodies may decide at some point to no longer make their institutional repositories
available to people outside of their institution.&lt;/p&gt;

&lt;h3 id=&quot;data-discoverability-access-and-reuse&quot;&gt;Data discoverability access and reuse.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;- deposit you data into existing structured DBs where they are available
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&quot;http://www.elixir-europe.org&quot;&gt;Elixir&lt;/a&gt; is mentioned in this talk.&lt;/p&gt;

&lt;p&gt;There is a new copyright exception in the UK, but this is limited to non-commercial uses. New copyright exceptions are coming online, but they
are not perfectly fit, in their current form, to totally support Big Data reuse.&lt;/p&gt;

&lt;p&gt;There is a comment that the work Elsevier has done on article of the future, with creating in-article visualisations, involved some discussions around whether
these visualisations would be subject to copyright, as they were a derivative work of the original article.&lt;/p&gt;

&lt;p&gt;It was mentioned that we need to keep an eye on the emergence of new data types or new technologies. An eye needs to be
kept on return on investment.&lt;/p&gt;

&lt;p&gt;There is data that shows that an article that has associated data published will get cited more.&lt;/p&gt;

&lt;p&gt;If we want open data, then we should also have open access.&lt;/p&gt;

&lt;p&gt;When it comes to copyright infringement of machine copying, what should count is not that a copy is made, but the intent behind the copying.&lt;/p&gt;

&lt;h3 id=&quot;rewards-and-incentives-for-good-data-management-the-carrot-session&quot;&gt;Rewards and incentives for good data management (the carrot session).&lt;/h3&gt;

&lt;p&gt;I’ve written up this session earlier in this blog post, so I’m going to pass over the summing up of the session.&lt;/p&gt;

&lt;h3 id=&quot;breakout-session---post-summing---discussion&quot;&gt;Breakout session - post summing - discussion.&lt;/h3&gt;

&lt;p&gt;There is a comment that we need to support the skills for interpreting the data in addition to the skills for creating data. Time for a quick coffee.&lt;/p&gt;

&lt;p&gt;That discussion session was fairly low key, I think we have hit maximum overlap on the issues, and we are definitely recycling both issues, and proposed solutions. What
the concluding discussion will bring we will now discover.&lt;/p&gt;

&lt;h3 id=&quot;concluding-discussion-session&quot;&gt;Concluding discussion session.&lt;/h3&gt;

&lt;p&gt;PLOS mention that they are going to automatically start to collect usage of data, and extend their ALM activity towards data use. They have an NSF grant to look at this. I understand that this program is called “making data count”.&lt;/p&gt;

&lt;p&gt;Good data management is good science!&lt;/p&gt;

&lt;p&gt;The carrot is a better approach than the stick. We need to listen to what scientists are telling us about how they see this situation, and we need to be responsive to that.&lt;/p&gt;

&lt;p&gt;When talking about raw costs for infrastructure, the purchasing power of an institution or a funder is much bigger than an individual researcher. This points towards an idea where funders possibly ought to do bulk negotiation, and distribute storage or compute credits to researchers, rather than raw funding. This is the approach the Phil Bourne is discussing with the NIH.&lt;/p&gt;

&lt;p&gt;There is a discussion on costs. Storage is mentioned as being perhaps not a significant factor, compute and electricity are also mentioned. (I’ve done an estimate that by 2050 it will cost 1$ to store an exobyte of data, however the truth here is that costs are highly domain specific, and there is a wide distribution of use cases and levels of expertise amongst researchers, raw storage costs are only one aspect of the issue.) I think that a general discussion on this topic is not as helpful as identifying specific issues, or specific solutions.&lt;/p&gt;

&lt;p&gt;The discussion on enforcement of policy is mentioned. The commission says that they want a bottom up solution, but it is mentioned that a data management plan represents a contractual obligation. (It’s fairly well known that funders are very shy of brandishing sticks, it’s unpopular, it could lead to unintended consequences, but when it comes to altering behaviour through financial incentive it’s hard to see options that could be as powerful as penalties for not sharing data as laid out in data management plans, though given the underlying complexity of different research areas I would not want to be the one to pull that trigger).&lt;/p&gt;

&lt;p&gt;It’s mentioned that making papers, data and software open will give a benefit to industry and innovation.&lt;/p&gt;

&lt;p&gt;We tip toe over to the topic of open peer review. I’ll just tip toe away from this topic right now, as it’s fairly off topic for this workshop.&lt;/p&gt;

&lt;h2 id=&quot;closing-remarks&quot;&gt;Closing remarks&lt;/h2&gt;

&lt;p&gt;This has been a harmonious workshop. There is general agreement that we should have open access to research data, and we have many interested parties. We have a long way to go, we also have agreement that we need to change the culture at every level, and that we are possibly not moving fast enough. Being able to hire and obtain technical support has resonated, and has been mentioned several times (I’ll put in another shout out to &lt;a href=&quot;http://software-carpentry.org&quot;&gt;http://software-carpentry.org&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Where does the data go? Who pays for it? Those are still big questions, and should be developed trans-nationally.&lt;/p&gt;

&lt;p&gt;It’s mentioned that we need to identify specific repositories for specific disciplines, and I would refine that and say that we have very clear locations for specific kinds of data right now, what we need to identify are the fields that are struggling now, and in particular identify fields that are at early risk of walking into a data avalanche where there are no previous good examples of data care in those fields, and who have gotten into this situation due to new tools that have become available to them, for example microscopy.&lt;/p&gt;

&lt;h2 id=&quot;issues-and-questions-that-came-up-today&quot;&gt;Issues and questions that came up today.&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;- how do you deal with large unstructured data sets?
- legal and ethical issues affect the use of such data
- how does the distance to the commercial market affect acceptance of and practices in data sharing
- who sets the metadata structures in different communities?
- can we introduce licences that can be interoperable for data?
- who pays, who is responsible for paying?
- Issue: need coordination between different data repositories and related services
- can you trust the data in a repository?
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;suggested-solutions-to-issues-that-came-up-today&quot;&gt;Suggested solutions to issues that came up today.&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;- give DOIs, or similar, to data
- move towards an internationally level playing field on ethics for research
- create a profession of data curators
- appropriately label datasets to support fine-grained attribution
- develop a culture of acknowledgement
- provide funding for data sharing
- use embargoes as a mechanism to incentivise researcher to make timely use of their own data
- take a percent, say 15%, and set that aside in every grant for data sharing, curation and storage
- update the EU copyright directive
- give a prize for examples of good use of data (it&#39;s mention that there is a data prize in The Netherlands).
- convince people to copy good data management plans (and follow them)
- cite data in reference lists, use the [FORCE 11 data citation principles](https://www.force11.org/datacitation)
- create an open marketplace of good data management plans
- data managmeent plans should be a living document
- include the data scientist at the point of experimental design
	- (I&#39;m remineded of a story from Janelia Farm ...)
- cite the data
- enfore data policies
- reward data contributions
- create an EU-wide directive on data policy for scientific research
- provide certification for digital repositories
- improve advocacy around exising solutions
- Funders shuold mandate open data
- The EU shuoljd take care of infrastrucutre euope-wide to promote a level playhing field.
- create a code of conduct teaching young researchers about the ethical issues around data
- depost you data into existing strucutred DBs where they are available
- do bulk purchasing from providers, and distribute compute and storage credits to researchers
&lt;/code&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>ERC data management workshop, day 1</title>
   <link href="http://partiallyattended.com/2014/09/21/erc-workshop-day1"/>
   <updated>2014-09-21T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/09/21/erc-workshop-day1</id>
   <content type="html">&lt;!-- toc --&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#initial-thoughts-about-the-workshop&quot;&gt;initial thoughts about the workshop.&lt;/a&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#opening-remarks&quot;&gt;Opening remarks.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#setting-the-scene&quot;&gt;Setting the scene.&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#sabrina-leonelli-the-epistemology-of-data-intesive-science&quot;&gt;Sabrina Leonelli - the epistemology of data-intesive science.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#dr-hans-pfeiffenberger-open-science-opportunities-challenges-datasciencefeedhttpstwittercomdatasciencefeed&quot;&gt;Dr Hans Pfeiffenberger - Open Science – opportunities, challenges … [@datasciencefeed](https://twitter.com/DataScienceFeed).&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#bernd-pulverer-finding-and-accessing-the-data-behind-figures&quot;&gt;Bernd Pulverer - finding and accessing the data behind figures.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#dr-roar-skålin-norwegian-researchers-want-to-share-but-are-afraid-of-jeopardising-their-career&quot;&gt;Dr Roar Skålin - Norwegian researchers want to share, but are afraid of jeopardising their career.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#summary-of-points-from-the-scene-setting&quot;&gt;Summary of points from the scene setting.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#afternoon-breakout-session-life-sciences&quot;&gt;Afternoon breakout session - Life Sciences.&lt;/a&gt;
        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#short-comments&quot;&gt;Short comments&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#iris-hovatta-group-leader-department-of-biosciences-university-of-helsinki&quot;&gt;Iris Hovatta, Group Leader, Department of Biosciences, University of Helsinki.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#dr-bouke-de-jong-head-of-unit-mycobacteriology-at-the-institute-oftropical-medicine-antwerp&quot;&gt;Dr Bouke de Jong, Head of Unit Mycobacteriology at the Institute ofTropical Medicine, Antwerp.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#sebastian-luyssaert-user-and-provider-perspectives-on-data-sharing-at-the-interface-between-life-and-earth-sciences&quot;&gt;Sebastian Luyssaert - user and provider perspectives on data sharing at the interface between life and earth sciences.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#discussion&quot;&gt;Discussion&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#summary-of-issues-from-breakout-session&quot;&gt;Summary of issues from breakout session.&lt;/a&gt;&lt;/li&gt;
          &lt;li&gt;&lt;a href=&quot;#summary-of-solutions-from-breakout-sessions&quot;&gt;Summary of solutions from breakout sessions.&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#summary-of-issues-from-the-workshop&quot;&gt;Summary of issues from the workshop.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#summary-of-solutions-proposed-by-the-workshop&quot;&gt;Summary of solutions proposed by the workshop.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#hallway-conversations&quot;&gt;Hallway conversations.&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#bingo-card-terms&quot;&gt;Bingo card terms&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;!-- toc stop --&gt;

&lt;p&gt;These are notes from the first day of the European Research Council Research Data Management &amp;amp; Sharing Workshop. I’ve also &lt;a href=&quot;http://partiallyattended.com/2014/09/21/erc-workshop-day2/&quot;&gt;posted notes from the second day&lt;/a&gt;, and I’ll shortly add another post examining problems and potential solutions raised over the course of the workshop. Jennifer Lin from PLOS has also posted &lt;a href=&quot;https://www.evernote.com/shard/s215/sh/76269856-3b62-4103-81ba-2068dca1b470/9ac27bc2968e5e9ea3e245eb44f9dff2&quot;&gt;some excellent notes&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;These notes are bit jagged, but I thought there was more value in getting them out in a rough form ahead of the RDS meeting that starts tomorrow, rather than waiting to get them into better shape, but missing that event. My apologies up front for errors, and incomplete sentences.&lt;/p&gt;

&lt;h1 id=&quot;initial-thoughts-about-the-workshop&quot;&gt; initial thoughts about the workshop.&lt;/h1&gt;

&lt;p&gt;The opening document, that was distributed a few days before the workshop, highlights the great heterogeneity in how data is used, understood and licensed, across different disciplines. It’s a big old gordian knot. I advocate doing small simple things that move us, step by step, into a better future.&lt;/p&gt;

&lt;p&gt;I will be keeping an ear out for tools that are in use in real workflows, and I’ll be keeping an ear out for any comments that float up during the course of the meeting that resonate for one reason or another. In principle this meeting is about the EU listening to the research community, and other stakeholders, and hearing what it is that we want as an appropriate future for how data should be managed.&lt;/p&gt;

&lt;p&gt;(I’ll see if the docs can be posted somewhere, for the purposes of this blog.)&lt;/p&gt;

&lt;h2 id=&quot;opening-remarks&quot;&gt;Opening remarks.&lt;/h2&gt;

&lt;p&gt;In addition to the normal remakes on heterogeneity, Professor Nicholas Canny made the excellent point that within the EU business model viability is also a real issue within the EU. What works in one country does not always work in another.&lt;/p&gt;

&lt;p&gt;The nub of Prof. Canny’s remarks is that sustainability is the key issue, not only in terms of storage, but also in terms of verification and validation of the data at a later point in time.&lt;/p&gt;

&lt;p&gt;A use case of interest about digital preservation and sharing is the Boston archive of the IRA recollections. This was collected with the promise that no material would be released until later, but then …. &lt;a href=&quot;http://bostoncollegesubpoena.wordpress.com&quot;&gt;they were subpoenaed&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are problems, and this conference is addressing those problems. The hope is that we can provide solutions to those problems.&lt;/p&gt;

&lt;p&gt;The next speaker also focusses on publications, as the main route towards data. It’s mentioned that some disciplines have been very self-organising, however some disciplines are even lacking recognition that there is currently an issue. It would be interesting to me to find out which disciplines are lagging the most.&lt;/p&gt;

&lt;p&gt;Sustainability also touches on the software, so it’s all about wares - hardware for storage, software for interoperability and wetware for expertise.&lt;/p&gt;

&lt;p&gt;We are informed that the agenda is both heavy and efficient. I suppose like an elephant. It’s mentioned again that there is a hope that this workshop will provide solutions. I am doubtful that we will manage that, however  if we can identify some small roadblocks, perhaps that might be sufficient, perhaps that will give us a few points against which we can apply some levers.&lt;/p&gt;

&lt;h2 id=&quot;setting-the-scene&quot;&gt; Setting the scene.&lt;/h2&gt;

&lt;p&gt;(It might be good for me to try to capture specially interesting questions that emerge in these opening sessions, we can then review later and see if there are common themes.)&lt;/p&gt;

&lt;h3 id=&quot;sabrina-leonelli---the-epistemology-of-data-intesive-science&quot;&gt;Sabrina Leonelli - the epistemology of data-intesive science.&lt;/h3&gt;

&lt;p&gt;(who is very very awesomely speaking with her very young baby on her shoulder, which is just awesome).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: how do we make data donation habitual?

Point: manual labour is required, the current credit system does not support that.

Point: formats need to be updated, needs to work in the long-term, needs intelligent curation, structures to support this does not exist.

Q: how might we create structures and systems to support data curation, and intelligent curation.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(on the question of how to update data, &lt;a href=&quot;http://dat-data.com&quot;&gt;dat&lt;/a&gt; is a very nice potential solution, as are &lt;a href=&quot;http://dataprotocols.org/data-packages/&quot;&gt;data packages&lt;/a&gt;, but these are both in an embryonic state. The reason that Dat is appealing is that it matches the model of git, and we know that git is successful, we know that git supports more items of code, in a way that is sustainable, reusable, and shareable, at a scale that currently dwarfs that number of researchers that are curating their own data sets, so if we had a system that could do the same for data that was provably as robust as git, there is an inference that we could make that such a system might be fit for purpose for the scholarly world).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Point: open data has been defined by rich labs, it&#39;s ambiguous, and currently non-inclusive

Q: how can we get to an agreed understanding of what Open Data is, and what currency it has in research communication
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sabrina makes the very interesting point that people are not very clear in their understanding of what is being shared, when they share their data, what do they get back in return. Sharing should be a reciprocal activity and what we do with research data is not a reciprocal activity. She prefers the term dissemination.&lt;/p&gt;

&lt;h3 id=&quot;dr-hans-pfeiffenberger---open-science----opportunities-challenges--datasciencefeedhttpstwittercomdatasciencefeed&quot;&gt;Dr Hans Pfeiffenberger - Open Science – opportunities, challenges … &lt;a href=&quot;https://twitter.com/DataScienceFeed&quot;&gt;@datasciencefeed&lt;/a&gt;.&lt;/h3&gt;

&lt;p&gt;Everyone is afraid of data publishing, but who should be afraid? The people who make data up should be afraid of sharing their data. (the bottom line here is that researchers with shit practices should be afraid of data sharing, the inverse inference is that if you are afraid of sharing your data you might be considered to be a shit research, however that’s a stretch, and I want to be clear that Dr. Pfeiffenberger does not make this inference).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: how might we define data, per discipline

Q: how do you reward data dissemination? how do you provide incentives
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Mentions &lt;a href=&quot;http://www.argo.net&quot;&gt;Argo&lt;/a&gt; as a great example of an open data project. (I’d not seen argo before, it’s amazing). Dr. Pfeiffenberger gives examples of where making the data open had doubled the research output.&lt;br /&gt;
(The royal society report on science as an open enterprise is mentioned again).&lt;/p&gt;

&lt;p&gt;NSF have started to ask for a list of five products from researchers, where the citable product can include a data set, and not only a research paper.&lt;/p&gt;

&lt;p&gt;DFG rules have been amended to say that you can be an author of a paper if you contributed to the creation of some data.&lt;/p&gt;

&lt;p&gt;A recommendation is made to not sign bad contracts. A recommendation is also made to fight against numerical assessment practices (this relates to &lt;a href=&quot;http://www.ascb.org/dora/&quot;&gt;DORA&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&quot;bernd-pulverer---finding-and-accessing-the-data-behind-figures&quot;&gt;Bernd Pulverer - finding and accessing the data behind figures.&lt;/h3&gt;

&lt;p&gt;The data behind figures is critical, it’s currently hard to get to, &lt;a href=&quot;http://emboj.embopress.org&quot;&gt;EMBO&lt;/a&gt; is working on improving this situation.&lt;/p&gt;

&lt;p&gt;Bernd emphasis that not all data is useful. Raw and unstructured data age rapidly.  &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: how do we deal with scooping?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(here are some &lt;a href=&quot;http://www.slideshare.net/DataDryad/pulverer-embo-sourcedatanfdp13&quot;&gt;slides&lt;/a&gt; on the source data project). A key thing they are working on is tagging and identifying information in papers at the figure panel level to identify methods, entities and authors of individual components of a figure. This will allow horizontal navigation based on data rich and resource rich facets.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: how do we deal with data fraud
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Do we open the gates to heaven or to hell?&lt;/p&gt;

&lt;h3 id=&quot;dr-roar-sklin---norwegian-researchers-want-to-share-but-are-afraid-of-jeopardising-their-career&quot;&gt;Dr Roar Skålin - Norwegian researchers want to share, but are afraid of jeopardising their career.&lt;/h3&gt;

&lt;p&gt;They surveyed researchers, and got responses from 1474 researchers, a response rate of just over 30%. This was statistically representative. A large number of researchers actively decided to opt out from the survey.&lt;/p&gt;

&lt;p&gt;40 - 50% of researchers state that data is available, but on request.&lt;/p&gt;

&lt;p&gt;Researchers in this system broadly reflect the concerns that we have seen from other studies, concerns about scooping, about misinterpretation, and the time and effort required to&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: how might we provide a proper citation and reward system

Q: how might we provide more training

Q: how might we provide better infrastructure for data

Q: how is infrastructure organised, nationally, via publishers, via institutions, independent entities

Q: bottom up or top down?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Money is not the number one concern, more concern over infrastructure and training.&lt;/p&gt;

&lt;p&gt;Most researchers are in agreement that data should be provided on publication.&lt;/p&gt;

&lt;h3 id=&quot;summary-of-points-from-the-scene-setting&quot;&gt;Summary of points from the scene setting.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Q: how do we make data donation habitual?

Point: manual labour is required, the current credit system does not support that.

Point: formats need to be updated, needs to work in the long-term, needs intelligent curation, structures to support this does not exist.

Q: how might we create structures and systems to support data curation, and intelligent curation.

Point: open data has been defined by rich labs, it&#39;s ambiguous, and currently non-inclusive

Q: how can we get to an agreed understanding of what Open Data is, and what currency it has in research communication

Point: who pays, what do they pay for?

Q: how might we define data, per discipline

Q: how do you reward data dissemination? how do you provide incentives

Q: how might we define data, per discipline

Q: how do you reward data dissemination? how do you provide incentives

Q: how do we deal with data fraud

Q: how might we provide a proper citation and reward system

Q: how might we provide more training

Q: how might we provide better infrastructure for data
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;afternoon-breakout-session---life-sciences&quot;&gt;Afternoon breakout session - Life Sciences.&lt;/h2&gt;

&lt;h3 id=&quot;short-comments&quot;&gt;Short comments&lt;/h3&gt;

&lt;p&gt;These are going to be quite short, and then we will kick into discussions, so I’m going to aim to only outline these comments.&lt;/p&gt;

&lt;h3 id=&quot;iris-hovatta-group-leader-department-of-biosciences-university-of-helsinki&quot;&gt;Iris Hovatta, Group Leader, Department of Biosciences, University of Helsinki.&lt;/h3&gt;

&lt;p&gt;She studies anxiety, and uses mice to study gene regulatory networks.&lt;/p&gt;

&lt;p&gt;Most of their data is stored in excel files. Standardisation seems to be challenging. Mice in different labs seem to behave differently, even if genetically identical.&lt;/p&gt;

&lt;p&gt;They also product RNA-seq data. This kind of data is well supported, many journals require it’s availability.&lt;/p&gt;

&lt;p&gt;(On the excel data, I wonder whether they have experimented with any plugins, and how did they find them?).&lt;/p&gt;

&lt;p&gt;They want to integrate their behavioural and expression data together. There is a lack of expertise in their lab for database construction. Hiring DBAs on a monthly basis is hard.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Point: hiring domain experts, e.g. DBAs, on a temporary basis is hard

Solution: have a bank of data domain experts ready in the library/institution that can be seconded out or hired on short term contracts by researchers

Q: how do we obtain informed consent?
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;dr-bouke-de-jong-head-of-unit-mycobacteriology-at-the-institute-oftropical-medicine-antwerp&quot;&gt; Dr Bouke de Jong, Head of Unit Mycobacteriology at the Institute ofTropical Medicine, Antwerp.&lt;/h3&gt;

&lt;p&gt;Studying TB, and TB transmission. They look at infection by comparing the genotypes of the bacteria from different patients within a study area. The geneotypic clustering is a proxy for recency of infection.&lt;/p&gt;

&lt;p&gt;Challenges again reside around complex and large data sets, combining demographic and genomic data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: how do we combine heterogeneous data from within one discipline or study
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;They have non-automated data collection issues. Cleaning the data is labor intensive. They are creating dedicated DBs.&lt;/p&gt;

&lt;p&gt;If doing again they would like to enter data in the filed using bar-code methods to avoid double entry.&lt;/p&gt;

&lt;p&gt;They have clustering at multiple levels.&lt;/p&gt;

&lt;p&gt;(publishable unit is mentioned for the first time).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: where do we put our data?

Q: who owns the data/a bacterium?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In routine diagnostics patients have not given explicit consent. You might say that with anonymised data this might be OK, but the question of ownership of the bacteria remains an open question.&lt;/p&gt;

&lt;p&gt;How do you provide service to the community like this (of giving data away) count as a key performance indicator when it comes to evaluation?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q: what&#39;s the incentive?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(Narrative seems to be an issue, if the researcher can construct that narrative within a paper and we can tightly link back to those narratives from the data, would that help?)&lt;/p&gt;

&lt;p&gt;Jo McEntyre asks a question about why not deposit some of this interesting MD with the core “genetic data”.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We have a quick conversation around what we do with “unstructured” data at the point of publication. If we got that working, that might be a route to help with this issue, but it might lead to more noise. This needs to be worked out a bit more.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There is a question about anonymising the data&lt;/p&gt;

&lt;h3 id=&quot;sebastian-luyssaert---user-and-provider-perspectives-on-data-sharing-at-the-interface-between-life-and-earth-sciences&quot;&gt; Sebastian Luyssaert - user and provider perspectives on data sharing at the interface between life and earth sciences.&lt;/h3&gt;

&lt;p&gt;He looks at managing forestry, with a view of looking at how that can affect greenhouse gases and climate change. They have a model with about 500k lines of code. They run this model on a big computational infrastructure.&lt;/p&gt;

&lt;p&gt;One of the data sets that they use is forest inventory data from the EU. There are about 400k data points. This is economic data and is therefore hard to get access to. This data is held at the national level. They need to contact 30 bodies. It is very labor intensive to get this data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Problem: data is useless without the computational infrastructure behind the data

Solution: share data and operational algorithms (data cubes)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;He mentions &lt;a href=&quot;http://fluxnet.ornl.gov&quot;&gt;fluxnet&lt;/a&gt; as an example of a community effort. Data sharing is doing via a fair-use policy, where the data is made available on request, but not all data are shared, so you still need to contact the PI to get the data.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Solution: make data sharing mandatory, like in [ICOS](http://www.icos-infrastructure.eu) &amp;amp; [NEON](http://www.neoninc.org/science/data)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;He mentions that the old-school method has the advantage the it forces conversations between researchers, and collaborations emerge.&lt;/p&gt;

&lt;p&gt;Where data is taken from an environment where there is a lot of competition, it is better for you to share your data, as if you don’t people will work with the others who have similar data that are sharing it. If you have data from a location that is hard to get this data, then it is better to not share your data, as people will contact you anyway, and you will get to be a co-author.&lt;/p&gt;

&lt;p&gt;ESA recently realised that no-one was using their data. The reason is that NASA data was free and ESA data was expensive. ESA data is now free.&lt;/p&gt;

&lt;p&gt;Data is so large that to do data sharing they buy disks and post it around.&lt;/p&gt;

&lt;p&gt;There is no way to talk to people at NASA or ESA about how the data was produced.&lt;/p&gt;

&lt;p&gt;After they improve their models they become more of a software provider than a data provider. At this point he is struggling a lot with conversations in the&lt;/p&gt;

&lt;p&gt;130 person months will end up in one paper, in doing a large extension to the underlying software model. There is no tradition in sharing software, however the only way people will be able to do experiments in the future is that they will be able to use the software that this group created. They want to get credit for this work.&lt;/p&gt;

&lt;p&gt;They are looking to distribute the model with a fair use policy. They have this software under version control, but how does this match up to IP? They are thinking of breaking the model up into components, and each component could come with a list of data and contributors to that component.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Q/Problem how do you give credit for software
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;He is worried that in the next year he is going to have to take up a lot of time in cleaning up his data and code, in order to be in a position of getting his next grant. He is more interested in doing science than spending time on cleaning his data sets.&lt;/p&gt;

&lt;h3 id=&quot;discussion&quot;&gt;Discussion&lt;/h3&gt;

&lt;p&gt;We get into a really good conversation about tools, competency and training, &lt;a href=&quot;http://software-carpentry.org&quot;&gt;Software Carpentry&lt;/a&gt; and &lt;a href=&quot;http://software-carpentry.org/v4/data/&quot;&gt;Data Carpentry&lt;/a&gt; are mentioned.&lt;/p&gt;

&lt;p&gt;We gather a list of potential issues with data in this domain. Someone mentions the issue of access to materials, or even accurate description of materials, such as reagents.&lt;/p&gt;

&lt;p&gt;Data management plans are mentioned as potentially problematic in terms of overhead. The worry is that a data management plan is something people write at the start, but then they ignore them after getting the money. Thinking about them as a step for submitting proposals could be a problem. Leaving them to the level of institutions can be problematic. Could one think of a system where the plan is discussed before and after submission, and the funder plays a role of coordinating data management at a super-institutional level. It’s mentioned that researchers are now being asked to review data management plans, but often don’t feel qualified to make these peer review decisions. It’s mentioned that in the UK the humanities council has a special committee for reviewing technically heavy applications.&lt;/p&gt;

&lt;p&gt;A question is raised about licensing of facts, it’s pointed out that you can’t licence facts.&lt;/p&gt;

&lt;p&gt;All of the UK funders have said that it is acceptable to ask for funding for data provisions, but you can’t ask  for a blank cheque, you have to justify the request in the grant. This automatically interacts with the institutional level, as you will eventually end up interacting with whatever resources are available at your institutions.&lt;/p&gt;

&lt;p&gt;It’s mentioned that it’s a mistake to consider infrastructure as only hardware. It needs to expand it’s definition to include skills.&lt;/p&gt;

&lt;p&gt;The issue of rewards and incentives is mentioned. Bernd mentions that making data available can help with discoverability. Making data required at point of publication is mentioned as a mechanism (but to be honest the researchers do not seem convinced).&lt;/p&gt;

&lt;p&gt;We ask the researchers what incentives they need to see to become more open to the idea of sharing, we get a variety of answers&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- seeing that people who share are more successful
- knowing that a shared body of knowledge can provide more power in terms of making scientific advances (when I can see more data through the act of sharing my data)
- already has benefitted from sharing, got 80% good experience, 20% bad experience, but is mostly concerned that if he has to make all of his data available it will be too much of a burden, will take time away from doing science.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(transmitting data is mentioned again, I wonder about sending computation to the data, rather than the other way around).&lt;/p&gt;

&lt;p&gt;A comment is made that big data sets can be expensive to store, up to 30K for two years of storage. This can freeze out younger researchers. (Jo makes mentions again that we have places to put some data, but our systems do not cover all data types at this point in time).&lt;/p&gt;

&lt;p&gt;We devolve into writing a power point slide via committee.&lt;/p&gt;

&lt;h3 id=&quot;summary-of-issues-from-breakout-session&quot;&gt; Summary of issues from breakout session.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Point: hiring domain experts, e.g. DBAs, on a temporary basis is hard

Q: how do we obtain informed consent?

Q: how do we combine heterogeneous data from within one discipline or study

Q: where do we put our data?

Q: who owns the data/a bacterium?

Problem: data is useless without the computational infrastructure behind the data

Q/Problem how do you give credit for software

Problem: access and description of materials is often poor
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;summary-of-solutions-from-breakout-sessions&quot;&gt;Summary of solutions from breakout sessions.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;Solution: have a bank of data domain experts ready in the library/institution that can be seconded out or hired on short term contrasts by researchers

Solution: share data and operational algorithms (data cubes)

Solution: make data sharing mandatory, like in [ICOS](http://www.icos-infrastructure.eu) &amp;amp; [NEON](http://www.neoninc.org/science/data)

Solution: docker or vagrant
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;summary-of-issues-from-the-workshop&quot;&gt;Summary of issues from the workshop.&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;Point: hiring domain experts, e.g. DBAs, on a temporary basis is hard

Q: how do we make data donation habitual?

Point: manual labour is required, the current credit system does not support that.

Point: formats need to be updated, needs to work in the long-term, needs intelligent curation, structures to support this does not exist.

Q: how might we create structures and systems to support data curation, and intelligent curation.

Point: open data has been defined by rich labs, it&#39;s ambiguous, and currently non-inclusive

Q: how can we get to an agreed understanding of what Open Data is, and what currency it has in research communication

Point: who pays, what do they pay for?
Q: how might we define data, per discipline

Q: how do you reward data dissemination? how do you provide incentives

Q: how might we define data, per discipline

Q: how do you reward data dissemination? how do you provide incentives

Q: how do we deal with data fraud

Q: how might we provide a proper citation and reward system

Q: how might we provide more training

Q: how might we provide better infrastructure for data

Q: how do we combine heterogeneous data from within one discipline or study

Q: where do we put our data?

Q: who owns the data/a bacterium?

Problem: data is useless without the computational infrastructure behind the data
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;summary-of-solutions-proposed-by-the-workshop&quot;&gt;Summary of solutions proposed by the workshop.&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;Solution: have a bank of data domain experts ready in the library/institution that can be seconded out or hired on short term contracts by researchers

Solution: share data and operational algorithms (data cubes)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;hallway-conversations&quot;&gt;Hallway conversations.&lt;/h2&gt;

&lt;p&gt;I chatted briefly with an engineer over coffee. She described some of the data that they deal with when looking at modelling the potential effects of building tunnels under a city, and that effect on the buildings on the ground.&lt;/p&gt;

&lt;h2 id=&quot;bingo-card-terms&quot;&gt;Bingo card terms&lt;/h2&gt;

&lt;p&gt;Lot’s of topics come up again and again, so I’ve quickly created a small set of &lt;a href=&quot;https://www.dropbox.com/s/uf3iv6h13j7s6qh/UOjgo0-print-bingo-com.pdf?dl=0&quot;&gt;data sharing bingo cards&lt;/a&gt;. I’ve used the following terms:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;who pays
    &lt;ul&gt;
      &lt;li&gt;relation to open access ?&lt;/li&gt;
      &lt;li&gt;royal society report&lt;/li&gt;
      &lt;li&gt;privacy concerns&lt;/li&gt;
      &lt;li&gt;the humanities are different&lt;/li&gt;
      &lt;li&gt;data standards&lt;/li&gt;
      &lt;li&gt;embargos&lt;/li&gt;
      &lt;li&gt;how do we cite data&lt;/li&gt;
      &lt;li&gt;data quality&lt;/li&gt;
      &lt;li&gt;big data&lt;/li&gt;
      &lt;li&gt;unreproducable science&lt;/li&gt;
      &lt;li&gt;legal restrictions&lt;/li&gt;
      &lt;li&gt;licensing&lt;/li&gt;
      &lt;li&gt;I’ll get scooped&lt;/li&gt;
      &lt;li&gt;no time to share&lt;/li&gt;
      &lt;li&gt;my data will be misunderstood&lt;/li&gt;
      &lt;li&gt;there is no infrastructure&lt;/li&gt;
      &lt;li&gt;my data is sensitive&lt;/li&gt;
      &lt;li&gt;bottom up&lt;/li&gt;
      &lt;li&gt;top down&lt;/li&gt;
      &lt;li&gt;sustainability&lt;/li&gt;
      &lt;li&gt;PLOS&lt;/li&gt;
      &lt;li&gt;discoverability&lt;/li&gt;
      &lt;li&gt;incentives&lt;/li&gt;
      &lt;li&gt;data citation&lt;/li&gt;
      &lt;li&gt;publishable unit&lt;/li&gt;
      &lt;li&gt;supercomputer  &lt;/li&gt;
      &lt;li&gt;anonymise the data&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>Some pittfalls in using iPython to generate talk slides</title>
   <link href="http://partiallyattended.com/2014/08/11/pitfalls-of-iPython-for-talk-slides"/>
   <updated>2014-08-11T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/08/11/pitfalls-of-iPython-for-talk-slides</id>
   <content type="html">&lt;p&gt;Yesterday I gave a talk using iPython notebook to generate the talk slides. You can get the &lt;a href=&quot;https://github.com/IanMulvany/wikimania-open-scholarship-tools&quot;&gt;notebook on github&lt;/a&gt;, and you can 
see a &lt;a href=&quot;http://www.mulvany.net/presentations/WikimaniaOpenScholarshipTalk.slides.html#/&quot;&gt;live version of the slides&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It succeeded in generating an artefact that was somewhat literate, in that the code and documentation are nicely woven together, 
so anyone who has the time can get to exactly the same point that I got to, with this repo, however there were also
a couple of problems that I ran into that make me feel that this is not yet ready for mainstream use, specifically: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;While I was waiting for my talk to begin I had loaded the slides in Chrome. The chrome window crashed just before I started
the slideshow, and I had to switch over to using Safari, right at the last moment.  &lt;/li&gt;
  &lt;li&gt;I was using the &lt;code&gt;from IPython.display import HTML&lt;/code&gt; function to show screenshots, none of the screenshots showed up during the 
presentation.   &lt;/li&gt;
  &lt;li&gt;I didn’t figure out how to hide cell input on slides where I would have prefered to only show the cell output. I’ve since 
found a &lt;a href=&quot;http://hannes-brt.github.io/blog/2013/08/11/ipython-slideshows-will-change-the-way-you-work/&quot;&gt;post&lt;/a&gt; that describes 
how to do this, but it was too late for me.  &lt;/li&gt;
  &lt;li&gt;I’m used to laying out concepts using shapes in Keynote, there is nothing equivalent to that in this stack.  &lt;/li&gt;
  &lt;li&gt;I failed to correctly convert my slides to PDF. I followed the docs from reveal.js, but it just didn’t work for me.  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This system is probably a step up from using LaTeX to create slides, but I don’t think it’s ready for mass market use yet. I
had more success with this than with running a presenation from evernote, which I tried earlier in the year, but I’m unlikley to 
use this again in the near future. &lt;/p&gt;

&lt;p&gt;I think if you were creating a very code-tutorial driven presentation then this would be a reasonable tool to consider using. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>shortcuts that I use for the git command line</title>
   <link href="http://partiallyattended.com/2014/08/09/git-command-line-shortcuts"/>
   <updated>2014-08-09T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/08/09/git-command-line-shortcuts</id>
   <content type="html">&lt;p&gt;I use git a lot, it’s pretty complicated, and it has a lot of command line optoins that I can never remember. I’ve copied
a couple of shortcuts from the web, and here are two that I use a lot. These are presented in the form of &lt;a href=&quot;http://fishshell.com&quot;&gt;fish shell&lt;/a&gt; scripts.&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;function gl
        git log –graph –abbrev-commit 
        –decorate –date=relative 
        –format=format:’%C(bold blue)%h%C(reset) 
        - %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset)
        %C(dim white)- %an%C(reset)%C(bold yellow)%d%C(reset)’ 
        –all
end&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This provides a nicer view on the git log, with the brancing tree also displayed. &lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;function branches
git for-each-ref –sort=-committerdate refs/heads/
git for-each-ref –sort=-committerdate refs/heads/ 
  –format=’%(refname) %(committerdate) %(authorname)’
  | sed ‘s/refs\/heads\///g’
end&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This shows two lists of current brances in the repo, in reverse chronological order. The first list provides the full sha, 
and the second list shows the last commit message. This is useful when coming back to repo that has a few branches, to help you get an
overview of the activity that’s happened in the different branches. &lt;/p&gt;

&lt;p&gt;I put these examples into a &lt;a href=&quot;https://gist.github.com/IanMulvany/3591216fb05b18f97b98&quot;&gt;gist file&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>looking for ideas for our wikimania talk on open scholarship tools</title>
   <link href="http://partiallyattended.com/2014/07/29/wikimania-openscholarship-preview"/>
   <updated>2014-07-29T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/07/29/wikimania-openscholarship-preview</id>
   <content type="html">&lt;p&gt;Inspired somewhat by the aweome &lt;a href=&quot;http://sciencetoolbox.org&quot;&gt;http://sciencetoolbox.org&lt;/a&gt;, along with Martin Fenner, we proposed a session
for the upcoming Wikimania conference. We will be talking about Open Scholarship Tools on Sunday the 10th of August at 9:30 am. In our &lt;a href=&quot;https://docs.google.com/a/elifesciences.org/document/d/133LXxlgeJfvAtUJCMdGLGKiLIhGhpnNcaJu5UX29fJc&quot;&gt;outline&lt;/a&gt; for our talk we 
have decided to possibly think about:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;CrossRef API (and possibly also the DataCite and ORCID APIs) &lt;/li&gt;
  &lt;li&gt;Pandoc  &lt;/li&gt;
  &lt;li&gt;Rstudio  &lt;/li&gt;
  &lt;li&gt;Zotero  &lt;/li&gt;
  &lt;li&gt;iPython Notebook  &lt;/li&gt;
  &lt;li&gt;Plotly  &lt;/li&gt;
  &lt;li&gt;Datawrapper  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What do you think we should try to cover in our 30 minute slot? &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>FuturePub - future of publishing event, hosted by NESTA and WriteLaTeX</title>
   <link href="http://partiallyattended.com/2014/05/30/future-pub2"/>
   <updated>2014-05-30T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/05/30/future-pub2</id>
   <content type="html">&lt;p&gt;This is the second #futurepub event that I’ve been to. I also attended &lt;a href=&quot;http://partiallyattended.com/2014/01/18/writelatex-overleaf-launch/&quot;&gt;the last one&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;The event was hosted by &lt;a href=&quot;http://www.nesta.org.uk&quot;&gt;Nesta&lt;/a&gt;. Nesta have just launched the &lt;a href=&quot;http://www.nesta.org.uk/project/longitude-prize-2014&quot;&gt;“new longitude” prize&lt;/a&gt; - which looks pretty interesting. There were six rapid fire talks, and I found the presentation format to be excellent. As with the previous event, this one was organised by the &lt;a href=&quot;http://writelatex.com&quot;&gt;WriteLaTeX&lt;/a&gt; guys, and I’d just like to extend a big thanks to them for again putting on a great little event. &lt;/p&gt;

&lt;h1 id=&quot;shane-from-blikbook&quot;&gt;Shane from BlikBook&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://www.blikbook.com&quot;&gt;BlikBook&lt;/a&gt; have a service that helps students and teachers communicate. They aim to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;connect students and courses around the world&lt;/li&gt;
  &lt;li&gt;maximise how knowledge is shared within a classroom&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Data coming out of behaviour is useful. (It looks a bit like a classroom version of a community hub, they also have some anonymous features). This started in London, they took their first round of investment in 2011. They are spread across a number of universities in the UK, with some penetration in the US. (would be interesting to understand how they compete/compare with course.com ??, and how big that opportunity is). 
They have had no abuse of the use of the anonymous tool. It’s been useful where there are large cohorts of foreign students, who have a tendency to be shy in real life situation. Also in situations where there are large variations within the cohorts.&lt;/p&gt;

&lt;h1 id=&quot;jo-mcarthur---open-access-buttonhttpswwwopenaccessbuttonorg&quot;&gt;Jo Mcarthur - &lt;a href=&quot;https://www.openaccessbutton.org&quot;&gt;Open Access Button&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;The bottom line is that this is awesome. They are moving forward with the original idea. They now have about 20 people involved in helping to manage the project. They are working on
	- integration into wikipedia
	- monitoring compliance with OA policy
	- linking published research with research in repositories &lt;/p&gt;

&lt;p&gt;One great idea that was hinted at via the Q&amp;amp;A was that if they see a specific paper being requested by a lot of people, they may try to encourage that author to deposit a version of their manuscript into an institutional repository, and then direct other users of the OA button to that version. &lt;/p&gt;

&lt;h1 id=&quot;lou-woodley---myscicareer-with-eva-amson&quot;&gt;Lou Woodley - MySciCareer (with Eva Amson)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://myscicareer.com&quot;&gt;MySciCareer&lt;/a&gt; is a place where you can get stories about what people have ended up doing, who have come from a scientific background - including stories about people who have continued in the academic track. &lt;/li&gt;
  &lt;li&gt;Scientists become preoccupied by the research cycle&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;reading papers  &lt;/li&gt;
      &lt;li&gt;writing grants  &lt;/li&gt;
      &lt;li&gt;getting data  &lt;/li&gt;
      &lt;li&gt;publishing  &lt;/li&gt;
      &lt;li&gt;communicating  &lt;/li&gt;
      &lt;li&gt;assessing/being assessed  &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;but there is one other big thing that troubles researchers:	 
    &lt;ul&gt;
      &lt;li&gt;carrer decisions&lt;br /&gt;
        &lt;ul&gt;
          &lt;li&gt;0.45% of people who start in research end up as a professor   &lt;/li&gt;
          &lt;li&gt;from NIH less than 8% end up on tenure track   &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;MySciCareer&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;collates stories from across the web about the paths that people have taken in their careers  &lt;/li&gt;
      &lt;li&gt;you can also search the site by last scientific qualification or job type  &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;they would like to:&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;expand the number of contributions on the site (if you have a story, do let them know).  &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;nowomicscomhttpnowomicscom---richard-smith&quot;&gt;&lt;a href=&quot;http://nowomics.com&quot;&gt;nowomics.com&lt;/a&gt; - Richard Smith&lt;/h1&gt;
&lt;p&gt;This allows you to follow the latest data and papers related to genes, and other entities. It’s a bit like “twitter” for genes. &lt;/p&gt;

&lt;p&gt;There are &amp;gt; 1500 biological databases. &lt;/p&gt;

&lt;p&gt;You follow the genes that you work on, or the processes that you are interested in. Does text mining on abstracts from pubmed. Sounds pretty interesting, and a bit of a low hanging fruit. (I later checked out the product, and it looks very nice). &lt;/p&gt;

&lt;p&gt;There are a lot of questions that one could ask of this service. 
	- are the feeds available as RSS&lt;br /&gt;
	- how many users to they have&lt;br /&gt;
	- what’s their traction &amp;amp; growth&lt;br /&gt;
	- how much of pubmed have they&lt;br /&gt;
		- do they have longitudinal information&lt;br /&gt;
	- do they distinguish OS vs non OA&lt;br /&gt;
	- do they look at citation based metrics&lt;br /&gt;
	- what is their DB, what’s their stack&lt;br /&gt;
	- can we feed a full text into this system?&lt;br /&gt;
		- no yet, but sometime in the future?  &lt;/p&gt;

&lt;h1 id=&quot;greg---full-stack-developer-at-sparrhohttpwwwsparrhocom&quot;&gt;Greg - full stack developer at &lt;a href=&quot;http://www.sparrho.com&quot;&gt;sparrho&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Greg gave a nice little talk. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;greg mentions that the lab their CEO Vivian worked in had a personal curator - Steve - who would do a scan the journals that the group was interested in.  &lt;/li&gt;
  &lt;li&gt;sparrho is the attempt to build a digital Steve.  &lt;/li&gt;
  &lt;li&gt;sparrho creates a recommendations engine for people who want to read updated abstracts from the literature.   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They have had researchers who have found those gems they would not have found via their normal search patterns. It looks like a good service, I’v been helping this team a little with advice on product development, and I wish them a lot of luck with what they are doing.  &lt;/p&gt;

&lt;h1 id=&quot;altmetrics---cat---who-is-doing-the-marcomms-for-alt-metrics&quot;&gt;Altmetrics - Cat - who is doing the marcomms for alt-metrics&lt;/h1&gt;

&lt;p&gt;Cat is adamant that they are not saying that a paper is a good paper or a bad paper.  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;300k doughnuts served a day  &lt;/li&gt;
  &lt;li&gt;3M API calls per day  &lt;/li&gt;
  &lt;li&gt;1 mention per second  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Publishers are starting to integrating this data into marketing. Nature are doing a social selection page - online and in print. They are showing trending articles on their site. &lt;/p&gt;

&lt;p&gt;Elsevier have created a virtual special issue around international archeology day.&lt;/p&gt;

&lt;h1 id=&quot;wrap-up&quot;&gt;wrap-up&lt;/h1&gt;
&lt;p&gt;So that was it, there were a few nice conversation after the talks, and it was well worth spending the evening attending. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Designing better UX deliverables - Anna Dahlström</title>
   <link href="http://partiallyattended.com/2014/05/30/designing-better-ux-deliverables"/>
   <updated>2014-05-30T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/05/30/designing-better-ux-deliverables</id>
   <content type="html">&lt;p&gt;This talk happened a few weeks ago now, but the topic is timeless, so there is no harm in getting my notes up a bit late. Anna Dahlstrom(&lt;a href=&quot;https://twitter.com/annadahlstrom&quot;&gt;@annadahlstrom&lt;/a&gt;) came up to Cambridge to give a talk on how to design better UX deliverables, but more broadly the talk had many lessons about how to present results to different stakeholders, not just for UX. &lt;/p&gt;

&lt;h2 id=&quot;a-litte-bit-about-anna&quot;&gt;A litte bit about Anna&lt;/h2&gt;

&lt;p&gt;Anna had gone from only working with HMRC to working agency side - multiple clients, multiple project, different industries. Needed to go from fairly straightforward work, so a lot more creative work, needed to be more strategic, needed to sell her work - both internally and externally. (One of my favourite moments in the talk came up when someone asked her how had she managed to move from HMRC to this agency, when the type and pace of work seemed so different. Anna’s answer was that she just applied for the job. I think there can often be a feeling that we get defined by our roles, rather than by our inherent capacity or potential, and too often there can be a feeling of not having permission to go out and try something because of these boundaries that exist, but my own experience has taught me that its often worth just rolling the dice, if you roll enough times your numbers come up). &lt;/p&gt;

&lt;p&gt;The agency where she moved to was creative and open, with less set templates. The people in the UX team felt more like designers, than IA’s. The team was really talented, and it initially left her feeling that she needed to up her game in some areas.&lt;/p&gt;

&lt;p&gt;She needed to advance her wireframing skills - experimenting with different tools, different ways of calling out components of the wireframe. The strategic documentation came a bit harder. Had to find her own style. &lt;/p&gt;

&lt;p&gt;One thing that really helped is they had weekly one on ones. They would talk through work in these one on ones and the mentor would show their work at the same time. Critiquing in a constructive way really helped Anna find her style. (Is sounded like that atmosphere of positive criticism was a large component is allowing Anna to rapidly improve her skills, and I think it’s a great takeaway for anyone who is in a mentoring role, or is being mentored). &lt;/p&gt;

&lt;p&gt;Being a champion for UX and IA was a part of her role in the team. Collaborative working is not a given everywhere, and you still need to identify how to work with people. &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We always need to sell our work, one way or another. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;the-value-and-role-of-ux&quot;&gt;The value and role of UX&lt;/h2&gt;
&lt;p&gt;UX adds value. When it comes to convincing others of that, it’s not always easy. You need to understand where your peers are coming from, and you need to explain things to them in a way that they can understand. &lt;/p&gt;

&lt;p&gt;She asked a few people in different disciples. what makes for good UX deliverables. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;needs to meet the audience it’s intended for  &lt;/li&gt;
  &lt;li&gt;clearly communicates its purpose, what it is trying to achieve  &lt;/li&gt;
  &lt;li&gt;its not created for the sake of it, it has to add value   &lt;/li&gt;
  &lt;li&gt;should be prototyping on wireframes (less large documentation) – spend time adding value rather than documenting process  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What’s needed depends on where you work. In-house developers needs are different from where the development is out-sourced&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;UX is about delivery, not deliverables. Best ones are the ones that take the least amount of time to produce, that move the project forward the most.  &lt;/li&gt;
  &lt;li&gt;Make them fucking appropriate. The truth is you need to communicate to lots of people at lots of different levels  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Not every client is the same. 
	- … consider the whole customer journey, and looks at the business requirement in the context of the journey&lt;br /&gt;
	- demonstrate enough for the stakeholders to understand the essential details, for developers to be able to build with minimum questions&lt;br /&gt;
	- has a narrative and clearly tells a story&lt;br /&gt;
We wouldn’t have anything without content
	- has a close understanding of our content.  &lt;/p&gt;

&lt;h2 id=&quot;examples&quot;&gt;Examples&lt;/h2&gt;
&lt;p&gt;The examples are great, but I’m not going to summarise them here, however, there is great use of and attention given to layout of information, and judicious use of visual elements. Some tools that she touches on are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;customer experience maps  &lt;/li&gt;
  &lt;li&gt;colour and iconography  &lt;/li&gt;
  &lt;li&gt;Userflows and journeys  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Overall, what is going on here is that colour is being used as an almost abstract form of metadata, it’s being used as an informational extra dimension in the artefacts, and it’s not being used for it’s own sake. It’s used judiciously, so as not to overwhelm itself. (In seeing these examples, thinking back to them I’m struck again at the genius of the tube map). &lt;/p&gt;

&lt;h2 id=&quot;guiding-principles&quot;&gt;guiding principles&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;create something people want to read&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;remove the fluff  &lt;/li&gt;
      &lt;li&gt;pull out the key points  &lt;/li&gt;
      &lt;li&gt;add some of the delight  &lt;/li&gt;
      &lt;li&gt;don’t waste people’s time  &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;ensure the reader knows that they are looking at&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;include page titles, page numbers    &lt;/li&gt;
      &lt;li&gt;use visual cues  &lt;/li&gt;
      &lt;li&gt;pull out or highlight what has changed from the last time  &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;make it easy to follow&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;a read thread is crucial &amp;amp; makes your work engaging &lt;br /&gt;
        &lt;ul&gt;
          &lt;li&gt;the narrative that runs through your work   &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;consistency   &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;mostly it won’t be you presenting your own work  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Narrative is the key thing. It’s only when people tell stories that people feel engaged. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Make things reusable between projects&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;stencils  &lt;/li&gt;
      &lt;li&gt;keep assets organised  &lt;/li&gt;
      &lt;li&gt;spend some time setting up elements properly  &lt;/li&gt;
      &lt;li&gt;use layers and shared canvases  &lt;/li&gt;
      &lt;li&gt;keep your documents organised   &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;adapt to the reader  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;use a mixture or colours white space and fonts&lt;/li&gt;
  &lt;li&gt;Don’t be lazy&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;check spelling  &lt;/li&gt;
      &lt;li&gt;ensure alignment  &lt;/li&gt;
      &lt;li&gt;include spacing  &lt;/li&gt;
      &lt;li&gt;alway proof  &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;don’t be unrealistic with wireframes  &lt;/li&gt;
  &lt;li&gt;don’t spend unneccesary time polishing&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;work with simple tools   &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;min-exercise&quot;&gt;15 min exercise&lt;/h2&gt;
&lt;p&gt;We are given an exercise to design the layouts for a mobile app, and to spend the time thinking about putting into practice some of the tips presented in the talk. What is astonishing about this is that in 15 minutes, when you put things on paper, you can actually get really quite far, when you set aside the and let go of the inner censor, and just allow yourself to get the work out onto paper. I felt that the act of making visual the idea raises questions inherent to the idea, and makes you address problems as the exist, rather than as you think they may exist. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Trial by public, open peer review and the power of attention.</title>
   <link href="http://partiallyattended.com/2014/04/16/a-new-model-of-peer-review-maybe"/>
   <updated>2014-04-16T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/04/16/a-new-model-of-peer-review-maybe</id>
   <content type="html">&lt;p&gt;There are two very interesting recent examples of review by community on highly exciting results. They both share one very important characteristic, but stand in stark contrast to one another in almost every other regard.&lt;/p&gt;

&lt;p&gt;The first is the &lt;a href=&quot;http://dx.doi.org/10.1038/nature12968&quot;&gt;[paper on making STAP cells via use of an acid bath]&lt;/a&gt; lemon juice.  If confirmed, the result is transformative. The result was published after peer review to tremendous fanfare in Nature. Very quickly the community tried to replicate the result with no confirming replication happening. A community effort has spring up to document evidence, and &lt;a href=&quot;http://www.nature.com/news/acid-bath-stem-cell-study-under-investigation-1.14738&quot;&gt;irregularities have been found in the paper&lt;/a&gt;. It’s starting to look like there is going to be a retraction.&lt;/p&gt;

&lt;p&gt;The second recent example was the announcement, ahead of peer review, of the &lt;a href=&quot;http://arxiv.org/abs/1403.3985&quot;&gt;BICEP2 result&lt;/a&gt;. This is the first claimed observation that could provide evidence for a period of cosmological inflation in the early universe. As far as can be stated, if confirmed, a Nobel prize is up for grabs. Big news.&lt;/p&gt;

&lt;p&gt;The BICEP2 group announced their results before their paper was peer reviewed, but the way they have done this looks like it is going to ensure that this paper will be reviewed in the open far more rigorously than via traditional means. At the same time they have gotten both the result and all of the underlying data out much faster than had they waited for formal peer review. They announced their result via press conference, and at the moment of announcement made the paper and underlying data freely available. &lt;/p&gt;

&lt;p&gt;What both of these papers have in common is the ability to attract attention. As a result of this they are both receiving review in an open fashion in full view of the public. The difference however is that one was released before formal review and one after. The one that was released before formal review was done in a way to encourage further examination by the community. They did the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;making the data available at the time of announcement&lt;/li&gt;
  &lt;li&gt;having people online at the moment of the announcement, ready to engage with questions, and in particular on facebook. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The authors of the other paper have been less forthcoming. It might be said that they have hidden behind the reputation of the journal that they published in. &lt;/p&gt;

&lt;p&gt;Does this trial by public represent a new model of peer review? I think it certainly speaks towards how very highly contentious claims may no longer be able to rely on the existing format of peer review for confirmation. News travels instantly, and those who make such claims are well advised to be prepared for attention at scale. However when trying to argue that this will be a new model for peer review, the question of attention is critical. Most claims struggle to get the attention of even three reviewers Simply posting such items on to an archive will not ensure that they will be reviewed by more people than would have reviewed them in the traditional way.&lt;/p&gt;

&lt;p&gt;If you do have a paper that is going to get a lot attention I think it’s also fair to say that you now should be highly confident in your result prior to publication. In the case of the BICEP2 paper I would expect that the preprint went through many rounds of internal review in preparation for this step. It seems that with the other paper even some of the coauthors were not fully up on all of the contents if the paper. &lt;/p&gt;

&lt;p&gt;These two example stand in fascinating contrast to each other, and show how, and how not to, break news of extraordinary importance. What lessons we can take for the reviewing of the bulk of the literature is, in my kind, less clear.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>April digital strategy forum</title>
   <link href="http://partiallyattended.com/2014/04/14/digital-strategy-forum-april-2014"/>
   <updated>2014-04-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/04/14/digital-strategy-forum-april-2014</id>
   <content type="html">&lt;p&gt;On the 1st of April I had the pleasure of being invited to a digital strategy forum event hosted by the Wellcome Trust. People involved in digital and online projects from across a number of not for profit organisations gathered to hear some short talks about using, and contributing to, open source, agile project development and responsive design.  &lt;/p&gt;

&lt;h1 id=&quot;open-source-development&quot;&gt;Open Source development.&lt;/h1&gt;

&lt;h2 id=&quot;open-sourcing-wellcome-library-player--tom-crane-digirati-agency&quot;&gt;Open Sourcing Wellcome Library Player – Tom Crane, Digirati agency&lt;/h2&gt;

&lt;p&gt;The player can be embedded in other sites. They used lot’s of OS technology. It’s extensible. This is a general purpose container for exposing generally digitised objects.&lt;/p&gt;

&lt;p&gt;The player takes JSON from a content store. The project was too complex to just put up on github, as it requires a content repository behind it to make it useful. After launching they were able to see which parts of the player were universal. On day one they didn’t know which parts of the player were Wellcome specific, compared to the general components, so it might not have been possible to think of it as an open source project at the outset. They took a step back, reworked the player, created a core version, and refactored the Wellcome version to be built on top of the core version via extensions.&lt;/p&gt;

&lt;p&gt;They realised that they also needed to have enough documentation to make this useful. Tom wrote the tutorial from the point of view of someone at home with a scanner, could that person use the documentation to create a stack that the player could use to display, that became the benchmark for the documentation.&lt;/p&gt;

&lt;p&gt;They did a dry run of launching a timeline viewer. Within a few weeks they had someone using this piece of code. The &lt;a href=&quot;https://github.com/wellcomelibrary/player&quot;&gt;player is on github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;They feel that questions on usage will depend on things like  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;is it maintained?  &lt;/li&gt;
  &lt;li&gt;is there a community?  &lt;/li&gt;
  &lt;li&gt;is it cool?  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Feels it’s important that you have a bit of wow about the tool. A good example of a tool that doesn’t do this is PUTTY. They spent a bit of time making their site a bit more exiting than that.&lt;/p&gt;

&lt;h2 id=&quot;advantages-of-drupal-as-an-open-source-cms-mosaic-example--alasdaire-cowie-fraser-drupal-developer-ex-code-enigma&quot;&gt;Advantages of Drupal as an Open Source CMS (Mosaic example) – Alasdaire Cowie-Fraser, Drupal developer (ex Code Enigma)&lt;/h2&gt;

&lt;p&gt;This will be about Drupal. There is also some discussion around the MOSAIC content, and that the content is CC-BY. This has been working well for distribution of the content. (there is probably little that I can add on the topic of Drupal that I can add from this session that will be of interest of the eLife team).&lt;/p&gt;

&lt;p&gt;Danil does make the point that one of the big benefits of Drupal is the existence of a community. They had a case a few weeks ago where they were able to get over an issue with the site by starting that conversation within Drupal.org.&lt;/p&gt;

&lt;p&gt;Some questions from me?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;is there a future for content editable in Drupal?&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;that will be coming in in Drupal 8, for Drupal 7 it might be quicker than that.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;what’s the upgrade timeline for Drupal8?&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;next 18 months stick on Drupal 7.&lt;/li&gt;
      &lt;li&gt;caching has been revolutionised in Drupal 7 in the last year&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;how do you manage the maintenance of a system in code only&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;they kept everything in code, the mosaic project is “zero touch”.&lt;/li&gt;
      &lt;li&gt;all changes are introduced through code and CI systems.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;are there any comments on it’s efficiency?&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;it’s heavy, you need to do some work to make it preformant, it’s about the caching strategy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;another question comes up about caching&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;someone from the EBI mentions that when they make changes they take a time to propagate&lt;/li&gt;
      &lt;li&gt;caching strategy is mentioned, you need to have rolling expiration caching&lt;/li&gt;
      &lt;li&gt;caching is a really interesting conversation (I mention the Drupal Cambridge talk from Mick Diplock)&lt;/li&gt;
      &lt;li&gt;there seems to be an agreement that you want to take caching out of the hands of the CMS&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What about Dross in the Drupal Module, how does this team ensure that the modules that they plug in are safe over time?
    &lt;ul&gt;
      &lt;li&gt;Danil ensures this by having an internal team that is competent that is literate in the modules that are being brought into the site.&lt;/li&gt;
      &lt;li&gt;In terms of being safe, Drupal is self policing, there is a security team. (I guess you have to be careful to keep an eye on Drupal security updates).&lt;/li&gt;
      &lt;li&gt;It is something you have to think about when using a module, Al checks the following
        &lt;ul&gt;
          &lt;li&gt;usage of module&lt;/li&gt;
          &lt;li&gt;downloads&lt;/li&gt;
          &lt;li&gt;bug reports&lt;/li&gt;
          &lt;li&gt;check the opinion/reputation of certain developers&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;agile-projects-and-responsive-design&quot;&gt;Agile Projects and Responsive Design:&lt;/h1&gt;

&lt;h2 id=&quot;agile-development-and-project-management-mosaic-example--angie-vanhegan-wellcome-trust-web-team&quot;&gt;Agile development and project management (Mosaic example) – Angie Vanhegan, Wellcome Trust Web Team&lt;/h2&gt;

&lt;p&gt;She has received lots of requests from other parts of the organisation to talk about agile. She is going to talk about some of the things that worked well, that surprised them, some of the areas that they are struggling with, and an example of how agile has helped in the design process.&lt;/p&gt;

&lt;h2 id=&quot;where-it-went-well&quot;&gt;Where it went well.&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;build prototype in agile, but then built the full site in a non-agile way&lt;/li&gt;
  &lt;li&gt;stagger sprints (in a waterfall way)&lt;br /&gt;
 they has some sprints that were focussed on front end, and some on back end.&lt;/li&gt;
  &lt;li&gt;additional bug fixing and UAT at the end&lt;br /&gt;
 they devoted several weeks at the end to deal with bugs. UAT uncovered
 lot’s of bugs. Do make sure you have that extra time.  &lt;/li&gt;
  &lt;li&gt;push for real content early, and leave time to enter it
 this helps discover some of the user needs, you can also uncover issues with the back end tools.  &lt;/li&gt;
  &lt;li&gt;training as doing&lt;br /&gt;
 they did a week, with two day sprints, they did a full agile project within a week (this is a really interesting idea).&lt;/li&gt;
  &lt;li&gt;used a pilot agile project to kick things off
they decided to do only one project, so that they were not over promising.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;things-they-are-still-struggling-with&quot;&gt;Things they are still struggling with&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;getting the product owner more involved in the process&lt;br /&gt;
 a. writing great stories and owning the backlog&lt;br /&gt;
 b. managing stakeholders !!!&lt;br /&gt;
 c. focus on epic stories (and not on details!!!)  &lt;/li&gt;
  &lt;li&gt;Done criteria  &lt;/li&gt;
  &lt;li&gt;release planning and backlog management could be improved, leaving some flexibility, she things they should be using better tools.  &lt;/li&gt;
  &lt;li&gt;Stakeholder feedback at demos&lt;br /&gt;
 started as a congratulatory event, but when you get some critical feedback that can sit badly with the team.&lt;br /&gt;
 person from Natural History museum says that for them they have to be very clear in preparing stakeholders for what they are going to see in the demo. They do not show work in progress. Someone else mentions that they have managed to train their stakeholders. There is also a discussion on who the Product Owner vs the stakeholders are.  &lt;/li&gt;
  &lt;li&gt;achieving more exclusivity for dev team  &lt;/li&gt;
  &lt;li&gt;managing the scrum board  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;self-timing&quot;&gt;self-timing&lt;/h2&gt;
&lt;p&gt;Their story on how to hand hold senior stakeholder through the design process was very interesting. They controlled the discussion space, and broke down the process into actionable steps. The actual process was very labor intensive, but worthwile.  &lt;/p&gt;

&lt;p&gt;The key combination was to make the key stakeholders feel involved, but you control how they are invoked, and to what extent they can influence aspects of the process at given moments in time.  &lt;/p&gt;

&lt;h1 id=&quot;responsive-design--ben-sauer-clearleft-agency---ten-things-about-responsive-design&quot;&gt;Responsive Design – Ben Sauer, Clearleft agency - ten things about responsive design&lt;/h1&gt;

&lt;h2 id=&quot;things-about-responsive-site&quot;&gt;10 things about responsive site&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;ROI  &lt;/li&gt;
  &lt;li&gt;there is no design (singular) it’s not a photoshop flat any more. HTML was never about fixed designs. It’s like we are going back to the fabric of the web  &lt;/li&gt;
  &lt;li&gt;development is design. you developers and your designers need to be sat as close to each other as possible&lt;/li&gt;
  &lt;li&gt;do small screen first, starting big, and getting smaller is really hard
 take all the things on a screen, put them on post-its, and stack em.&lt;/li&gt;
  &lt;li&gt;content, not devices, do not think of break points as device points, think about them in terms of the content.&lt;/li&gt;
  &lt;li&gt;know your patterns
 brad frost’s &lt;a href=&quot;http://patternlab.io&quot;&gt;pattern lab&lt;/a&gt; is the best site for this.&lt;/li&gt;
  &lt;li&gt;architect in parallel - do not do this as a separate exercise&lt;/li&gt;
  &lt;li&gt;design in the browser/decide in the browser  &lt;/li&gt;
  &lt;li&gt;performance is design - provide kilobyte budgets  &lt;/li&gt;
  &lt;li&gt;the mobile trojan horse  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ben-on-stakeholder-management&quot;&gt; ben on stakeholder management&lt;/h2&gt;

&lt;p&gt;What are they accountable for? They are accountable for business objectives. Their job is not tactical stuff, it is not design. Most cannot clearly describe what these are. Make them responsible for business strategy, not design.  &lt;/p&gt;

&lt;p&gt;What is the criteria for success, not what it looks like, but does the site work for people.  &lt;/p&gt;

&lt;p&gt;Reframing what they are responsible for is important, but difficult.  &lt;/p&gt;

&lt;p&gt;Reframing uncertainty. There is uncertainty and risk.  &lt;/p&gt;

&lt;p&gt;Don’t do big show and tells, if you can. Do usability testing in the corridor.  &lt;/p&gt;

&lt;p&gt;Don’t show it all at once. Just black out bits of the design, and get them to focus on the bits that they need to understand.  &lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion.&lt;/h1&gt;

&lt;p&gt;It was a great day. I often had a feeling that I had heard many of these points before, but reflecting back on my notes, it’s great to know that the things that are hard for me in product development are those things that are hard for everyone, and that’s it, that’s the job, you just have to roll up your sleeves and get stuck in. The presenters were all excellent, and a big thank you to Danil and the Wellcome trust for hosting the event.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Php user group March 2013 - BeHat.</title>
   <link href="http://partiallyattended.com/2014/04/08/behat-php-cambridge-meetup"/>
   <updated>2014-04-08T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2014/04/08/behat-php-cambridge-meetup</id>
   <content type="html">&lt;h1 id=&quot;background&quot;&gt;Background.&lt;/h1&gt;

&lt;p&gt;On Monday the 31st of March I attended the &lt;a href=&quot;http://www.meetup.com/phpcambridge/events/168024132/&quot;&gt;Cambridge PHP Meetup&lt;/a&gt;, the topic was BeHat testing. Johnathan Gough gave the talk.  &lt;/p&gt;

&lt;p&gt;This is something we are getting started with in eLife. We have a few small tests in place, we have a few regressions on the site that we want to tackle, and we are looking to use it as a way of pinning down requirements from the company for new features that we want to roll out. After attending this talk I also found this great blog post on why BDD is &lt;a href=&quot;https://cucumber.pro/blog/2014/03/03/the-worlds-most-misunderstood-collaboration-tool.html&quot;&gt;the world’s most misunderstood collabroation tool&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;notes&quot;&gt;NOTES:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;lots of reasons to test&lt;/li&gt;
  &lt;li&gt;some reasons not to&lt;/li&gt;
  &lt;li&gt;it’s suggested that TDD can be quite brittle&lt;/li&gt;
  &lt;li&gt;BDD via BeHat is introduced as outside-in testing, a user story is introduced&lt;/li&gt;
  &lt;li&gt;one should use behat with composer  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An interesting thing is that behat will create a /bin directory in the project directory. (I wonder whether that is something that can be set to system level, probably. (I would image that would be much nicer)).  &lt;/p&gt;

&lt;p&gt;behat creates a &lt;code&gt;/features&lt;/code&gt; directory.  &lt;/p&gt;

&lt;p&gt;Behat lives in a universe of other tools, it sits on top of &lt;code&gt;Behat Context&lt;/code&gt; and &lt;code&gt;Mink Context&lt;/code&gt;. The &lt;code&gt;Behat Context&lt;/code&gt; is a vanilla file in which you write your own context for how behat should interpret the tests. &lt;code&gt;Mink&lt;/code&gt; provides web browser functionality. It can sit on top of  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;seleneum  &lt;/li&gt;
  &lt;li&gt;goutte&lt;/li&gt;
  &lt;li&gt;zombie  &lt;/li&gt;
  &lt;li&gt;sahi   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you are using a framework, you can fire up the framework, inject the request, and get the response out, and this kind of customisation is available to people writing their own contexts. An open question is whether one can mock up Drupal requests to insert into the manual contextual scripts. &lt;/p&gt;

&lt;p&gt;Mink exposes descriptive commands that you can use to describe how your web application should work.  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Selenium: popular, multi-browser, js, slow  &lt;/li&gt;
  &lt;li&gt;goutte: défaut, native PHP, fast, no javascript  &lt;/li&gt;
  &lt;li&gt;sahi: multi-browser, js, slow, easier setup than selenium - maybe?  &lt;/li&gt;
  &lt;li&gt;zombie: headless browser in js written in node.js   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can specify at the level of an individual tests or scenarios as to which context that scenario should use (that sounds potentially really useful).   &lt;/p&gt;

&lt;p&gt;Bottom line, Behat makes testing a lot easier, makes testing fun, and can be quite revolutionary. &lt;/p&gt;

&lt;p&gt;Questions:&lt;br /&gt;
- how compliant is this user story language to the python/ruby equivalents - lettuce/cucumber
    the answer is they all use the same language - gherkin, so tests are cross system writable. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;can one get to a level of creating these kinds of stories for extremely fine grained visual elements?&lt;br /&gt;
  the answer to this is how do you get the balance between brittle tests, and tests that are too loose to
  be of use. If can do this, it might not be the best idea to do this.   &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Climbing goals update 1, 2014</title>
   <link href="http://partiallyattended.com/2014/03/30/q1-climbing-goals-update"/>
   <updated>2014-03-30T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2014/03/30/q1-climbing-goals-update</id>
   <content type="html">&lt;p&gt;I wrote a large post at the start of this year reviewing my &lt;a href=&quot;http://partiallyattended.com/2014/01/18/climbing-review-2013-goals-2014/&quot;&gt;climbing goals over previous years&lt;/a&gt;, and 
laying out my goals for 2014. A key modification for me in 2014 is changing to a strategy where I set goals quarterly, rather than yearly. Let’s review Q1. &lt;/p&gt;

&lt;h2 id=&quot;goals-for-q1-2014&quot;&gt;Goals for q1 2014&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;try at least 12 routes of 6c or harder&lt;br /&gt;
  I managed to try exactly 12 routes of 6c in the last 12 weeks, and my last try yielded success. The last time I had led a route of 6c was in Jan 2013. I made it to the climbing wall 10 times, though didn’t manage to do routes on each occasion, due to partner availability. I tried 29 lead routes over that time. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;at least one fingerboard session per week&lt;br /&gt;
  I managed 16 fingerboard sessions, and across those did 23 “5 min burn” sets, where I roped up, popped my feed on a chair, and hung from the board for five minutes, while placing gear, clipping, unclipping, removing gear, to give a deep endurance set. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;get to the shoreditch boulder at least 4 times&lt;br /&gt;
 I visited the shoreditch boulder for the fourth time this morning, and had a good session, getting in 2 V3’s, and making progress on one of the V4’s that I can’t do. In addition. I also managed to get the [inner city riots][http://www.ukclimbing.com/logbook/c.php?i=126436] problem, a boulder problem that I’d had as a goal for last year, and only just missed out on towards the end of last year. On the day I did it twice to make sure that it wasn’t a fluke. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, pretty good progress, I’m pretty happy. It’s time to set goals for the next 12 weeks. Everything I’m building towards is to get a 7a in calendar year 2014. I’m going to divide up the next 12 weeks into three phases - 6, 4 and 2 week phases. In the 6 week phase I’m going to drop the route level, and increase volume. In the second phase I’m going to get back to bouldering and finger boarding for pure power - and bump back to 6c, and in the last phase I’m going to start aiming at 7a. &lt;/p&gt;

&lt;p&gt;For the first phase I’m going to set the following goals:&lt;br /&gt;
- try 10 routes per wall session, with routes done back to back 2x6a, 2x6a+, 6x6b. 
- try one wall session per week. 
- fingerboard once per week, again doing 5min burns. &lt;/p&gt;

&lt;p&gt;For phase 2 I’m going to:&lt;br /&gt;
- try 2 6c routes per week.&lt;br /&gt;
- switch to bouldering for power, and return to my bouldering notebook, and get to match all high points that are therein noted for the fingerboard.  &lt;/p&gt;

&lt;p&gt;For phase 3 I’m going to:&lt;br /&gt;
- try 6 7a routes in that two week window. &lt;/p&gt;

&lt;p&gt;I’ve noticed in the last 12 weeks that circumstance often gets interestingly entangled with training plans, small colds, busy periods at work, climbing partners not making it to the wall, so I’ll actually do a mini review in 4 weeks to see if the high volume I’ve set as a goal in the first phase is realistic. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Discussing Open Access - a comment</title>
   <link href="http://partiallyattended.com/2014/03/23/discussing-oa-comment"/>
   <updated>2014-03-23T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2014/03/23/discussing-oa-comment</id>
   <content type="html">&lt;p&gt;Discussing Open Access
http://discussingoa.wordpress.com/&lt;/p&gt;

&lt;p&gt;I read through this piece by Rick Anderson. It’s a very good piece. It does an excellent job of articulating some of the challenges of subscription publishing and of various forms of open access publishing. &lt;/p&gt;

&lt;p&gt;I have a couple of relativly minor issues with it. &lt;/p&gt;

&lt;p&gt;The impression I got from reading it was that OA advocates are more shouty and incapable of a serious debate on the issue than advocates of a subscription model, and possibly those who pursue subscription models are more open minded. I don’t buy that. I agree that the behaviours that Rick points out do need to be raised, but I don’t think there is a strong balance of rationality in one side of the argument over the other. I admit I could be wrong. &lt;/p&gt;

&lt;p&gt;When I analyse how I come to feel this way I end up drawing from the following: &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;subscription based publishers have attempted to introduce legislation restricting OA models. That speaks to an aggressive intent on that side of the argument. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Kent Anderson seems to be a troll, and by extension lends a trollish tone to the scholarly kitchen. One can argue whether he is a troll or not, and one can argue whether his arguments stand up or not, but the claim I make here is that his tone of writing will appear trollish to an unbiased reader. It ought be noted that I am am a biased reader - most of the products I have worked on in my career have received negative reviews on the scholarly kitchen, but to support this claim I point to the interaction between Kent Anderson and the editorial community of Wikipedia, in which it seems to me that Kent’s tone led to more heat than light in the discussion. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So to summarise, Rick’s article is great, we should have more balanced conversations, but I don’t think that one side has a monopoly on ideology. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>How to create threads between publications and clinical trial registraion numbers</title>
   <link href="http://partiallyattended.com/2014/01/31/threaded-publications-discussion"/>
   <updated>2014-01-31T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2014/01/31/threaded-publications-discussion</id>
   <content type="html">&lt;p&gt;Yesterday I attended an interesting meeting to discuss how to improve the connection between clinical trial registration ids and publications. My raw notes from the meeting follow. This is being discussed as publication threads, but the idea discussed here stands apart from the kind of publication threads that the endcode project worked on. &lt;/p&gt;

&lt;h1 id=&quot;attendees&quot;&gt;attendees&lt;/h1&gt;
&lt;p&gt;## ATTENDEES - organisations:
eLife
f1000
PLOS
BMC
Springer
lancet
BMJ
crossref &lt;/p&gt;

&lt;h2 id=&quot;attendees---people&quot;&gt;attendees - people&lt;/h2&gt;
&lt;p&gt;Geoffrey Bilder, CrossRef, Director of Strategic Initiatives Rachael Lammey, CrossRef, Product Manager CrossMark Daniel Shanahan, BioMed Central, Associate Publisher Tim Stevenson, BioMed Central, Product Manager
Deborah Kahn, BioMed Central, EVP Publishing Caroline Black, BioMed Central, Senior Publisher Katherine Barton, BMJ, Operations Manager Josie Breen, BMJ, Head of Editorial Production Isaac Jones, BMJ, Production Manager
Ian Mulvany, eLife, Head of Technology
Iain Hrynaszkiewicz, F1000, Outreach Director
Karen Rowlett, F1000Research, Managing Editor
Helene Faure, ISRCTN Database Manager
Hannah Jones, The Lancet, Managing Editor
Dan Lewsley, The Lancet, Head of Production
Joseph Brown, PLoS, Senior Editorial Manager
Volker Boeing, Springer, Director, Process and Content Management Mirjam Kessler, Springer, Bibliographic Metadata Manager&lt;/p&gt;

&lt;h2 id=&quot;background-and-status&quot;&gt;Background and status&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;this is a followup for the idea that was originally &lt;a href=&quot;http://blogs.biomedcentral.com/bmcblog/2011/01/14/towards-threaded-publications-helping-to-set-the-scientific-record-straight/&quot;&gt;blogged by iainh in 2011&lt;/a&gt;. &lt;/li&gt;
  &lt;li&gt;the initiative stalled in 2013&lt;/li&gt;
  &lt;li&gt;about 30k trials are registered per year&lt;/li&gt;
  &lt;li&gt;for trials that are registered, there is nothing to link all of this together &lt;/li&gt;
  &lt;li&gt;currently we have 1 way links from the trial to the publications&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The vision is for every publication to forward and backward link to every other publication, but this is not practical. This is where crossmark comes in. The idea would be to implement a hub and spoke model, and get everyone to wire things together in crossmark. (My take from the technical side was that the trial registration id will be the parent in all of the relationships, but this needs a bit more fleshing out).&lt;/p&gt;

&lt;h2 id=&quot;crossmark-notes&quot;&gt;Crossmark notes&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;lots of uptake. &lt;/li&gt;
  &lt;li&gt;over 1M assertions so far. 
### Fundref&lt;/li&gt;
  &lt;li&gt;the key thing here is that it’s a typed namespace that sits under the crossmark metadata container. They call this a “program” within crossmark. 
### Threaded publications proposal&lt;/li&gt;
  &lt;li&gt;they would like to mock the fundref approach for publication threads, and this meeting is to promote this idea, and to move towards an agreement for the namespace. &lt;/li&gt;
  &lt;li&gt;Geoff does the “can you identify” the blacked out paper. 
### Threaded publications model&lt;/li&gt;
  &lt;li&gt;mentions that delays were related to missing infrastructure and competing with priorities&lt;/li&gt;
  &lt;li&gt;feels that they have launched another project that can act as a good model for threaded publications&lt;/li&gt;
  &lt;li&gt;this model is fundref 
#### Fundref&lt;/li&gt;
  &lt;li&gt;was done quickly
    &lt;ul&gt;
      &lt;li&gt;they tried to do the simplest thing that could possibly work&lt;/li&gt;
      &lt;li&gt;they put together a quick governance group from funders and publishers&lt;/li&gt;
      &lt;li&gt;knew that they didn’t want to overcomplicate things &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;they did a couple of things
    &lt;ul&gt;
      &lt;li&gt;they standardised on a vocabulary released under CC0&lt;/li&gt;
      &lt;li&gt;have an update mechanism&lt;/li&gt;
      &lt;li&gt;provided an example widget for filling out the info
        &lt;ul&gt;
          &lt;li&gt;main thing was this is an example for implementation purposes &lt;a href=&quot;labs.corssref.org/fundref/widget&quot;&gt;labs.corssref.org/fundref/widget&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;the data collected is also released under a CC0 licence 
##### Proposal&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;create a working group&lt;/li&gt;
  &lt;li&gt;create a registry of registries
    &lt;ul&gt;
      &lt;li&gt;assign registry ids to the registries that we are interested in interoperating with&lt;/li&gt;
      &lt;li&gt;registration template for URLs to get to the registration (might need a resolution service?)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;how do we collect it? would like to put up a similar widget to the fundref one, and get this implemented in the submission systems &lt;/li&gt;
  &lt;li&gt;this all then gets passed into crossref in the same way that fundref information gets in. &lt;/li&gt;
  &lt;li&gt;then using the crossref API you can answer the following question
    &lt;ul&gt;
      &lt;li&gt;“show me all the articles that refer to the same clinical trial numbers mentioned in this document”&lt;/li&gt;
      &lt;li&gt;could be extended to also include the following query &lt;/li&gt;
      &lt;li&gt;AND “the publisher of that article is in a list of trusted participants”&lt;/li&gt;
      &lt;li&gt;BOOM! done, thank you! 
##### Issues&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;how do you find out if something has been updated?
    &lt;ul&gt;
      &lt;li&gt;the “do you know what this is” game does not work with how we signify that there is an update to an article &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;open-discussion&quot;&gt;open discussion&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;the proposal is to only include the trial ID&lt;/li&gt;
  &lt;li&gt;original proposal from ian H proposed in addition
    &lt;ul&gt;
      &lt;li&gt;article type&lt;/li&gt;
      &lt;li&gt;publication date&lt;/li&gt;
      &lt;li&gt;some other attributes …
### Issues&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;no article ontology&lt;/li&gt;
  &lt;li&gt;systematic reviews could explode the threads&lt;/li&gt;
  &lt;li&gt;many papers may not cite the trial &lt;/li&gt;
  &lt;li&gt;how do you identify the trial ID in the content?
    &lt;ul&gt;
      &lt;li&gt;some publishers have collected this from some point in time, however not all publishers will have this data retroactively. &lt;/li&gt;
      &lt;li&gt;BMC tags this in their XML, and example can be seen here: &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;how journals publish the id and name is not at all standardised 
    &lt;ul&gt;
      &lt;li&gt;checking that the trial id is valid &lt;/li&gt;
      &lt;li&gt;that the registration is valid
        &lt;ul&gt;
          &lt;li&gt;Geoff mentions that they had exactly the same issues at the start of fundref&lt;/li&gt;
          &lt;li&gt;mentions that we might be able to identify the “shape of an id”&lt;/li&gt;
          &lt;li&gt;issue is raised that journals might just screw this up&lt;/li&gt;
          &lt;li&gt;AIP did a survey and ran fundref to see how often people got things wrong &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;discussions&quot;&gt;Discussions&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;there is no standard article type ontology across publishers
    &lt;ul&gt;
      &lt;li&gt;Geoff mentions that his take is that the thing we are trying to capture is the relationship between the article and the protocol. &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;the issue of systematic reviews is that they are important, can we afford not to include them
    &lt;ul&gt;
      &lt;li&gt;perhaps get the author to fill in the widget, ask them to be thoughtful in terms of which trials they link to. &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data is mentioned as being important&lt;/li&gt;
  &lt;li&gt;tracking provenance of claims is mentioned as an issue
    &lt;ul&gt;
      &lt;li&gt;how do we allow other people to make assertions about DOIs after the fact, this leads to issues of provenance, and is related to trust&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;if we only go forward from this date, it will be years before we have any useful data, if we can go backwards as well as forwards (make assertions on existing entities), it would help	
    &lt;ul&gt;
      &lt;li&gt;publishers could try and get their authors to go back and post-annotate their own publications - perhaps via ORCID&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;funders should be involved
    &lt;ul&gt;
      &lt;li&gt;wellcome should be involved&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Geoff mentions that more requirements on the initiative will increase the chances the initiative would fail
    &lt;ul&gt;
      &lt;li&gt;Iain H mentions that there is probably an editorial issue of what our tolerance to the data quality is. Are editors happy with the quality of the result? 
        &lt;ul&gt;
          &lt;li&gt;is that an important enough of an issue to stop a pilot?&lt;/li&gt;
          &lt;li&gt;thinks that a pilot is a great way to have that conversation, if people know we are tracking this data, then people will start playing attention to the data more quickly&lt;/li&gt;
          &lt;li&gt;might help sort out the predatory publishers 
            &lt;ul&gt;
              &lt;li&gt;mentioned that that might not be the case, we should worry about this, but on the other hand, the more contribuions you get from researchers, the easier it is to self regulate &lt;/li&gt;
              &lt;li&gt;will get sock puppet problems, but these problems are there anyway, this initative won’t be a cause of that issue&lt;/li&gt;
              &lt;li&gt;clearly there are people out there who are trying to game the system, best thing you can do is provide as much evidence as you can&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;would there be a role for an admin and curation role
        &lt;ul&gt;
          &lt;li&gt;these are the kinds of things that fundref are discussing&lt;/li&gt;
          &lt;li&gt;in any of these cases you need to know who is making the assertion &lt;/li&gt;
          &lt;li&gt;at the moment in the crossref system everything is being asserted by the publisher &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;interesting question, how is this better than just scraping pubmed?
    &lt;ul&gt;
      &lt;li&gt;would capture more articles that are connected to clinical ids, where at the moment those connections are not tagged&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Geoff mentions that there are many situations where the best answer is to force people to cite this information, but his instinct is that they don’t want to overload that section, there won’t be a way to enforce consistency. (we all know that won’t work :P)&lt;/li&gt;
  &lt;li&gt;do we include article type? &lt;/li&gt;
  &lt;li&gt;do we need any other metadata? can anyone think of any other kind of metadata &lt;/li&gt;
  &lt;li&gt;how do we identify the trial id in the content? &lt;/li&gt;
  &lt;li&gt;how feasible is this for production/operations to manage?
    &lt;ul&gt;
      &lt;li&gt;really needs to happen at submission, and automate everything downstream from there&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;is there any additional cost on top of crossref?
    &lt;ul&gt;
      &lt;li&gt;NO (at this point)
        &lt;ul&gt;
          &lt;li&gt;if however the steering group complicated the spec, the cost might need to be recouped, basically easier is cheaper &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;trials can be registered in many different places, often because trials can happen in different countries, each requiring registration
    &lt;ul&gt;
      &lt;li&gt;could the system under discussion be used to connect one trial to another trial&lt;/li&gt;
      &lt;li&gt;how do you then traverse this graph&lt;/li&gt;
      &lt;li&gt;could this be done in a self-policing kind of a way?&lt;/li&gt;
      &lt;li&gt;how do you distinguish between multiple ids for the same trial and trials related to a clinical review
        &lt;ul&gt;
          &lt;li&gt;the parent is always the clinical trial, under one trial a clinical review will only be listed once&lt;/li&gt;
          &lt;li&gt;if you want to traverse to publications that are tied a trial via another name for that trial, under the parent trial you would want to have the other trial listed as a child, and you could then traverse to the children of that node.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Do we need to worry about article types now?
    &lt;ul&gt;
      &lt;li&gt;Geoff says that we should come up with a proposed name for the relationships and if the debate goes on too long, then pass on and not worry about it.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;round-table-wrap-up&quot;&gt;round table wrap up&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;good idea &lt;/li&gt;
  &lt;li&gt;registration of trials is a worry &lt;/li&gt;
  &lt;li&gt;could become self policing&lt;/li&gt;
  &lt;li&gt;doubts we could get back data
    &lt;ul&gt;
      &lt;li&gt;everything needs critical mass&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;prospect and licensing information is mentioned
    &lt;ul&gt;
      &lt;li&gt;Geoff mentions that this is all confused a bit&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;great project, need to talk to editors&lt;/li&gt;
  &lt;li&gt;if you have a field in your submissions system then you want to make this as a condition of acceptance&lt;/li&gt;
  &lt;li&gt;can we say that back-files are optional?
    &lt;ul&gt;
      &lt;li&gt;yes, we have to say that this is optional&lt;/li&gt;
      &lt;li&gt;we would also say that back-files are not out of bounds&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;from the perspective of a registrar, there is a benefit
    &lt;ul&gt;
      &lt;li&gt;more often than not a trial, when quoted, it’s correct&lt;/li&gt;
      &lt;li&gt;the key issue is that not all papers about trials quote the trial&lt;/li&gt;
      &lt;li&gt;registers can find related papers via keyword search &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;thinks its worth doing from the point of the enduser
    &lt;ul&gt;
      &lt;li&gt;what’s the data policy? who owns the data? what’s the licence of the data?, crossref make no claims on the data, there are batch delivery methods, and there are charges for this delivery, with opt outs. &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;another element of this is that sometimes papers are recommended in F1000, and they will check if they include trial IDs there&lt;/li&gt;
  &lt;li&gt;what next? is this system, or a version of this, a model for any funded piece of research that creates multiple outputs?
    &lt;ul&gt;
      &lt;li&gt;it has to be something that links them there has to be a starting point&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;f1000 research also thinks it’s a great idea, they have a posters type that might also be something that could be included. Is slightly worried about letting authors put the info in. Would be great to have a check to see if the registration is a valid registration. 
    &lt;ul&gt;
      &lt;li&gt;anything we can do to help them not put in typos is a good idea, enforcing honesty is a much harder issue&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;voice of the researcher would be nice to have in the room&lt;/li&gt;
  &lt;li&gt;BMC thinks its a strong idea, they think it’s overdue, it’s based on clinical trial registration, and we are not doing anything with this data at present. We are not currently exposing benefits of getting links between trials and publications. We need to possibly start simple, be aware that we might encounter some issues, but we need to move forward. &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;actions&quot;&gt;Actions&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;- propose a namespace for relationships to be modelled  
- create an interest group now, that could potentially move towards being a crossref working group
	- get a funder involved  
	- get someone from the registry community  
	- get a chair who is not from crossref @done 
		- chair will come from BMC @done 
	- have a product manager who helps coordinate the meeting  
	- we can call the meeting today - meeting 0  
	- arrange the next meeting   
&lt;/code&gt;&lt;/pre&gt;

</content>
 </entry>
 
 <entry>
   <title>WriteLateX/Overleaf launch event at the British Library</title>
   <link href="http://partiallyattended.com/2014/01/18/writelatex-overleaf-launch"/>
   <updated>2014-01-18T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2014/01/18/writelatex-overleaf-launch</id>
   <content type="html">&lt;p&gt;Last Thursday I attended the launch event for &lt;a href=&quot;https://www.writelatex.com/overleaf&quot;&gt;OverLeaf&lt;/a&gt;. The event was composed of a set of very short talks, followed by a good chance to chat to people. It was a pretty nice evening. &lt;/p&gt;

&lt;h1 id=&quot;dr-bibiana-campos-seijo---mrsc---magazines-publisher-and-editor-of-chemistry-world&quot;&gt;Dr Bibiana Campos Seijo - MRSC - magazines publisher and editor of chemistry world.&lt;/h1&gt;

&lt;p&gt;Science is changing, publising is changing, a lot of this is being driven by technology. There is information overlaod. Publishers need to try to provide solutions to these issues. &lt;/p&gt;

&lt;h2 id=&quot;what-was-interesting-in-2013&quot;&gt;What was interesting in 2013:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;OA mandate  &lt;/li&gt;
  &lt;li&gt;Predetary OA journals  &lt;/li&gt;
  &lt;li&gt;Luxury journals - (Go Randy!!!)&lt;/li&gt;
  &lt;li&gt;Takedown notices from Elsevier  &lt;/li&gt;
  &lt;li&gt;Peer reiew developments  &lt;/li&gt;
  &lt;li&gt;Data management storage and sharing &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(I think that’s a pretty good overview, I also think that the rise of tablets is the main broad technology trend. Another big story that might change how we think about interacting online are the NSA stories, but it’s not clear how that will break down in scientific publihsing. I also think that the increased focus on reproducability is of interest).&lt;/p&gt;

&lt;h2 id=&quot;new-publishing-models&quot;&gt;New publishing models&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;PeerJ  &lt;/li&gt;
  &lt;li&gt;Rubriq  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It’s noticed that chemists are a bit more conservative.  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Figshare institutional data platform is mentioned.  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The finishing line is in sight for libel reform (this is a great move). Is mentioned that this is indirectly related to publishing, but core to freedom of expression. &lt;/p&gt;

&lt;p&gt;The example of &lt;a href=&quot;http://retractionwatch.com/2013/08/08/insert-data-here-did-researcher-instruct-co-author-to-make-up-results-for-chemistry-paper/&quot;&gt;“Emma, please insert NMR data here!”&lt;/a&gt; was mentioned. It was noticed by bloggers, and they are now playing a role in what is happening &lt;a href=&quot;http://www.hyperorg.com/blogger/2014/01/08/what-blogging-was/&quot;&gt;see comments on blogging by David Weinberger&lt;/a&gt;, one of his quotes from this article is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;We have changed where we turn for analysis, if not for news. We expect the Web to be easy to post to. We expect conversation. We are more comfortable with informal, personal writing. We get more pissed off when people write in corporate or safely political voices. We want everyone to be human and to be willing to talk with us in public.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;whats-in-sotre-for-2014&quot;&gt;What’s in sotre for 2014?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;OA, more and more OA&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;linus-schumacher---a-scientist---wolfson-centre-for-mathematical-biology-university-of-oxford-wcmbloghttpstwittercomwcmblog&quot;&gt;Linus Schumacher - a scientist - Wolfson Centre for Mathematical Biology, University of Oxford &lt;a href=&quot;https://twitter.com/WCMBlog&quot;&gt;@WCMBlog&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;Language. Differences in understanding of jargon can hinder progress. He thinkgs more and more scientists in the future could act as connectors - jack of all trades, masters of none - but critical to the success of progress of science. They will translate across disciplines.&lt;/p&gt;

&lt;p&gt;Meeting in person is still more critical and productive that vitual meeting.&lt;/p&gt;

&lt;p&gt;In terms of sharing artefacts, and raw data, this can take a lot of space. Cloud based storage often does not cut it any more. BitTorrent Sync can be one way around this (I like that idea).&lt;/p&gt;

&lt;p&gt;Sharing annotations and literatire can be helpful, but the tools to do this are still not great, or are costly (should check out the &lt;a href=&quot;http://www.openannotation.org&quot;&gt;OpenAnnotation&lt;/a&gt; standard).&lt;/p&gt;

&lt;p&gt;Finally on writing, a lot is still done on emailing word documents back and forth. (Yeah, that sucks). &lt;/p&gt;

&lt;p&gt;Preprints opens and accelerates the scientific process. In collaborations this is still often hindered by reservations of some researchers (mentioned bioarxive, interestingly PeerJ’s preprints have more volume, genreally things are going in the right direction here).&lt;/p&gt;

&lt;p&gt;He mentions contributions. Now that the maths and biology are so intergrated that you no longer can see the maths anymore, it’s harder to see what contribtions a mathematcian might have made in a particualr paper. This integration is great, but how do you capture quite abstract contributions, and how do you acknowledge and mesure them beyond word of of mouth. &lt;/p&gt;

&lt;p&gt;Summary&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;more scientists as connectors&lt;/li&gt;
  &lt;li&gt;better software needed&lt;/li&gt;
  &lt;li&gt;praise for preprints&lt;/li&gt;
  &lt;li&gt;acknowledge coneptual insights &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;karen-rowlett---managing-editor-f1000-research&quot;&gt;Karen Rowlett - Managing Editor, F1000 research.&lt;/h1&gt;

&lt;p&gt;They insist that authors include all the data (I wonder how they deal with very large data - ah, they use figshare, so there are very well understood data limits). &lt;/p&gt;

&lt;p&gt;Karen talks through the review process (of which I am a very big fan indeed).&lt;/p&gt;

&lt;p&gt;They have published 372 articles as of 2014-01-15. &lt;/p&gt;

&lt;p&gt;They are gonig to be working on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ORCIDs&lt;/li&gt;
  &lt;li&gt;doi’s for reports&lt;/li&gt;
  &lt;li&gt;article collections (planned for February - that’s almost certainly the &lt;a href=&quot;http://www.ebi.ac.uk/Tools/biojs/registry/&quot;&gt;BioJS&lt;/a&gt; collectoin of papers).&lt;/li&gt;
  &lt;li&gt;integraion with WriteLaTeX into editorial workflow&lt;/li&gt;
  &lt;li&gt;more repository integration&lt;/li&gt;
  &lt;li&gt;data plotting tool to allow readers to play with datasets&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I do like that they have a template on their site that includes all of the elements that are required to produce a paper that will run through the F1000 process quickly. &lt;/p&gt;

&lt;p&gt;They are also very interested in focussing on reproducablity in science. &lt;/p&gt;

&lt;h1 id=&quot;john-hammersly---overleaf&quot;&gt;John Hammersly - OverLeaf&lt;/h1&gt;

&lt;p&gt;WriteLaTeX launched in 2011. They now have:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;50k authors in 170 countries  &lt;/li&gt;
  &lt;li&gt;over 500k documents created  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OverLeaf is that system in which the document is held centrally, and authors, reviewers, editors and publishers can come to the document. (I will be very interested to see how they manage the premissions process for the reviewing stage, it seems the idea is that where the document lives is held externally from the workflow process of managing the permissions of who gets to review the paper. In my opinion we need to improve that interface, and the place where the document is held can be abstraced, and become a plug and play kind of thing). &lt;/p&gt;

&lt;p&gt;Overleaf also has a RichText editor, this will be critical for gaining wider adoption.&lt;/p&gt;

&lt;h1 id=&quot;conclusion-from-the-evening&quot;&gt;Conclusion from the evening&lt;/h1&gt;

&lt;p&gt;It was fun evening. I got to chat to quite a few people that I’d not met before. The space is continuing to evolve, and this event was a good 
example of the innovation that is happening here. There was nothing earth shattering mentioned, it was nice to see the Luxury Journal meme being taken up, and it was very nice to chat to Karen and to Bibiana. WriteLaTex have a very small, agile team, and they have created a nice tool, that is gaining market share amongst LaTeX users. I will watch with interest how it evolves. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Review of climbing goals, goals for 2014</title>
   <link href="http://partiallyattended.com/2014/01/18/climbing-review-2013-goals-2014"/>
   <updated>2014-01-18T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2014/01/18/climbing-review-2013-goals-2014</id>
   <content type="html">&lt;p&gt;For the last couple of years I have done an end of year review of my climbing over the previous year, and set myself some goals for the coming year. Rather than doing exactly the same thing this time, I thought it would be good to look back at several of these reviews over the past couple of years, look at the data on my climbing, and see if I could discover any insights.&lt;/p&gt;

&lt;p&gt;The key takeaways are that I have very rarely managed to achieve any of my end of year goals, while at the same time I have been improving, in spite of having less opportunity to train and fewer chances to go on climbing trips.&lt;/p&gt;

&lt;p&gt;In addition to all of this, 2014 will mark the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I’ll turn 40&lt;/li&gt;
  &lt;li&gt;I’ll have been climbing for 23 years&lt;/li&gt;
  &lt;li&gt;my hardest redpoint (7a) will have happened 10 years ago.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If we look at all the annual goals I’ve set myself over all years, I have only managed to achieve 7/30 of those goals.&lt;/p&gt;

&lt;p&gt;The goals and successes break down as follows:&lt;/p&gt;

&lt;h3 id=&quot;goals-2008---27&quot;&gt;Goals 2008 - 2/7&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Onsight Grit E2  (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;Redpoint f6c B  (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;10 weekende trips in UK  (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;5 red problems in a day in font (&lt;strong&gt;&lt;font color=&quot;#1a862e&quot;&gt;done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;80 kg weight (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;build climbing wall (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;get driving license (&lt;strong&gt;&lt;font color=&quot;#1a862e&quot;&gt;done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;goals-2009---05&quot;&gt;Goals 2009 - 0/5&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;My long term goal is to redpoint an 8a by the age of 40. (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;CLimb font 6a in font (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;4 trad climbing trips (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;Onsight E2 (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;Indoor 7a (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;goals-2010---15&quot;&gt;Goals 2010 - 1/5&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;fr 7a redpoint indoors (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;V5 (I’ve done a few V4’s towards the tail end of last year) (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;a font 6a in font, preferably la marie rose (trip to font planned for April) (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;) &lt;/li&gt;
  &lt;li&gt;Trad E1 (I’ve lowered this goal as I’ve had so little trad experience in the past number of years) (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;A few trips to do some trad climbing (&lt;strong&gt;&lt;font color=&quot;#1a862e&quot;&gt;done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;goals-2011---&quot;&gt;Goals 2011 - ?&lt;/h3&gt;

&lt;p&gt;I’m unable to reconstruct my goals for 2011. &lt;/p&gt;

&lt;h3 id=&quot;goals-2012---25&quot;&gt;Goals 2012 - 2/5&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;remain injury free (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;significantly reduce the amount of alcohol that I consume (&lt;strong&gt;&lt;font color=&quot;#1a862e&quot;&gt;done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;fall off at least 10 routes of 6c or harder/month (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;redpoint 7a, but don’t stop trying harder things (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;get three campus board sessions or power hand sessions into my training per month (&lt;strong&gt;&lt;font color=&quot;#1a862e&quot;&gt;done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;goals-2013---213&quot;&gt;Goals 2013 - 2/13&lt;/h1&gt;

&lt;p&gt;SMART goals for 2013   &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;520 boulder problems (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)  &lt;/li&gt;
  &lt;li&gt;one fingerboard session/week for weeks where I am at home (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)  &lt;/li&gt;
  &lt;li&gt;La Marie Rose (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)  &lt;/li&gt;
  &lt;li&gt;climbing Inner City Riots (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;Try font 6b/6c and 7a problems when in font. (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;redopiont 7a+ indoors (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;read “Better Bouldering” by John Sherman (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;get away for one climbing trip to Switzerland with Daniel (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;climb a Dream of White Horses (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Long term goals with now-actions  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Climb V6&lt;/td&gt;
          &lt;td&gt;try V4/V5 problems every month for the first six months of 2013 (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Get to 79 kg&lt;/td&gt;
          &lt;td&gt;get to 80 kg by the end of Jan (&lt;strong&gt;&lt;font color=&quot;#1a862e&quot;&gt;done&lt;/font&gt;&lt;/strong&gt;)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Climb 520 boulder problems in 2012 (&lt;strong&gt;&lt;font color=&quot;#a10024&quot;&gt;not done&lt;/font&gt;&lt;/strong&gt;)&lt;/td&gt;
          &lt;td&gt;climb 40 boulder problems in Jan (&lt;strong&gt;&lt;font color=&quot;#1a862e&quot;&gt;done&lt;/font&gt;&lt;/strong&gt;)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The biggest goal that I set myself - to climb 8a by the age of 40, is one that I will clearly fall very short of. 2013 looks particularly bad, but that’s the year just gone, it’s frech in my mind, and it wasn’t a bad year at all. My highlights from 2013 were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;3 trips to font&lt;/li&gt;
  &lt;li&gt;putting up a new V4 - &lt;a href=&quot;http://www.ukclimbing.com/logbook/c.php?i=274151&quot;&gt;half dome&lt;/a&gt; on the Shoreditch Boulder&lt;/li&gt;
  &lt;li&gt;without really seeming to try, getting in 420 boulder problems in the year  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On the goal of climbing Inner City Riots - an extremely crimpy/fingery V4 on the Shoreditch boulder - I made a lot of progress, and found myself consistently falling off the top move on the last three days of the year. At the beginning of the year I was unable to even hold the crux move in the middle of the problem - so close, soooo close. &lt;/p&gt;

&lt;h1 id=&quot;a-closer-look-at-the-training-data&quot;&gt;A closer look at the training data&lt;/h1&gt;

&lt;p&gt;Let’s have a look at the data on my performance over the last couple of years. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://partiallyattended.com/images/training-sessions-by-year.png&quot; alt=&quot;training sessions by year and type&quot; /&gt;
&lt;img src=&quot;http://partiallyattended.com/images/boulders-by-type.png&quot; alt=&quot;boulders by type&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A couple of things really jump out at me:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I stumbled into doing more boulder problems last year than in any other year of my
life. That was a pleasant surprise. &lt;/li&gt;
  &lt;li&gt;I squeezed in three trips to font in a year through being opportunistic, that’s what led to the high number of days climbed outside.&lt;/li&gt;
  &lt;li&gt;The number of days that I can get to climb on are diminishing, but performance is holding steady, or slightly improving, there is scope to use the fingerboard more&lt;/li&gt;
  &lt;li&gt;my base level for bouldering really is improving, move V4s last year than any other year, mostly becuase I made myself try more. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Though you can’t see it in those graphs, when you look at the activity logs you can see that I’ve had a few month in each year where I lost motivation. Last year it was because I was unable to go on a climbing trip that I had arranged and I reacted petulantly. It was a childish reaction, and I’ll have to work to let go of those kind if feelings and focus more on the journey rather than the goal.&lt;/p&gt;

&lt;h1 id=&quot;what-can-i-learn-from-my-miserable-failure-on-my-goals&quot;&gt;What can I learn from my miserable failure on my goals?&lt;/h1&gt;

&lt;p&gt;I have to conclude that I’ve been taking a more of a waterfall approach to setting my goals. The takeaway is that I have to recognise that with the current configuration of my life external factors are simply stronger for me than my willingness to prioritise climbing. I am totally OK with that, I have a fucking awesome life, but I have to adapt how I set climbing goals to take this into account in a realistic way.&lt;/p&gt;

&lt;p&gt;This year I am going to set performance goals around training only. I’m going to set those goals in terms of effort and volume, and not achievement, and I’m going to set them no longer than 3 months out. I’ll review progress on a rolling three month basis.&lt;/p&gt;

&lt;p&gt;In terms of things I would like to climb or achieve, I’ll list those here on my wish list for 2014, knowing that there are more than I can achieve this year owing to time constraints. In doing this I want to leave myself open to opportunity, while at the same time I want to defend myself from feeling too pissed off at not getting a chance to do any of these things.&lt;/p&gt;

&lt;p&gt;My preformance data is very promising, and the steady approach is providing gains over the years, I just have to keep that in mind. &lt;/p&gt;

&lt;p&gt;For 2014 here is my aspirational, but optional list of things that it would be awesome to get done:&lt;/p&gt;

&lt;h2 id=&quot;aspirations&quot;&gt;2014 aspirations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;7a sport, indoor, outdoor - whatever.&lt;/li&gt;
  &lt;li&gt;as ever - la marie rose&lt;/li&gt;
  &lt;li&gt;le trou du simon&lt;/li&gt;
  &lt;li&gt;a climbing trip to Ireland- fair head- glendaloch- the burren - wherever&lt;/li&gt;
  &lt;li&gt;climbing trip to Italy ir Spain&lt;/li&gt;
  &lt;li&gt;mufti pitch anything - preference for Switzerland - preference for 6c or harder.&lt;/li&gt;
  &lt;li&gt;any psychoblock.&lt;/li&gt;
  &lt;li&gt;all of the v4s on the Shoreditch boulder&lt;/li&gt;
  &lt;li&gt;video all of the routes I can climb - on the shoreditch boulder.&lt;/li&gt;
  &lt;li&gt;I count 10 problems that I can climb on the Shoreditch boulder - do all of these in one day.&lt;/li&gt;
  &lt;li&gt;v5 indoors.&lt;/li&gt;
  &lt;li&gt;avoid falling into a muti month lull&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;training-goals-for-first-3-months-of-2014&quot;&gt;Training goals for first 3 months of 2014&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;try at least 12 routes of 6c or harder.&lt;/li&gt;
  &lt;li&gt;at least one fingerboard session per week.&lt;/li&gt;
  &lt;li&gt;get to the shored itch boulder at least 4 times.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I started drafting this post at the beginning of January, and so far things are going well. As of writing we are about three weeks in and my tally so far is:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;5 fingerboard sessions&lt;/li&gt;
  &lt;li&gt;dogged my way up 5 6c routes&lt;/li&gt;
  &lt;li&gt;flashed a 6b+ route, the hardest thing I’ve done on a rope since January 2013.&lt;/li&gt;
  &lt;li&gt;done 4 v4s&lt;/li&gt;
  &lt;li&gt;done 30 boulder problems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Probably all quite reflective of the start of the year enthusiasm that I can see in my training data from the last couple of years. The challenge for the next 9 weeks is to keep at it in a nice and steady way.&lt;/p&gt;

&lt;p&gt;To finish here is a rendered &lt;a href=&quot;http://photosynth.net/preview/view/9c8aec7d-4673-4651-8df8-e26ba124f1a3&quot;&gt;3d model of the shoreditch boulder&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>advice on publishing research online</title>
   <link href="http://partiallyattended.com/2014/01/08/advice-on-publishing-online"/>
   <updated>2014-01-08T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2014/01/08/advice-on-publishing-online</id>
   <content type="html">&lt;p&gt;I have posted this post as a comment on the thread over at software carpentry in answer to the question &lt;a href=&quot;https://github.com/swcarpentry/bc/issues/199&quot;&gt;What do we teach about writing/publishing papers in a webby world?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;I ended up writing a bit more than I expected, so here are the main peices of advice:&lt;/p&gt;

&lt;p&gt;tl;dr:&lt;br /&gt;
	- use a reference management tool&lt;br /&gt;
	- try to find the fastest venue to publish in &lt;br /&gt;
	- try to publish in an OA journal&lt;br /&gt;
	- have a look for the best preprint server for your discipline, and add your work there too (might be a university archive)&lt;br /&gt;
	- add as much supporting material as you can to the right locations, e.g. &lt;a href=&quot;&quot;&gt;github&lt;/a&gt; for code, &lt;a href=&quot;&quot;&gt;figshare&lt;/a&gt; for anything, &lt;a href=&quot;&quot;&gt;vimeo&lt;/a&gt; or &lt;a href=&quot;&quot;&gt;you tube&lt;/a&gt; for videos&lt;br /&gt;
	- do register for an &lt;a href=&quot;&quot;&gt;ORCID&lt;/a&gt; and add your newly minted publication to your ORCID profile&lt;br /&gt;
	- don’t be afraid to screw around with copyright transfer statements &lt;br /&gt;
	- use version control for your own sanity&lt;br /&gt;
	- remember that all the time you spend pretty formatting your paper will be ignored and thrown away by large publishing companies, especially the work you do on reference formatting, so don’t do it&lt;br /&gt;
	- if the collaborative environment of your choice is not working for the group, be pragmatic, drop it, get the damn paper finished already  &lt;/p&gt;

&lt;p&gt;I would start by advising people to keep in mind the goals of publishing. You want to get your work out into a venue that will be respected by your peers, and noticed by them. In most cases - but not all cases - this will be a journal published by one of the large STM publishers. Elsevier, Springer, Wiley, Taylor &amp;amp; Francis, PLOS and Sage represent a very large part of that market. &lt;/p&gt;

&lt;p&gt;You want this process to happen as quickly as possible. Aside from the act of writing, and constructing your story, the act of publishing - getting it onto the web - is pure schlep. Every minute longer that you spend in this process is a minute wasted, as it’s not adding value to your research or your ability to put yourself in the position of being able to get the resources you need to do the research you are interested in.&lt;/p&gt;

&lt;p&gt;Your first priority is to understand the most appropriate venue and then understand the system that this venue uses to get the work online. Tailor your process to lower the friction between the artefact you create and the process that will be used to get it online. &lt;/p&gt;

&lt;p&gt;The great failure of my industry in the face of the web has been to make allow this process to remain orders of magnitude harder than publishing a post on blogger or wordpress.  &lt;/p&gt;

&lt;p&gt;I’ll step through some advice covering these topics now. &lt;/p&gt;

&lt;h2 id=&quot;the-most-appropriate-venue&quot;&gt;The most appropriate venue&lt;/h2&gt;

&lt;p&gt;Ask your colleagues, confer with your coauthors, it’s usually not hard to determine. A tool like the &lt;a href=&quot;http://www.biosemantics.org/jane/&quot;&gt;Journal author name estimator&lt;/a&gt; has been around for years and it can suggest a journal based on the text of your abstract. In addition the following resources can also help &lt;a href=&quot;http://www.miketaylor.org.uk/tmp/journal-finder.html&quot;&gt;Journal Finder&lt;/a&gt;, &lt;a href=&quot;http://www.edanzediting.com/journal_selector&quot;&gt;http://www.edanzediting.com/journal_selector&lt;/a&gt;, &lt;a href=&quot;http://www.journalguide.com/&quot;&gt;http://www.journalguide.com/&lt;/a&gt; and &lt;a href=&quot;http://etest.vbi.vt.edu/etblast3&quot;&gt;http://etest.vbi.vt.edu/etblast3&lt;/a&gt;. Most of these are for the life sciecnes. &lt;/p&gt;

&lt;p&gt;If your publication is an OA publication the &lt;a href=&quot;http://www.eigenfactor.org/openaccess/index.php&quot;&gt;Eigenfactor Journal Rank tool&lt;/a&gt; will tell you if you are getting good value for money. This ranks cost of the article processing fee against a rank of the journal determined by their own algorithm. &lt;/p&gt;

&lt;h2 id=&quot;speed-of-publication&quot;&gt; Speed of publication&lt;/h2&gt;

&lt;p&gt;It might be worth checking if there is an alternative venue that might be a lot faster than your first choice. &lt;/p&gt;

&lt;p&gt;A common approach is to submit to a high profile journal, and on rejection submit to PLOS one. This is done in order to reduce the thrashing around within the peer review system. Perhaps consider submitting to PLOS one first? You could also look for a journal that is smaller, and might be more responsive. In the life sciences the journal I work for - &lt;a href=&quot;http://elife.elifesciences.org&quot;&gt;eLife&lt;/a&gt; - is both prestigious and fast. &lt;/p&gt;

&lt;p&gt;For the life sciences &lt;a href=&quot;&quot;&gt;Anna Sharman&lt;/a&gt; has a great resrouce for a selection of journals giving information about &lt;a href=&quot;http://www.sharmanedit.co.uk/resources/decision-times&quot;&gt;decision times&lt;/a&gt;, &lt;a href=&quot;http://www.sharmanedit.co.uk/resources/open-access-charges&quot;&gt;OA charges&lt;/a&gt; and &lt;a href=&quot;http://www.sharmanedit.co.uk/resources/journal-metrics-spreadsheet&quot;&gt;journal metrics&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;It might be interesting to encourage people attending your courses to contribute to these, or to create similar resources for their own disciplines. &lt;/p&gt;

&lt;h2 id=&quot;preprint-servers--archives&quot;&gt;Preprint servers / archives&lt;/h2&gt;

&lt;p&gt;Your discipline may have a discipline specific archive. Make sure a copy of your work is deposited there. If the full stext is deposited in one of these venues Google Scholar will be able to provide readers with a link to a full text version of your article - even if you have had to publish in a paywalled journal. &lt;/p&gt;

&lt;p&gt;Often you can get your work in draft up there before the peer review process is complete (if that’s considered Kosher in your field). This can give you priority on an idea, even before the idea has been formally reviewed.  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Physical sciences, astronomy, mathematics - &lt;a href=&quot;http://arxiv.org&quot;&gt;ArXiV&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;Biomedicine - &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/&quot;&gt;Pub Med Central&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;Social Sciences - &lt;a href=&quot;http://www.ssrn.com&quot;&gt;Social Sciences Research Network&lt;/a&gt;   &lt;/li&gt;
  &lt;li&gt;Economics - &lt;a href=&quot;http://repec.org&quot;&gt;Repec&lt;/a&gt;   &lt;/li&gt;
  &lt;li&gt;High energy Physics - &lt;a href=&quot;http://inspirehep.net/?ln=en&quot;&gt;inspirehep&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Also, check with your university library and find out what archives they run, deposit there for the same reasons as above. &lt;/p&gt;

&lt;h2 id=&quot;the-oa-advantage&quot;&gt;The OA advantage&lt;/h2&gt;

&lt;p&gt;Keeping control of your own content is a significant advantage that authors can derive from publishing in an OA journal. I’ll touch on that a bit later. &lt;/p&gt;

&lt;p&gt;There is another advantage, and that’s the advantage of discoverability. &lt;/p&gt;

&lt;p&gt;Currently - as of writing this post, the Google main search bot does not index content that is behind an academic paywall for users who do not have access. That means if you publish at an non paywalled venue more people have a chance to find your content. &lt;/p&gt;

&lt;p&gt;Now most of your immediate peers will probably be able to access your content by virtue of having it in either the appropriate venue or in an appropriate repository, but it can’t hurt to make it even easier to find. &lt;/p&gt;

&lt;p&gt;If your coauthors will not agree to publishing in an OA venue, you can always try to modify the copyright transfer agreement that the publishing company will ask you to sign. &lt;/p&gt;

&lt;p&gt;You can follow these examples to allow you to retain the right to distribute the paper in any way that you see fit. This is the one piece of advice that I’m giving that might slow down the process of publication, but go on, you know you want to do it, don’t you? &lt;/p&gt;

&lt;h2 id=&quot;what-happens-to-my-paper-in-a-big-publishing-company-and-why-should-i-care&quot;&gt;What happens to my paper in a big publishing company, and why should I care?&lt;/h2&gt;

&lt;p&gt;During the reviewing stage a very badly formatted version of your article will be created to be sent to the reviewers of your article. If you have a preprint of your article available, that might even be an easier artefact for the reviewers to use, and it might speed up the review process, though I don’t have any evidence to suggest that it will. &lt;/p&gt;

&lt;p&gt;If your manuscript is accepted for publication then it will be sent to a large typesetting company, where it will be digitally torn apart and converted to XML. All of the formatting that you do on figures, text and on the reference lists, will be thrown away. I’ll just say that again. All of the work and hours you spend carefully formatting your reference lists will be ignored as the content goes through an automated typesetting system. (That’s why at eLife we don’t have a proscriptive requirement on the format of the references that we get sent, we will take them in any format). &lt;/p&gt;

&lt;p&gt;All of your specially chosen fonts, and special text alignment will be mostly ignored. &lt;/p&gt;

&lt;p&gt;Depending on the state of the manuscript and the quality of the language in the manuscript it may be checked by a copy editor, either for internal journal style, or for the quality of the language. Much of this work is undertaken by highly educated graduates in developing countries, particularly India, the Philippines and increasingly China - globalisation in action.  &lt;/p&gt;

&lt;p&gt;Why is this? For the most part the systems that run our global publication infrastructure are old, many of them have code bases that are older than 20 years. Back in the day XML was the only reliable transfer format, and it remains the industry standard today. A slow evolution has been happening with the XML that publishers are using, and under the gentle pressure to deposit into PubMed and PubMedCentral most publishers and typesetters are starting to target one of the many dialects of the NLM DTD. This has become a de-facto standard in the industry, however no writing tools export natively to this format, and the DTD supports, and is designed for, archiving print material. One of the very many consequences of this is that code that is typeset in this DTD is usually typeset as dumb text. On the other hand it does allow a resource like PMC to archive millions of articles, from thousands of publishers, and provide a very fine grained search interface on top of all of this content. I’ll mention writing tools a little later.&lt;/p&gt;

&lt;p&gt;In order to potentially reduce the time to review your manuscript, and in order to reduce your the time your manuscript takes in the copy editing / typesetting process the following things could help:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;As mentioned -having a preprint version of your article available that the reviewer may know about, e.g. on the ArXiVe.&lt;/li&gt;
  &lt;li&gt;If English is not your first language, have the manuscript proofed by a native speaking colleague, or pay to have the proofing done.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Use a tool for managing your references, and don’t sweat the formatting details. Tools you might consider using any of:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.bibtex.org&quot;&gt;bibtex&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.mendeley.com&quot;&gt;mendeley&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.zotero.org&quot;&gt;zotero&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.papersapp.com/mac/&quot;&gt;papers&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Remember, this is probably a lifestyle choice, my main advice is pick a tool that does not have too much lock in. I used to work at Mendeley and believe it to be as good as any tool out there. &lt;/p&gt;

&lt;h2 id=&quot;but-wait-i-want-to-do-ipython-interactive-open-data-virtual-machines-3d-printed-dna-dinosaur-replication-and-what-you-have-just-told-me-sound-like-like-i-cant-do-that---that-sucks-&quot;&gt; But wait! I want to do iPython, interactive, open data, virtual machines, 3D printed DNA dinosaur replication and what you have just told me sound like like I can’t do that - that sucks :(&lt;/h2&gt;

&lt;p&gt;Yes, yes, it does suck, and I hear what you are saying, but remember, at the moment of publishing, your priority is to get the damn work published, and unfortunately that still means interacting with a system that has changed little since the late 17th century. There are moves in the right direction, oaises of sanity, but there is a long long way to go. &lt;/p&gt;

&lt;p&gt;If you feel really passionate about this then the best thing you can do is to keep the rights to your own work, get the paper out as a CC-BY paper in a boring old venue, and then do the kind of publication that you really want to on your own academic home page, and build your own audience around your work that way. In that case you want the boring route to take up as little time as possible.&lt;/p&gt;

&lt;p&gt;You should also deposit artefacts of your paper in the best possible place for them. Code to a location like &lt;a href=&quot;github&quot;&gt;github&lt;/a&gt;. Videos to &lt;a href=&quot;youtube&quot;&gt;youtube&lt;/a&gt; or &lt;a href=&quot;Vimeo&quot;&gt;Vimeo&lt;/a&gt;. Images to &lt;a href=&quot;http://www.flickr.com&quot;&gt;flickr&lt;/a&gt;. Data to &lt;a href=&quot;http://figshare.com&quot;&gt;Figshare&lt;/a&gt;, &lt;a href=&quot;http://datadryad.org&quot;&gt;DataDryad&lt;/a&gt;, &lt;a href=&quot;http://zenodo.org&quot;&gt;Zenodo&lt;/a&gt;, or one of the very many other subject specific data repositories that may be appropriate for your field. &lt;/p&gt;

&lt;p&gt;Try and keep your artefacts well organised, and backed up off of your machine. You can back a lot up to github as part of a git repo, but that’s not it’s main use case. You can use a service like &lt;a href=&quot;https://www.evernote.com&quot;&gt;EverNote&lt;/a&gt;, or get a licence for a research specific asset management tool like &lt;a href=&quot;http://www.digital-science.com/products/projects&quot;&gt;Projects&lt;/a&gt; or &lt;a href=&quot;http://www.labarchives.com&quot;&gt;LabArchives&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The aim here is to reduce the friction in getting instances of these resources into the hands of others - if you believe that this is a critical part of doing research. &lt;/p&gt;

&lt;p&gt;It can also to make it possible to recover this informaiton in the instance of losing your main machine. (I decomissioned my main machine last summer via cup of coffee).&lt;/p&gt;

&lt;p&gt;For the purposes of archiving your work you should also check with your institution and library to see if they can provide support or systems. Librarians in many institutions are mustard keen to help, as it provides a way for them to prove value to the academy in a world in which library subscriptions are under extreme pressure. You may find yourself with the problem of having too many options - which is not a bad problem at all.&lt;/p&gt;

&lt;h1 id=&quot;authoring-tools-and-why-does-this-all-suck-so-much&quot;&gt;Authoring tools, and why does this all suck so much?&lt;/h1&gt;

&lt;p&gt;I noticed that there was some discussion in the thread about collaborative tools for authoring. Again, I’ll just stress, get the work published as soon as possible. This might mean sending a PDF of the article to a publishing house, or having to just send in a Word file.&lt;/p&gt;

&lt;p&gt;On the other hand, there are a new generation of online tools emerging for writing, and also tools emerging for writing on the iPhone and iPad. I think we have more viable options now at our fingertips than at any time in the past. I don’t believe that there are any serious contenders yet ready to oust the Word/LaTeX duopoly, but it would not hurt to take some of the following for a test drive to help with the authoring experience. It’s too broad a topic to go into a detailed review of each one, I’ll leave an investigation of these tools as an exercise for the interested reader. The list below is just a smaple, there are a bunch of others out there. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.writelatex.com&quot;&gt;writelatex&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sharelatex.com&quot;&gt;sharelatex&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://fiduswriter.org&quot;&gt;fidus wrtiter&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.google.com/drive/&quot;&gt;google docs/drive&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://johnmacfarlane.net/pandoc/&quot;&gt;panodc&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.martinfenner.org/2013/06/17/what-is-scholarly-markdown/&quot;&gt;scholarly markdown&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.authorea.com&quot;&gt;authorea&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.hogbaysoftware.com/products/writeroom&quot;&gt;WriteRoom&lt;/a&gt; (iOS/Mac)&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://brettterpstra.com/projects/nvalt/&quot;&gt;nvALT&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://agiletortoise.com/drafts/&quot;&gt;drafts&lt;/a&gt; (iOS)  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://vesperapp.co&quot;&gt;Vesper&lt;/a&gt; (iOS)  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The tool that I see emerging at some time on the horizon, and that I have a lot of excitement for, is the work on the &lt;a href=&quot;http://about.substance.io&quot;&gt;substance reader and composer&lt;/a&gt; and &lt;a href=&quot;http://lens.elifesciences.org&quot;&gt;eLife lens&lt;/a&gt;. What’s really nice about this is that to get started you can import NLM XML directly, or markdown via panodoc. It does a great job of separating the view, logic and control of the writing experience, and so it should also be possible to write directly in browser, and export to a publication ready format directly - but some work remains. &lt;/p&gt;

&lt;p&gt;In my own ideal world you can submit an idea to a journal as part of a pull request to the publication, peer review takes place in some system similar to how we do code review today. On acceptance the full digital artefact is published instantly. The writing and collaboration happens in almost any tool that the user likes, modifications are synced via something like dropbox. In this world writing tools support offline, as well as online modes, and content logic and views can be assembled independantly. In my ideal world the source is open. We are a little bit away from that at the moment, but there is no doubt in my mind that we are moving in that direction. [this great post by plos] has some great insights discussing what the native format for publihsing on the web should be. &lt;/p&gt;

&lt;h1 id=&quot;about-this-post&quot;&gt;About this post.&lt;/h1&gt;

&lt;p&gt;As we are discussing publishing on the web, I thought it might be useful to describe the tools I used to write this post. The body of the text is stored on my machine as a plain text file, and I store all of these in one directory using &lt;a href=&quot;http://brettterpstra.com/projects/nvalt/&quot;&gt;nvALT&lt;/a&gt; to manage them. This directory is also held under a Dropbox account, and I can access the content from my iPhone through a variety of editors, but in this case I didn’t use any of these. &lt;/p&gt;

&lt;p&gt;For writing this post I used WriteRoom for mac in distraction free mode. I often use &lt;a href=&quot;http://www.sublimetext.com&quot;&gt;SublimeText&lt;/a&gt; in distraction free mode too. For some shortcuts in formatting I used &lt;a href=&quot;http://smilesoftware.com/TextExpander/index.html&quot;&gt;TextExpander&lt;/a&gt;. To format the links I write the post in markdown, and did the formatting in SublimeText. I previewed the post using &lt;a href=&quot;http://marked2app.com&quot;&gt;Marked&lt;/a&gt;. I also used Marked to verify that all of the links were working, at the time of writing. In order to publish the post on my blog I posted it directly into a github repo using &lt;a href=&quot;http://pages.github.com&quot;&gt;github pages&lt;/a&gt; to render the content. You can see the result at … . I used the &lt;a href=&quot;http://brettterpstra.com/2013/07/04/grablinks-bookmarklet-2-dot-0/&quot;&gt;GrabLinks&lt;/a&gt; bookmarklet to gather all of the links from this post to add in as a resources list at the end of this post. &lt;/p&gt;

&lt;h1 id=&quot;final-thoughts&quot;&gt;Final thoughts&lt;/h1&gt;

&lt;p&gt;I realise that I have mostly been answering the question about what shlould people know about the world as it is now, and not so much about what tools or approahces we should advocate to make the world a better place, but I hope that we can have a clear view on what is bad, so that this can help people make pragmatic decisions about how to change things for the better. &lt;/p&gt;

&lt;h1 id=&quot;resources&quot;&gt; resources&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://partiallyattended.com/2014/01/08/advice-on-publishing-online/&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.biosemantics.org/jane/&quot;&gt;Journal author name estimator&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.miketaylor.org.uk/tmp/journal-finder.html&quot;&gt;Journal Finder&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.edanzediting.com/journal_selector&quot;&gt;http://www.edanzediting.com/journal_selector&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.journalguide.com/&quot;&gt;http://www.journalguide.com/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://etest.vbi.vt.edu/etblast3&quot;&gt;http://etest.vbi.vt.edu/etblast3&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.eigenfactor.org/openaccess/index.php&quot;&gt;Eigenfactor Journal Rank tool&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://elife.elifesciences.org/&quot;&gt;eLife&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.sharmanedit.co.uk/resources/decision-times&quot;&gt;decision times&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.sharmanedit.co.uk/resources/open-access-charges&quot;&gt;OA charges&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.sharmanedit.co.uk/resources/journal-metrics-spreadsheet&quot;&gt;journal metrics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://arxiv.org/&quot;&gt;ArXiV&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/&quot;&gt;Pub Med Central&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ssrn.com/&quot;&gt;Social Sciences Research Network&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://repec.org/&quot;&gt;Repec&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://inspirehep.net/?ln=en&quot;&gt;inspirehep&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.bibtex.org/&quot;&gt;bibtex&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.mendeley.com/&quot;&gt;mendeley&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.zotero.org/&quot;&gt;zotero&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.papersapp.com/mac/&quot;&gt;papers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://partiallyattended.com/2014/01/08/advice-on-publishing-online/github&quot;&gt;github&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://partiallyattended.com/2014/01/08/advice-on-publishing-online/youtube&quot;&gt;youtube&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://partiallyattended.com/2014/01/08/advice-on-publishing-online/Vimeo&quot;&gt;Vimeo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.flickr.com/&quot;&gt;flickr&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://figshare.com/&quot;&gt;Figshare&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://datadryad.org/&quot;&gt;DataDryad&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://zenodo.org/&quot;&gt;Zenodo&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.evernote.com/&quot;&gt;EverNote&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.digital-science.com/products/projects&quot;&gt;Projects&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.labarchives.com/&quot;&gt;LabArchives&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.writelatex.com/&quot;&gt;writelatex&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sharelatex.com/&quot;&gt;sharelatex&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://fiduswriter.org/&quot;&gt;fidus wrtiter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.google.com/drive/&quot;&gt;google docs/drive&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://johnmacfarlane.net/pandoc/&quot;&gt;panodc&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.martinfenner.org/2013/06/17/what-is-scholarly-markdown/&quot;&gt;scholarly markdown&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.authorea.com/&quot;&gt;authorea&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.hogbaysoftware.com/products/writeroom&quot;&gt;WriteRoom&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://brettterpstra.com/projects/nvalt/&quot;&gt;nvALT&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://agiletortoise.com/drafts/&quot;&gt;drafts&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://vesperapp.co/&quot;&gt;Vesper&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://about.substance.io/&quot;&gt;substance reader and composer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lens.elifesciences.org/&quot;&gt;eLife lens&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.sublimetext.com/&quot;&gt;SublimeText&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://smilesoftware.com/TextExpander/index.html&quot;&gt;TextExpander&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://marked2app.com/&quot;&gt;Marked&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://pages.github.com/&quot;&gt;github pages&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://brettterpstra.com/2013/07/04/grablinks-bookmarklet-2-dot-0/&quot;&gt;GrabLinks&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>STM innovations seminar, London, 2013</title>
   <link href="http://partiallyattended.com/2013/12/04/STM-innovations-2013"/>
   <updated>2013-12-04T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/12/04/STM-innovations-2013</id>
   <content type="html">&lt;p&gt;Today I’m at the STM innovations seminar. The twitter tag for today is &lt;a href=&quot;https://twitter.com/search?q=%23ukinno&amp;amp;src=typd&quot;&gt;#ukinno&lt;/a&gt;. The program is &lt;a href=&quot;http://www.stm-assoc.org/events/innovations-seminar-2013/&quot;&gt;online&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I’m going to take a light approach to blogging today, I’ll probably hang out mostly on Twitter. &lt;/p&gt;

&lt;h2 id=&quot;the-research-data-revolution-sayeed-choudhury-associate-dean-for-research-data-management&quot;&gt; 9.35 The Research Data Revolution, Sayeed Choudhury, Associate Dean for Research Data Management,&lt;/h2&gt;
&lt;p&gt;Johns Hopkins University 
&amp;gt; Data has become a major topic of interest from all sectors of society with headlines such as “Data is the new oil” to assertions from McKinsey that data is the fourth factor of production. Within higher education, new forms of data intensive scholarship have already begun to transform research and learning. The “Research Data Revolution” will examine the implications of these developments for libraries and publishers especially as they relate to new forms of competition.&lt;/p&gt;

&lt;p&gt;Sayeed is talking about data in general, he is associated with &lt;a href=&quot;http://dataconservancy.org&quot;&gt;http://dataconservancy.org&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Some key points from his talk.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;data is the new Oil&lt;/li&gt;
  &lt;li&gt;data has to be made open and actionable by machines&lt;/li&gt;
  &lt;li&gt;from the libraries perspective, data are a new form of collections &lt;/li&gt;
  &lt;li&gt;treat manuscripts like a dataset, even humanists are starting to see new possabilites and new methods, creating a completely new experience online. &lt;/li&gt;
  &lt;li&gt;as librarians, think about the realtionship you can have with your communities, if they start to manage and curate the data, this leads to an opportunity for creating new relationships built around those special collections. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nice take on &lt;code&gt;Big Data&lt;/code&gt;. If a community is overwhelme by it’s data, then the data becomes big. For the Astronomers today the SDSS is no longer big - 150TB, as the astronomers now have tools to deal with this data. New proposed experiments are creating data that will overwhelm the field, lead to a situation in which most of the data will have to be thrown away on first run. &lt;/p&gt;

&lt;p&gt;He makes the point of needing to know the provenonce of data, how data moves from one fromat to another. I’m a big fan now of making this available in code, via automated tool chains such as &lt;a href=&quot;http://www.opscode.com/chef/&quot;&gt;chef&lt;/a&gt; and &lt;a href=&quot;http://www.vagrantup.com&quot;&gt;vagrant&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;If data collections become open, no one is going to care about how much data you have, in contrast to the services that you provide. Some services may be hard to run across the network, but generally libraries and publishers might differentiate themselves via the servcies they offer, rather than as acting as gatekeepers to the content. We need to get serious about machine based services to the content. There will be some things that only humans can do. &lt;/p&gt;

&lt;p&gt;Mentions a seminal report on the dynamics of infrastrucure developement. (you can find a copy online &lt;a href=&quot;http://deepblue.lib.umich.edu/bitstream/handle/2027.42/49353/UnderstandingInfrastructure2007.pdf?sequence=3&quot;&gt;here&lt;/a&gt; - open access FTW!). The conclusion from the reoprt is that we will need new forms of infrastrucutre. Que story about stupid machines and reccomendation engines going wrong, but the machine corrected itself quickly. &lt;/p&gt;

&lt;p&gt;Google and Amazon have figured out that at scale even dumb machines can do well. That is why scale is important. It’s a means, but not an end. At Hopkins they have one large astronomy dataset, but there are many other astronomy data sets out there. They have to think of services across all of those data sets, not just on one data set. The scale will allow machines to appear to be clever, and this is where the role of the expert will remain important. &lt;/p&gt;

&lt;p&gt;The discussion moves on to curation of data, and who is doing a good job. He mentions &lt;a href=&quot;http://schema.org&quot;&gt;http://schema.org&lt;/a&gt;, mentions that top 5 places that do data management are Apple, Facebook, Twitter, Google and Amazon. Big question, are these pople doing the creation of these knowledge graphs with a view to preservation. The answer is proabaly not. The informaiton graphs that are coming out of the librarian community - OAE-ORE - are richer, smaller, are not incompatable with Schema.org, but at the moment they have no skin the the game, they have to offer something. (I didn’t really get the point here).  &lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;Publising is about content and not format&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Question time, but I’m probably not going to capture the Q&amp;amp;A session. &lt;/p&gt;

&lt;h2 id=&quot;morning-plenaryepublishing-evolutions&quot;&gt; 11.00 Morning plenary: ePublishing evolutions&lt;/h2&gt;
&lt;p&gt;Moderated by: Dave Martinsen, ACS
 
## Watson and the Journey to Cognitive Computing Frank Stein, IBM &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Today, many of our science, technical, and medical professionals can not keep up with the growing amount of new information being produced in the world.   The complication is that although we have ever faster computers, they haven’t been designed to process and understand this information which is mostly in human-consumable formats. This means we’re not getting the full value out of our scientific, medical, and technical endeavors.  This talk will provide a brief overview of Watson as a cognitive computing exemplar, and of Cognitive Computing more generally. We will discuss some of the implications of this new technology, providing a basis to envision changes that will start impacting our world and to understand some of the benefits and challenges that cognitive computers will bring to the scientists and professionals in the fields that you support.
 
He is making the Watson algorithm seem comprehensible. I’m sure there is a lot of work behind this system. I like that the Watson system uses inference, and they use probablistic reasoning. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;They have over 100 algorithms to do the matching between input and the underlying knowledge corpus. &lt;/p&gt;

&lt;p&gt;Semaintic technlogy was helpful, but not the be all, and end all, they used a whole bunch of other techniques in order to win at Jeapordy. &lt;/p&gt;

&lt;p&gt;How do they start appying the Watson technology to the needs of their customers? They have a new divsion of the company to just figure out how to commmercialise the tech. They started with appliations in Medicine, have moved to finance, and they are looking at networks of industries now that this could be applied in. &lt;/p&gt;

&lt;p&gt;(Of course a great question is how could we imagine brining this technology into the publishing domain). &lt;/p&gt;

&lt;p&gt;They are moving forward with productising Watson, however they have a problem. For them the next phase they are looking at cognitive computing. The Watson brain used about 85 - 100KW of power. If they are going to get bigger more sophisticated systems, they would need to spend more power.&lt;/p&gt;

&lt;p&gt;There are a bunch of techologies that need to be enabled, but they boil down to doming more networked computing on smaller faster less power hungry chips, with better learning algorithms sitting on top of this. &lt;/p&gt;

&lt;p&gt;They want natural language interactions to these systems, and they want to move away from the von Neumann architectures, these future architectures will break down the barrieres between memory and computaton, on the chip. They are prototyping chips - such as the SyNAPSE chip. Does not use a clock, it’s all event based on the chip. This needs an entirely new stack of programming tools, from compliers - all the way up. More information on these chips &lt;a href=&quot;http://www.research.ibm.com/cognitive-computing/neurosynaptic-chips.shtml#fbid=OH8oQM4QCP0&quot;&gt;here&lt;/a&gt;. The goal for SyNAPSE is to&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;IBM’s long-term goal is to build a neurosynaptic chip system with ten billion neurons and hundred trillion synapses, all while consuming only one kilowatt of power and occupying less than two liters of volume.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Basically, they want to build a brain on a chip - good luck to them!&lt;/p&gt;

&lt;p&gt; 
## Source Data and other article enrichments Thomas Lemberger, EMBO Journals&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;The aim of the EMBO SourceData project is to build tools that will allow journals to integrate data and structured biological metadata in published papers and to develop data-oriented methods to search the literature. 
 
I’ve reported on what Thomas talks about elsewhere before. I’ll really focus my notes here on any specific, interesting and new thoughts that come up in the course of this talk. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Makes the good point that the majority of journals in the life science are data journals as they all have data in them. Small scale data, but data nonetheless. &lt;/p&gt;

&lt;p&gt;They look for Actionable data, this does not have to be the underlying raw data. An example is the graph derviced from high throughput screening. The underlying data is several TB in size. They allow the community to decide what the most actionable, and processed version of the data are, that should be presented with the paper. &lt;/p&gt;

&lt;p&gt;For tagging the metadtaa in their papers they have three levels of metadata:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;level 1 - lists of chemcial and biological components  &lt;/li&gt;
  &lt;li&gt;level 2- representation of the causality of the experiment, e.g. “measurement of Y as a function of A using method C”.&lt;/li&gt;
  &lt;li&gt;level 3 - machine readable representation with standard identifiers &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They are generating tools to help with this curation. ‘Data copy editors’. This is very interesting, and it would be great to understand their toolchain. Hopefully I’ll get a chance to see it more closely at the workshop that we are organising next week on data and literature integration. &lt;/p&gt;

&lt;p&gt;Now using Filemaker to demo how a structured query based on tagged entities could do for simplifying discovery. I suspect that the next speaker will have something to say about this topic too. &lt;/p&gt;

&lt;h2 id=&quot;actionable-data---the-wolfram-approach-matthew-daywolfram-research&quot;&gt;Actionable Data - the Wolfram Approach Matthew Day, Wolfram Research&lt;/h2&gt;
&lt;p&gt; &amp;gt;
Wolfram Research has created several actionable data technologies, particularly WolframAlpha.com and the Computable Document Format. The new focus is on enhancements that will greatly extend our ability to make all sorts data files readily actionable with minimal work from data producers or curators.&lt;/p&gt;

&lt;p&gt;(In terms of the context of Matt’s talk, it might be interesting to point to the recent blog post by Stephen Wolfram on &lt;a href=&quot;http://blog.stephenwolfram.com/2013/11/something-very-big-is-coming-our-most-important-technology-project-yet/&quot;&gt;the promise of the Wolfram ecosystem&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;They want to be able to create an engine that can provide answers, where those answers don’t exist yet, so an engine like google can’t currently help. &lt;/p&gt;

&lt;p&gt;Not taking so many notes, getting a little nervous about my impending flash presentation. &lt;/p&gt;

&lt;h2 id=&quot;special-introduction-on-science-20-and-current-developments-in-the-eu-prof-jean-claude-burgelman-eu-commission-dg-research-and-innovation-head-of-unit&quot;&gt;14 00 Special Introduction on Science 2.0 and current developments in the EU, Prof Jean-Claude Burgelman, EU Commission, DG Research and Innovation, Head of Unit&lt;/h2&gt;

&lt;p&gt;Bottom line, most stakeholders support open science. Different aspects of open science, and science2.0, are moving at different paces. The directorate is producing a green paper on the topic. This will focus on what actions, or not, the EC will take. &lt;/p&gt;

&lt;h2 id=&quot;afternoon-keynote-e-science-and-we-science-making-citizen-science-work-moderated-by-dave-smith-ietlessons-from-the-zooniverse--science-with-nearly-a-million-collaborators-chris-lintott-researcher-oxford-astrophysics-and-principal-investigator-zooniverse&quot;&gt; 14 15 Afternoon Keynote: e-Science and we-Science: Making citizen science work Moderated by: Dave Smith (IET)  ## Lessons from the Zooniverse : Science with (nearly) a million collaborators Chris Lintott, Researcher, Oxford Astrophysics and Principal Investigator, Zooniverse&lt;/h2&gt;

&lt;blockquote&gt;

  &lt;p&gt;The Zooniverse is the world’s most successful platform for citizen science - the involvement of non-professionals in the scientific enterprise. Zooniverse founder Chris Lintott will cover the highlights of six years of collaboration, including mysterious galaxy-sized gas clouds, unusual planets and a journey across the Serengeti, and explain the lessons for researchers and publishers alike in bringing science to such a large audience.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is an amazing talk. I’m not even going to try to take notes, I’m enjoying the talk waaaaay too much. &lt;/p&gt;

&lt;p&gt;There is an interesting issue raised at the end of the talk. Zooniverse still cares about scientific publications, but they see little interaction between the community who do the contribution, and the research publications. There is a strong desire from Chris to do something about this, but what to do is not yet aswered. &lt;/p&gt;

&lt;p&gt;15 00 Afternoon Plenary: e-Science, e-Research, e-Publishing
 
## e-Research and the demise of the scholarly article. David De Roure, Director of e-Research Centre, Oxford&lt;/p&gt;

&lt;p&gt;Dave is going to focus on the intersection between large numbers of people and large computaional capacity. (A great example is that facebook is genering 100s of terabytes of data per year). &lt;/p&gt;

&lt;p&gt;A nice story on how Dave came up with the 8 things that will have led to the demise of the paper. &lt;/p&gt;

&lt;p&gt;“A pdf exploded today when a scientist tried to paste in the twitter firehose” &lt;/p&gt;

&lt;h2 id=&quot;afternoon-plenary-e-science-e-research-e-publishingmoderated-by-howard-ratner-chorustext-and-data-mining-discovering-new-patterns-nicko-goncharoff-digital-science&quot;&gt; 16 00 Afternoon Plenary: e-Science, e-Research, e-Publishing Moderated by: Howard Ratner, CHORUS   ## Text and Data Mining, discovering new patterns Nicko Goncharoff, Digital Science&lt;/h2&gt;

&lt;p&gt;Very interesting. SureChem is going into the public domain. Will find out more during the course of this talk. Bottom line, EMBL is taking over. &lt;/p&gt;

&lt;p&gt;(This is obviously the first entity that Digital Science is divesting. It’s important that Digital Science do this if their model is to succeed in the long term, it’s intersting to see this starting to happen. It will be interesting to see if this trend continues).&lt;/p&gt;

&lt;p&gt;  
## Wearable Computers: Future Fix-All or Fashion Faux Pas? Heather Ruland Staines, SIPX    
&amp;gt; 
From Google Glass to the Samsung Gear, technology blogs and expos are all over wearable computing. Whether as extensions to our phones or as sensors to monitor our health or purchasing behavior, wearables are coming. Learn about how wearable computers are being tested in education and teaching contexts, what the latest initiatives are, and hear from a Glass Explorer about the potential and the perils of a computer on your face.&lt;/p&gt;

&lt;p&gt;She is wearing a google glass. I really like the idea of diminished reality, in which a google glass like device could block out aspects of reality that you don’t want to interact with - like advertising (pverty and misery perhaps?).&lt;/p&gt;

&lt;p&gt;(Getting one of these things into a contact lens would really really annoy my wife, so I applaud the rest of humanities march towards the cyborg singularity, and I shall be watching quietly from the sidelines.)&lt;/p&gt;

&lt;p&gt;Final word on ethics of using the google glass&lt;/p&gt;

&lt;blockquote&gt;

  &lt;p&gt;If you are going to be a jerk, you’re going to be a jerk. &lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>STM brainstorming session - 2013</title>
   <link href="http://partiallyattended.com/2013/12/03/STM-brainstorming-meeting"/>
   <updated>2013-12-03T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/12/03/STM-brainstorming-meeting</id>
   <content type="html">&lt;p&gt;Just attended the STM brainstroming session. I’ll update these notes in due course, and fix spelling issues, but I wanted to get the post live first. &lt;/p&gt;

&lt;h1 id=&quot;notes-ill-just-mention-the-things-that-i-found-interesting&quot;&gt;Notes I’ll just mention the things that I found interesting.&lt;/h1&gt;

&lt;h2 id=&quot;round1&quot;&gt; Round1&lt;/h2&gt;

&lt;p&gt;Science Gists get a mention, yay!! &lt;/p&gt;

&lt;p&gt;Google scholar library gets a mention. &lt;/p&gt;

&lt;p&gt;Visualising data as maps is mentioned, mentions that there are no standards &lt;/p&gt;

&lt;p&gt;Howard mentions much richer tagging in the article, and upfront semantic tagging. Someone mentions PeerJ as a submissions system that can do this. &lt;/p&gt;

&lt;p&gt;New payment methods. &lt;/p&gt;

&lt;p&gt;A growing trend in peer review experiments. John Sack mentions prescore, a service that evaluates the people participating in the peer review process, and gives those people an impact rating. &lt;/p&gt;

&lt;p&gt;Of course research data is getting a bunch of mentions. &lt;/p&gt;

&lt;p&gt;Detection of scientific fraud needs to be dealt with. This is related to reproducability but not always. Fraud happens. &lt;/p&gt;

&lt;p&gt;The importance of communicating science through images and graphics, not visualisation, rather explaining the contents of an article through an image, sometimes called graphical abstracts. Readers start reading articles through the images, and writers start writing through the images, the role of a publisher could be to create image creation and curation services. &lt;/p&gt;

&lt;p&gt;The notion of virtual laboratories is meniotned, sucah a chemconnective out of carnegie mellon. This is going to require different types of content than we are used to. &lt;/p&gt;

&lt;p&gt;A machine processable format to enable textmining, perhaps a format that all publishers can make avilalbel, normalise all the formats. Pharma have been asking for this too. &lt;/p&gt;

&lt;p&gt;Smart articles are mentioned, the article that finds you, and not you finding the articles. (this matches my point #2). &lt;/p&gt;

&lt;h1 id=&quot;round-2&quot;&gt;Round 2&lt;/h1&gt;

&lt;p&gt;Following on from standards for text mining - standard formats for research data (interestingly I’ll be at a meeting about this next week). This also touches on reproducabilty. Crossref guy mentions virtual machine enviornment issue. &lt;/p&gt;

&lt;p&gt;The cloud is mentioned, for running all of the computers, the hosting, will run on several clouds. &lt;/p&gt;

&lt;p&gt;I mention the eclipse of the authoring tool.&lt;/p&gt;

&lt;p&gt;eBooks is mentioned. The development of the good display of ebooks using ePub3, it might not happen, but it might be good to have happen.&lt;/p&gt;

&lt;p&gt;The importance of google and google scholar, and the control that they drive over the sites. We just jump and do whatever they say. ACS is not alone in that upwards of 40-50% of usage can originate from google. (I do mention that OA can help).&lt;/p&gt;

&lt;p&gt;Unoticable search, like google now. &lt;/p&gt;

&lt;p&gt;The notiion of text mining and digital humanities. In connection with this the issue of data privacy is mentioned.&lt;/p&gt;

&lt;p&gt;Metadata, this is the future. Tim O’Reilly has mentioned the notion of digital smog. Project Mesur from Johan Bollen is mentioned. Watching the behaviour of scholars via DOI resolvers, and finding where users are at the intersection of new and emerging fields of study. There is someting very interesing there. &lt;/p&gt;

&lt;p&gt;Licencing at the component level, below the traditional level of the article, this is realted to the metadata issue. &lt;/p&gt;

&lt;p&gt;Standards for supplimentary data for articles (this is sounds like standard formats for research data), though one might say is that &lt;/p&gt;

&lt;p&gt;Crossref mentions hosted journals as a platform. I mention scholastica, based out of chicago. &lt;/p&gt;

&lt;p&gt;Jeremey mentions services for individuals. (Eefke mentions that it could be related to predictive analytics, Jeremey mentions that the important thing is thinking about turing this into services for individuals).&lt;/p&gt;

&lt;p&gt;The work around altmetrics is mentioned as something that has really exploded. Beckham medial library have mentioned that they are collecting 350 measures of impact. Mentioned that last year . Crossref is taking on the PLOS ALM tool, and providing that as a service for publishers. They have started to look at metrics that PLOS have. They have log files from the dx.doi resolution log files. They are considering whether they can make that data avilalbe. &lt;/p&gt;

&lt;p&gt;Machine readable article reuse rights is mentioned by Howard. Says that CC is fine, but there are a lot of publishers who don’t want to use those license. Eefke mentions the NISO groups.&lt;/p&gt;

&lt;p&gt;John Sack mentions the effects of dealing with industrial espionage. He says that their servers are getting hit hard by usage patterns that look like those it’s coming from china. This is counter complient usage, you can’t just filter it out, it’s the. &lt;/p&gt;

&lt;p&gt;Someone mentioned that someone tried to log in to their peer review system 10k times within the same hour from the same IP address. &lt;/p&gt;

&lt;p&gt;The infrastrucutre and business model coming from funder mandates. &lt;/p&gt;

&lt;p&gt;Sharing sutes, how can publishers work with the usage on sharing sites. (From Elsevier). Want to make it a win win situation, do not want to obstruct the scientific collaboration. (really intersging).&lt;/p&gt;

&lt;p&gt;Richard from OUP - an increasing value in privacy and secrecy in a world that is open. &lt;/p&gt;

&lt;p&gt;Wearable Computers, content creation and content comsumption on these devices, example geo tagging. Touches on privacy issue. &lt;/p&gt;

&lt;p&gt;The last word, Socail networkding for scientists, and whether their needs are filled by linkedin or google plus, or whether they should build those sites. &lt;/p&gt;

&lt;p&gt;IBM guy comments. Many of these ideas impact on cognitive computing. Mentions that the doctors don’t have the time to read all of the articles. The machines are going to read these articles for the doctor, gets into the question of computers that can also interpret images, like X-Rays. Now they are starting to get into rich media. Now everythin is being recoreded on a you tube challen (each executive seems to have their own you tube channell). Can Watson interpret the grahps, the spreadsheets. There is the whole questions. Then there is the other aspect that these computers can theoretically come up with new knowledge. How does that get disseminated. Can the computer publihs to the world that it is creating. (what would it look like for the computer to apply for grant funding). &lt;/p&gt;

&lt;p&gt;John mentioned the research that happened at Stanford that showed that AI can generate hypothesis. The collossus experiment is mentioned. &lt;/p&gt;

&lt;h1 id=&quot;some-general-discussion&quot;&gt; Some general discussion&lt;/h1&gt;

&lt;p&gt;A question come up on what are the metrics that will come out from the text and data mining world, what will be success? (I suggest that we indeed don’t have the answer to that question). &lt;/p&gt;

&lt;h1 id=&quot;now-we-are-going-to-group-these-themes-into-common-themes&quot;&gt; Now we are going to group these themes into common themes.&lt;/h1&gt;

&lt;p&gt;We are looking for people to standup and talk about what they think the main themses are. Here are some: &lt;/p&gt;

&lt;h3 id=&quot;machine-to-machine-and-machine-enabled&quot;&gt;Machine to Machine, and machine enabled.&lt;/h3&gt;

&lt;p&gt;Many items came up in this, from machine readable data, to the general issue of standards. Computational lingusitsics as an enabling technology. &lt;/p&gt;

&lt;h3 id=&quot;new-authoring-mechanisims&quot;&gt;New authoring mechanisims&lt;/h3&gt;

&lt;p&gt;From new authoring tools, to experiential data, and this leads in to big data. There is some discussion that ALMs and enrichment might fall under this category, but enrichement and metadtaa might be …&lt;/p&gt;

&lt;h3 id=&quot;enrichment-and-metadta-is-its-own-topic&quot;&gt;Enrichment and metadta is it’s own topic.&lt;/h3&gt;

&lt;p&gt;A better way to describe this is artefact enrichment. &lt;/p&gt;

&lt;h3 id=&quot;helping-the-human&quot;&gt;Helping the human&lt;/h3&gt;

&lt;p&gt;Helping the human at both ends, submissions systems that coulld help get the content in, the peer review process, the publication process, these are all pain points for authors and readers. Can this publisher to human interaction be made more efficient. &lt;/p&gt;

&lt;h3 id=&quot;b3b-vs-b2c-is-an-interesting-tension-the-author-as-the-new-customer-and-where-is-the-librarian&quot;&gt;B3B vs B2C is an interesting tension, the author as the new customer, and where is the librarian.&lt;/h3&gt;

&lt;p&gt;The individual is becoming more imporant (I mention APC and the rise of the social media as something that can make these complaints louder). Looking after the author in the way we have to gear up to is a different way to thinking about how to manage the business. Someone mentions the cost of geraing up to this is a hidden cost. &lt;/p&gt;

&lt;h2 id=&quot;howard-asks-about-media&quot;&gt; Howard asks about media&lt;/h2&gt;

&lt;p&gt;Is this an area that we just do? Has it become rote? I suggest that it has. &lt;/p&gt;

&lt;h2 id=&quot;headaches&quot;&gt; Headaches&lt;/h2&gt;

&lt;p&gt;I mention that 150 GB is a headache for me. Someone mentions conversions of small chunks of traditional written english or spanish content, and translating it to a local audio or video file that can be disseminated via smarphones, epscially in Afriac, across langages, in BRIC countries &lt;/p&gt;

&lt;p&gt;Someone mentions that the google translate widget was put on their platform. The usage is phenomenal - that’s really interesing to me. John Sack mentioned that the editor;s of the journals complained a few years ago as the quality was so bad. It was put on places like the aims and scope, and it has helped drive submissions. It is also used on the abstracts. (could one do a tranlstion of the gist of the aritlce, like the digest). It was not marketed as pure translation. IBM for the first time passed the point where they have more employees in India than in the US, and soon this will also be true for China. Nairobi is the latest place where IBM have a research lab - you go where the customers are, you go where the world is. If you did that 5 years ago, you might have thought that South Africa would have been the place to be. &lt;/p&gt;

&lt;p&gt;Comment on where is the growth in submissions are coming from - obviously Asia, &lt;/p&gt;

&lt;h2 id=&quot;google&quot;&gt; Google&lt;/h2&gt;

&lt;p&gt;Eefke mentioned that this is the first time for a while that Google has been mentioned. Howard mentions that google is changing. Knowledge graph is mentioned. The death of the UI is mentioned. Is google the Publisher UI now? It’s mentione dthat the UI can now speak to you, or drop a &lt;/p&gt;

&lt;h2 id=&quot;the-steam-gamings-platforms-is-mentioned&quot;&gt; The Steam gamings platforms is mentioned.&lt;/h2&gt;

&lt;p&gt;This allows games to be allowed to compete on a common platform. &lt;/p&gt;

&lt;h2 id=&quot;google-scholar&quot;&gt; Google Scholar&lt;/h2&gt;

&lt;p&gt;What will happen to google schoalr. The sentiment is taht this product is going to be dead in the water. &lt;/p&gt;

&lt;p&gt;Hmmm, my notes become a bit distracted at this point. There is a conversation about the death of the UI, being replaed by google, hooking into siri, into google now, selling that as a service. &lt;/p&gt;

&lt;p&gt;IBM person mentions the development of an ecosystem, they have just opned a Watson developers platform that helps move towards an ecosystem.  &lt;/p&gt;

&lt;p&gt;THere is a discussion of APIs. I’m going to stop talking now, I’ve talked a little bit too much today. There is the mention of STM being a place where these kinds of standards can emerge. &lt;/p&gt;

&lt;p&gt;Last year the hybrid reading experience was a trend last year. John mentions eLife lens as an experiment in the reading experience. The Elsevier person mentions that the reading experience is changing because of the rise of the PDF. He thinks that the tablet might kill the PDF. Howard things that the PDF has had a resurgance because the the PDF. &lt;/p&gt;

&lt;p&gt;Another trend from last year was the movement from the institution to the individual, and this year we are talking about the author. Someone raises the question of what do you get for your money if you are an author. If you were to sign up to Kudos, for example, who is going to pay for that - it’s said that publishers are currently paying for that, would funders pay for that in the future. The transactional stuff of how you watch money flow is difficult. For a hybird journal this is really complicated. There is also a thing about the various pots of money. &lt;/p&gt;

&lt;p&gt;Another trend from last year OA is still a hot topic. We are beginning to understand it better. Is there a place in the world for a common payment system for paying for OA. There was a hope that OAK could have done something, but it didn’t happen. The Ebsco’s and SWETS are possibly looking to move into that market. It might be the university that decides what system is going to be used. One mechanisim would be institutional payment accounts. This also comes back to the comment about authoring tools. &lt;/p&gt;

&lt;p&gt;I was unable to not talk any more, and I mentioned my idea around vendors havine a bigger capacity to do digital product development. The rise of more startups is also mentioned. &lt;/p&gt;

&lt;p&gt;(As a comment, looking over the discussion to date, it’s hard to view a few key actionables that will actually effect the industry. What do we d?). &lt;/p&gt;

&lt;p&gt;John Sack mentions that a lot of what we have up here is evolution from last year. One trend that John sees is that there are more startups. They are driving the conversation, they might not be making money, but they are driving the convesation. Open access is also driving this. &lt;/p&gt;

&lt;p&gt;There is a lot of change that has to come in education, and that is drving money into the system too. Talking about education, have there been discussions around the differnece in the role of scholarly material in education, rather than in the research context, for example K12, Professor who is teaching. There is huge growth in the budgets in education in Inida and China. &lt;/p&gt;

&lt;p&gt;Research data is mentioned again. We might think of the new ego-system, rather than an eco-system, in terms of our relationships with our authors. There is also the data citation component. &lt;/p&gt;

&lt;p&gt;We saw a bunch of startups around citation managmend, now about the authoring proces, and increasingly about the managment of the research data component. There is also the open data pressure from funding agencies. There is a growing need to handle data. Libraries are morphing into the experts on how to do grants, how to manage data, how to support the research process, and how to support researchers. &lt;/p&gt;

&lt;h1 id=&quot;we-are-moving-to-the-final-summary&quot;&gt; We are moving to the final summary.&lt;/h1&gt;

&lt;p&gt;We are that STM ecosystem. As an industry trend can see us collaborating more for the common good. The issue is raised, why can’t we standardise around submission systems?&lt;/p&gt;

&lt;p&gt;My one thought is that some of these issues are easier to deal with if you are an OA publisher (As Hpward says, we still have not solved the Machine to Macine MD issue - and I agree with that)&lt;/p&gt;

&lt;p&gt;Someone mentions that most of the revenue that comes from institutional subscriptions, the “transition” is going to be a multiyear tool.&lt;/p&gt;

&lt;p&gt;What are the trends and standards that are either dead now, or what are our predctions that have not matured. It would make for an intersting article or white paper. Eefke says that many of the startups that were mentioned in previous years have now been aqcuired, or are dead. &lt;/p&gt;

&lt;p&gt;How do you do innovation within the establishment. Startups have it easy. For larger publhsers, you always have to make some kind of jsutification to a set of people to whom your idea can never succeed. &lt;/p&gt;

&lt;p&gt;The issue of where data sharing used to be unknown in schoalry research. Holding on to your data is becoming no longer a culturally viable option (I think we are still behind on this, in that data sharing remains the exeption rather than the rule).&lt;/p&gt;

&lt;p&gt;Archives and the grey literaure, and content being mopped up from these archives, is an interesting trends. The feeling is that for publishers to stuff this content into dark archives will no longer cut it. We run the risk of getting excited by exiting stuff, but we have to think about this. There is some disagreement on this point. &lt;/p&gt;

&lt;p&gt;The increase in the amount of semantic information that is becoming avialabe is intersing. The growth of DOIs, it’s ending up in organisation that is not siloed, like crossref and ORCID. It is gong to be interesting to see waht else comes out from this. John mentions that it’s interesting that corssref becomming a hub is interesting. &lt;/p&gt;

&lt;p&gt;Jeremey says that we have a lot to learn, it’s early days, where these trends will take us, we don’t know. For publishers who are in transition, it is going to be a very interesing project. &lt;/p&gt;

&lt;p&gt;Standards are mentioned. 70 million articles having been managed at Portico shows that there are wildly different levels of quality, even within a single publisher. It’s exiting, but there is a lot of work.&lt;/p&gt;

&lt;p&gt;The transition to multiple devices is exiting, some preparatory work has happned, but there is a lot of work left. We can never more as fast as we would like.&lt;/p&gt;

&lt;p&gt;Howard says that the validation of all of this metadata is really important. There is a difference between good enought for a human and good enough for a machine. &lt;/p&gt;

&lt;p&gt;John mentions that social media has not been mentioned that much. Sharing tools were mentioned from the Elsevier guy. He says that it’s not a part of most platforms, but it’s a part of the life of most users. Someone mentions that the ussage they get from traffic come from social media has been really good. It’s driving full text downloads. You can do marketing campegins on top of this. &lt;/p&gt;

&lt;p&gt;The biggest oppportunities for catastopic disintermediation are right at the beginning and right at the end. At one end google, at the other end authoring tools. &lt;/p&gt;

&lt;p&gt;Collective responsability from us as publishers to do fraud detection is really important. We have to go after the abuse of science. He does not know how to handle that. As an industry wide group we need to go after that. For example when malicously incorrect articles are being sent. Pulling out missing clinical trials has been mentiond. Can you do analysis on anamolous looking data. There could be a question that could be takeld as an industry standard, like doing automatic checking of figures. It is mentioned that this is difficult, that COPE is a good way to tackle this after the fact, but it is reiterated that we want to capture these instances after the fact. &lt;/p&gt;

&lt;p&gt;What happens with societeis, OA is going to affect societies more in the next few years. &lt;/p&gt;

&lt;p&gt;The opportunity for linked data is mentinoed. Could this be used as a fraud detection tool, such as “this particular author does not seem to have enough connections to have done this reseracher”. An example is mentioned that a faculty discovered that their math faculty’s strengths were not what they thoguht they were.&lt;/p&gt;

&lt;p&gt;We get back to the chair, and his final comments. The key phrases he sees are “moving from B2B to B2C” and the label of moving to an “ego-driven system”. Many of the things we discussed last year we discussed today. One thing we didn’t really talk about this were Mendeley Readcube. We didn’t have a conversation about these sites this year - why is that. Do we see them as becoming part of our own platforms, are they still a threat? Perhaps the authoring mechanisims is an areas. It’s mentioned that these are more people to collaborate wiht, and to work with. If they can build technology that a publisher can use, then that’s great. Are they community driven? Does one of them appeal to specific communities. It’s mentioned that endnote also belongs in that space. And that concludes this afternoon. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Hidden In Plain Sight</title>
   <link href="http://partiallyattended.com/2013/12/02/hidden-handholds"/>
   <updated>2013-12-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/12/02/hidden-handholds</id>
   <content type="html">&lt;p&gt;I was bouldering yesterday. At my local block - a lump of granite embedded in the middle of shore ditch park. I’ve been climbing on this block pretty much since the week it was put in place. &lt;/p&gt;

&lt;p&gt;Yesterday I saw that a hold I’d never noticed had been chalked up. It’s a great hold, at about shoulder height. It fits that pads of two and a half fingers, and in spite of being quite small, it feels pretty positive. I don’t know if I’ll ever be able to use it, but the pony is that until yesterday is never even noticed it before.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://farm8.staticflickr.com/7289/11157837665_467888f889.jpg&quot; alt=&quot;http://farm8.staticflickr.com/7289/11157837665_467888f889.jpg&quot; title=&quot;handhold&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That’s one of the things I love about climbing at an area you know well. Even after years there are small little details of the rock that constantly reveal themselves. It might be the pattern the rain runoff makes, or subtle colours seen on a particular autumns evening when the light hits just so, or even a hold unnoticed for several years.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Setting up Vagrant, Librarian-Chef and Vagrant aws plugins on OSX Mavericks.</title>
   <link href="http://partiallyattended.com/2013/11/19/osx-mavericks-vagrant-librarian"/>
   <updated>2013-11-19T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/11/19/osx-mavericks-vagrant-librarian</id>
   <content type="html">&lt;p&gt;I have a new macbook pro. I want to install vagrant, chef and librarian, with the vagrant-aws plugins. I’m working on OSX Mavericks, and I want to get as clean an install as possible. For the most part I am also using the fish shell. This is what I’ve just run through over the last 20 minutes. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Install command line tools from the terminal&lt;br /&gt;
  &lt;code&gt;$ xcode-select --install&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next we are going to install homebrew, with homebrew we will install &lt;code&gt;rvm&lt;/code&gt; and with &lt;code&gt;rvm&lt;/code&gt; we will install ruby. The goal is to have a ruby avilable at &lt;code&gt;/usr/local/bin&lt;/code&gt; and to avoid using the system provided ruby, which is at &lt;code&gt;/usr/bin&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;install homebrew&lt;br /&gt;
  &lt;code&gt;$ ruby -e &quot;$(curl -fsSL https://raw.github.com/mxcl/homebrew/go)&quot;&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;update homebrew&lt;br /&gt;
  &lt;code&gt;$ brew doctor&lt;/code&gt;
  &lt;code&gt;$ brew update&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;$ brew doctor&lt;/code&gt; will do a healthcheck. As a result of running this I was reminded to re-order my &lt;code&gt;$PATH&lt;/code&gt; to point to &lt;code&gt;\usr\local\bin&lt;/code&gt; over ‘\usr\bin’.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Install prequisites for rvm&lt;br /&gt;
  &lt;code&gt;$ brew install autoconf automake libtool libyaml readline libksba openssl&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install &lt;code&gt;rvm&lt;/code&gt;&lt;br /&gt;
  &lt;code&gt;$ curl -L https://get.rvm.io | bash -s stable&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Install a ruby&lt;br /&gt;
  &lt;code&gt;$ rvm install ruby-2.0.0-p247&lt;/code&gt; &lt;br /&gt;
  &lt;code&gt;$ which ruby&lt;/code&gt; will now return something like &lt;code&gt;/Users/ian/.rvm/rubies/ruby-2.0.0-p247/bin/ruby&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;I use the &lt;a href=&quot;http://fishshell.com&quot;&gt;fish&lt;/a&gt; shell, and for some reason after intalling ruby with rvm the order of my &lt;code&gt;$PATH&lt;/code&gt; got rearranged, so I rest &lt;code&gt;\usr\local\bin&lt;/code&gt; to the front with &lt;br /&gt;
  &lt;code&gt;$ set PATH /usr/local/bin $PATH&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;OK, now we can try to install librarian with
  &lt;code&gt;$ gem install librarian-chef&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;This installs 31 gems on my system - fun! I immediatly tested this in a repo with a working &lt;code&gt;Cheffile&lt;/code&gt;, for a long running project that is ongoing withing &lt;a href=&quot;http://elife.elifesciences.org&quot;&gt;eLife&lt;/a&gt;. 
  &lt;code&gt;$ librarian-chef install&lt;/code&gt; &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This worked, and downloaded 21 &lt;code&gt;chef&lt;/code&gt; repositories, as expected. I’m feeling pretty good at this point.   &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Let’s also get vagrant. I downloaded the latest version of vagrant - &lt;a href=&quot;http://downloads.vagrantup.com/tags/v1.3.5&quot;&gt;version 1.3.5&lt;/a&gt;, and installed it via dmg. 
After this &lt;code&gt;$ which vagrant&lt;/code&gt; returns &lt;code&gt;\usr\bin\vagrant&lt;/code&gt;, and &lt;code&gt;$ vagrant -v&lt;/code&gt; returns &lt;code&gt;Vagrant 1.3.5&lt;/code&gt;.  &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Let’s install the aws-plugin for vagrant. We do this with &lt;br /&gt;
  &lt;code&gt;$ vagrant plugin install vagrant-aws&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That gets me &lt;code&gt;Installed the plugin &#39;vagrant-aws (0.4.0)&#39;!&lt;/code&gt;, yay!!. We still need to install chef, and check that vagrant up works on the project. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Spoton13</title>
   <link href="http://partiallyattended.com/2013/11/10/solo13-friday"/>
   <updated>2013-11-10T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/11/10/solo13-friday</id>
   <content type="html">&lt;p&gt;I managed to squeeze in a few hours on Friday attending the spoton conference in London. I’ve been at each one since 2008, and have  had the good fortune to present something at most of them. This time I had been asked to sit in on a panel to talk about elife’s policy around media relations, but as I was flying in that morning from an editorial board meeting held in Washington it was not clear to me that I would make it in time, so the fantastic &lt;a href=&quot;https://twitter.com/sciencescoops&quot;&gt;@sciencescoops&lt;/a&gt; (Jennifer Mitchell) represented for eLife in my place. &lt;/p&gt;

&lt;p&gt;There was a strong tail wind that brought us early to Heathrow, and I managed to make it to the conference in time to catch the end of Salvatore Miele’s keynote. &lt;/p&gt;

&lt;p&gt;As with last year, I was time-sharing the conference with my wife, so I only attended on the Friday. I heard that Saturday was as least as good as the day before, all in all a great two day meeting.  &lt;/p&gt;

&lt;p&gt;I had quite a few highlights during the day. the data and literature session was fascinating - I’ll write up about that later this week. &lt;/p&gt;

&lt;p&gt;It was great catching up with some folk from PLOS, and there were a couple of good hallway conversations about the state of software to support an open publishing infrastructure. &lt;/p&gt;

&lt;p&gt;I had a good chat with the founder of colwiz, whom I’d not had the pleasure of meeting before. &lt;/p&gt;

&lt;p&gt;The session on starting a revolution was phenomenal, I we’ll remember Stephen Curry back in his pre blogging days of 2008, back  when events were being  co-hosted on second life, and google wave was about to be the new new. &lt;/p&gt;

&lt;p&gt;By far my favourite aspect of the day was
seeing all of the unfamiliar faces. I’m an old hand at the conference and perhaps three years ago it might have started to begin to seem a bit cliquey.  I didn’t know most of the people there this year, and that was fantastic.  It tells me that those of us who got into this space early were on the right track, and even though the questions and problems we are tackling are so much bigger than any one of us,  there are a growing mass of people ready to engage with those issues. &lt;/p&gt;

&lt;p&gt;It will take a community, and it will take an ongoing shift in practice amongst all of science, the solutions to dozens of collective action problems dependant on is flipping behaviour.  &lt;/p&gt;

&lt;p&gt;In spite of that there are some individuals who have moved the needle through individual effort and on that note I want to mention my friend &lt;a href=&quot;https://twitter.com/LouWoodley&quot;&gt;Lou Woodley&lt;/a&gt;. Lou announced her upcoming departure from Nature. I had the great pleasure of working closely with her there from around 2008 - 2010. I’m sure she will join the long list of people who are doing amazing things now, but who also used to work at Nature at some point in the past. I have one very specific wish for her in relation to spoton 2014, and future such events. I dearly hope that she can attend just as a participant and panelist, rather than as organiser. There are very few people out there with the depth of experience which bridges the physical and the digital, the academy and the polis, the corporate and the community, as she has, and it would be fantastic to sit in on a session to hear her thoughts on the present and future of science communication. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Vertigo</title>
   <link href="http://partiallyattended.com/2013/11/06/vertigo-review"/>
   <updated>2013-11-06T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/11/06/vertigo-review</id>
   <content type="html">&lt;p&gt;This post was mostly written earlier this summer, in the days after I had finished reading a book. &lt;/p&gt;

&lt;p&gt;I’ve just finished reading W. G. Seabald’s &lt;a href=&quot;http://www.amazon.co.uk/Vertigo-W-G-Sebald/dp/0099448890&quot;&gt;Vertigo&lt;/a&gt;. This is the second of his books that I’ve read over the last decade, and it is as haunting as the first. The first of his I read was &lt;a href=&quot;http://www.amazon.co.uk/The-Rings-Of-Saturn-Sebald/dp/0099448920/ref=tmm_pap_title_0?ie=UTF8&amp;amp;qid=1378290886&amp;amp;sr=1-1&quot;&gt;The rings of Saturn&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Towards the closing pages of the book I was filled with a great expectation that I might possibly experience some deep revelation. The way he cast his prose against the timbre of reality made me feel from moment to moment that some veil might be drawn aside. &lt;/p&gt;

&lt;p&gt;Most of my reading is snatching pieces of flotsam out of the constant ocean of content we have ever expanding in front of us. The times when I sat in a state of reflection seem to have receded, and it seems to me that I am always going somewhere, thinking ahead, or fast with the regrets of the moments just past. &lt;/p&gt;

&lt;p&gt;I’m sitting writing these notes in a town that I have orbited for the last ten years, a place that holds many memories and hopes. A place that I find my mind wandering too, perhaps too often. &lt;/p&gt;

&lt;p&gt;The fabric of what Seabald writes about - memory, place, in some sense the  struggle to understand the very possibility of existence, these themes hold up well tonight. I left my family this morning, and for the next few hours I am a stranger, revisiting a part of his own past.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;em&gt;postscript&lt;/em&gt; On returning from Switzerland with my wife and son, in the guest bedroom of her parents house I found my copy of &lt;a href=&quot;http://www.amazon.co.uk/The-Rings-Of-Saturn-Sebald/dp/0099448920/ref=tmm_pap_title_0?ie=UTF8&amp;amp;qid=1378290886&amp;amp;sr=1-1&quot;&gt;The Rings of Saturn&lt;/a&gt; lying on a shelf. I’ve been in that room many times in the last number of years, and passed over the book. I must have left it there sometime around our honeymoon. It has a bookmark nestled inside, one that was cut out from a transparency I had prepared years earlier, little cells, each containing either a simulation of water flowing around a cube, or the outflows of gasses from the centre of violent galaxies. I can no longer quite recall. Each cell now, more like a fragment of a memory, jogging the mind, a pattern at once distantly familiar, and at the same time foreign enough that I no longer have any hope of being sure where it came from. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>PLOS ALM 13 day 2</title>
   <link href="http://partiallyattended.com/2013/10/17/plos-alm-13-day2"/>
   <updated>2013-10-17T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/10/17/plos-alm-13-day2</id>
   <content type="html">&lt;h1 id=&quot;connecting-alm-and-literature&quot;&gt;Connecting ALM and Literature&lt;/h1&gt;

&lt;p&gt;As I took part in the first session I don’t have many notes from it. I’ve posted the &lt;a href=&quot;https://speakerdeck.com/ianmulvany/connecting-data-and-literature&quot;&gt;slides from my talk&lt;/a&gt;, and I’ll write up some more on those in due course. For me the standout talk of the session, if not the entire meeting, was from [Jevin West][jw] who talked about using networked ranked data to provide recommendations. The algorithms his group are working on are being tested on [SSRN][ssrn], and will be rolled out to PLOS. The first set of tests indicated that recommendations driven by this algorithm are out-preforming a random recommendation, and out-preforming a collaborative-filter based approach. From discussion the previous day it looks like the emergence of reader driven metrics might also provide opportunities to explore how to make not only recommendations on the existing literature, but also how to predict future success. In particular that Post-Docs and PhD students were found to read more highly cited literature than other demographics in Mendeley begs the question, could we identify a cohort amongst these groups that reads papers before they become highly cited. Aside from those speculations, the work that Jevin presented was both visually appealing, and possibly useful. The platform he is working on is open, and is ready to be tried by you, dear interested publisher. &lt;/p&gt;

&lt;p&gt;[jw]: 
[ssrn]:&lt;/p&gt;

&lt;p&gt;Lisa Schiff and Carly Strasser talked about the intricacies of introducing ALMs into the context of an organization that has a high bureaucratic overhead. It was nice to be reminded that the sacred DOI only covers a set of the scholarly record. ARCs are in widespread use, and as a community we should get on top of that. I was very impressed by Carly’s passion to bring change to this system, and share her hopes that we can make things better. &lt;/p&gt;

&lt;h1 id=&quot;putting-alm-in-context&quot;&gt;Putting ALM in Context&lt;/h1&gt;
&lt;p&gt;## Amy Brand	Faculty appointments and the record of
scholarship&lt;/p&gt;

&lt;p&gt;Amy wrote on this topic in eLife in &lt;a href=&quot;http://elife.elifesciences.org/content/2/e00452&quot;&gt;Point of view: Faculty appointments and the record of scholarship&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Harvard only introduced tenure track about 7 years ago. They now have a real commitment to tenuring junior faculty. They do a lot of faculty coaching and mentoring. &lt;/p&gt;

&lt;p&gt;She only heard about the San Francisco &lt;a href=&quot;http://am.ascb.org/dora/&quot;&gt;Declaration on Research Assessment&lt;/a&gt; a few days ago - but this mirrors a lot of what Harvard does in terms of faculty appointment.&lt;/p&gt;

&lt;p&gt;Harvard only gives tenure to people who have a Harvard degree. If you come from outside of Harvard and they want to give out tenure, then they give you an honorary degree. &lt;/p&gt;

&lt;p&gt;The main thing that flows through the system is the “Case statement” - a dossier. &lt;/p&gt;

&lt;p&gt;The works of scholarship that are getting featured in the CV is getting diverse - including software and public communications, which also includes artifacts such as blog posts. &lt;/p&gt;

&lt;p&gt;The most important part is the peer review, and the peer evaluations - that come from 10 - 15 independent experts, and confidential letters from every member of the faculty to the Dean.&lt;/p&gt;

&lt;p&gt;They do this analysis in a comparison set, where they look at a set of scholars together. One of the key things is field definition. They look at citations to papers - journal name is not listed. This citation report is not extremely important, they just want to know if the person is in range, it’s only interesting if it indicates that there are any outliers. I’ll say that again. For the citation record they don’t look at the journal names. They only use citations to help understand whether the candidate is operation within the normal expected range within their discipline, and in comparison to their peers. It’s used as a sanity check, and not insanely used as the key piece of evidence.&lt;/p&gt;

&lt;p&gt;ORCID is really important. They want to extend the “on-grid” record. They want service info to be included in the ORCID record. &lt;/p&gt;

&lt;p&gt;Change will happen in an institution like Harvard if it is driven from the faculty. &lt;/p&gt;

&lt;p&gt;Peer review of people and papers tend to be closed systems. There is high trust, known expertise, but closed systems. In open systems there is less trust, but the actors can be identified, and that’s an opportunity. &lt;/p&gt;

&lt;h2 id=&quot;mike-taylorthe-many-faces-of-altmetrics-mapping-the-social-reach-of-research&quot;&gt;Mike Taylor	The many faces of altmetrics: mapping the social reach of research&lt;/h2&gt;

&lt;p&gt;Mike is with &lt;a href=&quot;labs.elsevier.com&quot;&gt;labs.elsevier.com&lt;/a&gt;. He has been working on Altmetrics for the last two years. He is looking at the social reach of research. &lt;/p&gt;

&lt;p&gt;He finds it helpful to explain ALMs simply but putting them into low-judgment buckets of data classes. This helps to communicate internally. His buckets are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Social activity  &lt;/li&gt;
  &lt;li&gt;Component re-use  &lt;/li&gt;
  &lt;li&gt;Scholarly commentary   &lt;/li&gt;
  &lt;li&gt;Scholarly activity   &lt;/li&gt;
  &lt;li&gt;Mass Media mentions   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;He is trying to see if these buckets can be tied against the different areas in which ALMs can be applied. It turns out that there are lot’s of areas of research needed. Mike shows a great graph looking at different type of activity. &lt;/p&gt;

&lt;p&gt;A few years ago we were were in a black hole. A paper would be published and we would wait a few years before citations coming in. ALM data is now starting to sprinkle some light into that darkness, but we need a lot more data, the volume of papers with ALM data remains low. &lt;/p&gt;

&lt;p&gt;We need more data points, more buckets. &lt;/p&gt;

&lt;p&gt;He had a look at PR notices going out. Many don’t have links to the primary research. Government documents are worse. &lt;/p&gt;

&lt;p&gt;Mike mentions Geo Location to research - that’s the first mention of that idea across the three days so far. &lt;/p&gt;

&lt;p&gt;Not all buckets are equal. &lt;/p&gt;

&lt;p&gt;If research gets picked up in social networks it often drops it’s formal name, gets known by a nickname, happens in real time. As it progresses through these networks, the more the name changes and evolves, the less likely that it will continue to be linked back to the original paper. &lt;/p&gt;

&lt;h2 id=&quot;juan-alperinare-almsaltmetrics-propagating-global-inequality&quot;&gt;Juan Alperin	Are ALMs/altmetrics propagating global inequality?&lt;/h2&gt;

&lt;p&gt;Juan is talking about the potential dangers of ALMs. This is a barnstorming talk. One of the other stand out highlights of the conference. I’m embarrassed that I didn’t take notes, I must have been too engaged. TL;DR we have to be careful not to fuck up how we structure these systems to not leave the global south behind. We are building these tools through the lens and web of the affluent North. Just go look at his &lt;a href=&quot;https://speakerdeck.com/jalperin/altmetrics-propagating-global-inequality&quot;&gt;slide deck&lt;/a&gt; now. &lt;/p&gt;

&lt;h1 id=&quot;expanding-the-breadth-of-alms&quot;&gt;Expanding the breadth of ALMs&lt;/h1&gt;

&lt;h2 id=&quot;eva-amsen-the-metrics-of-public-referee-reports&quot;&gt;Eva Amsen The metrics of public referee reports&lt;/h2&gt;

&lt;p&gt;She is going to talk about a product that doesn’t exist yet - ALMs for referee reports. F1000 research uses Cross Mark to link versions of the article together. Great slide on the history of open peer review in the literature. If you are accused of being a predatory journal, having open reviews really helps. &lt;/p&gt;

&lt;p&gt;They are providing a 50% reduction in article processing fees on any article that is submitted in the next year, for researchers who do a review for them - smart!.&lt;/p&gt;

&lt;p&gt;When they asked their community what feedback they had - they were asked for badges, metrics and making the reports “citable”.&lt;/p&gt;

&lt;p&gt;Is there anything that we can standardize about how we display referee reports? That would allow for aggregation of report data across different journals.&lt;/p&gt;

&lt;p&gt;Would a referee report metric affect the ALM metric? &lt;/p&gt;

&lt;p&gt;If you are a referee of an article that is very popular, does that credit get to rub off on you? - we could totally do this in eLifee. &lt;/p&gt;

&lt;h2 id=&quot;martin-fenner--jennifer-songbuilding-for-the-future-plos-alm-application&quot;&gt;Martin Fenner &amp;amp; Jennifer Song	Building for the future: PLOS ALM application&lt;/h2&gt;

&lt;p&gt;They use vagrant to get the PLOS ALM app running. They have a feature that tracks health of the calls to external API calls. &lt;/p&gt;

&lt;p&gt;They have integrated ALM scores into search results page of PLOS. I got to play with the ALM app over the weekend, and was able - with Martin’s help - to setup an instance with eLife DOIs. We will probably roll that out permanently over the next few weeks. &lt;/p&gt;

&lt;h2 id=&quot;gregg-gordonthe-real-impact-of-alms&quot;&gt;Gregg Gordon	The real impact of ALMs&lt;/h2&gt;

&lt;p&gt;They have about 240k authors in the library. They have about 500k papers, and are getting about 70k papers per year. They are getting to the point where they were getting more revisions happening per day, than new submissions - shows that this is a corpus of living documents, they go into SSRN and then they evolve there. &lt;/p&gt;

&lt;p&gt;There are a lot of different metrics out there, their first metric was Download. They spend between 50 - 100k per year verifying downloads. &lt;/p&gt;

&lt;p&gt;There is trust in the systems, and authors are now using these downloads as a proxy to look at other factors of impact.&lt;/p&gt;

&lt;p&gt;You see gaming everywhere, you just have to deal with it. They have an internal fraud index report. &lt;/p&gt;

&lt;p&gt;They created CiteReader within SSRN. They have introduced eigenmetrics into their system. &lt;/p&gt;

&lt;p&gt;Get the book - picture cook see make eat - a different interface for recipes. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>PLOS ALM 13, day1</title>
   <link href="http://partiallyattended.com/2013/10/16/plos-aml-13-day1"/>
   <updated>2013-10-16T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/10/16/plos-aml-13-day1</id>
   <content type="html">&lt;h2 id=&quot;cameron-neylon---introduction--welcome&quot;&gt; Cameron Neylon - Introduction &amp;amp; Welcome&lt;/h2&gt;

&lt;p&gt;Interesting - this is the first PLOS ALM meeting that is a “normal” scheduled presentation. Time is going to be tight. &lt;/p&gt;

&lt;h2 id=&quot;pete-binfield-alm-looking-back-moving-forward&quot;&gt;Pete Binfield ALM: Looking back, moving forward&lt;/h2&gt;

&lt;p&gt;A large chunk of OA does not select for impact - this is why ALMs are key for this space. PLOS didn’t invent ALMs - Frontiers were doing it a little ahead of PLOS’s launch. Web of science didn’t tell PLOS until 2010 that PLOS one was being tracked for an impact factor. &lt;/p&gt;

&lt;p&gt;People are quoting ALMs in their resumes for applying to be on the editorial board on PeerJ! &lt;/p&gt;

&lt;p&gt;Steve Pettifair claims ALMs have helped him to get tenure. &lt;/p&gt;

&lt;p&gt;The big thing that is missing is that we have not provided mechanisms to provide readers with recommendations. Filtering mechanisms for ALMs have not been well developed yet. &lt;/p&gt;

&lt;p&gt;There has been a period of talking to ourselves, but there seems to a broader interest now. &lt;/p&gt;

&lt;p&gt;Why have publishers not yet improved on the display of the PLOS ALM data?&lt;/p&gt;

&lt;p&gt;ALMs were built on the assumption that there is a pool of data available via APIs, but already in the last few years a number of sources have already hit the deadpool. (We need to own local copies of our own ALM data, as a publisher - really really important). &lt;/p&gt;

&lt;p&gt;Filtering tools were on the backlog from day one - but not yet built. &lt;/p&gt;

&lt;h1 id=&quot;best-practices-and-standards&quot;&gt;Best Practices and Standards&lt;/h1&gt;

&lt;h2 id=&quot;todd-carpenter---niso-altmetrics-project&quot;&gt; Todd Carpenter - NISO altmetrics project&lt;/h2&gt;

&lt;p&gt;Probably best to see my notes that I &lt;a href=&quot;http://partiallyattended.com/2013/10/16/niso-alm-standardisation/&quot;&gt;posted&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;scott-chamberlain---programmatic-access-for-altmetrics&quot;&gt; Scott Chamberlain - Programmatic access for Altmetrics&lt;/h2&gt;

&lt;p&gt;Works with &lt;a href=&quot;http://ropensci.org/&quot;&gt;rOpenSci&lt;/a&gt; - creates open software to make science better. &lt;/p&gt;

&lt;p&gt;Mentions &lt;a href=&quot;http://raml.org/&quot;&gt;raml.org&lt;/a&gt; - a markdown file for creating an API. I’ve not heard about this before, sounds very interesting. &lt;/p&gt;

&lt;h2 id=&quot;kaitlin-thaney-metrics-for-web-native-science&quot;&gt;Kaitlin Thaney Metrics for web-native science&lt;/h2&gt;

&lt;p&gt;This was a great talk, but I as I’m quite familiar with a lot of the topics that Kaitlin was discussion, I ended up working on my own slides during this talk. &lt;/p&gt;

&lt;h2 id=&quot;geoffrey-bilder---crossref-metadata-and-services-in-the-service-of-alms&quot;&gt; Geoffrey Bilder - CrossRef metadata and services in the service of ALMs&lt;/h2&gt;

&lt;p&gt;Geoff has got to the point where he has started to caution people about the use of DOIs, there is a bit of a cargo cult growing around this. &lt;/p&gt;

&lt;p&gt;Brand is important - Geoff does the thing with showing a blacked out paper, we all recognize it.  &lt;/p&gt;

&lt;p&gt;He says that DOIs are beginning to gain that type of branding. By and large, when we encountering DOIs we tend to think of them as scholarly entities - but every DVD in the world now includes a DOI - these are just being used as a registry, DOIs may escape into the wild. &lt;/p&gt;

&lt;p&gt;DOIs are not an arbiter of quality - some articles have two DOI’s, one is the author copy and one is the publisher copy. &lt;/p&gt;

&lt;p&gt;search.crossref.org has had a nice facelift - it also has a REST api. &lt;/p&gt;

&lt;p&gt;Crossref has citations in their metadata, and an increasingly large number of publishers are starting to do this. They are collecting funder information via fundref, the funder taxonomy is available under a CC0 license. They are increasingly including license information in the form of URIs. They are gathering ORCID information too. Abstracts are starting to be distributed via JATS compatible abstracts (we should do this from within eLife). &lt;/p&gt;

&lt;p&gt;They are starting to gather patent info for any patent that cites a paper. &lt;/p&gt;

&lt;p&gt;They are starting to look at reverse lookup service for referrals via DOI. (some people played with some of this data at the data challenge hackday on the following Saturday, and it looks very promising and interesting).&lt;/p&gt;

&lt;p&gt;I really like the distinction between persist-able and persistent identifier. There is nothing intrinsically persistent about a DOI, it’s intrinsically redirect-able. Persistent doesn’t mean that something will be around forever, but rather that it’s stubborn. &lt;/p&gt;

&lt;h1 id=&quot;scholarly-research-on-alm&quot;&gt;Scholarly Research on ALM&lt;/h1&gt;

&lt;h2 id=&quot;william-gunn---research-assessment-using-mendeley-readership-data&quot;&gt;William Gunn - Research assessment using Mendeley readership data&lt;/h2&gt;

&lt;p&gt;William is going to talk about the Mendeley data set. William talks about wanting to measure units of innovation and impact (I think this is one use cases for ALMs, but I think other use cases, such as domain mapping, are also pretty interesting).&lt;/p&gt;

&lt;p&gt;One of the more interesting discussions I’ve had so far at the meeting was last night with William talking about the reproducibility initiative that he is working on with Elizabeth Iorns from &lt;a href=&quot;https://www.scienceexchange.com/&quot;&gt;ScienceExchange&lt;/a&gt;.  You can read more about that &lt;a href=&quot;https://www.scienceexchange.com/reproducibility&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;zohreh-zahedi---what-is-the-impact-of-the-publications-read-by-the-different-mendeley-users-could-they-be-considered-as-signals-of-future-impact&quot;&gt;Zohreh Zahedi - What is the impact of the publications read by the different Mendeley users? Could they be considered as signals of future impact?&lt;/h2&gt;

&lt;p&gt;It is fantastic to see the ALM community starting to bring in researchers from the bibliometrics community. Anything that we can have that can help with us to understand the robustness of ALMs can only help. They ran this study against 20k randomly selected documents, and then with 200k publications. &lt;/p&gt;

&lt;p&gt;This talk This is research in progress, but the answer seems to be that there are advantages to using readers over citations, and the trend is that post-docs and phd students read more highly cited papers than professors. Further testing needs to be done. &lt;/p&gt;

&lt;h2 id=&quot;ehsan-mohammadi---mendeley-readership-altmetrics-for-clinical-medicine-and-engineering&quot;&gt; Ehsan Mohammadi - Mendeley readership altmetrics for clinical medicine and engineering&lt;/h2&gt;

&lt;p&gt;He was unable to get a visa to come to the US. Stefanie will give Ehasn’s presentation instead. There are a number of bibliometritians looking at altmetrics, at the recent bibliometrics conference there were two full sessions on this. This is another talk that compares mendeley reader data to citations in clinical medicine. &lt;/p&gt;

&lt;p&gt;There is a significant correlation between Mendeley readers and citations. Cancer his the highest correlation of 0.6. Some fields have a lower correlation, but at some point over the conference it was mentioned that a lower correlation in clinical fields might be expected, where doctors do read, but publish less, and so in a field like that Mendeley may be capturing impact that is not visible through citation counts. &lt;/p&gt;

&lt;h1 id=&quot;stefanie-haustein---empirical-analyses-of-scientific-papers-and-researchers-on-twitterresults-of-two-studies&quot;&gt;Stefanie Haustein - Empirical analyses of scientific papers and researchers on Twitter: Results of two studies&lt;/h1&gt;

&lt;p&gt;I think this is similar to the talk that Stefaine gave yesterday. They looked at a large scale analysis of tweets on 1.4M articles from PMC, and they also looked at a small scale analysis of 32 astronomers who are active on twitter. &lt;/p&gt;

&lt;p&gt;They divided papers into four classes, based on low vs high coverage of documents from within a disciple against high vs low correlation with citations. &lt;/p&gt;

&lt;p&gt;The overall correlation of twitter was low - 0.1, with a 9% coverage of the literature. &lt;/p&gt;

&lt;p&gt;“Penis” papers get highly tweeted. (on the topic of tweets, the comment from Euan yesterday is interesting to keep in mind - that authors &lt;em&gt;love&lt;/em&gt; to read the actual tweets about their papers).&lt;/p&gt;

&lt;p&gt;The in-depth study was also interesting. Those who do not publish, tweet regularly. Those who publish frequently don’t tweet frequently. There is a negative correlation between the number of tweets and the number of publications. &lt;/p&gt;

&lt;p&gt;What this tells us is that tweets and followers are definitely a different measure to citations and standard citation metrics. &lt;/p&gt;

&lt;p&gt;Overlap between phrases in abstracts and twitter is pretty low. This means that 4.1% of tweets are tweeting bits of abstracts - this seems low, but of the 100 most frequently used terms in abstracts, most of these terms do make it to twitter. (So either tweets are having parallel conversations to the abstracts, or a using a very different shorthand to refer to abstracts.)&lt;/p&gt;

&lt;h1 id=&quot;reporting-on-alm&quot;&gt; Reporting on ALM&lt;/h1&gt;

&lt;h2 id=&quot;andrea-michalek---alternative-metrics-in-practice&quot;&gt; Andrea Michalek - Alternative metrics in practice&lt;/h2&gt;

&lt;p&gt;I really like the direction that this product is heading in. &lt;/p&gt;

&lt;h2 id=&quot;adam-dinsmore---an-exploratory-review-of-plos-alm-reports-a-funders-perspective&quot;&gt; Adam Dinsmore - An exploratory review of PLOS ALM Reports: a funder’s perspective&lt;/h2&gt;

&lt;p&gt;There is a great example of Wellcome looking at ALM data for evaluating one of their researchers. They used the PLOS ALM reports tool. Great example about looking at the people who tweeted about a paper on alcohol abuse. &lt;/p&gt;

&lt;p&gt;Institutional identifiers would help the Trust. &lt;/p&gt;

&lt;h2 id=&quot;juan-alperin---visualizing-alms-in-d3js&quot;&gt; Juan Alperin - Visualizing ALMs in d3.js&lt;/h2&gt;

&lt;p&gt;This talk could be very interesting for how we chose to visualize ALMs in the future on eLife. eLife is also using the D3 javascript library.&lt;/p&gt;

&lt;p&gt;Does not like:&lt;br /&gt;
- monotonically increasing numbers. For a reader it’s harder to see what the actual usage is over time. &lt;br /&gt;
- a table of a lot of numbers is hard to use.&lt;br /&gt;
- lot of prominence to the sources is not so useful.&lt;br /&gt;
- the doughnut is not helpful for the reader - you are only guided by the number.&lt;br /&gt;
- the line in the total-impact metric only tells you one number.&lt;br /&gt;
- badges from impact story are giving the you the same percentile info.&lt;br /&gt;
- does not like squeezing the three types of data into one view - you can’t follow the pdf trend-line.&lt;br /&gt;
- XML data does not add much value.  &lt;/p&gt;

&lt;p&gt;Does like:&lt;br /&gt;
- having a reference set.&lt;br /&gt;
- likes being able to get more details from altmetric - being able to see the individual tweets.&lt;br /&gt;
- does like the non-cumulative views.  &lt;/p&gt;

&lt;p&gt;His visualization tries to get to the following principles:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://jalperin.github.io/almviz/&quot;&gt;example&lt;/a&gt;, &lt;a href=&quot;https://github.com/jalperin/almviz&quot;&gt;repo&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;has a number for the source.  &lt;/li&gt;
  &lt;li&gt;has a sense of history and not giving you a cumulative view, I like the weekly/yearly switch.  &lt;/li&gt;
  &lt;li&gt;on the axis the only thing that is showing on the y-axis is the maximum value to drive a sense of history.    &lt;/li&gt;
  &lt;li&gt;being able to rollup into different time levels.  &lt;/li&gt;
  &lt;li&gt;few labels - no grid lines.  &lt;/li&gt;
  &lt;li&gt;having a tool-tip with hover over the data point.  &lt;/li&gt;
  &lt;li&gt;graphs are the same size, but stacked on top of each other, and scaled accordingly.&lt;br /&gt;
    &lt;ul&gt;
      &lt;li&gt;different data sources have different granularity, so it would not be simple to make the graphs switch to different   granularities simultaneously &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;when there is a small number of events you need to be able to turn off the graphs.  &lt;/li&gt;
  &lt;li&gt;being able to distinguish between a 0 count, and not having any data for that time.  &lt;/li&gt;
  &lt;li&gt;be like to be able to turn on and turn off sources, rearrange the stacking.   &lt;/li&gt;
  &lt;li&gt;should be able to go to a page that contains a more detailed article profile.   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They are going to roll this out to all of the journals that implement OJS and that sign up for the ALM service. They are going to run the PLOS ALM tool.&lt;/p&gt;

&lt;h1 id=&quot;heather-piwowar---the-altmetrics-cv-opportunities-and-challenges-also-featuring-jason-priem&quot;&gt; Heather Piwowar - The altmetrics CV: opportunities and challenges (also featuring Jason Priem)&lt;/h1&gt;

&lt;p&gt;They think that if you give researchers ALMs then you are putting science back in the hands of scientists (I guess rather than having it in the hands of ISI).&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>NISO ALM standardization workshop</title>
   <link href="http://partiallyattended.com/2013/10/16/niso-alm-standardisation"/>
   <updated>2013-10-16T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/10/16/niso-alm-standardisation</id>
   <content type="html">&lt;p&gt;This was a one day workshop discuss the creation of standards around Article Level Metrics. NISO has a &lt;a href=&quot;http://www.niso.org/publications/isq/2013/v25no2/nr1&quot;&gt;grant&lt;/a&gt; from the Sloan foundation to look into this, and this event was the first of three planned information gathering events. My own opinion on this topic has changed over the past year, evolving from being strongly opposed, to broadly supporting the idea of building some kind of standard or best practice for the field. There is currently a tight knit community of people working on ALMs, and we currently internally know that we are all &lt;code&gt;doing the right thing&lt;/code&gt; (TM), however as interest in the space grows the close community is not guaranteed to remain fully aware of everything that is happening in the space. In addition there is a desire in some sectors - librarian, institutional and funders - to get some clarity on what it all means. These two things make me feel that if not a standard, then at least an agreed set of best practices, will help with adoption. I could imagine the following conversation:&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Funder one&lt;/em&gt; - I’m using the PLOS alm explorer tool.&lt;br /&gt;
&lt;em&gt;Funder two&lt;/em&gt; - that looks interesting, but our administration would like some guarantee that it’s not totally unreliable.&lt;br /&gt;
&lt;em&gt;Funder one&lt;/em&gt; - well. the way they gather sources is transparently described, and they follow industry best practice, for what it’s worth.&lt;br /&gt;
&lt;em&gt;Funder two&lt;/em&gt; - oh, Ok, well, I’ll have a look then, and see if it’s helpful.   &lt;/p&gt;

&lt;p&gt;With that preamble in mind here are my simplified notes from the meeting. &lt;/p&gt;

&lt;p&gt;Generally the introduction is fairly standard. By far the most interesting point of discussion is whether this is the right time to do this. The underlying data is still shifting, and the tools of maximal utility are still to emerge, but if we have an attack into the mindset that needs standards, then I think this effort can be a good one, as long as cautionary aspects that I worry about can be allayed. &lt;/p&gt;

&lt;p&gt;Todd says that he wants the community (scholars) to be able to trust metrics that the ALM community provide in the same way that they currently trust the impact factor. &lt;/p&gt;

&lt;h1 id=&quot;lightening-talks&quot;&gt;Lightening talks&lt;/h1&gt;

&lt;h2 id=&quot;euan-adie---altmetriccom&quot;&gt;Euan Adie - Altmetric.com&lt;/h2&gt;

&lt;p&gt;Working with 24 publishers. They get about 2M requests to the API per day. &lt;/p&gt;

&lt;p&gt;Publishers tend not to care too much about the “metrics”, but authors really like, especially being able to see specific tweets.&lt;/p&gt;

&lt;p&gt;Generally the reaction is very positive, even when Altmetric misses stuff.&lt;/p&gt;

&lt;p&gt;Best CTR is 1% for a badge that is listed under the article title. Other links to info about the ALM info of an article has a lot lower CTR. &lt;/p&gt;

&lt;p&gt;Biggest blocker to adoption on behalf of publishers is it can be scary, what if there is no conversation happening around your article?&lt;/p&gt;

&lt;h2 id=&quot;michael-habib---elsevier&quot;&gt;Michael Habib - Elsevier&lt;/h2&gt;

&lt;p&gt;Looking back to May 2008 - Michael shows some data from a survey, back then about 50% of respondents to the survey said web 2.0 would play a key role in 5 years time (1800 respondents, mostly from researchers and librarians). &lt;/p&gt;

&lt;p&gt;1 year ago they selected 54k random samples from Scopus. They got 3k respondents. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;82% knew IF  &lt;/li&gt;
  &lt;li&gt;43% knew H-index  &lt;/li&gt;
  &lt;li&gt;10% journal usage factor  &lt;/li&gt;
  &lt;li&gt;1% knew about altmetrics   &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is really really interesting. Also of interest is that metrics with the highest awareness is also considered to be the most useful. &lt;/p&gt;

&lt;p&gt;People under 35 liked more metrics. Older people (over 65), don’t like altmetrics. &lt;/p&gt;

&lt;p&gt;Africa and developing nations are more open to altmetrics. Europe and USA like them less. &lt;/p&gt;

&lt;h2 id=&quot;stefane-haustein&quot;&gt;Stefane Haustein&lt;/h2&gt;

&lt;p&gt;Tweets don’t correlate well with citations. &lt;/p&gt;

&lt;h2 id=&quot;greg-gordon---ssrn---talking-about-trust&quot;&gt;Greg Gordon - SSRN - talking about Trust&lt;/h2&gt;

&lt;p&gt;Thinks that gaming is the bogey man in the story that could erode trust in ALMs. (I think data quality is the current biggest issue). &lt;/p&gt;

&lt;p&gt;How do you solve the problem before you get stuck with the idea that everything is bad. &lt;/p&gt;

&lt;p&gt;He cites research from someone. One of the main concerns with Altmetrics is that people just don’t know what they are, they are unfamiliar with them. There is also an information sharing issue. But a lot of the actual metrics are easily understood - a download - a like. &lt;/p&gt;

&lt;h2 id=&quot;heather-piwower---impact-story&quot;&gt;Heather Piwower - Impact Story&lt;/h2&gt;

&lt;p&gt;“we bleed for each data point”. If people don’t get credit for the data that they create, then they won’t share that data. &lt;/p&gt;

&lt;h2 id=&quot;william-gunn&quot;&gt;William Gunn&lt;/h2&gt;

&lt;p&gt;Mendeley have many different kinds and variants of a work uploaded to Mendeley. The challenge of keeping track, de-duplicating and keeping tracks of different documents has been where a majority of their work has gone into in the last year. FWIW I can attest to the fact that we had issues when I was with Mendeley, back in 2010 - 2012. &lt;/p&gt;

&lt;h2 id=&quot;peter-brantley---annotations&quot;&gt;Peter Brantley - annotations&lt;/h2&gt;

&lt;p&gt;Annotations are clearly web addressable, and as such should work really well with web addressable documents. &lt;/p&gt;

&lt;h2 id=&quot;cameron-neylon&quot;&gt;Cameron Neylon&lt;/h2&gt;

&lt;p&gt;Talks about the discussion around community standards. Todd mentions that some work took place with the Mesur project to look at the business model and business case for creating such a data clearinghouse, and that case study might prove a useful resource now.&lt;/p&gt;

&lt;h1 id=&quot;breakout---business-and-use-cases&quot;&gt;Breakout - Business and use cases&lt;/h1&gt;

&lt;p&gt;The most interesting thing about this session is how much against standardization both Heather from impact story, and Mike from Plumb Analytics were. They felt that standardization would cause calcification, and that none of their customers have asked for standardization. In the discussion we were unable to identify a single strong identified customer for a standardized version of ALMs. &lt;/p&gt;

&lt;p&gt;I felt that this session was an important one, as we need to clearly identify who our customer is, and what value this thing brings to that customer. I feel that an industry-wide adoption of at least best practice could help with wider adoption, but this is only a feeling that I have, and again, the two ALM  vendors in the room disagreed with me, so perhaps I’m wrong. I tried to introduce the product management tool “Desired outcomes” to these questions, but it didn’t work, we didn’t have a clearly enough defined thing to talk about, so we abandoned trying that framework. The one thing that framework did help with was to focus our discussion around who the customer is, so we discussed - publishers, authors, the ALM community and to a small extend funders. &lt;/p&gt;

&lt;p&gt;I will be interested to see the outcomes of the other planned workshops. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Cambridge usability group - UX and agile</title>
   <link href="http://partiallyattended.com/2013/09/30/cug-agile-ux"/>
   <updated>2013-09-30T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/09/30/cug-agile-ux</id>
   <content type="html">&lt;p&gt;Sophie Freiermuth(&lt;a href=&quot;https://twitter.com/wickedgeekie&quot;&gt;@wickedgeekie&lt;/a&gt;)) from &lt;a href=&quot;https://twitter.com/BaguetteUX&quot;&gt;Baguette UX&lt;/a&gt; gave tonight’s talk on how lessons learnt from operating as a UXer within an agile environment. I thought it was a great talk. When at Mendeley we always faced the problem of trying to square the challenge to fitting an inherently creative process into the systems that emerged while we attempted to adopt agile processes, in my time there we learnt a lot, we had some success and some areas where we obviously needed to learn more, so I was delighted to hear a very thoughtful presentation from the perspective of someone who it seems has worked with quite a few teams implementing agile in a variety of flavours.&lt;/p&gt;

&lt;p&gt;My notes below are pretty much a transcript typed out while listening, but as usual, any inaccuracies and typos are mine. &lt;/p&gt;

&lt;h1 id=&quot;agile&quot;&gt;Agile&lt;/h1&gt;

&lt;p&gt;Remember that Agile remains a manifesto - it was created by developers and is  aimed at solving problems that developers have in attempting to build products. &lt;/p&gt;

&lt;p&gt;The agile manifesto is now over 11 years old, over that time it’s been adopted by teams of all sizes worldwide. &lt;/p&gt;

&lt;p&gt;At Agile 2013 - the recent agile conference - there were lots of stories about agile at companies of all sizes.&lt;/p&gt;

&lt;p&gt;Nokia and Spotify are two of the bigger companies that have adopted it, and Sophie talked quite a bit about Spotify’s experience. Spotify say that for them agile is still a work on progress. &lt;/p&gt;

&lt;p&gt;One of their big secrets is that the spaces need to be managed to enable collaboration. They have built the 3-wall rooms. The 3 walls allow enough space to pin up work, but the 3rd wall makes the work visible to people outside of those rooms, and also the work in action visible. Each space has enough room for people to co-share, to have meetings, and to collaborate.&lt;/p&gt;

&lt;p&gt;They need a large space - they needed more room to allow people to collaborate, and move around. (need more space than is usually assigned by facilities). Line management bought in, but the big blocker was getting facilities management to agree to the space requirements. &lt;/p&gt;

&lt;p&gt;Points that worked in this setup  - needs to be flexible - self sufficient - 3 walls only - mix of desks and meeting spaces - self organised, a team of up to 12 people. &lt;/p&gt;

&lt;p&gt;Spotify have been experimenting with team size, there is a magic number of about 12 people. 12 includes all the people that are needed to get the work done - design - front end - ux - qa - Product Owner. When a team gets to larger than 12 they break the team up, and split the work streams. The team needs to have all of the skills required. Every team is responsible for how they work, there is no company-wide process. They are allowing teams to self-organise around how they manage their work. &lt;/p&gt;

&lt;p&gt;They are trying to allow functions across the teams to get together in structures they call guilds, to share function specific know-how.&lt;/p&gt;

&lt;p&gt;The PO’s job is to ensure that the right jobs get into the room (Many problems just should never enter the dev room, and should be answered  in other locations). The PO has this responsibility. Some POs don’t want to know how the team tackles problems, some POs are interested - each team is finding it’s own way. &lt;/p&gt;

&lt;p&gt;Another interesting thing is the role of the agile coach.  In one instance mentioned the agile coach helped the business feel that there was oversight, however some people in the agile community think that coaches can disrupt the natural learning cycle of a team can be disrupted. In the story presented here having an agile coach helped the presenter. We used a couple of agile coaches at Mendeley, and my experience was generally positive, but I was standing on the pointy hair’d side of the desk, so I had some sense that I was bringing control to a situation. Some of the people who did some of the coaching liked it, and some didn’t.&lt;/p&gt;

&lt;h1 id=&quot;how-has-agile-worked-for-this-ux-person&quot;&gt;How has agile worked for this UX person?&lt;/h1&gt;

&lt;p&gt;Sitting with a dev team can be invaluable, seeing the thing being built as it goes along is invaluable. It also helps to ensure that the quality stays in place, conversations can happen about shortcuts before they get backed into the product, and optimal decisions can be taken, rather than being laboured with decisions that have taken place on the fly. &lt;/p&gt;

&lt;p&gt;The walls are an amazing resource. Placing the user journey on the walls as a print out, next to the stories can really help the developers. Developers can also comment on the user flows when they see that there might be a technical issue. By doing the work on the board, and making the process apparent, this leads to collaboration, and to reaching a solution faster, it also brings confidence to the team that UX can bring a lot of value. (Sophie mentioned in the Q&amp;amp;A that where she had drawn a user journey on the whiteboard, when explaining it to other people she would erase it and re-draw it. By making them a participant in the bringing out of the journey onto the whiteboard they got it a lot faster, and could often ask critical questions that she might have overlooked, she described this as something like “sharing the deliverable” rather than “arriving with the deliverable”).&lt;/p&gt;

&lt;p&gt;When a UX person is placed with a dev team, often the UX person will have invested in the idea that the developers know what they are doing, however the developers often don’t have trust yet in the UX person. That person has to prove value.&lt;/p&gt;

&lt;p&gt;The UX/Design/Copy team - how this fits into the sprint cycle has not been cracked. Smaller tasks can be easier to fit in within a sprint cycle, however you need to be clear on the work that needs to be done, what the request means - e.g. we need to improve conversions - is not often clear - is it page speed, does the flow need to be improved - is there a code issue, does some user research need to be done?&lt;/p&gt;

&lt;h1 id=&quot;tools&quot;&gt;Tools&lt;/h1&gt;

&lt;p&gt;Taking tools from agile can be very helpful, for example using Kanban to display where a bottleneck might occur, even when the work is flowing through one person. (At Mendeley we discovered that our bottleneck was not in UX, where we had thought it was, but rather downstream from UX in the front end development side of the product).&lt;/p&gt;

&lt;h1 id=&quot;another-big-tip-is-lower-the-definition&quot;&gt;Another big tip is lower the definition.&lt;/h1&gt;

&lt;p&gt;You can say that you need to release &amp;gt; test &amp;gt; iterate within the UX cycle. Give a definition of done. Done is easy to say, but impossible to define within UX. What is the definition of done within UX - a sketch - a full spec? Try and find the lowest definition of done as possible, it’s a win for everyone, as long as the developer can work with it, and you don’t lose information. This will serve the team better, to make this work you need to be sure you are collaborating, you need to have trust with the team, you can’t start with scribbles from day one - but you can get there. &lt;/p&gt;

&lt;h1 id=&quot;lean&quot;&gt;Lean&lt;/h1&gt;

&lt;p&gt;The lean manufacturing process defined by Taiichi Ohno has a lot of value. You eliminate waste, you empower people, and you introduce Kanban. The more you adopt the thinking that one thing can only be in one place at one time. Agile is not faster, but it does show pieces of the solution earlier. The overall time spent may not be less than the waterfall process, but you will see parts of the solution earlier - (In my opinion you should in theory be able to reduce waste, and make invisible work more visible). Lean is human first, it’s about people. &lt;/p&gt;

&lt;h1 id=&quot;firefighting&quot;&gt;Firefighting&lt;/h1&gt;

&lt;p&gt;Often the dev team is going full speed ahead - surfacing problems that were not identified earlier. If you drop into a team, you won’t be able to just shout “STOP”. The best way to firefight is to know the technology as much as possible - have accurate technical knowledge. Agile is all about &lt;code&gt;people&lt;/code&gt; &lt;code&gt;people&lt;/code&gt; &lt;code&gt;people&lt;/code&gt;. Empower people, make them feel successful, make them feel valued. UX people naturally tend towards being empathetic, so people relations should work well for them. Define what success looks like. Often the question of what success looks like surprises the stakeholders. If you can get this question out, you can get the steak-holders to commit to what the success should look like. Be Michael Schumacher. This is not about being the fastest, but about cutting the right corners in the right way - e.g. can you get away with a low fidelity sketch, can you get away with shorter stand-ups in the morning? It’s not about making time to squeeze more work in, but rather making the time you have count, and making sure you have a life. &lt;/p&gt;

&lt;h1 id=&quot;side-competencies-and-agile&quot;&gt;Side competencies and Agile&lt;/h1&gt;

&lt;p&gt;Refuse the absurd (or at least point it out) - when you see these issues crop up in user stories. Make sure the stories have a target, a requirement for success. Every team is unique. There is no generalisation, everyone is trying to make agile work. No one has fully cracked it, but it seems to work. Every case is different. Agile is for people who can deal with constant change, with people who like experimenting. This is a method of working that suites outgoing people. Apply top skills first, and refine later - reach wide, try and solve problems where you can, then refine later. You need to learn the value of getting things done, rather than getting things perfect. In agile teams there is the rise of the unicorns. A UX who is a developer, a great copy writer - these people &lt;em&gt;do not exist&lt;/em&gt;. It’s OK not to have unicorns on the team. Fight the battle with the troops you have, not the troops you wish you had. &lt;/p&gt;

&lt;h1 id=&quot;what-is-the-future-of-agile&quot;&gt;What is the future of agile?&lt;/h1&gt;

&lt;p&gt;Agile has guardians! The people who designed the agile manifesto are still out there, still communicating. There are lots of flavours, we have had scrum, lean, XP … there will be something coming along next. One big problem with agile is when will something be done, what will the stakeholders get. In agencies it is really difficult. When you go agile you need to work with a client who understands this. Each team has it’s own process. Are we all in harmony towards a common goal? Is agile the promised land? This still needs to be cracked. Could there be a riot of fed-up UXers brandishing sharpies and stickies? Yes! UX and design cannot sit perfectly in harmony, but agile is going to stick around, and the future will be interesting. &lt;/p&gt;

&lt;p&gt;Remember that agile was developed by developers, take the spirit, but don’t take it as a cookie cutter approach. &lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Great talk!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Some advice on learning web development.</title>
   <link href="http://partiallyattended.com/2013/07/29/web-dev-advice"/>
   <updated>2013-07-29T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/07/29/web-dev-advice</id>
   <content type="html">&lt;p&gt;Here is some advice I gave a few months ago to a friend on becoming a web dev. I think it still holds up.&lt;/p&gt;

&lt;h3 id=&quot;the-most-important-thing&quot;&gt;The most important thing&lt;/h3&gt;

&lt;p&gt;I have lots of advice, it I think the most important advice that I
have boils down to do work.
Build up a portfolio, and get comfortable and fluid with the tools
that you will use to do web development.&lt;/p&gt;

&lt;p&gt;We look for skilled passionate people, and the best way to show that,
is to show projects that you have been working on.&lt;/p&gt;

&lt;p&gt;If you are not in a position to get paid work that will allow you to
show off your work, then the following tactics will allow you t build up a portfolio of work:&lt;/p&gt;

&lt;p&gt;Find an open source project that you believe in, and that is written
using the tools you wish to master,
and start making contributions. These might initially be about
providing documentation, extending test coverage, or
doing some internationalization work.&lt;/p&gt;

&lt;p&gt;Find some local charities that you can offer to do some pro bono web work for.&lt;/p&gt;

&lt;p&gt;Create a public profile on github, and post your code there, here is
mine: https://github.com/IanMulvany&lt;/p&gt;

&lt;h1 id=&quot;key-skillsabilities&quot;&gt;Key Skills/abilities&lt;/h1&gt;

&lt;p&gt;JavaScript and in particular jQuery.&lt;/p&gt;

&lt;p&gt;Some large web frameworks, backed by php, ruby, python.&lt;/p&gt;

&lt;p&gt;API handling, REST and JSON. Know about
loading http headers and content negotiation.&lt;/p&gt;

&lt;p&gt;Populating a template from a DB.&lt;/p&gt;

&lt;p&gt;Setting up a system in the cloud, even if its just running on heroku or google app engine.&lt;/p&gt;

&lt;p&gt;A revision control system, git is the main one to learn.&lt;/p&gt;

&lt;p&gt;Unit testing.&lt;/p&gt;

&lt;h1 id=&quot;be-able-to&quot;&gt;Be able to:&lt;/h1&gt;

&lt;p&gt;Get very quick at implementing the following types of work in your
favorite set of tools, even if quick is just a small example
application:  &lt;/p&gt;

&lt;p&gt;Consuming data from a rest API with HTTP basic auth and showing some
of this data on your site, asynchronously.  &lt;/p&gt;

&lt;p&gt;Templating pages and populating data from a db.  &lt;/p&gt;

&lt;p&gt;Using a framework with a good data object mapper that connects to a db.  &lt;/p&gt;

&lt;p&gt;Connecting to a db.  &lt;/p&gt;

&lt;p&gt;Doing any one thing in your pages with a jQuery plugin that changes the DOM.  &lt;/p&gt;

&lt;h3 id=&quot;nice-to-haves&quot;&gt;nice to haves&lt;/h3&gt;

&lt;p&gt;Things that are nice I know that help, but that will really only be
required for specific types of jobs:&lt;/p&gt;

&lt;p&gt;NOSQL, learn Redis, understand that it has limitations in terms of
multithreaded apps. Understand that Mongo db is probably a dog of an
application.  &lt;/p&gt;

&lt;p&gt;Read about everything on the amazon web services stack. Build an
application on top of it.  &lt;/p&gt;

&lt;p&gt;Figure out if you like front end or back end work.  &lt;/p&gt;

&lt;p&gt;Read hacker news, but don’t take it too seriously, my advice is to
spend a few weeks reading quite a bit of it until you get a sense of
the types of things people post there. After that pick no more than
three articles a day. It will help you understand trends and can point
to some nice tutorials, but time spent reading it is time not spent
working.  &lt;/p&gt;

&lt;p&gt;Understand the syntax of Xpath queries  &lt;/p&gt;

&lt;p&gt;Oauth  &lt;/p&gt;

&lt;h3 id=&quot;links-and-resources&quot;&gt;Links and resources&lt;/h3&gt;

&lt;h1 id=&quot;hosting&quot;&gt;hosting&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;http://www.heroku.com/  &lt;/li&gt;
  &lt;li&gt;http://aws.amazon.com/  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;frameworks&quot;&gt;frameworks&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;https://www.djangoproject.com/  &lt;/li&gt;
  &lt;li&gt;http://flask.pocoo.org/  &lt;/li&gt;
  &lt;li&gt;http://drupal.org/  &lt;/li&gt;
  &lt;li&gt;http://rubyonrails.org/  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;tddbdd&quot;&gt;TDD/BDD&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;http://cukes.info/  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;git&quot;&gt;git&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;http://git-scm.com/  &lt;/li&gt;
  &lt;li&gt;http://gitready.com/  &lt;/li&gt;
  &lt;li&gt;http://github.com/  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;nosql&quot;&gt;nosql&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;http://redis.io/  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;news&quot;&gt;news&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;http://news.ycombinator.com/  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;skills&quot;&gt;skills&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;http://stackexchange.com/sites  &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>EC consultation on Open Data - a report.</title>
   <link href="http://partiallyattended.com/2013/07/02/ec-open-data-consultation-report"/>
   <updated>2013-07-02T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/07/02/ec-open-data-consultation-report</id>
   <content type="html">&lt;p&gt;This is a report on todays consultation on open data that was help by the EC. The notes are long, so I have put my conclusions and general comments at the start.&lt;/p&gt;

&lt;h1 id=&quot;general-comments&quot;&gt;General comments&lt;/h1&gt;

&lt;p&gt;There was not much disagreement throughout the day. There were repeated calls  for the need to incentivise  researchers to engage in data sharing, but not too many concrete proposals on how to do this. It does seem from my perspective that libraries could do an amazing job here, but that will depend on to which extent these libraries have deep technical expertise. One problem libraries seem to have is bridging the gap between their expertise and the scientist at the bench who just doesn’t know about what services they can call on.&lt;/p&gt;

&lt;p&gt;I spoke late in the day, but I was the first to mention CC0 explicitly, and the first to call for the explicit adoption of CC0/CC-BY, I was surprised by this. &lt;/p&gt;

&lt;p&gt;There was an overwhelming reiteration that primary research data is a public good, and as such the default position is that this data should be “open by default”. This was hugely encouraging. There was plenty of nuanced discussion that there are indeed areas where one would need to have restrictions in place around certain kinds of data, but the majority of people who made this point wanted to start from a default open position, and look for explicit reasons on a case by case basis for why one might not adopt this principle. I think this is a healthy way to proceed. &lt;/p&gt;

&lt;p&gt;There were some skirmishes over IP, patents and an explicit call from representatives from Phillips and from the German Defence industry that data should not be made open. One even saying that they liked public funding, but didn’t like the idea of opening that data (hello, can someone please let this person know what a “public good means?”). Anyway, both representatives were amenable to the idea of embargoes for data that is generated in public-private partnerships, so I think that was healthy. One aside is that this thread of conversation popped up throughout that day, but I feel that it is largely a distraction from the core question, one of the status of OpenData for primary publicly funded research. What it does show is that in this debate we need to get the lines really clear, so as not to waste cycles discussing edge cases, and so that we don’t end up imposing artificial restrictions for fears that should not really be applicable.&lt;/p&gt;

&lt;p&gt;No one mentioned linked data. No one.&lt;/p&gt;

&lt;p&gt;The really key issue, in my mind, is how do you build a system that captures data in a way that is more robust than the life time of the researcher who created it. If we could say with confidence that the data that a researcher used is as accessible to future generations, in the way that their publications are available, then we will have succeeded. We can still get out hands on the finches that Darwin worked on, which is amazing. That we can’t get the excel file that Joe Postdoc created six years ago is a shame on us.&lt;/p&gt;

&lt;h2 id=&quot;notes-from-the-day&quot;&gt;Notes from the day.&lt;/h2&gt;

&lt;p&gt;My notes on the actual discussions through the day are pretty much sketch like. If anything is unclear, I’m happy to respond in the comments.&lt;/p&gt;

&lt;h2 id=&quot;opening-notes&quot;&gt;Opening notes&lt;/h2&gt;

&lt;p&gt;Opening remarks, sets out three reasons that the commission believes the opening access to research data is a must. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;good for science&lt;/li&gt;
  &lt;li&gt;good for SME’s - they have evidence for this already&lt;/li&gt;
  &lt;li&gt;good for the citizen&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There will be room until the 15th of July to send written contributions to the consultation. Today is not a workshop, it is a hearing, and the main purpose for the day is to hear opinions from the stakeholders. &lt;/p&gt;

&lt;p&gt;The day starts with:&lt;/p&gt;

&lt;h2 id=&quot;the-research-perspective&quot;&gt;The research perspective.&lt;/h2&gt;

&lt;h4 id=&quot;jildau-bouwman-tno-department-of-microbiology-and-systems-biology&quot;&gt;Jildau Bouwman, TNO Department of Microbiology and Systems Biology&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;negative data.&lt;/li&gt;
  &lt;li&gt;small data from home experiments.&lt;/li&gt;
  &lt;li&gt;information in the methods section, including the meta-data data, the paper should be reusable. &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Limits should be on sensitive data, commercial data. Need a specific budget in projects to help data being put into the open.&lt;/p&gt;

&lt;h4 id=&quot;paola-de-castro-istituto-superiore-di-sanit&quot;&gt;Paola De Castro, Istituto Superiore di Sanità&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;data management plans should be stressed&lt;/li&gt;
  &lt;li&gt;mentions the g8 policy &lt;/li&gt;
  &lt;li&gt;need a way to provide incentives for researchers&lt;/li&gt;
  &lt;li&gt;they stress the importance of creating a global infrastructure. &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;menno-kok-erasmus-universiteit-rotterdam&quot;&gt;Menno Kok, Erasmus Universiteit Rotterdam&lt;/h4&gt;

&lt;p&gt;Discusses the why of this.&lt;/p&gt;

&lt;p&gt;An important factor in the why, is how can we get more value from data. This means data enrichment. Mentions the danger of making some data available, specifically genome sequences. Sequences and phenotypes are the things that are dangerous. &lt;/p&gt;

&lt;p&gt;How do we stimulate the process? This is to do with fairness. This relates to when data should be made available. &lt;/p&gt;

&lt;p&gt;The patent question is going to be an important one. We may have to come to a tailor made solution that fits to all types of research. &lt;/p&gt;

&lt;p&gt;How can you get to this kind of solution? Through trial and error. &lt;/p&gt;

&lt;p&gt;They would like to propose that EU incorporates OA under Horizon 2020 as a carefully monitored limited trial. &lt;/p&gt;

&lt;h4 id=&quot;salvatore-mele-cern&quot;&gt;Salvatore Mele, CERN&lt;/h4&gt;

&lt;p&gt;How can you get 1000’s of people to share and to cooperate? If you build a community, where every contributor is known, and every contribution is acknowledged. He advocates that we can build a global community of sharing. &lt;/p&gt;

&lt;p&gt;He mentions the ODIN project. They found a very clear answer, they need to augment the existing infrastructure, need one that is technical, social and something else.&lt;/p&gt;

&lt;p&gt;Mentions key pieces of the infrastructures. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ORCID&lt;/li&gt;
  &lt;li&gt;DataCite &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We need to accelerate the adoption of these approaches.&lt;/p&gt;

&lt;p&gt;No researcher should be left behind. Researchers without access to specific infrastructure should be able to make use of tools such as Zenodo.&lt;/p&gt;

&lt;h4 id=&quot;corrette-ploem-academic-medical-center-university-of-amsterdam&quot;&gt;Corrette Ploem, Academic Medical Center, University of Amsterdam&lt;/h4&gt;

&lt;p&gt;Patients, which are the providers of data, may expect that their data is shared as much as possible, from their perspective, It is not in their interest that researchers sit on their data (the patients want to be cured, right?).&lt;/p&gt;

&lt;p&gt;Standardisation of data, and encoding techniques, and legislation, on an EU level, is required. &lt;/p&gt;

&lt;h4 id=&quot;section&quot;&gt;?&lt;/h4&gt;

&lt;p&gt;Incentives are crucial to build up a culture of data sharing. Research data needs to be considered as a research output on the level of journal articles. &lt;/p&gt;

&lt;p&gt;Costs should be included in project funding. Data management and data sharing plans should be required. Such an approach was proposed by the US government. &lt;/p&gt;

&lt;p&gt;Initiatives such as the Research Data alliance are helpful. &lt;/p&gt;

&lt;h4 id=&quot;andrew-smith-embl-ebi--elixir&quot;&gt;Andrew Smith EMBL-EBI / ELIXIR&lt;/h4&gt;

&lt;p&gt;We need to look at the term open data. That is a bit misleading, in life science, clearly not all data will be made open. When we talk about open data, we really are talking about accessible data. &lt;/p&gt;

&lt;p&gt;Mentions EU-PMC and EBI infrastructure. Where we can we should look to build on existing data bases. &lt;/p&gt;

&lt;p&gt;When we use the term data storage, we need to be careful. The costs in running these repositories often sits on the curation, running courses, developing standards, the cost is not just on the storage side.&lt;/p&gt;

&lt;p&gt;Feels that we should use Horizon 2020 for driving change. &lt;/p&gt;

&lt;h4 id=&quot;rolf-vermeij-european-consortium-of-innovative-universities&quot;&gt;Rolf Vermeij, European Consortium of Innovative Universities&lt;/h4&gt;

&lt;p&gt;Need to be able to find the data through a search engine. Need ways to enable searching that goes beyond Google. &lt;/p&gt;

&lt;p&gt;Some areas of science have a long standing history of data sharing. Chemists do not share data. &lt;/p&gt;

&lt;p&gt;People will need to be educated. &lt;/p&gt;

&lt;p&gt;Need stronger peer review on the data. &lt;/p&gt;

&lt;h4 id=&quot;debate&quot;&gt;Debate&lt;/h4&gt;

&lt;p&gt;A lot of data that is used is often coming from public administration. There is not much of a culture of data sharing from public sector information. These sources of information should be considered.&lt;/p&gt;

&lt;p&gt;Education is important. We need to convince researchers that their data is worth sharing. We need to educate researchers about what the basic elements of sharing are. Feels that naturally libraries have a role to play in that.&lt;/p&gt;

&lt;p&gt;There is a study that says that peer review of data is just too difficult, there is too much of it, and it would just break the system, we need to think of some other way of doing this. &lt;/p&gt;

&lt;p&gt;One approach is to just allow users to make comments on the data that they are using. The second approach is to do this through journals, journals should ensure that data is reviewed. &lt;/p&gt;

&lt;p&gt;If there is a clear understanding of whose job it is to do what when it comes to review, that’s helpful.&lt;/p&gt;

&lt;p&gt;My comments on peer review of data:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;aside from reuse, making data available helps to prove that the experiment happened&lt;/li&gt;
  &lt;li&gt;not the only solution, but tracking reuse is a good indicator that the data is useful&lt;/li&gt;
  &lt;li&gt;must support negative publication results, to overcome publication bias for successful events in the lab.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A comment is made about what is data, archaeology provides great examples of how heterogeneous data is.&lt;/p&gt;

&lt;p&gt;If you can really associate who has provided which part of the data, then you are pinning reputation on the quality of the data. If you identify who is putting data out, you do not need a peer review system. &lt;/p&gt;

&lt;p&gt;In medical science the citation index is more important for your reputation than the quality of the data that you produce. Therefore some fields need education, and a change to their incentive structures.&lt;/p&gt;

&lt;h2 id=&quot;industry--industrial-research-perspective&quot;&gt;Industry / industrial research perspective&lt;/h2&gt;
&lt;p&gt;#### Jan van den Biesen, Philips Research 2 &lt;/p&gt;

&lt;p&gt;OA to Scientific publications is really not an issue. No interference with the ability to protect IPR.&lt;/p&gt;

&lt;p&gt;Open access to research data is another matter. Open access to research data could affect the ability to protect innovations and IPR. Fully OA might destroy more value than it creates.&lt;/p&gt;

&lt;p&gt;They think it should be decided case by case. For example unsuccessful clinical trials, sharing these results can help reduce redoing unnecessary experiments, however making data from Enabling technologies open could scare away partners. &lt;/p&gt;

&lt;p&gt;They support the OA approach &lt;a href=&quot;http://www.whitehouse.gov/blog/2013/02/22/expanding-public-access-results-federally-funded-research&quot;&gt;proposed by the Obama administration&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Making raw data available to citizens doesn’t really help, this data should be refined into products by industry for citizens. &lt;/p&gt;

&lt;h4 id=&quot;helge-pfeiffer-advisory-council-for-aeronautics-research-in-europe-&quot;&gt;Helge Pfeiffer, Advisory Council for Aeronautics Research in Europe /&lt;/h4&gt;

&lt;p&gt;Needs to avoid inflation of papers - though salami slicing and fraud. &lt;/p&gt;

&lt;h4 id=&quot;thomas-weise-federation-of-german-security-and-defence-industries&quot;&gt;Thomas Weise, Federation of German Security and Defence Industries&lt;/h4&gt;

&lt;p&gt;Funding is highly appreciated, however OA cannot be in the interest of industry. 100% ownership of background information has to be guaranteed to industry. Release to 3rd parties has to be agreed by industry. &lt;/p&gt;

&lt;h4 id=&quot;debate-1&quot;&gt;Debate&lt;/h4&gt;

&lt;p&gt;Strong debate on the topic of standard position for openness. &lt;/p&gt;

&lt;p&gt;Someone makes the case that there is a strong difference between pure research and applied research. They believe that this is one of the things that the Horizon 2020 pilot should investigate. &lt;/p&gt;

&lt;p&gt;Mentions that there are parallels in an amendment that has been seen in public sector information directive, and the research cycle within industry. The directive has said that for public private partnerships, the default will be open, but that openness will happen under embargo. In addition those embargoes can be challenged. The PSI directive might provide a good framework.&lt;/p&gt;

&lt;p&gt;Thomas Weise could agree to this idea for embargo. In the US in defence, secret programs are suddenly published, but this means that they might not be interesting any more. &lt;/p&gt;

&lt;p&gt;q: does it make sense for Europe to have a policy, in spite of policies in other parts of the world, or do these policies need to be global. Thomas Weise says that there should be an EU policy in order to retain EU competitiveness. Need and EU publication strategy and research data strategy. &lt;/p&gt;

&lt;p&gt;It’s important that Europe is showing leadership in open policies. On the other hand you cannot limit open access to within specific regions. So - yes European policies make sense, especially to join forces with other regions that are interested, but you cannot limit access to this research.&lt;/p&gt;

&lt;p&gt;Do not think that we should wait to harmonize our policies.&lt;/p&gt;

&lt;h2 id=&quot;research-funder-perspective&quot;&gt;Research funder perspective&lt;/h2&gt;
&lt;p&gt;#### Juan Bicarregui, UK Research Councils &lt;/p&gt;

&lt;p&gt;Thinks most countries are already producing polices that are already harmonized. G8 agenda is mentioned again. &lt;/p&gt;

&lt;p&gt;STFC holds 40 PB of data, doubles every 15 months, soon they will hold 80PB. They also support a bunch of other tools, including the Square Kilometre meter Array.&lt;/p&gt;

&lt;h4 id=&quot;david-carr-wellcome-trust&quot;&gt;David Carr, Wellcome Trust&lt;/h4&gt;

&lt;p&gt;Value of data vs resources required. 
There can be limits to data sharing via IP.
Need to balance the needs between data generators and users.&lt;/p&gt;

&lt;p&gt;There are challenges:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;enhancing implementation and enforcement of policies&lt;/li&gt;
  &lt;li&gt;guiding a sustainable culture of data sharing&lt;/li&gt;
  &lt;li&gt;recognise that different disciplines are at different stages&lt;/li&gt;
  &lt;li&gt;need to forge partnerships between funders the research community and other stakeholders&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;anne-wetterbom-swedish-research-council--science-europe&quot;&gt;Anne Wetterbom, Swedish Research Council / Science Europe&lt;/h4&gt;

&lt;p&gt;Funders role is to provide the framework for their research environments. &lt;/p&gt;

&lt;p&gt;Swedish government in October 2012 published a bill on research and innovation. There is already a Swedish bill for making public information open, and research conducted through universities is considered to be public information. 
The universities are responsible for archiving data from their scientists, but this puts a burden on universities, with the current data deluge. &lt;/p&gt;

&lt;p&gt;They want infrastructures to be cost efficient, and heterogeneous. &lt;/p&gt;

&lt;p&gt;They will work with different stakeholders over the coming year. &lt;/p&gt;

&lt;p&gt;During 2014 they are going to go to the government with a draft policy. &lt;/p&gt;

&lt;p&gt;They would like to have a discussion on funding models. &lt;/p&gt;

&lt;h4 id=&quot;debate-2&quot;&gt;Debate&lt;/h4&gt;

&lt;p&gt;A comment to focus on success stories, which can be used to show the value of access to open data. &lt;/p&gt;

&lt;p&gt;Should the way that IP is currently working be discussed, particularly around patents?&lt;/p&gt;

&lt;p&gt;Perhaps we should look at the property issue in a new way? In medical research contracts are very one sided. This is really a problem, we should think about the cash that is being generated through these partnerships. &lt;/p&gt;

&lt;p&gt;Public directive indicates that from 2015, any information that ends up in the university library will be considered as public information, including public sector information that has been generated from within the university.&lt;/p&gt;

&lt;p&gt;The question of licensing is being raised. A proposal is made to clarify copyright and licence, and suggests that there should be a limited set of patterns, like as in what has happened with creative commons. &lt;/p&gt;

&lt;p&gt;The decision about licensing should happen at the proposal stage, so that funders will know whether to fund up front. &lt;/p&gt;

&lt;p&gt;There is a defence of the patent system, a description of “the deal” for patents. (There is a strong [argument that the patent system is broken are broken][brpat], as &lt;a href=&quot;http://www.thisamericanlife.org/radio-archives/episode/441/when-patents-attack&quot;&gt;this American life episode&lt;/a&gt; The White House &lt;a href=&quot;http://www.whitehouse.gov/the-press-office/2013/06/04/fact-sheet-white-house-task-force-high-tech-patent-issues&quot;&gt;seems to agree&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;For open data, public funding is involved, and this does not preclude the protections that companies have. When we are talking about open access to data for public funding, we should not add more protections or additional layers of protection, as these layers already exist - via the patent system. &lt;/p&gt;

&lt;h2 id=&quot;information-systems--e-infrastructure-perspective&quot;&gt;Information systems / e-infrastructure perspective&lt;/h2&gt;

&lt;h4 id=&quot;nikos-askitas-institute-for-the-study-of-labor-in-bonn-germany&quot;&gt;Nikos Askitas, Institute for the Study of Labor in Bonn Germany&lt;/h4&gt;
&lt;p&gt;(I think this person is an economist)&lt;/p&gt;

&lt;p&gt;Sharing is a good thing, but not all researchers should share, it’s like donating, it’s a good thing, but not everyone will do it. &lt;/p&gt;

&lt;p&gt;Data is insurance against fact pollution. Data is not cheap. &lt;/p&gt;

&lt;p&gt;You have to make sure that the data stays meaningful over time. Research data is potentially any data. &lt;/p&gt;

&lt;p&gt;Research data could be defined as data that has been used at least once to answer a research question. &lt;/p&gt;

&lt;p&gt;What does making it available mean? Making it available separates research from hearsay. That must be what defines openness in this context.&lt;/p&gt;

&lt;p&gt;On limiting, two remarks - open does not mean free, at the same time proprietary does not mean closed. In the context of data, perhaps we could introduce a data tax. &lt;/p&gt;

&lt;p&gt;Perhaps an idea of corporations paying for proprietary data, could be opened in the form of data taxes (definitely an economist).&lt;/p&gt;

&lt;p&gt;In terms of storage, there could be journals, libraries, individuals. So centrally or distributed? The library of Alexandria no longer existed. Monks stored the data in a distributed fashion.&lt;/p&gt;

&lt;h4 id=&quot;donatella-castelli-italian-national-research-council-and-openaire--yannis-ioannidis&quot;&gt;Donatella Castelli, Italian National Research Council and OpenAIRE / Yannis Ioannidis&lt;/h4&gt;

&lt;p&gt;Requirements on data preservation, and management should be light at the project submission stage, and become much more rigorous before awarding of grants. &lt;/p&gt;

&lt;p&gt;Openness should be limited to quality data. &lt;/p&gt;

&lt;h4 id=&quot;peter-doorn-data-archiving-and-networked-services&quot;&gt;Peter Doorn, Data Archiving and Networked Services&lt;/h4&gt;

&lt;p&gt;Important to address small data, in addition to BIG data. We should not make open data a religion or a dogma, it’s important to be pragmatic. &lt;/p&gt;

&lt;p&gt;Researchers should not own the data that they collect with public funding. On limiting openness, protection of privacy is a factor, but it should not be a dogma. Certain public interests should be protected. &lt;/p&gt;

&lt;p&gt;It is good to allow an embargo for up to two years, for researchers who want to publish on data. &lt;/p&gt;

&lt;p&gt;On reuse, we need certain citation rules for data. These should include at least a persistent identifier. Make data available for peer review. &lt;/p&gt;

&lt;p&gt;It should be stored in trustworthy archives, should be certified by the EU framework - there are German and  ISO standards, for data archiving standards (could be very helpful).&lt;/p&gt;

&lt;p&gt;Make data management eligible for funding. &lt;/p&gt;

&lt;h4 id=&quot;matthew-dovey-joint-information-systems-committee--knowledge-exchange&quot;&gt;Matthew Dovey, Joint Information Systems Committee / Knowledge Exchange&lt;/h4&gt;

&lt;p&gt;Half of funding agencies in north Europe had data management plans, but only half of them had plans to implement these plans. &lt;/p&gt;

&lt;p&gt;Makes the point that sometimes it’s cheaper to recreate data, rather than storing.&lt;/p&gt;

&lt;p&gt;Data is often generated from an array of funding, and researchers are often not aware of the funder requirements. &lt;/p&gt;

&lt;p&gt;Funders need to fund ongoing support of data. &lt;/p&gt;

&lt;p&gt;Again, training is important. Do we concentrate on new researchers, or the exiting researchers? &lt;/p&gt;

&lt;p&gt;Infrastructure is easy, technology is easy, getting people to use the infrastructure is harder. (often often, the social context is harder than the technology).&lt;/p&gt;

&lt;p&gt;Any technology must fit with existing workflows and not impose new workflows.&lt;/p&gt;

&lt;h4 id=&quot;adam-farquhar-datacite&quot;&gt;Adam Farquhar, DataCite&lt;/h4&gt;

&lt;p&gt;DataCite now have 1.7M DOIs. +3M resolutions in 2013, 200 data centres. 275k DOIs in 2013. &lt;/p&gt;

&lt;p&gt;Founded in 2009.&lt;/p&gt;

&lt;p&gt;Data identification has now matured up away from local country standards. The point is there is no need to re-invent the wheel. Identification and citation level meta data are critical for incentives systems. &lt;/p&gt;

&lt;p&gt;Data citation require interoperable APIs and meta data (e.g. content negotiation with crossref).&lt;/p&gt;

&lt;p&gt;Data identification is more than just assigning a number. You need essential services to support this. &lt;/p&gt;

&lt;h4 id=&quot;david-giaretta-alliance-for-permanent-access&quot;&gt;David Giaretta, Alliance for Permanent Access&lt;/h4&gt;

&lt;p&gt;The common thread is how can we add value? Not just adding value to the creator, but also in other disciplines - commerce, government, the general public. &lt;/p&gt;

&lt;p&gt;Most data is unfamiliar to most people. Most people don’t think anything of clicking through 100 different web pages, most people would never do this for data sets - life is just too short. &lt;/p&gt;

&lt;p&gt;The key question is who pays, how much, and why? No one makes indefinite commitments. &lt;/p&gt;

&lt;p&gt;The solution seems to be to make data usable, by as many people as possible, for as long as possible. CIBER-DS is a project that is trying to do this. &lt;/p&gt;

&lt;p&gt;Need to investigate data marketplaces.&lt;/p&gt;

&lt;h4 id=&quot;bram-luyten-mire&quot;&gt;Bram Luyten, @mire&lt;/h4&gt;

&lt;p&gt;Data should be stored in the research institution. Researcher’s are able to forge large volumes of data. The reputation of the institution is at stake. The academic institution has a horizon that is longer than the span of an individual career, or a single project. &lt;/p&gt;

&lt;h4 id=&quot;discussion&quot;&gt;Discussion&lt;/h4&gt;

&lt;p&gt;Two specific questions - what should be the embargo period? When do you start counting the embargo period. Would it be reasonable for a funding agency, that has a rejection rate of 90%, should they ask for this up front, or as a first deliverable? &lt;/p&gt;

&lt;p&gt;Someone is missing the researcher in terms of how we are arguing how things should be like. Many people are arguing that their projects should be the one that holds the data. This person (the economist again), does not thing we should over burden the researcher. We may end up with shiny open mediocre stuff. Putting all of your data into one big trough makes it easy to put in, but hard to get out, thinks it is better to have small projects, with community driven curation, the solution needs to be distributed. (of course this perspective does not address the actual problem that our current data policies address). &lt;/p&gt;

&lt;p&gt;Salvatore says that adding more things to do when writing a proposal is not great, but some thinking about data management can be hugely useful. We could think of a process which encourages people to make sure that the data curation and opening can happen, for example, allowing time at the end of a project with funding, for doing the curation. Set an example, and let people know that it’s OK to take time out from core research to make the data open.&lt;/p&gt;

&lt;p&gt;If you want to convince researchers to publish data, you need to make researchers understand what is happening with their data - simple legal templates could help with this. &lt;/p&gt;

&lt;p&gt;Someone says something, but I couldn’t follow what they were talking about.&lt;/p&gt;

&lt;p&gt;On the question of embargoes it’s not possible to say that this should start at the end of data collection, as this is not a well defined point in time. In the data management plan if there is a request for embargo, this should be laid out in the data management plan. A way that could work, is to tie it to the end of the funding period, and tie this to the need to have embargo requests as part of the data management plan negotiation.&lt;/p&gt;

&lt;p&gt;In the UK, we are seeing that data management plans are being required up front in the grant application. In terms of support for creating data management plans, there is a role here for libraries to help in this domain. &lt;/p&gt;

&lt;p&gt;What you need at proposal time are data management intentions, and what you need during implementation is data management practice. &lt;/p&gt;

&lt;p&gt;At proposal time getting a feeling for how much it costs would also be good. &lt;/p&gt;

&lt;h2 id=&quot;publisher-perspective&quot;&gt;Publisher perspective&lt;/h2&gt;
&lt;p&gt;#### Ian Mulvany, eLife / PLOS / PeerJ / Ubiquity Press &lt;/p&gt;

&lt;p&gt;See my statement, and slides at my &lt;a href=&quot;http://partiallyattended.com/2013/07/02/ec-open-data-consultation-our-view/&quot;&gt;previous blog post&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;fiona-murphy-wiley&quot;&gt;Fiona Murphy, Wiley&lt;/h4&gt;

&lt;p&gt;Mentions PREPARDE - this is an ongoing project and set of activities. &lt;/p&gt;

&lt;p&gt;Adapting the publication model for publication is about adapting the existing model. &lt;/p&gt;

&lt;h4 id=&quot;jarosaw-perzyski-polish-chamber-of-books&quot;&gt;Jarosław Perzyński, Polish Chamber of Books&lt;/h4&gt;

&lt;p&gt;Polish publishers do not think about growing, rather about surviving. There are two examples of alarming ideas from Poland. At the end of 2012 the polish ministry proposed that publishers mush transfer electronic rights, in this situation the government wanted to pay 50% of the cost, and have 100% control of the work - this would have been a disaster for the polish book industry.&lt;/p&gt;

&lt;p&gt;An other example is graphene research in 2012. The question is who is able to apply for the commercial use of this research. OA would mean that only rich states would be able to benefit from this work.&lt;/p&gt;

&lt;p&gt;He mentions a question about spying and connects this to open access, but I don’t understand what he said in this regard. &lt;/p&gt;

&lt;p&gt;It’s mentioned by the chair that opening things is a way to prevent spying. &lt;/p&gt;

&lt;h4 id=&quot;eefke-smit-international-association-of-scientific-technical-and-medical-publishers-stm&quot;&gt;Eefke Smit, International Association of Scientific, Technical and Medical Publishers (STM)&lt;/h4&gt;

&lt;p&gt;Publishers welcome this imitative. It is no secret to us how much of a hot topic research data is. &lt;/p&gt;

&lt;p&gt;If you want to reuse data, they must be understandable. There needs to be a connection between research data and publication. This addresses some of the fears that researchers would have in terms of researchers being afraid of others misusing their data. &lt;/p&gt;

&lt;p&gt;On the culture of sharing - it is again very important that data is integrated with publications. &lt;/p&gt;

&lt;h4 id=&quot;anita-de-waard-elsevier-data-collaborations&quot;&gt;Anita de Waard, Elsevier, Data Collaborations&lt;/h4&gt;

&lt;p&gt;Elsevier∫ - we are a large publisher (one of the best lines of the day).&lt;/p&gt;

&lt;p&gt;Storing/annotation/curation is not the same thing as sharing. &lt;/p&gt;

&lt;p&gt;They do advocate the creation of data catalogues, so that if even data is not shared, there could be a role for data catalogues, so you can at least discover what there is, who has it, and what the rights are around it.&lt;/p&gt;

&lt;p&gt;where do you store the data? there are three types of repositories&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;generic repositories&lt;/li&gt;
  &lt;li&gt;domain specific repositories&lt;/li&gt;
  &lt;li&gt;institutional repositories&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;They are interested in developing machines accessible formats for interrogating the data&lt;/p&gt;

&lt;p&gt;How do we enhance data awareness? &lt;/p&gt;

&lt;p&gt;Need to look at how the researchers are working now, need to develop tools that can store data at the point of capture - the older self wants to reuse the data created by the younger self.&lt;/p&gt;

&lt;p&gt;Allow the researcher insight into why, and the extent to which data was reused.&lt;/p&gt;

&lt;p&gt;They would like to suggest the creation of a shared network of best practice in data sharing. &lt;/p&gt;

&lt;h2 id=&quot;library-perspective&quot;&gt;Library perspective&lt;/h2&gt;
&lt;p&gt;#### Paul Ayris - LIBER&lt;/p&gt;

&lt;p&gt;Libraries should retool to be able to support data management. LERU is compiling a roadmap for the impact of research data, this will be available end of 2013. It will include looking at costs - the first question that any vice-chancellor will ask.&lt;/p&gt;

&lt;p&gt;LERU believes that there are boundaries, not all data can be bade open on day one, but they believe that the default position should be open and not closed.&lt;/p&gt;

&lt;h4 id=&quot;thomas-bourke-european-university-institute-florence&quot;&gt;Thomas Bourke, European University Institute (Florence)&lt;/h4&gt;

&lt;p&gt;Mirrors what Paul says. There are huge differences between financial economic data and development economic data. The question of scope is a key question. Libraries have established quality control mechanisms around publication, they might be able to provide something like this on the data side.&lt;/p&gt;

&lt;p&gt;The source of the data should be captured, is it original data, derived data, modified data?&lt;/p&gt;

&lt;p&gt;Would be good if the commission could hear from publishers of primary data - Bloomberg, Thompson Reuters. &lt;/p&gt;

&lt;h4 id=&quot;michael-franke-max-planck-digital-library-3&quot;&gt;Michael Franke, Max Planck Digital Library 3&lt;/h4&gt;

&lt;p&gt;What types of data should be open? 
	It is important to find intelligent ways to assess how valuable a data set is, or how appropriate it is to archive, rather than recreating.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Continuous monitoring of data reuse could tell you whether a data set should be kept any longer. It should find out how well a data set preforms in terms of reuse
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;On data awareness and the culture of sharing
	This contains a motivation problem for the researchers. There is hardly any
	individual incentive to share this. One way to overcome this dilemma is a reward system for sharing data. Such a system could go hand in hand with the San Francisco Declaration on Research Assessment (&lt;a href=&quot;http://am.ascb.org/dora/&quot;&gt;DORA&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;(at this point in the evening we are starting to heavily retread over points discussed earlier, so I am cutting back on note taking).&lt;/p&gt;

&lt;h4 id=&quot;discussion-1&quot;&gt;Discussion&lt;/h4&gt;

&lt;p&gt;On quality - libraries don’t do peer review. They do do some selection, and they ensure that the stuff you get in is the stuff that you will get out later on. Increasingly we are seeing the use of digitised material as research data collections. The libraries is increasingly becoming the data provider as well as the archiver of the data.&lt;/p&gt;

&lt;p&gt;The issue of text and data mining conversation around licensing within the EU and the breakdown of those discussions is raised as a point of discussion.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>EC consultation on Open Data - my presentation.</title>
   <link href="http://partiallyattended.com/2013/07/02/ec-open-data-consultation-our-view"/>
   <updated>2013-07-02T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/07/02/ec-open-data-consultation-our-view</id>
   <content type="html">&lt;p&gt;The following is the written representation that I made to the EC hearing on Open Data on behalf of Co-Action publishers, Copernicus Publications, eLife, F1000 Research, FigShare, Frontiers, Open Books Publishers, PeerJ, the Public Library of Science, Ubiquity Press and Bloomsbury Qatar Foundation Journals (QScience). I had a five minute slot to present, and the key recommendations at the end of this written response formed the basis of that presentation. I added one slide at the end with a personal view on some of the challenges of getting researchers to share data. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#slides&quot;&gt;Slides&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#written-representation&quot;&gt;Written representation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-can-we-define-research-data-and-what-types-of-research-data&quot;&gt;How can we define research data and what types of research data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#when-and-how-does-openness-need-to-be-limited?&quot;&gt;When and how does openness need to be limited?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-should-the-issue-of-data-re-use-be-addressed?&quot;&gt;How should the issue of data re-use be addressed?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#where-should-research-data-be-stored-and-made-accessible?&quot;&gt;Where should research data be stored and made accessible?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#how-can-we-enhance-data-awareness-and-a-culture-of-sharing?&quot;&gt;How can we enhance data awareness and a culture of sharing?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#key-recommendations&quot;&gt;Key Recommendations:&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;a-idslidesa-slides&quot;&gt;&lt;a id=&quot;slides&quot;&gt;&lt;/a&gt; Slides&lt;/h1&gt;

&lt;script async=&quot;&quot; class=&quot;speakerdeck-embed&quot; data-id=&quot;0951acc0c59301306b9616ef2e465d1f&quot; data-ratio=&quot;1.33333333333333&quot; src=&quot;//speakerdeck.com/assets/embed.js&quot;&gt;&lt;/script&gt;

&lt;h1 id=&quot;a-idwritten-representationa-written-representation&quot;&gt;&lt;a id=&quot;written-representation&quot;&gt;&lt;/a&gt; Written representation&lt;/h1&gt;

&lt;h3 id=&quot;a-idhow-can-we-define-research-data-and-what-types-of-research-dataa-how-can-we-define-research-data-and-what-types-of-research-data&quot;&gt;&lt;a id=&quot;how-can-we-define-research-data-and-what-types-of-research-data&quot;&gt;&lt;/a&gt; How can we define research data and what types of research data&lt;/h3&gt;
&lt;p&gt;should be open?&lt;/p&gt;

&lt;p&gt;Research data are primary outputs of a research process that are intended to be incorporated into research communications as support for the claims of that research. As with other research outputs, research data can be valuable to others for the purpose of validation, confirmation, and critique of research, as well as for entirely new applications that were not considered by the original researchers. Research data can be in any format. &lt;/p&gt;

&lt;p&gt;Research data generated with the support of public funds is a public good and should be open by default. This means making it available in a format and with contextual information that makes it technically usable, with the legal rights that enable re-use in any field.  We endorse the concept of “Intelligent Openness” described in the report of the UK Royal Society “Science as an open enterprise”. Data needs to be accessible, intelligible, assessable and usable.  Given a default position that data should be open the more appropriate question to ask is where and how should that openness be limited.&lt;/p&gt;

&lt;h3 id=&quot;a-idwhen-and-how-does-openness-need-to-be-limiteda-when-and-how-does-openness-need-to-be-limited&quot;&gt;&lt;a id=&quot;when-and-how-does-openness-need-to-be-limited?&quot;&gt;&lt;/a&gt; When and how does openness need to be limited?&lt;/h3&gt;

&lt;p&gt;Research data created with support from public funds should be open by default. Release of, and access to, research data should be limited in cases where making the data available will do more harm to the public good than restrictions of access. Such cases might include clinical data where personally identifiable information is included, data that reveal the location of critically endangered species, data that has potential to create a public health or security risk, poses a danger to the researchers themselves, or where the release of data would damage the conduct of the research itself.&lt;/p&gt;

&lt;p&gt;The appropriate approach to limiting openness will depend on the case in hand and should be subject to a risk assessment by appropriate experts. Methods for restricting access with a proven track record include, delaying publication for a defined period, providing access under specific conditions, or only to approved persons, or after review of a specific access request. Such systems need to be carefully considered and designed so that they hamper access as much as is appropriate but no more. We emphasise again that the default should be open, and such systems should be used only where they can be justified.&lt;/p&gt;

&lt;p&gt;The question of access to research data where there is a commercial contribution to their creation is a separate issue. Research data created by private interests is the property of the creator and can be shared in a way that advances their interests. Where public and private interests contribute to the creation, collection, or analysis of data it may be appropriate for the release of data (and other communications) to be delayed for some defined period. Such periods should be negotiated and defined in collaboration and grant agreements. We would recommend that the maximum such period should be one year after the conclusion of the project or two years after the creation of the data, whichever occurs first.&lt;/p&gt;

&lt;h3 id=&quot;a-idhow-should-the-issue-of-data-re-use-be-addresseda-how-should-the-issue-of-data-re-use-be-addressed&quot;&gt;&lt;a id=&quot;how-should-the-issue-of-data-re-use-be-addressed?&quot;&gt;&lt;/a&gt; How should the issue of data re-use be addressed?&lt;/h3&gt;

&lt;p&gt;If data is to be made available with the intention of maximising the economic impact and the public good created it is critical that re-use be enabled both technically and legally. Researchers should adopt best practice in the formatting and description of data and the Commission and other funders and community groups should support the creation, documentation, and communication of such community best practice. Data should be placed in the repositories and archives that best support the availability, discoverability and usability of the specific data. Data should be released under a license which maximises the potential for re-use and recombination of that data. The appropriate licenses are the Creative Commons CC0 waiver and CC BY copyright licenses. This approach is similar to that of “Intelligent Openess” described in the Royal Society Report.&lt;/p&gt;

&lt;p&gt;To create incentives for publicly funded researchers to maximise the re-usability of their research outputs it is important that the Commission and other funders adopt and develop approaches that measure re-use and require researchers to report on the re-use of their data. The Commission and other funders should engage with the emerging tools for tracking re-use and engagement of web resources, including data. These include initiatives and tools to support Data Citation, measures of data downloads, and online conversations around this data.&lt;/p&gt;

&lt;h3 id=&quot;a-idwhere-should-research-data-be-stored-and-made-accessiblea-where-should-research-data-be-stored-and-made-accessible&quot;&gt;&lt;a id=&quot;where-should-research-data-be-stored-and-made-accessible?&quot;&gt;&lt;/a&gt; Where should research data be stored and made accessible?&lt;/h3&gt;

&lt;p&gt;Research data should be made available in the place which best supports its use in a sustainable and reliable fashion. The question needs to be addressed on a domain by domain basis, as well as for specific data types. Funders play a critical role in supporting the infrastructure that makes data available, both its creation, and long term sustainability and shared systems and community infrastructures need to be put in place to support these services in the long term.&lt;/p&gt;

&lt;p&gt;It is generally not ideal for data to stored as supplementary data to published research papers on a publishers website. While we recognize that this is the current default for many domains of research we recommend a shift towards the housing of data in dedicated repositories, ideally specialised for specific data types and domains, but in any case focussed on the preservation, discoverability, and re-use of data as opposed to research papers. To ensure the connection between data and research communications that may be spread between a number of different repositories it is critical that effective and persistent citation systems are in place to link research to its supporting data. &lt;/p&gt;

&lt;h3 id=&quot;a-idhow-can-we-enhance-data-awareness-and-a-culture-of-sharinga-how-can-we-enhance-data-awareness-and-a-culture-of-sharing&quot;&gt;&lt;a id=&quot;how-can-we-enhance-data-awareness-and-a-culture-of-sharing?&quot;&gt;&lt;/a&gt; How can we enhance data awareness and a culture of sharing?&lt;/h3&gt;

&lt;p&gt;As noted above a critical aspect of enhancing data awareness and building a culture of data sharing is for funders to explicitly show that they value data sharing as a primary output of funded research. Specifically funders should engage with the emerging field of usage measurement and require evidence of re-use from researchers. An infrastructure that supports data citation and usage tracking is required to provide the underlying data to support this and we recommend and support the principles of the Amsterdam Manifesto on Data Citation. &lt;/p&gt;

&lt;p&gt;Funders should act as exemplars of data sharing by sharing their own data effectively and efficiently. In addition the creation of specific funding initiatives, such as Marie Curie Fellowships  that support the creation of data sharing platforms, or those providing data resources that improve reproducibility and re-usability, send a powerful message on the importance of this work to the Commission. In addition to acting as exemplars funders will also need to place achievable and appropriately scoped requirements on grant conditions to ensure effective data sharing. Such conditions should be clear, agreed, and most importantly auditable. These need to be combined with advocacy for data sharing, collection and promotion of success stories, and clear rewards for those leading the development of best practice in specific communites.&lt;/p&gt;

&lt;h2 id=&quot;a-idkey-recommendationsa-key-recommendations&quot;&gt;&lt;a id=&quot;key-recommendations&quot;&gt;&lt;/a&gt; Key Recommendations:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Publicly funded research data is a public good and should be shared effectively to maximise the benefits that arise from the public funding of research. To achieve this the default position must be that data is open.&lt;/li&gt;
  &lt;li&gt;We endorse the concept of “Intelligent Openness” from the Royal Society report. Data must be accessible, legally usable, and technically usable to maximise the benefits from sharing.&lt;/li&gt;
  &lt;li&gt;In specific and limited cases access to, or release of, research data should be restricted. There is existing and appropriate best practice in this space that can be adopted.&lt;/li&gt;
  &lt;li&gt;To support and maximise the re-use of publicly funded research data funders should promote and require best practice in data sharing and explicitly monitor and reward those who can demonstrate the re-use of data generated.&lt;/li&gt;
  &lt;li&gt;Research data should be made available from the place or places that best support its discovery and re-use, preferably in subject specific repositories. This will differ from domain to domain and between types of data. &lt;/li&gt;
  &lt;li&gt;Support for the development of infrastructure that tracks the usage and discussion of data is crucial. &lt;/li&gt;
  &lt;li&gt;Systems that support data citation and the tracking of usage are developing, require support, and should be retained in the public domain. We recommend and support the principles of the Amsterdam Manifesto on Data Citation&lt;/li&gt;
  &lt;li&gt;Funders need to act explicitly to demonstrate that they value data sharing. This can be achieved through a) acting as exemplars of best practice in sharing their own data b) supporting those that demonstrate and embody best practice in datasharing and the development of new tools that support data sharing c) requiring data sharing as a condition of funding.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;http://www.force11.org/AmsterdamManifesto&quot;&gt;Amsterdam Manifesto&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://royalsociety.org/uploadedFiles/Royal_Society_Content/policy/projects/sape/2012-06-20-SAOE.pdf&quot;&gt;Science as an Open Enterprise&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Some Thoughts on web scale annotation.</title>
   <link href="http://partiallyattended.com/2013/05/16/q-and-a-on-web-annotations"/>
   <updated>2013-05-16T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/05/16/q-and-a-on-web-annotations</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.markwareconsulting.com/&quot;&gt;Mark Ware&lt;/a&gt; recently asked me some questions about the state of web scale annotation, based on my impressions from the recent &lt;a href=&quot;http://iannotate.org/&quot;&gt;iannotate&lt;/a&gt; conference (at which I gave a short talk on the idea of &lt;a href=&quot;https://www.youtube.com/watch?v=PI-Xek9M2gU&quot;&gt;research threads&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;What is the eLife view of annotation systems? &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We like the fact that there is now a W3C standard for Open Annotations (OA). We are encouraged that so many projects out there are looking to make their annotations interoperable with this standard.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Are you planning to support open annotation on the eLife site?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We implemented discussion using Disqus, and we are happy with that so far, but we are looking at (OA) for some other potential products. If there were a way to make other annotations from other sources apparent
to our readers on our article pages we would definitely look into supporting that. We have been looking at some of the work of the &lt;a href=&quot;http://opencitations.wordpress.com/&quot;&gt;open citations project&lt;/a&gt; , and my understanding is that there is a move to make data from this project available under the OA framework.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If so, which platform would you use, Hypothes.is or something else?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We would probably use Hypothes.is, [Domeo][dom] or [annotator][ano], but it would come down to the pros and cons when it got to the point of implementation. We need to look at all of these tools more closely, but all three of these tools are excellent.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Do you see open annotation as offering something distinctively
different from earlier commenting approaches, which (I think) have had
rather limited success?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Yes. Two things mainly:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;1) many tools are looking to make their data cross functional through the OA W3C spec, that could be huge if many academic players adopt tools that support this. Think of like being RSS for scientific assertions, that would just be huge. It opens the door to all sorts of applications that simple RSS of comments don’t support.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;2) the ability to tie an activity to a specific location in the text. Though frequency of annotation may not be higher than commenting, location specific activity is intrinsically more valuable, being able to see quickly, for example, the location of a paper that has interested the most people. In addition this framework is ideally suited to making machine learning runs over the literature connect well to the human reading experience.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;How critical is the reputation management part? Hypothes.is have
made a big deal of this, with a workshop last year and a lot of
reputation experts in their advisers, but I wonder if it will add
unnecessary complexity for STM annotation? I think Hypothes.is see as
an important part of ensuring quality though?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This was not the focus of the recent workshop, which was far more about implementing the underlying infrastructure of annotation. That said I personally think you can look at three broad use cases around annotation.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Personal annotation (public or private). In this case reputation is not a concern.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Public annotation as a signifier of activity. In this case you are looking that there is annotation, rather than looking at what the annotation says. In this case reputation is required only at the level of determining whether the annotation is span or not. We have a reasonable handle on how to deal with this in other web scale systems.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Annotation as a guide to insight. In this case reputation is critically important, and it seems that the key is going to be making annotation systems interoperable, so that karma can flow from one system to another. It’s a subtle issue, and one that we will need to address going forward. John Perry Barlow made the great point that information is not the same as knowledge and not the same as insight, and it is knowledge systems that we should be striving to create.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Do you have any concern about pseudonymous commenting at eLife?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We do. We allow anonymous comments on eLife, but only where the commenter has explained who they are, and justified why their comment should be anonymous. In terms of pseudonymous commenting, this is something I am less worried about in the academic sphere, as name, identity reputation and prestige are so deeply linked. Were one academic to impersonate another I feel that this would be uncovered very quickly. In the few cases where there has been high profile sock puppetry there is usually a fairly clear smell around the topic area.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Are there any concerns about long term preservation of annotations
alongside the original article, i.e. is there any danger of them not
being as robustly preserved as journal content (e.g. with dark
archives etc.) and/or getting separated from the content?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;This is a subtle question. It’s not clear that you want all comments available all the time. A new student might be better served by the text being presented as a blank slate (something that rapgenius is not yet able to do). On the other end, were we to be able to see every annotation that had ever been made on the the bible, the annotation corpus would significantly outweigh the underlying corpus. Perhaps our systems will need to be able to selectively forget, or fumble the information? I’m not sure.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;In terms of preservation, this is something that came up in the talk and was mooted as one of the fundamental “Hilbert problems” for the annotation community. Other people felt that the majority use cases were going to be personal. I think it is fair to say that there are indeed concerns, but how those concerns break down is not clear, and what we do about them is also not clear.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;One of the deep insights in the conference was that we have not created a web, but rather a directed graph. The architecture of the internet does not allow resources to know what other resources are saying about them, or what other resources are pointing at them. Perhaps this is the problem that annotation can solve?&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>Some thoughts on the Taylor and Francis Survey.</title>
   <link href="http://partiallyattended.com/2013/04/27/tf-survey"/>
   <updated>2013-04-27T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/04/27/tf-survey</id>
   <content type="html">&lt;p&gt;I took a look at the &lt;a href=&quot;http://www.tandf.co.uk/journals/pdf/open-access-survey-march2013.pdf&quot;&gt;T&amp;amp;F survey&lt;/a&gt; with interest. I’m also very aware of the concerns and confusions that exist around licensing. I’m also aware of the “one size doesn’t fit all” argument. &lt;/p&gt;

&lt;p&gt;I’ll address the T&amp;amp;F survey first, and then I’ll briefly discuss CC-BY pros and cons, purely from the point of view of my own understanding of these issues - I might be very wrong on this.&lt;/p&gt;

&lt;p&gt;I believe there are two core flaws with the T&amp;amp;F survey.&lt;/p&gt;

&lt;p&gt;1.When asking about reuse and licensing, ownership of the work was presented as if the author owned the work. In some cases this may be true, but for the most part the work is owned either by the university or the grant funder. Most academics don’t thing that way, naturally, but this is the reason why funders can take a role in dictating licensing. &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The opportunity costs of the current system were not presented to authors in the survey, especially the aspect of financial gain that publishers make from the content that authors sign over. In effect the questions around licensing were biased in favor of the status quo. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Notwithstanding these issues, the survey had a large number of respondents, and you can’t look at those results and argue in any way that there is no concern amongst authors over the issue of licensing. For those of us who believe in the value of CC-BY it clearly sends a message that we have to up our game in explaining that value, and showing that value. &lt;/p&gt;

&lt;p&gt;On CC-BY, it really is the case that there is a potential lose of revenue to both publishers and authors, in that commercial value can be created outside of the control of either the publisher or the author. But that’s kind of the point! In reality the commercial value that will be created is very unlikely to every be actually created by publishers or authors. Saying that you don’t want this to happen is a “dog in a manger” kind of approach. It’s selfish, and short sighted. It’s the tragedy of the commons. To promote an argument like that authors might miss an opportunity to generate revenue, is to promote fear uncertainty and doubt - FUD. There will be a few cases where some authors will miss out, but the counter balance of making this content open to the commons far outweighs this downside. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Communicating better, moving from virtualenv to vagrant/Chef</title>
   <link href="http://partiallyattended.com/2013/04/23/chef-vagrant-over-virutalenv"/>
   <updated>2013-04-23T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2013/04/23/chef-vagrant-over-virutalenv</id>
   <content type="html">&lt;p&gt;I’ve been using &lt;a href=&quot;http://www.virtualenv.org/en/latest/&quot;&gt;virtualenv&lt;/a&gt; for a while, but in the past few months, since taking up the role of head of technology for eLife, I’ve been giving much more thought about how to build scalable development environments. &lt;/p&gt;

&lt;p&gt;Ever since I was managing &lt;a href=&quot;http://en.wikipedia.org/wiki/Connotea&quot;&gt;connotea&lt;/a&gt;, one of the biggest pains has been &lt;a href=&quot;http://www.mulvany.net/files/README.osx.html&quot;&gt;configuration management&lt;/a&gt;. I seem to have spent almost more time on configuring environments than on actually doing any development work (disclaimer, I don’t actually do much coding, I usually do more product management, but it’s really useful to know the development pain points). &lt;/p&gt;

&lt;p&gt;For sure package installation has gotten a lot easier over the past couple of decades. In the 1990’s I was up to my next in make files, now I usually just &lt;code&gt;pip install&lt;/code&gt; something. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.virtualenv.org/en/latest/&quot;&gt;virtualenv&lt;/a&gt; has been really nice for working with different versions of the same library on the same system, but this week I ran into a problem when trying to make &lt;a href=&quot;http://ipython.org/&quot;&gt;iPython&lt;/a&gt; aware of the packages installed within a virtual environment. The result was an afternoon of faff. &lt;/p&gt;

&lt;p&gt;At the same time I’ve been learning about &lt;a href=&quot;http://www.vagrantup.com/&quot;&gt;vagrant&lt;/a&gt;, &lt;a href=&quot;http://wiki.opscode.com/display/chef/Chef+Solo&quot;&gt;chef&lt;/a&gt; and that toolchain. Over the weekend I wondered if it could provide a replacement for virtualenv. After mucking around for a few hours
with &lt;a href=&quot;https://github.com/applicationsonline/librarian&quot;&gt;librarian&lt;/a&gt;, &lt;a href=&quot;http://www.vagrantup.com/&quot;&gt;Vagrant&lt;/a&gt; and &lt;a href=&quot;http://wiki.opscode.com/display/chef/Chef+Solo&quot;&gt;chef solo&lt;/a&gt; I ended with a virtual machine with a number of python packages installed, running an instance of &lt;a href=&quot;http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html&quot;&gt;iPython Notebook&lt;/a&gt; that can be accessed from the host browser via port forwarding. &lt;/p&gt;

&lt;p&gt;If you have already have &lt;a href=&quot;http://www.vagrantup.com/&quot;&gt;Vagrant&lt;/a&gt;, &lt;a href=&quot;http://wiki.opscode.com/display/chef/Chef+Solo&quot;&gt;chef solo&lt;/a&gt; and &lt;a href=&quot;https://github.com/applicationsonline/librarian&quot;&gt;librarian&lt;/a&gt; installed you can have it too by following these steps  &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;ss&quot;&gt;git&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sr&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elifesciences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;elife&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;git&lt;/span&gt;
   &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;elife&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;
   &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;librarian&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chef&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;
   &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vagrant&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;up&lt;/span&gt;
   &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vagrant&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssh&lt;/span&gt;
   &lt;span class=&quot;err&quot;&gt;$&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ipython&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;notebook&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ip&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;192&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;168&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;33&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Then in your host browser open &lt;a href=&quot;http://192.168.33.10:8888&quot;&gt;http://192.168.33.10:8888&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;https://github.com/elifesciences/elife-template-env&quot;&gt;elife-template-env&lt;/a&gt; repo contains a longer description of the setup.&lt;/p&gt;

&lt;p&gt;It strikes me that this way forward is a much friendlier way of packaging code. With an upcoming release of Vagrant one would also be able to deploy immediate to AWS. I was chatting to someone last night about good development practices. When we write code in a team we are communicating with other developers. How we decide to package our work is also an act of communication. I think that the vagrant approach has a lot going for it. You take a definite performance hit in setting up the VM on first run , so I’m already planning on upgrading my setup. On the other hand, in principle you get systems that can be shared really painlessly, and on balance that feels like the more important aspect. &lt;/p&gt;

&lt;p&gt;It will be interesting to see if the packaged approach also has any hope of uptake in the distribution of scientific research. We are already in discussion with a number of researchers who are interested in this idea, but I’m not sure there enough familiarity with the tools to make it take off super quickly. I’m hopeful though, as the tools are getting easier to use all the time.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Font, Spring 2013, preview</title>
   <link href="http://partiallyattended.com/2013/03/24/font-spring-2013-preview"/>
   <updated>2013-03-24T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/03/24/font-spring-2013-preview</id>
   <content type="html">&lt;p&gt;I’m about to head to Fontainbleau for another short climbing trip. I’ve been going there since 2003, this will be my 10th anniversary of going to font. &lt;/p&gt;

&lt;p&gt;The first time I went there I brought a lot of expectations with me. I was climbing pretty well and I fully expected that I should be able to run up problems of about font 6a. I think I fell off of that first 3a 6 times before I got it. It must have been years before I got any problem of 5 or harder. &lt;/p&gt;

&lt;p&gt;I really was never sure that I ever would climb something as hard as a font 6. It seemed beyond a level that I would be able to do. &lt;/p&gt;

&lt;p&gt;Eventually in 2010 I climbed a verifiable font 6a - le surplomb du lepreaux at elephant. &lt;/p&gt;

&lt;p&gt;In all that time, all the years I’ve been going, there has been one climb that has represented a level to aspire to - la Marie rose, the first 6a in the world. I’ve been falling off it for about six years now. Going into &lt;a href=&quot;http://partiallyattended.com/2013/03/24/font-spring-2011/&quot;&gt;my last trip&lt;/a&gt; I was confident. It didn’t happen.&lt;/p&gt;

&lt;p&gt;I’m going again next week.&lt;/p&gt;

&lt;p&gt;In the last six months I’ve done over 300 bouldering problems in the gym. I’ve done more fingerboard sessions targeted at improving my strength on slopers, than ever before. I’ve done more v4s in 2013 in the gym than in all other years combined. &lt;/p&gt;

&lt;p&gt;Fuck it, there really is no more that I could have done in preparation for the upcoming trip. I’m going to try la Marie rose again, and I might get it this year, or I might not. The conditions might be great, it might rain. &lt;/p&gt;

&lt;p&gt;The one thing I know is that this time when I try it, there will be no excuses, and I won’t have any regrets over my preparation. I hope I get it, and honestly I’m nervous that I might not, but I’m really happy with my training and I’m really really looking  forward to measuring it up against reality. &lt;/p&gt;

&lt;p&gt;There are a few bouldering problems lurking in the world, one took me 10 years to do, one 18 solid months of effort, trying almost every week. Marie Rose is a wonderful project, this boulder will be there, I’ll do it or I won’t, and I’ll probably keep coming back to it, hopefully for the next 10 years at least. I hope I get it. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8110/8587906112_12eec1982d_c.jpg&quot; alt=&quot;Me not getting very far on La Marie Rose in 2011&quot; title=&quot;Marie Rose, Bas Cuvier, the first 6a.&quot; /&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Font, Spring 2011, quick report</title>
   <link href="http://partiallyattended.com/2013/03/24/font-spring-2011"/>
   <updated>2013-03-24T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/03/24/font-spring-2011</id>
   <content type="html">&lt;p&gt;Well, it’s been almost a week since I got back from Fontainbleau. It was, as usual, a magical trip. Were took advantage of the row of bank holidays to get in a nice long spell in the forest without having to take too much time off work.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://farm6.staticflickr.com/5181/5685509661_68977e7df5_z.jpg&quot; alt=&quot;Trying a problem in Fontainbleau.&quot; title=&quot;bouldering&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I’d been training like a fair old bastard in order to get fit for Marie Rose, but in the end a couple of injuries stopped me going near the route, which was a pity. The first injury really dropped by level of confidence and motivation, 
but a couple of good ticks during the rest of the week, and a read of the ‘art of mastery’ pulled me out of my mini-cycle of depression and got me all rearing to go again.&lt;/p&gt;

&lt;p&gt;Firstly, a quick description of the two injuries, on the morning of the second day I suffered a hyper extension injury on my left knee. I could hobble around camp a bit painfully the next morning, and knew the game was somewhat up. I rested and iced it for two days, and then got back to climbing, though a good bit more tentatively than I’d been hoping.&lt;/p&gt;

&lt;p&gt;It help up well for the rest of the week, and I’ve just been to see am Osteopath of all people, who had given be a all clear on the injury (will continue to be sore for a little while, but continued icing and moderate exercise should see a rapid and full recovery, yay!).&lt;/p&gt;

&lt;p&gt;The second injury was just dumb. It happened on the second day that I was back on climbing after the rest from the knee injury. I was on a pretty precarious top out, though I had a clean landing and loads of spotters and loads of mats I panicked. I slapped really really hard for a flat finishing hold and bruised the shit out of my right index finger. It was really big. I thought I’d rightly buggered it. One of the people spotting me was a Sheffield bloke out in the forest with his wife and family. He got me to tape the finger, wrap it around a cold bottle for a few moments, and try the damn problem again, so I dutifully did, with a bit of doubt in my mind, and this time I pulled over the top with a bit more care. Finger still hurt like fuck though.&lt;/p&gt;

&lt;p&gt;By the end of the trip I was a bit of a walking wreck, but it was an amazing tip.&lt;/p&gt;

&lt;p&gt;The climbing hi-lights were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;watching &lt;a href=&quot;http://vimeo.com/25928351&quot;&gt;Gioia flow gracefully across a 5c+&lt;/a&gt; that no-one else could do&lt;/li&gt;
  &lt;li&gt;doing the entire 53 orange problems at 91.1 with only 7 falls (the jingo wobbly challenge in the bag). &lt;a href=&quot;http://vimeo.com/23389690&quot;&gt;The feat mad Conor bow down at my feet&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;getting my first font 6b, and maybe doing a second on the same trip!!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Doing a complete circuit in a day with Mike was magical, and one of the best climbing days of my life. 53 problems, over 250m of ascent. It was a dream.&lt;/p&gt;

&lt;p&gt;It’s clear that I need to improve some foot technique, some flexibility and some core strength, so I’m going to start a Yoga class, probably from next week on. I’m pretty strong, fingers could get stronger, to be sure, but core strength and stability at the moment is much more important.&lt;/p&gt;

&lt;p&gt;I can’t wait to go back. Some &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/sets/72157626641391660/&quot;&gt;photos&lt;/a&gt;. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Climbing review of 2012, goals 2013.</title>
   <link href="http://partiallyattended.com/2013/03/24/climbing-review-2012"/>
   <updated>2013-03-24T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/03/24/climbing-review-2012</id>
   <content type="html">&lt;h1 id=&quot;climbing-review&quot;&gt;212 climbing review.&lt;/h1&gt;

&lt;p&gt;OK, time to review the year. I wrote out some &lt;a href=&quot;http://partiallyattended.com/2012/01/08/climbing-goals-2012/&quot;&gt;goals&lt;/a&gt; at the start of last year.&lt;/p&gt;

&lt;h2 id=&quot;goals-for-2012-were&quot;&gt;Goals for 2012 were&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;remain injury free (&lt;strong&gt;not done&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;significantly reduce the amount of alcohol that I consume (&lt;strong&gt;done&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;fall off at least 10 routes of 6c or harder/month (&lt;strong&gt;not done&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;redpoint 7a, but don’t stop trying harder things (&lt;strong&gt;not done&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;get three campus board sessions or power hand sessions into my training per month (&lt;strong&gt;done&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My training diary from 2011 looked like:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://picasaweb.google.com/lh/photo/tHGUcS8CNkulh-nGJ1XDSdMTjNZETYmyPJy0liipFm0?feat=embedwebsite&quot;&gt;&lt;img src=&quot;https://lh6.googleusercontent.com/-tnkZpwNAT7k/Twok31B4M1I/AAAAAAAAAuI/QhsfYB8WWeA/s400/screen-capture.jpg&quot; height=&quot;264&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;And for 2012 it looked like:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://picasaweb.google.com/102755743034732738536/January82013#5830993441605081682&quot;&gt;&lt;img src=&quot;https://lh4.googleusercontent.com/-GzFhn0woQbY/UOvZpCaA2lI/AAAAAAAAucA/e6qrmkMKsuA/s800/Screenshot_08_01_2013_08_21.jpg&quot; height=&quot;264&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;There were two large disruptions to my climbing this year:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://partiallyattended.com/2012/06/26/go-fuck-yourself/&quot;&gt;I was diagnosed with Dupteron’s contracture&lt;/a&gt;, leaving a three month gap where I did no climbing.&lt;/li&gt;
  &lt;li&gt;I had a wonderful baby son.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The key effects were that I prioritised away from routes to bouldering for the second half of 2012. It also meant that I had far fewer trips out than in previous years, with only a few short day trips in January, and one afternoon trying a famous bouldering problem in Edinburgh. &lt;/p&gt;

&lt;p&gt;I also bought a beastmaker 1000, and started to use it regularly. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/8287399790/&quot; title=&quot;Time to get strong. by Ian Mulvany, on Flickr&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8349/8287399790_31d5b67bac.jpg&quot; width=&quot;500&quot; height=&quot;500&quot; alt=&quot;Time to get strong.&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;bouldering-tally&quot;&gt;Bouldering tally&lt;/h2&gt;

&lt;p&gt;In 2011 my bouldering tally looked like:&lt;/p&gt;

&lt;p&gt;total ~ 250&lt;br /&gt;
v3 - 55&lt;br /&gt;
v4 - 8&lt;br /&gt;
v5 - 0  &lt;/p&gt;

&lt;p&gt;And in 2012 it looked like:&lt;/p&gt;

&lt;p&gt;total - 322&lt;br /&gt;
V2	86&lt;br /&gt;
V3	90&lt;br /&gt;
V4	19&lt;br /&gt;
V5	2  &lt;/p&gt;

&lt;h2 id=&quot;climbing-highlights&quot;&gt;Climbing highlights&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;born free in Swanage, fr 6b+, one of the best lines I’ve ever climbed. I tried it in 2011, and didn’t get it clean. This time I didn’t feel as strong on the route, but I knew what was coming and I did it.&lt;/li&gt;
  &lt;li&gt;making real progress in my bouldering&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/8361012370/&quot; title=&quot;20120122-P1090024 by Ian Mulvany, on Flickr&quot;&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8073/8361012370_bceba56dd2.jpg&quot; width=&quot;500&quot; height=&quot;375&quot; alt=&quot;20120122-P1090024&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;goals-for-2013&quot;&gt;Goals for 2013&lt;/h2&gt;

&lt;p&gt;I guess it’s time to set some goals. I’ll try and use SMART metrics this time - Specific, Measurable, Attainable, Relevant and Timely. The main trip that I have planned for 2013 will be a trip to font, so that also provides a good anchor for goals for this year. I’ll also try to tie long term goals for 2013 with “now-actions” that move me towards those long term goals. &lt;/p&gt;

&lt;h3 id=&quot;smart-goals-for-2013&quot;&gt;SMART goals for 2013&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;520 boulder problems&lt;/li&gt;
  &lt;li&gt;one fingerboard session/week for weeks where I am at home&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ukclimbing.com/logbook/c.php?i=30358&quot;&gt;La Marie Rose&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;climbing &lt;a href=&quot;http://www.ukclimbing.com/logbook/c.php?i=126436&quot;&gt;Inner City Riots&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Try font 6b/6c and 7a problems when in font.&lt;/li&gt;
  &lt;li&gt;redopiont 7a+ indoors&lt;/li&gt;
  &lt;li&gt;read “&lt;a href=&quot;http://www.amazon.co.uk/Better-Bouldering-Falcon-Guides-Climb/dp/0762770317/ref=sr_1_1?ie=UTF8&amp;amp;qid=1357634978&amp;amp;sr=8-1&quot;&gt;Better Bouldering&lt;/a&gt;” by John Sherman&lt;/li&gt;
  &lt;li&gt;get away for one climbing trip to Switzerland with Daniel&lt;/li&gt;
  &lt;li&gt;climb a Dream of White Horses&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;long-term-goals-with-now-actions&quot;&gt;Long term goals with now-actions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Climb V6&lt;/td&gt;
          &lt;td&gt;try V4/V5 problems every month for the first six months of 2013&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Get to 79 kg&lt;/td&gt;
          &lt;td&gt;get to 80 kg by the end of Jan&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Climb 520 boulder problems in 2012&lt;/td&gt;
          &lt;td&gt;climb 40 boulder problems in Jan&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>ENCODE - an example of open publication and data integration.</title>
   <link href="http://partiallyattended.com/2013/01/30/euan-birney-data-publishing-talk-plos-elife"/>
   <updated>2013-01-30T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/01/30/euan-birney-data-publishing-talk-plos-elife</id>
   <content type="html">&lt;p&gt;On Monday the 14th of January we met at the PLOS offices in Cambridge to hear a talk from &lt;a href=&quot;http://genomeinformatician.blogspot.de/&quot;&gt;Euan Birney&lt;/a&gt; on lessons learned from publishing data rich publications though the &lt;a href=&quot;http://encodeproject.org/ENCODE/&quot;&gt;encode project&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This was the first time that Euan was far less worried about the print, and far more worried about how well the online version was going to work. &lt;/p&gt;

&lt;h2 id=&quot;dimensions-of-the-project&quot;&gt;Dimensions of the project&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;5 TeraBases&lt;/li&gt;
  &lt;li&gt;1715 times the size of the Human Genome&lt;/li&gt;
  &lt;li&gt;3k experiments&lt;/li&gt;
  &lt;li&gt;410 authors on the main paper&lt;/li&gt;
  &lt;li&gt;6 high profile papers&lt;/li&gt;
  &lt;li&gt;~35 companion papers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The output should not be thought of as papers, but as the raw data. The organisation and display of that data required non-paper publication methods. &lt;/p&gt;

&lt;h2 id=&quot;publishing-innovations&quot;&gt;Publishing innovations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Threads&lt;/li&gt;
  &lt;li&gt;iPad app&lt;/li&gt;
  &lt;li&gt;Interactive Figures&lt;/li&gt;
  &lt;li&gt;Virtual Machine for making the data available &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;threads&quot;&gt;Threads&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://www.nature.com/encode/&quot;&gt;Threads&lt;/a&gt; are basically paragraph level tagging. It was built by creating a HTML5 app, and the core interactivity model is the same for the website and the iPad app. A big question in the mind of the authors was would this be useful. Would reading a paragraph and a figure from different papers be too incoherent without the overall narrative of a single paper? Euan was really excited when he talked to someone who had printed an entire thread, and she asked questions about the thread. He has had more people talking to him about their use of threads, over the number of people talking about interactive figures. &lt;/p&gt;

&lt;p&gt;One of the main points behind doing threads was to bring the companion papers together with the main papers. To make it work you needed to make all of the papers open access. This could just not be done without the papers being open access. The tagging was done by the authors, they created 13 word documents, and they copy and pasted and curated the threads into these word documents. (it sounds like the worst process in the world, but the reader doesn’t care, to Euan this is just an implementation detail). They were never going to be in a position to get the different publishers to align their internal XML tagging processes so they went with the dumbest method that was guaranteed to work.&lt;/p&gt;

&lt;p&gt;For Science, Nature etcetera, they needed to make a “Special Case” to make these papers open access to allow this to work. There is an opportunity for OA publishers to be able to say “this is just what we do”. CC-BY makes the rights aspect of this trivial.&lt;/p&gt;

&lt;h5 id=&quot;some-lessons&quot;&gt;Some lessons&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Could be supported by an open tagging and mash-up site.&lt;/li&gt;
  &lt;li&gt;The tagging must be paragraph level, and not papers&lt;/li&gt;
  &lt;li&gt;You need ownership of tags, at individual and group levels. You might possibly need to include hierarchies. &lt;/li&gt;
  &lt;li&gt;The two way nature of this is interesting, threads point to papers, papers to threads.&lt;/li&gt;
  &lt;li&gt;The ordering of the tags is interesting. &lt;/li&gt;
  &lt;li&gt;A nice well executed site that scales in terms of UI is critical - what to do with thousands of threads?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This sounds like what &lt;a href=&quot;http://storify.com/&quot;&gt;storify&lt;/a&gt; does for Tweets and Blogs. &lt;/p&gt;

&lt;p&gt;In this scenario, should one just be publishing at the level of paragraphs and tags? Euan feels that the paper provide an important narrative structure. &lt;/p&gt;

&lt;p&gt;It was a decision that the threads did not require independent review, as each atom within them had already been reviewed. &lt;/p&gt;

&lt;p&gt;People have started to cite the threads via the URL of the thread, however Nature did not ask for DOI’s for the threads. (this would cause a problem for ISI and traditional citation counting practices). &lt;/p&gt;

&lt;h3 id=&quot;interactive-figures&quot;&gt;Interactive figures&lt;/h3&gt;

&lt;p&gt;This was not the most successful part of the project. There needs to be more investment into the widget creation process. There needs to be more standardisation. &lt;/p&gt;

&lt;p&gt;There was a lot of back and forth between the coders and the academics and the publishers on the creation of the interactive figures, but what does this actually give you? “It sort of doesn’t really change the world”. There could be a lot more if you could click on a data point, and drill down on that point. The authors spent a large amount of time, and created some JavaScript prototypes, and these were then refined, but they didn’t really get to a thing that they thought was useful. &lt;/p&gt;

&lt;p&gt;They tried to make every figure interactive, but they ran out of time, and perhaps lost a bit of focus around this. &lt;/p&gt;

&lt;p&gt;There needs to be an open library of JS with standard formats to go into the backed. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.biojs&quot;&gt;Biojs&lt;/a&gt; is a ground-up EBI widget group, something like this which is domain specific, targeted at specific standard data sets, could be more useful than doing custom visualisations. &lt;/p&gt;

&lt;h3 id=&quot;virtual-machine&quot;&gt;Virtual machine&lt;/h3&gt;

&lt;p&gt;This is the ultimate materials and methods for computational papers. This is not a sophisticated thing to publish, it’s just a big file. Euan is very proud of this as a scientist. It should be trivial to do from a publishing point of view. &lt;/p&gt;

&lt;p&gt;The only thing you have to worry about is the size of your supplementary file limits. Ideally one should deposit it before review, and allow reviewers to spin up for review.&lt;/p&gt;

&lt;p&gt;The thing that has been most used have been the tarballs for each individual figures, rather than the VM of the entire machine. &lt;/p&gt;

&lt;p&gt;The biggest piece of computation can’t be placed into a single VM, but they did put in one example pipeline (a bit like blue peter - here is one we did earlier).&lt;/p&gt;

&lt;h3 id=&quot;data-integration&quot;&gt;Data integration.&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Majority of structured databases have deposit during review&lt;/li&gt;
  &lt;li&gt;A few systems allow reviewer accounts, but they are not much used. The VM concept might be a better approach. &lt;/li&gt;
  &lt;li&gt;BioStudy database is piece of re-factoring for all data types - a new project coming out of the EBI in 2013. &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;biostudy&quot;&gt;BioStudy&lt;/h3&gt;

&lt;p&gt;This is a new initiative from EBI as a way to allow the weaving of multiple data intensive studies together. Each will have it’s own access number. These could be tied to individual papers, but not always. &lt;/p&gt;

&lt;h3 id=&quot;lessons&quot;&gt;Lessons&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;This kind of approach only makes sense if it’s Open Access. &lt;/li&gt;
  &lt;li&gt;The interactive figures will be harder to run if you have to make the data access hack proof.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At the outset, most people were interested in the interactive figures, the threads were known about, but not the main focus, however in the end the threads have been more successful. When they started curating threads they started out with about 26, these were collapsed down to 13 final threads. There was a balance between thin threads and thick threads, where you could think of a thin thread of being a hyper-focussed thread.&lt;/p&gt;

&lt;h3 id=&quot;message&quot;&gt;Message&lt;/h3&gt;

&lt;p&gt;He now thinks that digital publishing is truly the future, and for open access publishers this kind of thing should be easy, but it is soul searching for closed access publishers.&lt;/p&gt;

&lt;p&gt;This really highlights the difference between free to read and free to use. You can only do this when you are in the free to use domain. &lt;/p&gt;

&lt;p&gt;It has to be done generically, it can’t be done in a publishing house kind of way, as the science is not published though just one publishing house.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Product Tank 6, big data</title>
   <link href="http://partiallyattended.com/2013/01/23/product-tank-jan-2013"/>
   <updated>2013-01-23T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2013/01/23/product-tank-jan-2013</id>
   <content type="html">&lt;p&gt;I’m at &lt;a href=&quot;http://www.producttank.com/&quot;&gt;PridcutTank&lt;/a&gt; 6. Todays topic is big data.&lt;/p&gt;

&lt;h2 id=&quot;hether-savory---open-data-user-group&quot;&gt;Hether Savory - Open Data User Group&lt;/h2&gt;

&lt;p&gt;She is the chair of the &lt;a href=&quot;http://data.gov.uk/odug&quot;&gt;open data user group&lt;/a&gt;. She is using a recipe analogy for the use of data in the creation of products - data is an ingredient, but you have to get the ingredients right. (There are a number of people in the audience who work with public sector data, and more people who work with open data, but most people know about this, but they don’t use it). &lt;/p&gt;

&lt;p&gt;Public sector data is often:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;maps &amp;amp; location data&lt;/li&gt;
  &lt;li&gt;spending information&lt;/li&gt;
  &lt;li&gt;demographic and health data&lt;/li&gt;
  &lt;li&gt;traffic and transport data&lt;/li&gt;
  &lt;li&gt;business information&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The key issues is that this data is a by-product of what government does, and it is paid for by our taxes. There is an opportunity to build on top of this data. &lt;/p&gt;

&lt;p&gt;The data should be open and free because we already own the data. It’s already been paid for. &lt;/p&gt;

&lt;p&gt;They are looking to open up address data. They need the help of the community to put pressure on the Government to make this happen. They need a solid business case, and ideas from the community on how one would exploit the data to help create applications. &lt;/p&gt;

&lt;p&gt;(This is so so like the arguments around open access of the scientific literature).&lt;/p&gt;

&lt;p&gt;A question to the audience:
&amp;gt; Has charging for this data been a problem in developing applications?&lt;/p&gt;

&lt;h5 id=&quot;datagovuk&quot;&gt;Data.gov.uk&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;Nearly 9k data sets up there. &lt;/li&gt;
  &lt;li&gt;140+ data sets on the roadmap&lt;/li&gt;
  &lt;li&gt;810k visitors since July 2012&lt;/li&gt;
  &lt;li&gt;220 sites globally&lt;/li&gt;
  &lt;li&gt;worth at least 6 Billion to the economy&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;wheres-the-beef&quot;&gt;Where’s the beef?&lt;/h2&gt;

&lt;p&gt;Lots of data being used so far, but they need to know what’s missing. &lt;/p&gt;

&lt;p&gt;There are looking to get the Met office to make historic data open. They are trying to make the VAT register open. They want to make Land Registry historic price data open (as a householder I would love to get access to that data)
. River network centrelines and rights of way data is also in their sights. The most critical is the address data. &lt;/p&gt;

&lt;p&gt;There is a comparison between the ODI and Jamie Oliver - Blimey! &lt;/p&gt;

&lt;p&gt;The bottom line is that this product development community is in an ideal position to give input into what data can be used for making products. &lt;/p&gt;

&lt;h2 id=&quot;duncan-ross---director-of-data-science-teradata&quot;&gt;Duncan Ross - Director of Data Science, TeraData&lt;/h2&gt;

&lt;p&gt;Duncan is a data miner, and he is one of the founders of the &lt;a href=&quot;https://twitter.com/socdm&quot;&gt;society of data miners&lt;/a&gt;. He is very interested in prediction. Talking about the importance of prediction he points to the hilarious video of Karl Rove totally fucking up
the prediction of the election when Fox news called the election for Obama.&lt;/p&gt;

&lt;div&gt;
&lt;iframe width=&quot;640&quot; height=&quot;360&quot; src=&quot;http://www.youtube.com/embed/9TwuR0jCavk?feature=player_detailpage&quot; frameborder=&quot;0&quot;&gt;   &lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;Sam Walton, the founder of WalMart, understood the power of data. They replaced inventory with information. 
&amp;gt; You can make predictions that are wrong most of the time, but that are still incredibly valuable. &lt;/p&gt;

&lt;p&gt;He gives the example of Roulette. If you could make a prediction that was right only once in 36 times, then it would be hugely valuable. If you make a predictor about your customer base that is wrong most of the time, but that beats randomness, then if there is a return on the gambit, then the predictor can be hugely valuable. &lt;/p&gt;

&lt;p&gt;You can also use a predictor to refute. &lt;/p&gt;

&lt;p&gt;You can also test and measure your hypothesis. &lt;/p&gt;

&lt;p&gt;The topic of big data is big, and &lt;a href=&quot;http://www.amazon.co.uk/The-Signal-Noise-Science-Prediction/dp/1846147522/ref=sr_1_1?ie=UTF8&amp;amp;qid=1359016322&amp;amp;sr=8-1&quot;&gt;the signal and the noise&lt;/a&gt; by Nate Silver is recommended. &lt;/p&gt;

&lt;p&gt;The size of the data is one thing, however there are a number of other trends that enhance. &lt;/p&gt;

&lt;p&gt;CrowdSourcing on top of data is powerful. Google, &lt;a href=&quot;http://wecaptcha.com/&quot;&gt;weCAPTCHA&lt;/a&gt;, &lt;a href=&quot;http://www.kaggle.com/&quot;&gt;Kaggle&lt;/a&gt; and &lt;a href=&quot;http://www.waze.com/&quot;&gt;Waze&lt;/a&gt; are examples of companies making great use of CrowdSourcing. &lt;/p&gt;

&lt;p&gt;Location is another thing of great interest. &lt;/p&gt;

&lt;p&gt;Gamification is mentioned. (for the record I am not a fan). There is an interesting piece of information about SAS. They nearly went bankrupt, and the frequent flyers of the airlines realised that if they cashed in their air-miles the airlines would have been pushed into bankruptcy, making all of the air-miles worthless, so there was a group plea for people to &lt;strong&gt;not&lt;/strong&gt; cash in air-miles. The point being made is that had these companies found a gaming mechanisim to endear loyalty it wold have been cheaper for them. &lt;/p&gt;

&lt;p&gt;Quantified Self is another movement that Duncan is interested in. If you can start to aggregate this data then the data becomes more valuable. (There are of course privacy issues, and I predict that there will be a question about this in the QA session. If so I will be sure to ignore it - Actually, by the end of the evening it was hardly mentioned, I guess that speaks to the keen business sense of the startup community). &lt;/p&gt;

&lt;p&gt;Consumer data lockers is another interesting idea. As an example take data generated by a customer with Orange, it’s kind of assumed that the data generated is owned by Orange. A data locker is the idea that this data is held in a locker that the user has control over. BillGuard does this for credit card transactions, they monitor your credit card transactions for you looking for fraudulent transactions or wasteful transactions (only works in the US at the moment).&lt;/p&gt;

&lt;p&gt;The last thing that Duncan wants to talk about is &lt;a href=&quot;http://datakind.org/&quot;&gt;DataKind&lt;/a&gt;. It is based in the US, but it’s coming to the UK soon. The question is:
&amp;gt; how come the brightest minds of my generation are trying to improve response rates to advertising, rather than solving real problems. &lt;/p&gt;

&lt;p&gt;Charities can’t afford to hire good data people. DataKind brings charities and data miners together to work on short hack weekends looking at problems that the data miners can help the charities with. &lt;/p&gt;

&lt;p&gt;There is a slide of the reverent &lt;a href=&quot;http://en.wikipedia.org/wiki/Thomas_Bayes&quot;&gt;Thomas Bayes&lt;/a&gt; (who is buried across the road in &lt;a href=&quot;http://en.wikipedia.org/wiki/Bunhill_Fields&quot;&gt;Bunhill Fields&lt;/a&gt;). &lt;/p&gt;

&lt;h2 id=&quot;nigel-shadboltns---odiodi&quot;&gt;&lt;a href=&quot;https://twitter.com/Nigel_Shadbolt&quot;&gt;Nigel Shadbolt&lt;/a&gt; - &lt;a href=&quot;http://www.theodi.org/&quot;&gt;ODI&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Although I’m covering the event, the issue of OpenData is probably well known to readers of this blog (all 12 of you), so I’ll only type up the highlights of the talk.&lt;/p&gt;

&lt;p&gt;Key issue about open data tends to be the licensing of the data (hear hear). &lt;/p&gt;

&lt;p&gt;They need a steady stream of successes. &lt;/p&gt;

&lt;p&gt;A new story of success is the publication of MRSA infection rates in the UK. League tables were published, and in the two years since the publication there has been a greater than 90% reduction in infections. There is no way to prove that publishing the data helped, but you know, it probably helped. &lt;/p&gt;

&lt;p&gt;Another great example is prescription data. Every month in the NHS every prescription is published. Data analysis that was done on the prescription of statins indicated that 200M pounds was wasted. This is moeny that can be save &lt;em&gt;every year in the future&lt;/em&gt;, by modifying future presecription behaviour.  &lt;/p&gt;

&lt;p&gt;Contracts, and council spending id being made available. Reported crime, and crime hotspots are being published. &lt;/p&gt;

&lt;p&gt;The real trick is to get the data that people care about, and then build an actionable service around this data. (what is the actionable data for research? I think it has to be related to funding, and making the funding information available).&lt;/p&gt;

&lt;p&gt;Weather data has been made available (this will probably only depress my German Wife).&lt;/p&gt;

&lt;p&gt;There are some examples of business data. A great example is that now that the spending data for local authorities are being published, there is a company that is selling analytics back to these authorities. Many of them didn’t realise, for example, that they were paying over the odds for services that other authorities were getting better deals on. &lt;/p&gt;

&lt;p&gt;There is a very nice overview of the &lt;a href=&quot;http://www.theodi.org/&quot;&gt;ODI&lt;/a&gt;. They have had a great first 10 weeks of operation. 
&amp;gt; How do you build a business on a data feed which might not be timely, and upon whose quality you cannot depend?&lt;/p&gt;

&lt;p&gt;The ODI is a convening point for these conversations, and a place to help bridge connections. Nigel believes that unless they can create a strong demand side for data then Government’s patience for this program may wane. One needs to get to a virtuous cycle. &lt;/p&gt;

&lt;h2 id=&quot;finishing-up&quot;&gt;Finishing up&lt;/h2&gt;

&lt;p&gt;Great event, you can &lt;a href=&quot;http://www.meetup.com/ProductTank/&quot;&gt;sign up&lt;/a&gt; for the next one, and you can get an overview of &lt;a href=&quot;http://www.producttank.com/&quot;&gt;ProductTank&lt;/a&gt;. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>SpotOn day 2.</title>
   <link href="http://partiallyattended.com/2012/11/12/spoton-solo12-day2"/>
   <updated>2012-11-12T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2012/11/12/spoton-solo12-day2</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://partiallyattended.com/2012/11/11/spoton-solo12-day1/&quot;&gt;Yesterday&lt;/a&gt; was awesome, let’s see how today goes. I was watching from afar, as my &lt;a href=&quot;https://twitter.com/GioiaMosler&quot;&gt;wife&lt;/a&gt; attended, and now I’m here for the afternoon sessions. &lt;/p&gt;

&lt;h2 id=&quot;sessionsa-idtopa&quot;&gt;sessions&lt;a id=&quot;top&quot;&gt;:&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#oa&quot;&gt;Ben Goldacre&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#data&quot;&gt;publishing data, what’s in it for researchers?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;now on to the sessions! &lt;/p&gt;

&lt;h2 id=&quot;incentivising-open-accessioaa-idoaa-toptop&quot;&gt;[Incentivising Open Access][ioa]&lt;a id=&quot;oa&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;Nice panel, you can see the list of the panel on the site homepage, I’ll again, mostly focus on the trend of the discussion.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;What do researchers get credit for?&lt;/em&gt;
	[David Shotton][ds]: getting grant applications coming in, and publications in high impact journals. He has been in hiring comittees where these are the only things that have mattered. &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;There are some dark aspects of getting credit, having a team beneath you, upon which you can place your name for their publications.

You don&#39;t get credit for working in teams. 

Personal referecens from people you have a good working relationhsip with. 

We should look for concrete pieces of evidence that open beahvior has a positive effect on the kinds of measures that are being used.

Not all of the things we are doing are measurable.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is a bit of a discussion around tying things to ORCID, the suggestion is made to tie reviewing work from frontiers to ORCID ids. (I think we as a community can see the potential of making contributions visible, and weaving n all of these non-traditional aspects, however it will take a social shift, which is where funder mandates come in).&lt;/p&gt;

&lt;p&gt;There is a bit of discussion around the stack overflow model. &lt;/p&gt;

&lt;p&gt;There is a bit of discssion around sticks, in particular the RCUK model. Why are funding agencies so polite to scientists, when they are putting in the model. The Wellcome are withholding 10% of the grant if the grantee is not OA complient. Stephen .. says he would like to see public statement disavowing the use the impact factor. 
&amp;gt;If you want to have other contributions considered the way to do this is to cure our addiction to the impact factor&lt;/p&gt;

&lt;p&gt;The RCUK person mentions that this has been made explicit with the RCUK policy. She also mentions that the issue with IF is that the addiciton is happening at the research level. She says that it would be good if there were a peer pressure around not publishing in open access.&lt;/p&gt;

&lt;p&gt;Graham from Frontiers agrees that funders have a signifcant role, but it can work on a much smaller scale with communutities of editors. As an example, one community within frontiers decided that no papers would be even considered for review unless authors made their data open. Communities can enable openess on a small scale, and technology can help with this. &lt;/p&gt;

&lt;p&gt;One of the final comments is about looking for cultural change
&amp;gt; every perosn in this room needs to go out an walk the walk and talk the talk. Scientists are not donkeys, but they are hurd animals, and we need to move the hurd.&lt;/p&gt;

&lt;p&gt;(It strikes me that tool makers have a big role to play, if we can make tools that build on top of open data, and open publicaitons. Problems that we can help solve include litature )&lt;/p&gt;

&lt;h2 id=&quot;publishing-data-whats-in-it-for-researcherspda-iddataa-toptop&quot;&gt;&lt;a href=&quot;http://www.nature.com/spoton/event/spoton-london-2012-publishing-research-data-whats-in-it-for-me/&quot;&gt;publishing data, what’s in it for researchers?&lt;/a&gt;&lt;a id=&quot;data&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;The [Royal Society][rs] report on science as an open enterprise, really hilights the importance of data - but as ever the question is going to be how to convince researchers what is in it for them. Panelst says that the case has already been made, and we should now be takling about how, and not why. I guess that if we just pretend that the case has been made, maybe that really is a viable option. You know, one day we wake up and just look surprised when a researcher says they don’t want to share their data, and then they shake their head and say, oh, I thought I was living in a differnet univers, or something. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://crc.nottingham.ac.uk/projects/jord.php&quot;&gt;JORD&lt;/a&gt; and &lt;a href=&quot;http://www.google.co.uk/search?q=dryad&amp;amp;oq=dryad&amp;amp;sugexp=chrome,mod=16&amp;amp;sourceid=chrome&amp;amp;ie=UTF-8&quot;&gt;dryad&lt;/a&gt; are mentiond. [eLife] already has a paper with data deposited in dryad. &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/npch&quot;&gt;Neil Chu Hong&lt;/a&gt; presents the best “one slide” I’ve seen so far, it has about 10 slides worth of content on it, Neil is talking about the &lt;a href=&quot;http://openresearchsoftware.metajnl.com/&quot;&gt;journal of open research software&lt;/a&gt;, and the cahllenges of getting scientists to use proper tools like version control, and the fact that the incremental benefit for an individual researecher is pretty small. Software is not just data, but there are a lot of things that are similar. (I’ve done a review of a couple of submissions for jors, and it’s interesting, as understanding other people’s code is hard).&lt;/p&gt;

&lt;p&gt;The issue of “intellegent openess” is mentioned. It seems to mean well structued openess where objects are made open in a way that allows them to be discovered, and possibly machine read. We are trying to make data connections to eLife articles wasy through our &lt;a href=&quot;http://dev.elifesciences.org/&quot;&gt;API&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Oh oh, a new thing, I’d not heard of the [PRIME][prime] project before, a meatdata exchange between publishers and repositories, I’ll definitly have a look at that. &lt;/p&gt;

&lt;p&gt;The PERPARADE project is mentioned, they are working with the &lt;a href=&quot;http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)2049-6060&quot;&gt;Geoscience Data Jounrnal&lt;/a&gt;. (the acronym of PREPARADE is a bit nutty, but the project looks good). &lt;/p&gt;

&lt;p&gt;I like the comment from &lt;a href=&quot;http://f1000.com/&quot;&gt;F1000&lt;/a&gt;, that when they said to researchers that publishing their data would give them precendence on the data was a very powerful argument. &lt;/p&gt;

&lt;p&gt;(At this moment in the discussion I got a little distracted). &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>SpotOn day 1.</title>
   <link href="http://partiallyattended.com/2012/11/11/spoton-solo12-day1"/>
   <updated>2012-11-11T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2012/11/11/spoton-solo12-day1</id>
   <content type="html">&lt;p&gt;I’ll keep a partial, live-idsh blog going during the day. I’ve been going to these things, I think, since about 2008. I really like these meetings. I’m going to probably keep these notes pretty lightweight. &lt;/p&gt;

&lt;h2 id=&quot;sessionsa-idtopa&quot;&gt;sessions&lt;a id=&quot;top&quot;&gt;:&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#ben&quot;&gt;Ben Goldacre&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#front&quot;&gt;Kamila &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#replace&quot;&gt;Session on whether science journalism will be replaced&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#alms&quot;&gt;Altmetric track&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;now on to the sessions! &lt;/p&gt;

&lt;h2 id=&quot;ben-goldacrebg---opening-keynote-on-data-a-idbena-toptop&quot;&gt;&lt;a href=&quot;http://www.badscience.net/&quot;&gt;Ben Goldacre&lt;/a&gt; - opening keynote, on data. &lt;a id=&quot;ben&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;Ben is talking about the issues that arise when you place a lot of data in one place. Modern tools that allow large data sets to be indexable create a new thing, a thing that not many people understand. He makes the analogy between bringing many atoms of uranium together, this creates a qualatativley different thing. Dangerous, but powerful. Data has a similar property. (We often manage to ignore the potential power that the elves at google have). He mentions the new data store on health data.&lt;/p&gt;

&lt;p&gt;For individual studies, we are learning ways to slightly distort the data to make it more useful. Bringing a lot of data together allows you to start looking for patterns. Sometimes you are only seeing faces in the cloud, but sometimes you do see real patterns. HRT is an interesting example where just observing leads you down very much the wrong path. You need to have randomised control trials. &lt;/p&gt;

&lt;p&gt;There is a great example of giving steroids to people with head injuries coming into A&amp;amp;E. There were no randomised trials, and people were unwilling to not give steroids, as there was a belief that it worked. When you are facing a person who is dying on the table it is very hard to take a step back and make the decision to not give the intervention &lt;em&gt;even if there was no evidence that the intervention worked&lt;/em&gt;. When they finally did the trial they discovered that people who were given the steroids were more likely to die. &lt;/p&gt;

&lt;p&gt;(Although not as dramatic, by a long way this issue of trying randomised trials is something that is also hard in a business context, as large companies start to increase the cost of trying small iterations, one of the issues being the overhead that comes along with increased amounts of communication with a larger number of stakeholders). &lt;/p&gt;

&lt;p&gt;Ben mentions the problem also extends to government policy. Government tends to like to do pilot studies, and not controlled trialls. He was involved in the writing of a &lt;a href=&quot;http://www.cabinetoffice.gov.uk/resource-library/test-learn-adapt-developing-public-policy-randomised-controlled-trials&quot;&gt;white paper&lt;/a&gt; on the value of randomised trials in determining the effectiveness of policy. (an old &lt;a href=&quot;http://sm.psc.isr.umich.edu/debra/&quot;&gt;climbing partnerr&lt;/a&gt; of mine works on these issues, it’s interesting to look at existing data to see where policy has a real effect). &lt;/p&gt;

&lt;p&gt;One of the threads of the talk is looking at data a low cost (how do you reduce the cost of iterating, and finding out whether what you are doing is working? - a common call in the startup scene, however it should be said that we often plough on regardless of the evidence, and just like doing what we like doing, it’s really hard to pay attention to the data). &lt;/p&gt;

&lt;p&gt;How do you design trials that are cheap, that show you how to find those small improvements? &lt;/p&gt;

&lt;p&gt;At the moment we are already collecting a lot of data in health system. If you take the opportunity to put a little bit of structure at the beginning you can get a lot of valuable information downstream. They are doing a trial by looking at &lt;a href=&quot;http://en.wikipedia.org/wiki/Statin&quot;&gt;statins&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;The idea is to randomly assign a statin to people at the doctor, and track this at the point of assignment. (there is no current information on which statin is better, and they are effectively being assigned randomly, but with no tracking). By adding this small piece of structure at the beginning you end up with a nice randomised trial. &lt;/p&gt;

&lt;p&gt;If you could impose this structure at any point where there was uncertainty in efficacy of interventions, you could turn the whole of the NHS into a testing machine for finding those 1% improvements, that collectivity can have en enormous positive effect on our health.&lt;/p&gt;

&lt;p&gt;Ben talks about the need to have tools that can find good content to read, over the crud, in the same way that we want to find good studies, over shit studies. (They are about to launch a project with the open data foundation that looks at waste that is happening at the point of prescription). &lt;/p&gt;

&lt;p&gt;He discusses &lt;a href=&quot;http://altmetrics.org/manifesto/&quot;&gt;altmetrics&lt;/a&gt; - briefly. &lt;/p&gt;

&lt;p&gt;(Of course these issues of looking for good filters, and finding context at point of consumption, is an interesting topic, that is top of mind for a lot of us).&lt;/p&gt;

&lt;h2 id=&quot;kamila-markramkm---publishing-science-in-the-internet-age-a-idfronta-toptop&quot;&gt;&lt;a href=&quot;http://bluebrain.epfl.ch/page-68308-en.html&quot;&gt;Kamila Markram&lt;/a&gt; - publishing science in the internet age &lt;a id=&quot;front&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;Kamila is one of the founders of &lt;a href=&quot;http://www.frontiersin.org/&quot;&gt;frontiers&lt;/a&gt;. She starts by talking about some trends with science online. A trend is facebook, most scientists are now there, however both facebook and linkedin do not cater the direct needs of scientists. (I have some opinions about the value of online scientific networks and the difficulty of building these things). &lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://www.frontiersin.org/events/all_events&quot;&gt;frontiers network&lt;/a&gt; immediately increased pageviews on articles and author profiles (+70% on some metrics). (this is pretty impressive). &lt;/p&gt;

&lt;p&gt;She mentions that google docs is being used to collaboratively creating papers. IMO getting the authoring tools fixed is one of the big areas of schlep/opportunity in the science communication space. &lt;/p&gt;

&lt;p&gt;(There are a very large number of services being mentioned in this talk, I have heard of most of them, but there seems to be too many for me to grok, and check on whether or not I know them). &lt;/p&gt;

&lt;p&gt;It also looks like frontiers is built on top of ASP, that is one stack that I have very little experience of. &lt;/p&gt;

&lt;p&gt;Kamila starts talking about publishing trends. There are some comments about open access. She is touching on the issue of bias in peer review. For sure, peer review is this weird process, and there is a lot of bias. (“~~Fixing~~”/Augmenting peer review, let’s do that - actually, the issue is the social aspect, it’s soylent green, it’s totally made up by researchers themselves, it was put to me that the least important community is are the senior academics, as they are the ones that will die soonest).&lt;/p&gt;

&lt;p&gt;What Frontiers have done with the peer review system is really nice. They have an open collaborative peer review system. In addition they track ALMs on published papers, and they do a review, looking for the most read papers, after a few months. Papers that get into this top list, get invited to be extended to review papers, and this has worked really well (though to be honest, on their journals pages it took me a few minutes to find the journals, I think this site is optimised for google to be the main landing route to the content). &lt;/p&gt;

&lt;p&gt;To see the reviewers you can navigate to the bottom of the paper, see &lt;a href=&quot;http://www.frontiersin.org/Non-Coding_RNA/10.3389/fgene.2012.00233/full&quot;&gt;here&lt;/a&gt;, for example. (the reviewers are exposed in a naked DOM element, this would be a really really great candidate for a microformat markup, the reviewers are not included in the article XML, so figuring out how to machine read this data is not totally transparent, but it is a great start.) &lt;/p&gt;

&lt;p&gt;They do link through to a &lt;a href=&quot;http://community.frontiersin.org/people/PengJin/14793&quot;&gt;profile of the reviewer&lt;/a&gt;. I couldn’t see a list of papers that this person had reviewed, but I understand that they have metrics which allow them to query in their backend to find out which reviewers end up accepting papers that get more reads, indicating that those reviewers are able to better identify better research. That would be really interesting information to make public. &lt;/p&gt;

&lt;p&gt;You can see an example of a &lt;a href=&quot;http://www.frontiersin.org/Journal/AbstractImpact.aspx?s=1270&amp;amp;name=Non-Coding_RNA&amp;amp;ART_DOI=10.3389/fgene.2012.00233&amp;amp;type=1&quot;&gt;metrics&lt;/a&gt; page here. &lt;/p&gt;

&lt;p&gt;(IMO the key thing about the network that they have generated is that there is a very close connection between the published object and the persons involved with those published objects. I always wanted that for nature network, and had wished that we could have auto-created profile pages for nature authors, but with a journal like Nature you just have a very large challenge with legacy data.)&lt;/p&gt;

&lt;p&gt;I’ve been looking for a landing page showing trending or top articles, but I can’t find one at the moment. I’ll post a link later if I find such a page. &lt;/p&gt;

&lt;h2 id=&quot;session-on-whether-science-journalism-will-be-replaceda-idreplacea-toptop&quot;&gt;Session on whether science journalism will be replaced&lt;a id=&quot;replace&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;There is a lot of violent agreement in &lt;a href=&quot;http://www.nature.com/spoton/event/spoton-london-2012-will-multimedia-content-created-by-organisations-replace-traditional-science-journalism/&quot;&gt;this session&lt;/a&gt;. Agreement is that new media won’t replace science news media, but can compliment it.  &lt;/p&gt;

&lt;p&gt;Some comments of moderate interest from this session:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;many members of the public still believe that news in unbiased&lt;/li&gt;
  &lt;li&gt;having a science presence in the newsroom is a &lt;strong&gt;good&lt;/strong&gt; thing&lt;/li&gt;
  &lt;li&gt;mainstream news continues to attract larger audiences than new media on it’s own.&lt;/li&gt;
  &lt;li&gt;need a guarantee of independence &lt;/li&gt;
  &lt;li&gt;“Wellcome trust funded everything to do with lovely things”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I guess the reason that this is even a topic is that there is a feeling that science can be presented in terribly distorting ways in the media. &lt;/p&gt;

&lt;p&gt;A good question is, who is doing long form journalism on science? The answer is not many, but rather that long form is happening, and if the science story is sufficiently interesting, then it will get run, however that said, there ain’t that much long form happening.&lt;/p&gt;

&lt;p&gt;An interesting point is raised that new media are just cutting science coverage as they feel they can get this info from PR sources, so rather than the question of whether science journalism &lt;em&gt;should&lt;/em&gt; be replaced, economic pressures may result in it being replaced. I would say that there may be very little that the people in this room can do about this. &lt;/p&gt;

&lt;p&gt;What seemed like a nice topic that we could all agree on, unsurprisingly, end up being about money, resourcing, and mission. The question is raised, would organisations that are investing in big PR resources, consider pooling money to support a fully independent journalist? The short answer from Wellcome is “yes”. &lt;/p&gt;

&lt;p&gt;In the Q&amp;amp;A session I mention the &lt;a href=&quot;http://hypothes.is/&quot;&gt;http://hypothes.is/&lt;/a&gt;, which I am interested in, but needs a bit more time. One of the big underlying questions, along with money, is trust. Ah, sure, it’s a small issue, I’m sure we will get an answer to it any day soon :/. &lt;/p&gt;

&lt;h2 id=&quot;altmetric-trackata-idalmsa-toptop&quot;&gt;&lt;a href=&quot;http://www.nature.com/spoton/event/spoton-london-2012-altmetrics-beyond-the-numbers/&quot;&gt;altmetric track&lt;/a&gt;&lt;a id=&quot;alms&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;This track on altmetrics is covering some of the basics. The room is very well attended, I’m interested in mostly hearing the questions from the audience. Brian Kelly has a &lt;a href=&quot;http://ukwebfocus.wordpress.com/2012/11/08/understanding-the-limits-of-altmetrics-slideshare-statistics/&quot;&gt;great post&lt;/a&gt; looking at some of the data issues around the numbers, but I’m mostly interested in hearing what the conversation is like on ALMs. &lt;/p&gt;

&lt;p&gt;So, questions:&lt;/p&gt;

&lt;h4 id=&quot;q-can-we-link-between-press-releases-and-alm-signals&quot;&gt;Q: can we link between press releases and ALM signals?&lt;/h4&gt;
&lt;p&gt;A: only if the press releases contain links to the papers. &lt;/p&gt;

&lt;h4 id=&quot;q-twitter-is-good-now-what-do-we-do-in-5-years-with-the-next-tool&quot;&gt;Q: Twitter is good now, what do we do in 5 years with the next tool?&lt;/h4&gt;
&lt;p&gt;A: No clear answer on this, um. &lt;/p&gt;

&lt;h4 id=&quot;q-can-you-images-alms-being-used-for-qualitative-measurement-to-determine-the-quality-of-the-content-in-the-paper&quot;&gt;Q: Can you images ALMs being used for qualitative measurement? To determine the quality of the content in the paper.&lt;/h4&gt;
&lt;p&gt;A: It would be useful, there is no indication from the answers on how we would do this? &lt;/p&gt;

&lt;h4 id=&quot;q-what-about-gaming&quot;&gt;Q: What about gaming?&lt;/h4&gt;
&lt;p&gt;A: That’s a big question, and it has a bit of a complex answer. The reality is that we are not yet in a moment where these metrics are having an actual effect yet. &lt;/p&gt;

&lt;h4 id=&quot;q-if-you-can-count-something-should-you-impact-factor-has-obvious-flaws-but-at-least-its-a-known-set-of-flaws-a-fixation-on-counting-without-understanding-the-meaning-is-significantly-problematic&quot;&gt;Q: If you can count something should you? Impact Factor has obvious flaws, but at least it’s a known set of flaws. A fixation on counting without understanding the meaning is significantly problematic.&lt;/h4&gt;
&lt;p&gt;A: Not a question, but no argument without that statement. &lt;/p&gt;

&lt;h4 id=&quot;q-what-does-the-audience-want-alms-for&quot;&gt;Q: What does the audience want ALMs for?&lt;/h4&gt;
&lt;p&gt;A:&lt;br /&gt;
- doing social network analysis on top of the data would be helpful. 
- &lt;/p&gt;

&lt;h4 id=&quot;q-there-seems-to-be-tremendous-potential-marrying-the-social-graph-to-alms-at-a-large-scale-but-scientists-are-generally-only-interested-in-a-small-set-of-people-so-is-it-worth-doing-it-at-a-large-scale-is-it-possible&quot;&gt;Q: There seems to be tremendous potential marrying the social graph to ALMs at a large scale, but scientists are generally only interested in a small set of people, so is it worth doing it at a large scale, is it possible?&lt;/h4&gt;
&lt;p&gt;A: Some thoughts on this ..&lt;/p&gt;

&lt;h4 id=&quot;q-what-is-missing-what-would-be-worthwhile-to-add&quot;&gt;Q: What is missing, what would be worthwhile to add?&lt;/h4&gt;
&lt;p&gt;A: &lt;br /&gt;
- anonoymized  library reading data
- crowd source links of interest 
- &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The new food.</title>
   <link href="http://partiallyattended.com/2012/11/11/cheese-not-jectpacks"/>
   <updated>2012-11-11T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2012/11/11/cheese-not-jectpacks</id>
   <content type="html">&lt;p&gt;&lt;img src=&quot;http://farm3.staticflickr.com/2192/2510965876_713aba466b.jpg&quot; alt=&quot;a piece of cheese&quot; title=&quot;a piece of cheese&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I got to spend a really fun forty minutes or so this morning with &lt;a href=&quot;http://en.wikipedia.org/wiki/Patrick_O._Brown&quot;&gt;Pat Brown&lt;/a&gt;, down at the home of &lt;a href=&quot;http://lyricalfoods.com/&quot;&gt;Lyrical Foods&lt;/a&gt;, the new project that he is involved in. They are aiming to replace the dairy and cattle industry by producing food from plant derived products that is indistinguisable from the original products. They have already created artisinal cheeses that are indistingushable from milk-based cheeses, and I understand that they are currently working on fake blood, that has the same response profile to cooking, as real blood does.&lt;/p&gt;

&lt;p&gt;Why? &lt;/p&gt;

&lt;p&gt;The goal is truly ambitious, to replace and restructure an indsutry that takes up a huge amount of land, water resources, and that causes significant amountns of greenhous gas emissiosns. &lt;/p&gt;

&lt;p&gt;I was actually visiting to chat about publishing, as Pat is also one of the founders of a small publisher that you might have heard of, goes by the names of &lt;a href=&quot;http://plos.org&quot;&gt;PLOS&lt;/a&gt;. They are located in an industrial unit in menlo park, and you walk in and it looks like most other office spaces, then you walk through past the front desk, and there is an open space, hang-out room, with some coders chilling on some sofas (very start up), and then past that there is a huge open spaced room with a large microbiology lab. A freakin large open spaced microbilogy lab, with loads of activity, of the “making cheese from plants” variety. &lt;/p&gt;

&lt;p&gt;He showed me some sample cheeses that they had cilling in the fride, one looked like an incredibly appetising brie. (I sadly didn’t get a chance to taste one). &lt;/p&gt;

&lt;p&gt;I asked what the cost margins were in contrast to the traditional route for cheese making, and Pat said, back of envelope, they have something like a 35-fold cheaper process, but that there are a lot of open questions to resolve. He said the food production industry has set a very low bar on efficiency. &lt;/p&gt;

&lt;p&gt;There have been some observations recently that the hi-tech industry has stalled in the big impact changes to impact society at large. Indoor plumbing, the car, maybe the cell phone, but the vast majority of innnovation has been navel-gazing stuff (shinier computers, flashier web sites). If you could get rid of the need to farm the majority of our food, you would have a o
breakthrough that would fundamentally change humanity. &lt;/p&gt;

&lt;p&gt;This is a &lt;strong&gt;big idea&lt;/strong&gt;, and really one that is worthy of the potential of the valley. You could save the ecosystem of the planet, you may be able to life billions of people out of poverty, or remove the need for them to toil for the creation of food. You would create a basis for the fundamental reappraisal of the ethical relationship beteen man and other species on earth, if we no longer were in a position where we had to eat those species.&lt;/p&gt;

&lt;p&gt;The following sloagans were written up on their walls:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Our mission is to revolutionise the food production industry by replacing meat and dairy with plant based alternatives”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“the impact of what we will do will be so profound, and so great, that the earth itslef will look different from space”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;“EVERY DAY MATTERS”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;http://www.flickr.com/photos/pacificbro/pacificbro&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Last minute changes to our solo12journals line up.</title>
   <link href="http://partiallyattended.com/2012/11/10/last-minute-changes"/>
   <updated>2012-11-10T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2012/11/10/last-minute-changes</id>
   <content type="html">&lt;style&gt;
* {margin:0; padding:0}
body {font:11px/1.5 Verdana, Arial, Helvetica, sans-serif; background:#FFF}
#text {margin:50px auto; width:500px}
.hotspot {color:#900; padding-bottom:1px; border-bottom:1px dotted #900; cursor:pointer}

#tt {position:absolute; display:block; background:url(images/tt_left.gif) top left no-repeat}
#tttop {display:block; height:5px; margin-left:5px; background:url(images/tt_top.gif) top right no-repeat; overflow:hidden}
#ttcont {display:block; padding:2px 12px 3px 7px; margin-left:5px; background:#666; color:#FFF}
#ttbot {display:block; height:5px; margin-left:5px; background:url(images/tt_bottom.gif) top right no-repeat; overflow:hidden}
&lt;/style&gt;

I&#39;m really excited about the session that we will be running at SpotOn London in just &lt;b&gt;two days time&lt;/b&gt;!!. We 
have titled the session &lt;a href=&quot;http://www.nature.com/spoton/event/spot-on-london-2012-the-journal-is-dead-long-live-the-journal/&quot;&gt;the journal is dead, long live the journal&lt;/a&gt;. There is a lot of change going on, in the
world of scientific publishing, pressures both intrinsic and extrinsic, and without doubt PLOS One 
is changing both the submission behaviour of researchers and the strategic planning of STM publishers.
&lt;/br&gt;
&lt;/br&gt;
Some advocates of revolution in the publishing ecosystem advocate for the total removal of publishers. Some 
publishers seem not to believe that OA poses any real threat to their business models, where does the truth lie?
&lt;/br&gt;
&lt;/br&gt;
Whatever you feel about the future of scientific publishing, it is unquestionable that change is afoot. Now we just need to 
see how much change, and how deep. 
&lt;/br&gt;
&lt;/br&gt;
We are interested in focusing the panel on the here and now - major publishers embracing OA, megajournals eating a growing portion of article submissions, article level metrics exposed on the top journals, open questions about what the value is that publishers really bring to the table, these are all questions of the now. 
&lt;/br&gt;
&lt;/br&gt;
With that aim in mind we had assembled a stellar panel, with a representative across almost every scale, the individual scientist pushing their research out on their homepage - &lt;a href=&quot;http://www.perlsteinlab.com/&quot;&gt;Ethan Perlstein&lt;/a&gt;, the one true megajournal - &lt;a href=&quot;http://www.plos.org/staff/damian-pattinson/&quot;&gt;Damian Pattinson&lt;/a&gt; from &lt;a href=&quot;http://www.plosone.org/home.action&quot;&gt;PLOS One&lt;/a&gt;, the big traditional publisher - Davina Quarterman from &lt;a href=&quot;http://eu.wiley.com/WileyCDA/&quot;&gt;Wiley&lt;/a&gt;, the software company creating tools that run across all journals - &lt;a href=&quot;http://twitter.com/mz2&quot;&gt;Matias Piripari&lt;/a&gt; from &lt;a href=&quot;http://www.mekentosj.com/papers/&quot;&gt;Papers&lt;/a&gt;. 
&lt;/br&gt;
&lt;/br&gt;
Unfortunately at the very last minute, for personal reasons, Davina has had to pull out. That leaves a little gap in our line up, but we have a cunning plan. We are going to try to convince as many people as we can from the publishing industry who will be attending the conference to come along to our session.
&lt;/br&gt;
&lt;/br&gt;
If you represent a traditional publisher, and you would like to sit up at the front, rather than lob questions in from the audience, please drop us a line, &lt;span class=&quot;hotspot&quot; onmouseover=&quot;tooltip.show(&#39;wonders if this should be the motto of the publishing industry&#39;);&quot; onmouseout=&quot;tooltip.hide();&quot;&gt;there is still plenty of time&lt;/span&gt;.
&lt;/br&gt;
&lt;/br&gt; 

&lt;script type=&quot;text/javascript&quot; language=&quot;javascript&quot;&gt;
var tooltip=function(){
	var id = &#39;tt&#39;;
	var top = 3;
	var left = 3;
	var maxw = 300;
	var speed = 10;
	var timer = 20;
	var endalpha = 95;
	var alpha = 0;
	var tt,t,c,b,h;
	var ie = document.all ? true : false;
	return{
		show:function(v,w){
			if(tt == null){
				tt = document.createElement(&#39;div&#39;);
				tt.setAttribute(&#39;id&#39;,id);
				t = document.createElement(&#39;div&#39;);
				t.setAttribute(&#39;id&#39;,id + &#39;top&#39;);
				c = document.createElement(&#39;div&#39;);
				c.setAttribute(&#39;id&#39;,id + &#39;cont&#39;);
				b = document.createElement(&#39;div&#39;);
				b.setAttribute(&#39;id&#39;,id + &#39;bot&#39;);
				tt.appendChild(t);
				tt.appendChild(c);
				tt.appendChild(b);
				document.body.appendChild(tt);
				tt.style.opacity = 0;
				tt.style.filter = &#39;alpha(opacity=0)&#39;;
				document.onmousemove = this.pos;
			}
			tt.style.display = &#39;block&#39;;
			c.innerHTML = v;
			tt.style.width = w ? w + &#39;px&#39; : &#39;auto&#39;;
			if(!w &amp;&amp; ie){
				t.style.display = &#39;none&#39;;
				b.style.display = &#39;none&#39;;
				tt.style.width = tt.offsetWidth;
				t.style.display = &#39;block&#39;;
				b.style.display = &#39;block&#39;;
			}
			if(tt.offsetWidth &gt; maxw){tt.style.width = maxw + &#39;px&#39;}
			h = parseInt(tt.offsetHeight) + top;
			clearInterval(tt.timer);
			tt.timer = setInterval(function(){tooltip.fade(1)},timer);
		},
		pos:function(e){
			var u = ie ? event.clientY + document.documentElement.scrollTop : e.pageY;
			var l = ie ? event.clientX + document.documentElement.scrollLeft : e.pageX;
			tt.style.top = (u - h) + &#39;px&#39;;
			tt.style.left = (l + left) + &#39;px&#39;;
		},
		fade:function(d){
			var a = alpha;
			if((a != endalpha &amp;&amp; d == 1) || (a != 0 &amp;&amp; d == -1)){
				var i = speed;
				if(endalpha - a &lt; speed &amp;&amp; d == 1){
					i = endalpha - a;
				}else if(alpha &lt; speed &amp;&amp; d == -1){
					i = a;
				}
				alpha = a + (i * d);
				tt.style.opacity = alpha * .01;
				tt.style.filter = &#39;alpha(opacity=&#39; + alpha + &#39;)&#39;;
			}else{
				clearInterval(tt.timer);
				if(d == -1){tt.style.display = &#39;none&#39;}
			}
		},
		hide:function(){
			clearInterval(tt.timer);
			tt.timer = setInterval(function(){tooltip.fade(-1)},timer);
		}
	};
}();
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>The journal is dead, long live the journal - abstract.</title>
   <link href="http://partiallyattended.com/2012/10/28/jidlltj-abstract"/>
   <updated>2012-10-28T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/10/28/jidlltj-abstract</id>
   <content type="html">&lt;p&gt;With &lt;a href=&quot;https://twitter.com/sharmanedit&quot;&gt;Anna Sharman&lt;/a&gt; and &lt;a href=&quot;https://twitter.com/BobOHara&quot;&gt;Bob O’Hara&lt;/a&gt;, I’ll be hosting a session on the future of academic journals at SpotOnLondon (formerly ScienceOnline London). You can check out the session details &lt;a href=&quot;http://www.nature.com/spoton/event/spot-on-london-2012-the-journal-is-dead-long-live-the-journal/&quot;&gt;here&lt;/a&gt;. They have posted the short version of the abstract on the site, I’m posting the longer version here, and you can also see our &lt;a href=&quot;https://docs.google.com/a/elifesciences.org/document/d/15AEAreKuPdQN1GFVWGozzvL4N_nxwNKC3j-zMuBU8ac/edit#&quot;&gt;google planning document&lt;/a&gt;. We will update with details on the panel very soon.&lt;/p&gt;

&lt;h2 id=&quot;abstract&quot;&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Today’s online articles and journals remain mostly an online mirror of print products. Reduced time to publication and the potential for low-cost widespread dissemination are the two main benefits that journals gain from being on the web, yet many online innovations have not had much of an effect on our core concept of what a journal is. Innovations in business models, technology and social behaviours could all lead to changes in what a journal could be. &lt;/p&gt;

&lt;p&gt;This session will touch on the following questions. Are there any innovations that are having an effect on the mainstay of scientific communication - the journal? If you are a publisher, should you be looking to do anything different from what you are doing today? What can you practically do in 2012, and what are the challenges? If you are a reader or an author, what should you be demanding? Are there any enhancements to the journal that could offer a significant improvement  to your ability to do science and to advance your career?&lt;/p&gt;

&lt;p&gt;In preparation for this session we have decided to direct the conversation towards three core areas of discussion.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Megajournals; their impact on the journal and on how papers are going to be organised into journals. Will megajournals lead to a two tier marketplace of high end journals and a few megajournals, with mid-tier journals disappearing from the market altogether? &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;How do we find the papers of interest, in a world where journal brand doesn’t help? In a world where issues disappear, and researchers’ main point of contact with the literature is through aggregation points such as Google Scholar and Pubmed, what are the signifiers that we can build or support that will enable researchers to find the content that they need? &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Once you get down to the paper, are there any innovations that we should be using now, at the individual paper level, and what are the barriers to us doing this? &lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We feel that this conference will offer plenty of opportunity to cover related topics, so we will try to avoid the following areas of discussion in this session:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;altmetrics&lt;/li&gt;
  &lt;li&gt;data publication &lt;/li&gt;
  &lt;li&gt;open access per se &lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Data literature integration workshop.</title>
   <link href="http://partiallyattended.com/2012/10/11/literature-data-integration"/>
   <updated>2012-10-11T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/10/11/literature-data-integration</id>
   <content type="html">&lt;h1 id=&quot;literature-data-integration-workshop-2012-10-10&quot;&gt;Literature Data integration workshop 2012-10-10&lt;/h1&gt;

&lt;p&gt;There are many people attending today. I’m not sure whether the attendee list will be released. I’ve taken notes, but rather rapidly. I may have ended up mis appropriating comments, missed comments, or inserted comments that didn’t happen, so take the below with the appropriate health warnings. I still need to check on the links, and pull together a link list at the bottom, but I wanted to get the write up out while it was still in front of me. I’ll also do a scan later for typos and grammatical errors. &lt;/p&gt;

&lt;h2 id=&quot;sessionsa-idtopa&quot;&gt;sessions&lt;a id=&quot;top&quot;&gt;:&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#intro&quot;&gt;13.05 - 13.30 Workshop scope and goals. Thomas Lemberger&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rrd&quot;&gt;Session 1: Data Reuse, Reproducibility and Discoverability&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ea&quot;&gt;13.30-13.40 Wolfgang Huber: Executable articles - publishing data with data analysis code and narrative&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#drsp&quot;&gt;13.40-13.50 Jason Swedlow: Data Reuse, Sharing and Publication with the Open Microscopy Environment&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#timo&quot;&gt;13.50-14.00 Timo Hannay: Text Mining and Data Publishing for Journals&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#dcd&quot;&gt;14.00-14.10 Lee-Ann Coleman DataCite: discover, access and re-use research&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#discss&quot;&gt;14.10-15.10 Discussion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#s2&quot;&gt;Session 2: Quality and Data Stewardship&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#unst&quot;&gt;15.30-15.40 Alvis Brazma Structured vs unstructured data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#gott&quot;&gt;15.40-15.50 Norbert from Gottingen&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#qas&quot;&gt;15.50-16.00 Todd Vision Will authors care about the quality and stewardship of their data?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#wiki&quot;&gt;16.00-16.10 Alex Bateman Crowd-sourcing literature data for Biological Databasesi&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#d2&quot;&gt;16.10-17.10 Discussion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thursday&quot;&gt;Thursday 11th October&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#jsdm&quot;&gt;Session 3: Journal Strategies for Data Management&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#pub&quot;&gt;9.00 - 9.10 Iain Hrynaszkiewicz Current and future approaches to data publication in scholarly journals&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#rrr&quot;&gt;9.10 - 9.20 Laurie Goodman Article Publication &amp;amp; Data Hosting to Improve Release, Reuse, &amp;amp; Reproducibility&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#plos&quot;&gt;9.20 - 9.30 Theo Bloom Current situation and future ideas for data associated with PLOS journals&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ppp&quot;&gt;9.30 - 9.40 John Sack Data: Publish, Post, or Perish&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#jcbv&quot;&gt;9.40 - 9.50 Mike Rossner JCB viewer, Rockefeller University Press&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#end&quot;&gt;11.00 - 11.15 Summing up. Led by: Ewan Birney &amp;amp; Mark Patterson&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;welcome--opening-remarks&quot;&gt;Welcome &amp;amp; Opening Remarks&lt;/h2&gt;
&lt;p&gt;#### 13.00 - 13.05 Welcome Jo McEntyre
#### 13.05 - 13.30 Workshop scope and goals. Thomas Lemberger&lt;a id=&quot;intro&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Some opening comments. A lot of data is unstructured, there are structured repositories too. Many of the unstructured repositories mostly live separately from the papers that are related to the data. Key point for this workshop, how can we bring ideas and evidence together again? A serious point is that there is a fear that most of the data in drug discovery cannot be reproduced, can have potential significant impacts on global health. What is a paper? - some tables, some figures, a lot of text. Providing the text as OA is fantastic, yet text mining has limitations. e.g. in extracting pathways. Figures are mostly data convolved into pixels in a way that makes it hard to extract that data. Figures are central to a formal scientific demonstration. They are part of the natural scientific workflow, they represent the structure of scientific investigation. &lt;a href=&quot;http://jcb-dataviewer.rupress.org/&quot;&gt;JCB data viewer&lt;/a&gt; is an example of how to move beyond this situation. Making the underlying data for tables and figures available is key. What underlying data should be made available? The underlying data, the original blots? What of very large underlying data? What of data about the data? There are some common characteristics among figures within biology papers. Think of figures as structured digital objects, they can be though of as objects that draw connections between the literature, curated dbs, datasets. The EMBO SourceData project is mentioned (I can’t find a link to this project yet). The paper of the future? It will probably remain something similar to the cognitive unit that we are used to today. OA to the underlying text will be there, but we need to go beyond that, where in the back there will be a machine readable version of the paper - data, methods, claims etc. &lt;/p&gt;

&lt;p&gt;There are alway tradeoffs. Some listed: &lt;/p&gt;

&lt;table cellpadding=&quot;5&quot; width=&quot;55%&quot;&gt;
	&lt;tr&gt;&lt;td&gt;structured&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;unstructured&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;raw&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;processed&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;data&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;metadata&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;centralised&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;distributed&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;scale&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;quality&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;automatic&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;manual&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;benefit &amp;amp; incentive&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;cost &amp;amp; burden&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;idealism&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;pragmatism&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;public&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;credit attribution&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;legal requirements&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;community norms&lt;/td&gt;&lt;/tr&gt;
	&lt;tr&gt;&lt;td&gt;bottom-up&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;top-down&lt;/td&gt;&lt;/tr&gt;	
	&lt;tr&gt;&lt;td&gt;openness&lt;/td&gt;&lt;td&gt;vs.&lt;/td&gt;&lt;td&gt;privacy&lt;/td&gt;&lt;/tr&gt;		
&lt;/table&gt;

&lt;p&gt;The goal of this workshop is to propose some pragmatic suggestions towards ‘intelligently open data’, within the context of basic biomedical research, and not clinical epidemiological data. &lt;/p&gt;

&lt;p&gt;Focus on low-hanging fruit, that we could reach within one year, such as for example: 
* data availability statement in a paper
* dedicated data reference list
* figure source data
* bi-directional links between db’s and papers
* other ideas …&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;session-1-data-reuse-reproducibility-and-discoverabilitya-idrrda-toptop&quot;&gt;Session 1: Data Reuse, Reproducibility and Discoverability&lt;a id=&quot;rrd&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;CHAIR: David Shotton&lt;/p&gt;

&lt;p&gt;The problem is that most research data rots on the hard-drives of postdocs. The problem is not lack of resources, but rather that the researchers are too busy doing things that are more important to them, they have few skills in data curation, and they are not rewarded for data curation. We need good tools, practices, and more sustainable publication sites for data. They have made citation data for a good chunk of the OA literature available at &lt;a href=&quot;http://opencitations.net/source-data/&quot;&gt;http://opencitations.net/source-data/&lt;/a&gt;. One of the formats that they make this data avilalbe as are &lt;a href=&quot;http://sw.deri.org/2008/07/n-quads/&quot;&gt;N-quads&lt;/a&gt; and &lt;a href=&quot;http://www.bibjson.org/&quot;&gt;bibJson&lt;/a&gt; (though today the N-quad link seems to be broken). &lt;/p&gt;

&lt;p&gt;David presents an interface that they have created to make it easier to capture metadata about datasets. It’s a web-form tool that can take the submitted data and convert it into an XML or RDF representation of the metadata. This is no doubt makes the downstream processing of data a lot easier, but I have to say that the screen shot presented looked like the usability of the form was fairly low. (A qustion of ease of use came up during the discussion, some researchers are placing data into unstrucutred repositories because it is easier to do, than to fill in the forms to get their data into more appropriate structured repositories. It is suggested that this is not a good excuse, almost that researchers have a duty to go through these hoops, however I strongly feel that unless we as tool makers taker the issue of usability seriously, then our tools are destined to fail.&lt;/p&gt;

&lt;h5 id=&quot;wolfgang-huber-executable-articles---publishing-data-with-data-analysis-code-and-narrativea-ideaa-toptop&quot;&gt;13.30-13.40 Wolfgang Huber: Executable articles - publishing data with data analysis code and narrative&lt;a id=&quot;ea&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Wolfgang presents a tool called &lt;a href=&quot;http://www.statistik.lmu.de/~leisch/Sweave/&quot;&gt;Sweave&lt;/a&gt;. Encode provide the full [virtual machine][evm], which can either be downloaded locally (as an 18GB vm!!!!), or spun up in AWS. (I think another tool that is like this is [dexy][dx])&lt;/p&gt;

&lt;p&gt;http://www.bioconductor.org/
http://www.bioconductor.org/packages/release/BiocViews.html#___ExperimentData 
[evm]: http://scofield.bx.psu.edu/~dannon/encodevm/
[dx]: http://www.dexy.it/&lt;/p&gt;

&lt;h5 id=&quot;jason-swedlow-data-reuse-sharing-and-publication-with-the-open-microscopy-environmentomea-iddrspa-toptop&quot;&gt;13.40-13.50 Jason Swedlow: Data Reuse, Sharing and Publication with the &lt;a href=&quot;http://www.openmicroscopy.org/site&quot;&gt;Open Microscopy Environment&lt;/a&gt;&lt;a id=&quot;drsp&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;One of the problems is that images are now used as measurements. In a lab it is routine for a single post-doc to generate up to 50Gigs of data in an afternoon. In OME what they do is provide ‘glue’. This could be a common file format. The first of these is OME-TIFF. It is really dumb, it just adds some MD into the top of a TIFF file. The XML they now place in these files is supported by many vendors. &lt;a href=&quot;http://loci.wisc.edu/software/bio-formats&quot;&gt;Bio-Formats&lt;/a&gt; is a java library, is open source, reads about 120 image formats. They have up to 70K data sets, up to 1TB of data. They have a data management platform - &lt;a href=&quot;http://www.openmicroscopy.org/site/products/omero&quot;&gt;OMERO&lt;/a&gt;. It’s a java application with a lot of code generation. OMERO also has some nice tools, like a slice viewer. The JCB data viewer is also backed by OMERO. ASCB created a CELL library, where anyone could submit data, and a human curation interface was built on top of this.&lt;/p&gt;

&lt;p&gt;Some lessons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;image data publication is now&lt;/li&gt;
  &lt;li&gt;re-use is anecdotal&lt;/li&gt;
  &lt;li&gt;download does not make the data accessible - you need the applications&lt;/li&gt;
  &lt;li&gt;do you want just some data, or do you want peer reviewed data&lt;/li&gt;
  &lt;li&gt;there is not substitute for manual curation of submissions  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt; &lt;/p&gt;

&lt;h5 id=&quot;timo-hannay-text-mining-and-data-publishing-for-journalsa-idtimoa-toptop&quot;&gt;13.50-14.00 Timo Hannay: Text Mining and Data Publishing for Journals&lt;a id=&quot;timo&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Timo describes &lt;a href=&quot;http://figshare.com/&quot;&gt;figshare&lt;/a&gt; and &lt;a href=&quot;http://SureChem.com/&quot;&gt;SureChem&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Likes to think of figshare as like a youtube for data, a place where you can put your data. Each item gets a DOI, there are metrics available on the items. Part of the business model for figshare is being able to provide this functionality to publishers. Publishers want to provide these services, but it’s not as easy to do as you would like. There has been a lot of interest amongst publishers, since launch, in having figshare providing this functionality and data hosting, for the journal. They are currently providing this for F1000 research. &lt;/p&gt;

&lt;p&gt;SureChem provides chemical patent search. Provides search over 80M documents. Underlying SureChem is some really smart technology, it will do entity identification, including items that is has never seen before. Lots of heuristics for dealing with fuzzy text. Will do the same with bitmapped images. You can draw a structure of sub-strucure, and you can use that to draw a structure to search by. &lt;/p&gt;

&lt;p&gt;They have started to link SureChem to the journals, and link the journals to the patent information, and link both to databases.  &lt;/p&gt;

&lt;h5 id=&quot;lee-ann-coleman-datacite-discover-access-and-re-use-researcha-iddcda-toptop&quot;&gt;14.00-14.10 Lee-Ann Coleman DataCite: discover, access and re-use research&lt;a id=&quot;dcd&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;http://www.datacite.org/&quot;&gt;DataCite&lt;/a&gt; was founded in 2009. It is a member of the international DOI foundation. It is a registry for DOI names. Not for profit, 16 full members, members work with data centres within their own countries. They provide a shared infrastructure for DOIs. There is also a social community element. At a global level members work to agree on standards, but at a local level people work together to swap ideas and new services. The [British Library][bl] is an allocating agent. They provide DataCite infrastructure to enable UK data centres to mint DOIs. They do not work with individuals, but rather with organisations. &lt;/p&gt;

&lt;p&gt;DOIs are global, widely adopted, most widely used identifier for research articles, there is a good governance and infrastructure, it is now an ISO standard. &lt;/p&gt;

&lt;p&gt;They expect mandatory metadata for datasets. Provide a landing page for each dataset, can maintain working URLs and has trust that the organisation has  curation and preservation policies in place. 116 active data centres. 1M records in the data store, 1.5M DOIs in total. 50k resolutions a months. There is a nice tool called &lt;a href=&quot;http://crosscite.org/&quot;&gt;crosscite&lt;/a&gt;, which is currently under construction. &lt;/p&gt;

&lt;h5 id=&quot;discussion-a-iddiscssa-toptop&quot;&gt;14.10-15.10 Discussion &lt;a id=&quot;discss&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;There was an interesting discussion, I didn’t capture any of it. &lt;/p&gt;

&lt;p&gt;Levels of reuse - citation, meta-analysis, computational analysis
Metadata  - who needs it, how much and which data? (fundability - meta-analysis)
Attribution and credit (citation)
Computation - text mining, semantic web (computational analysis)
The importance of data reproducibility - executable figures &amp;amp; articles&lt;/p&gt;

&lt;h5 id=&quot;tea&quot;&gt;15.10-15.30 Tea&lt;/h5&gt;

&lt;h3 id=&quot;session-2-quality-and-data-stewardshipa-ids2a-toptop&quot;&gt;Session 2: Quality and Data Stewardship&lt;a id=&quot;s2&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h3&gt;
&lt;p&gt;CHAIR: Wolfram Horstmann  &lt;/p&gt;

&lt;h6 id=&quot;alvis-brazma-structured-vs-unstructured-dataa-idunsta-toptop&quot;&gt;# 15.30-15.40 Alvis Brazma Structured vs unstructured data&lt;a id=&quot;unst&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h6&gt;

&lt;p&gt;At what level do we want to structure data? &lt;a href=&quot;http://www.mged.org/Workgroups/MIAME/miame.html&quot;&gt;MIAME&lt;/a&gt; is presented as a project that got it right. There us an experiment, and there are some well described characteristics if this. &lt;a href=&quot;http://www.ebi.ac.uk/arrayexpress/&quot;&gt;ArrayExpress&lt;/a&gt; gives as MIAME score. Reviewers and journal editors just don’t care about whether data is data is MIAME complete. MIAME is important, it has enabled the creation of a data refinery such as &lt;a href=&quot;http://www.ebi.ac.uk/gxa/&quot;&gt;ATLAS&lt;/a&gt;. Alvis is now the most least structured advocate at the EBI. New technologies are emerging, you have to be able to combine the new with the old. The data is growing to such an extent that it becomes challenging for one institute to say that they have “all the data”, but at the same time you want to link of all of the data together. EBI will not have a database for unstructured data. There is no name for this yet, but it is planned to be released in 2013. At the centre of the idea will be a “study”. This will become the key identifier for a linked object. Can be linked to data files, bio-samples, assays, external databases, publications, etc., etc., etc..&lt;/p&gt;

&lt;h5 id=&quot;norbert-from-gottingena-idgotta-toptop&quot;&gt;15.40-15.50 Norbert from Gottingen&lt;a id=&quot;gott&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Talking about the role of libraries, the institutional role, it’s education and training role, and the interoperability role. &lt;/p&gt;

&lt;p&gt;They have been spending quite some time talking about research data management. At the institutional level, you need to look across disciplines. Are there generic infrastructures that you need to bring into existence. A library will not speak of the discussions within a community, they have to seek communalities across discipline. He mentions an interesting initiative that happened in the early 90s to create identifiers for single journal articles. He mentions the importance of interoperability. Institutional archives are just emerging, China, South America, are just building out their repositories. Already in Europe there are over 50 research infrastructure initiatives. How do we make sure people do not spend their time in 10 working groups at different levels, talking about the same thing? &lt;/p&gt;

&lt;h5 id=&quot;todd-vision-will-authors-care-about-the-quality-and-stewardship-of-their-dataa-idqasa-toptop&quot;&gt;15.50-16.00 Todd Vision Will authors care about the quality and stewardship of their data?&lt;a id=&quot;qas&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Todd is involved with &lt;a href=&quot;http://datadryad.org/&quot;&gt;Dryad&lt;/a&gt;. This aimed at capturing the long-tail of data. Will researchers care about data stewardship? We really don’t know. An excellent example of a problem mentioned was where the data was provided, but it was not made clear which sub-set of provided data was used for the analysis in the journal article. Others trying to re-use this ran into trouble. This leads to dissatisfaction, and a tendency to not caring about data stewardship. How can we create a virtuous circle? How can authors compete to get good marks for stewardship of the data. At the moment we have a binary acceptance criteria, either the data is available or not. We need to have some kind of mark of data quality, if there was a competition amongst researchers to get this mark of quality for grant awards or promotion, then this could lead to a much better ecosystem. Todd is not sure that the solution is, but he sees two things that are promising, one is the use of altmetrics (he mentions &lt;a href=&quot;http://impactstory.org/&quot;&gt;impact story&lt;/a&gt;). Another element might be to have greater gradation of quality stamps for long-tail data. Dryad is guilty of this, as they only have accepted or non-accepted. They don’t have tiers of quality.  &lt;/p&gt;

&lt;h5 id=&quot;alex-bateman-crowd-sourcing-literature-data-for-biological-databasesa-idwikia-toptop&quot;&gt;16.00-16.10 Alex Bateman Crowd-sourcing literature data for Biological Databases&lt;a id=&quot;wiki&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Alex wants to get all of the good data out of the literature with relatively small teams of people. They would like the biologists to do this work for them, this is called community annotation, and it has been pretty disastrous over the last 20 years. &lt;/p&gt;

&lt;p&gt;With [rfam][rf]: their database is composed of wikipedia articles. In the past year they have had about 15k edits. They have managed to capture a long tail of people who have made edits. (the wikipedians tend to come along and delete a lot of stuff, they they also do a lot of formatting).&lt;/p&gt;

&lt;p&gt;They struck a deal with the journal RNA Biology. They had to submit a Wikipeida article along with the journal articles, but they have only had 20 articles submitted in the past 3 years.&lt;/p&gt;

&lt;p&gt;They have been creating stub-articles in wikipedia. They provide suggestions of papers that might be relevant. If you give people no motivation, you get on average 13% in growth in size of the articles. You get patchy results. You can get motivation by homework assignment to PhD studies. Increase in articles by 211% on a small number of articles. Of these people, none became regular contributors. &lt;/p&gt;

&lt;p&gt;If you want to ratchet up the motivation levels, you can make your job depend on it. This led to a 355% increase in the size of the articles, but this does not scale well. &lt;/p&gt;

&lt;p&gt;It’s hard to motivate scientists to do this. You get contributions, but it’s patchy. The bio-curators in the group are really the backbone of this. You need a core of people who will be there checking.&lt;/p&gt;

&lt;p&gt;Another experiment was run by &lt;a href=&quot;http://flybase.org/&quot;&gt;flybase&lt;/a&gt;, they did direct emailing of authors. They were asking authors, in a simplified way, to identifier what the elements were in their papers, and asking them to say something simple about the things in their papers.&lt;/p&gt;

&lt;p&gt;If they emailed authors within a few weeks of publication they got a response rate of about 50%, if they got the author in that sweet-spot. &lt;/p&gt;

&lt;p&gt;Rate of response against time dropped exponentially. &lt;/p&gt;

&lt;p&gt;One of the reasons this works is that this is a small community of people, helping to annotate a core community resource. If it is a small community, then then you can get that buy-in. &lt;/p&gt;

&lt;h5 id=&quot;discussiona-idd2a-toptop&quot;&gt;16.10-17.10 Discussion&lt;a id=&quot;d2&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Again a very nice discussion, that I didn’t capture, and a very nice dinner in Cambridge with much jovial discussion. &lt;/p&gt;

&lt;h2 id=&quot;thursday-11th-octobera-idthursdaya-toptop&quot;&gt;Thursday 11th October&lt;a id=&quot;thursday&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;h4 id=&quot;session-3-journal-strategies-for-data-managementa-idjsdma-toptop&quot;&gt;Session 3: Journal Strategies for Data Management&lt;a id=&quot;jsdm&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h4&gt;
&lt;p&gt;CHAIR: Véronique Kiermer &lt;/p&gt;

&lt;h5 id=&quot;iain-hrynaszkiewicz-current-and-future-approaches-to-data-publication-in-scholarly-journalsa-idpuba-toptop&quot;&gt;9.00 - 9.10 Iain Hrynaszkiewicz Current and future approaches to data publication in scholarly journals&lt;a id=&quot;pub&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Additional files are archiving ‘gaps in the market’ There is a really long tail of file types that are available. More best practices are needed. There are lots of examples of sub-optimal use, lots of things like tables in pdfs, but it is still a useful thing to be providing. &lt;/p&gt;

&lt;p&gt;How can we incentivise people to follow best practice for publishing data? [bopsharing&lt;a href=&quot;biosharing.org&quot;&gt;bios&lt;/a&gt; provide a good set of interoperable formats. BMC has been trying to make authors make use of these. They allow authors to publish for free if the author uses an interoperable format. People are not organically identifying this as a good initiative.&lt;/p&gt;

&lt;p&gt;A solution for a publisher is to not worry about managing data, just send it to a repository. &lt;a href=&quot;http://datacite.org/repolist&quot;&gt;datcite repolist&lt;/a&gt; lists over 100 repositories in life sciences.&lt;/p&gt;

&lt;p&gt;There is an ‘availability of supporting data’ section. Designed as a flexibly section, could just be a link to the repository, it is a standard section, you can do a free text search. It is optional for the most part, authors can use it if they want to demonstrate that they are being transparent, still need to do a lot of work to get authors to use best practices in citing data. A great example of a shit practice is authors only naming the repo and not providing a URI.&lt;/p&gt;

&lt;p&gt;Biomedcentral has a collaboration with &lt;a href=&quot;http://www.labarchives.com/&quot;&gt;labarchives&lt;/a&gt;. (people, labarchives rocks, it really does). A nice integration is that there are links straight from labarchives to the BMC submission system. &lt;/p&gt;

&lt;p&gt;BMC opened a [public conslutation on the licensing structure of data in OA publications][].&lt;/p&gt;

&lt;p&gt;There are some technical challenges, but I missed the slide. &lt;/p&gt;

&lt;p&gt;!! Concern regarding CCO allowing people to not cite work. Some academics are afraid that CC0 will mean that other researchers do not need to cite them. We need to work hard to stop this idea from taking hold, as it is wrong. There is also a fear that people are going to plagiarise, if work is in the public domain or that organistations may make money off of items in the public domain (which is you know, not at all like pubishers making money off of items behind paywalls). &lt;/p&gt;

&lt;p&gt;A nice counterpoint is the open data initiative from Nigel Shadbolt and Tim Berneres-Lee. &lt;/p&gt;

&lt;p&gt;We need to find better ways to educate authors about these issues. &lt;/p&gt;

&lt;p&gt;What will be the sustainability model for data journals and repositories. &lt;/p&gt;

&lt;h5 id=&quot;laurie-goodman-article-publication--data-hosting-to-improve-release-reuse--reproducibilitya-idrrra-toptop&quot;&gt;9.10 - 9.20 Laurie Goodman Article Publication &amp;amp; Data Hosting to Improve Release, Reuse, &amp;amp; Reproducibility&lt;a id=&quot;rrr&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;&lt;a href=&quot;http://www.gigasciencejournal.com/&quot;&gt;Gigasciecne&lt;/a&gt; has a novel publishing platform, in that they combine the data platform with the publishing platform. How do we do data review - that gigascience are already doing. How can we cite data and how can we create active papers.&lt;/p&gt;

&lt;p&gt;They will only accept data under a CC0 licence - easy! They include how one should cite the paper, they include related manuscripts, they include information on related DOIs. They also include accession numbers for data that is not housed in GigaDB. &lt;/p&gt;

&lt;p&gt;There are papers that have cited the data - in the references, and there are papers that have cited the data as released. This has required a cultural shift (it needs work on educating the academic community the editorial community of our journals). A list of publishers were asked whether they would accept data citations, may publishers - including Elsevier - said yes. Cell said they would not publish a paper that cites data. &lt;/p&gt;

&lt;p&gt;In terms of reviewing the data, they often select specific reviewers for the job of just looking at the data. They are trying to put in all of the tools that people use to do their analysis in place where reviewers can get to them, to aid reproducibility. &lt;/p&gt;

&lt;h5 id=&quot;theo-bloom-current-situation-and-future-ideas-for-data-associated-with-plos-journalsa-idplosa-toptop&quot;&gt;9.20 - 9.30 Theo Bloom Current situation and future ideas for data associated with PLOS journals&lt;a id=&quot;plos&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;It is now very rare for people to do science today not on a computer. There is instant capture. Then they put it in a box. Then they take some of it out of a box and throw away information by pushing information through some kind of Microsoft product. &lt;/p&gt;

&lt;p&gt;What would be better? An integration collection of methods results data and metadata. How close are we to the perfect world, and how much are we just bolting on things to the old world?&lt;/p&gt;

&lt;p&gt;What is data? PLOS are working with the following:&lt;/p&gt;

&lt;p&gt;The digital material collected and generated in the process of doing research.&lt;/p&gt;

&lt;p&gt;It does not include the bibliographic metadata
Not non-digital materials&lt;/p&gt;

&lt;h1 id=&quot;layers-of-data-associated&quot;&gt;layers of data associated&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;essential to replicate the major findings&lt;/li&gt;
  &lt;li&gt;all of the data that went into the pot to make the data, raw, unprocessed, replicated.&lt;/li&gt;
  &lt;li&gt;from beginning to end, the soup-to-nuts. Every single trace, and digital trail.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Sometimes we are not clear which level we are talking about.&lt;/p&gt;

&lt;p&gt;Where should it all go? In a nut - not on that author’s website. Bigger is better. &lt;/p&gt;

&lt;h5 id=&quot;john-sack-data-publish-post-or-perisha-idpppa-toptop&quot;&gt;9.30 - 9.40 John Sack Data: Publish, Post, or Perish&lt;a id=&quot;ppp&quot;&gt;?&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Highwire work with 150 publishers (including eLife), 1700 journals, 1k+ books. They work with so many publishers. &lt;/p&gt;

&lt;p&gt;There are a lot of stakeholders involved in data publication. Search engines are a key stakeholder (first time anyone mentioned this today, but it’s a great point). &lt;/p&gt;

&lt;p&gt;In terms of roles - data repositories - journals - search engines - funders.&lt;/p&gt;

&lt;p&gt;Are we re-inventing the problem of journals with data repositories. &lt;/p&gt;

&lt;p&gt;John raises the issue or centralisation vs federation, in terms of the rise of the number of data repositories. Authors just see the diversity of application-level interfaces, raises the question for the author of “where should I deposit”. John is advocating for fewer uniform larger deposit locations, with the applications layer built on top of those, and with authors having to worry about fewer places to place their data.&lt;/p&gt;

&lt;p&gt;The journal becomes an index to the data.&lt;/p&gt;

&lt;p&gt;The search engine in the index to the journal - google - google scholar - pubmed - etc. &lt;/p&gt;

&lt;p&gt;One of the issues that journals have is with the issue of “publishing data”. Most journals do not want to take on the responsibility of peer reviewing the data. Perhaps better to think about the journals as being a conduit to get to posted or deposited data. &lt;/p&gt;

&lt;p&gt;They wonder whether people actually reuse data?&lt;/p&gt;

&lt;p&gt;In terms of preservation there should be no dead links. There is a lot of link-rot in scientific journals. The link rot is 20% every two years. After about five years half of the links are dead. Typically these are author locations, or links to research projects. Author locations are definitely transient. &lt;/p&gt;

&lt;p&gt;What would google do with these transient links? Google recommends that we not use only opaque identifiers to point to data, but that we use textual descriptions in addition. This is a kind of belt and braces approach. Textual citations have worked for centuries, the link citation text can lead to a computed path to the location if the URI or ID goes dead. (that is a great point). &lt;/p&gt;

&lt;h5 id=&quot;mike-rossner-jcb-viewer-rockefeller-university-pressa-idjcbva-toptop&quot;&gt;9.40 - 9.50 Mike Rossner JCB viewer, Rockefeller University Press&lt;a id=&quot;jcbv&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h5&gt;

&lt;p&gt;Data need context. Funder policies say very little about implementation, enforcement of funding. People as a resort, have turned to the standard of publishing. &lt;/p&gt;

&lt;p&gt;Journals have always been drawing from the data, or connecting to it but what do you do if you publish a type of data for which there was no public repository. In 2007 this was the case, and led to the creation of &lt;a href=&quot;http://jcb-dataviewer.rupress.org/&quot;&gt;JCB&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Issues facing microscopy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;more than 100 file formats, many proprietary (.META is a real player format).&lt;/li&gt;
  &lt;li&gt;multi-dimensional - 5d&lt;/li&gt;
  &lt;li&gt;sheer volume of data - numbers and size of images (a single z-stack can generate 12k images).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;High content screens can produce 1M images. Recently they posted a 300 Gigapixel image. That was 20GB in size. The final resolution of the image was 16M dpi. &lt;/p&gt;

&lt;p&gt;The JCB data viewer is a browser based app for viewing these kind of images. &lt;/p&gt;

&lt;p&gt;For authors it gives them the opportunity to present the data as they have collected - no whiff of photoshop. In general this is a good thing. &lt;/p&gt;

&lt;p&gt;This tool is simply amazing, the hope is that it becomes a standard for publishing image data, and gains adoption across publishers. I was too busy looking at how amazing the tool is, to write up great notes on it. &lt;/p&gt;

&lt;p&gt;There are discussions with Stanford to set up a repository for this data. If that happens then there will be a large amount of curation and hand holding. &lt;/p&gt;

&lt;h5 id=&quot;session-4-concluding-discussion-and-workshop-outcomes&quot;&gt;Session 4: Concluding Discussion and Workshop Outcomes&lt;/h5&gt;
&lt;p&gt;CHAIR: Andrew Sugden&lt;/p&gt;

&lt;h4 id=&quot;summing-up-led-by-ewan-birney--mark-pattersona-idenda-toptop&quot;&gt;11.00 - 11.15 Summing up. Led by: Ewan Birney &amp;amp; Mark Patterson&lt;a id=&quot;end&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h4&gt;

&lt;p&gt;That was a really great day and a half. Euan and Mark sum up with suggestions for next steps, we still have a bit of work to do to pin down exactly what the next steps will be, but there are some clear next steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;writing group to sum up the discussions and recommendations with a representative from structured data, unstructured data, publisher and funder.&lt;/li&gt;
  &lt;li&gt;promotion of use of a data citation format&lt;/li&gt;
  &lt;li&gt;hi-lighting good examples, find a way to inspire researchers to do this&lt;/li&gt;
  &lt;li&gt;think about the complexities in the ecosystem, we talked little about non-OA publishers, the role of institutions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some other suggestions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;journals should ask authors for the underlying data for figures. 
&amp;gt; this leads to a good discussion, should this be the role of the funder or the institute, facilitated by the journal? It is good that there is a diversity of approaches out there. We don’t like top down approaches, there is the issue of integrity. The EU would like authors who have EU money to comply with standards around data standards. The Commission is not only a funder, but also a legislative body, so they have to be careful about how they approach directives. They have to label their explorations as pilots, and then make a decision after seeing the effects, after a number of years. Having a central structured global archive within a research discipline is a boon, but there are many disciplines where these archives do not exist, and institutional archives are emerging. We don’t want to penalise researchers who are using global archives. It is a challenge to make the language about data access be applicable pan-science.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;a proposal to convince non-oa publishers to make anything that is machine readable immediately open access?
&amp;gt; John Sack says that most publishers within the Highwire set feel that data fundamentally an open resource. NPG makes the supplementary data available. The part of the paper that lists where the data is, is often behind the firewall. Could we get publishers to place this statement in front of the firewall. (Could we recommend that this information be published as part of the article metadata?). &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Get an agreement between publishers on how accession numbers, grants and data are tagged within scholarly articles. &lt;/li&gt;
  &lt;li&gt;Look at a few case studies on something. &lt;/li&gt;
  &lt;li&gt;Recommend that data repositories expose usage data. &lt;/li&gt;
  &lt;li&gt;Get journals to ask for data, upon final submission to the journal. &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusions&quot;&gt;Conclusions&lt;/h2&gt;

&lt;p&gt;I learnt a lot at the meeting, there is a lot of will, it feels like there is a growing sense that there is a critical mass, there is still  some way to go, but perhaps it is not as far as it might seem. &lt;/p&gt;

&lt;h2 id=&quot;resources-linked-to-from-this-post&quot;&gt;Resources linked to from this post:&lt;/h2&gt;
</content>
 </entry>
 
 <entry>
   <title>Mind the product 2012, notes.</title>
   <link href="http://partiallyattended.com/2012/10/03/mtpcon"/>
   <updated>2012-10-03T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/10/03/mtpcon</id>
   <content type="html">&lt;p&gt;Last Friday I attended the amazing &lt;a href=&quot;http://conference.mindtheproduct.com/&quot;&gt;Mind the product&lt;/a&gt; conference in London. It was really inspirational. There were about 500 attendees, and having so many people with a concern for the same aspect of the product development process in one room led to a real buzz. The speakers were excellent, sadly I had to leave a little after lunch. The videos will be posted, keep an eye on the mind the product &lt;a href=&quot;http://mindtheproduct.com/&quot;&gt;main site&lt;/a&gt;. Below are my notes from a number of the morning sessions. &lt;/p&gt;

&lt;p&gt;The talks that I wrote up are&lt;a id=&quot;top&quot;&gt;:&lt;/a&gt;  &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#pookie&quot;&gt;Marty Kagan - Driving Disruption.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tcrp&quot;&gt;Tom Chi - Rapid prototyping&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#thpp&quot;&gt;Tom Hulme - Is purpose the new pivot&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#jemw&quot;&gt;John Earner - Mirror world&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;
##  [Marty Cagan][mk] - Driving disruption&lt;a id=&quot;pookie&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Interesting guy, I’m showing my ignorance here, but I hadn’t heard of him before. (that’s a reflection of how i came to be involved on the product management side things). He clearly has a lot of experience. He is going to talk about things that make a disruptive product. (After seeing his talk, and hearing people at the conference talk about him it is clear that he was one of the people who defined what product management was in the early days of the consumer web). &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Vision and Passion&lt;/strong&gt;, particularly for big problems. Solutions to big problems take years to build. You need to have the willingness to try many different things, if you are the product leader you need to be sincere, you need to work on a product that you are really passionate about. (He makes the point that there is such a demand for product leaders that you have no excuse if you find yourself working on a product that you have no passion for). &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Know what you can’t know&lt;/strong&gt;. Every single business plan is wrong, what is important is the team and the opportunity. There are many things we can’t know. If you have to do a business case for your project, there are going to be a lot of unknowns in there. What we can’t know is if the idea is going to be any good. You want to break the decision into two steps. Is this something worth working on? If we could solve this in a good way, is there anyone who wants this? Doing customer discovery is not that hard. The second question is can your team come up with a solution worth bringing to market - that’s product discovery.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Know what your customers can’t know&lt;/strong&gt;. People think we can learn what to build from our customers, but you can’t. Customers don’t know what’s possible - customers will never know this. They define the world based on what they understand we can already do. This applies to all of us. A route around this is to build many prototypes. &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Product discovery&lt;/strong&gt;. Two rules of thumb that guide Marty: at least 2/3rds of our ideas are never going to work, most likely because the customer doesn’t care. Sometimes it’s because its too complicated for the customer, sometimes it’s too expensive to build (The astonishing thing about the web stack is that cost of building
complex systems is continually decreasing, giving late entrants into a market enough of an advantage to make disruption feasible, whether all of this disruption leads to overall increase in market efficiency is &lt;a href=&quot;http://www.ft.com/cms/s/0/52286386-093b-11e2-a5a9-00144feabdc0.html#axzz28H4NGlwE&quot;&gt;another question&lt;/a&gt;). What % of your ideas are you killing? If you are launching everything then you are wasting opportunity cost, because you are not testing. Second rule, it is going to take at least 3 - 4 iterations before what you build does what it needs to well. Sometimes getting to this product fit happens sooner, sometimes later. In product discovery the job is to work though these iterations as fast as we possibly can. You want to get the time to money down. Microsoft can wait years to get there, but most companies don’t have that time, most companies have about three months. In a big company it’s management patience, in a startup it’s runway. Look at &lt;a href=&quot;http://www.youtube.com/watch?v=szr0ezLyQHY&quot;&gt;nordstrom lab&lt;/a&gt;. They do one iteration a day, they use rough prototypes. &lt;a href=&quot;http://www.balsamiq.com/&quot;&gt;Balsamiq&lt;/a&gt; is a great tool. There are also lots of high-fidelity prototypes. After that you look at a live data prototype, but it’s not a production ready product. It represents about 20 – 30% of the cost of real code, it doesn’t have test automation, only a few of the use cases, no performance, scalability, internationalisation or SEO work. It is just to see user behaviour. If it doesn’t behave the way you think it should. An A/B test only tells you that something does not work. User testing should answer only: can they use it, not would they use it. &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dedicated teams&lt;/strong&gt;. We have to move away from project based thinking. You need to have a dedicated product team, it needs to be cross-functional, co-located. Needs to have ux, coding, PM. They need to be sitting right next to each other. They should be durable teams. You don’t scope it around a project, you scope it around a type of user or product. They do all of the optimisations for that product. The other side of this is that you don’t want to give them a top down roadmap. The alternative is to give the team a set of outcomes that you are asking them to figure out. What is the reason for the existence of this product? What is the result? &lt;strong&gt;Not&lt;/strong&gt; what are the features. &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;HP called this “Manage by objectives”&lt;/strong&gt;. There is no guarantee that they will rise to the occasion, but there is a much bigger chance, if they own the product. &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;The role of design&lt;/strong&gt;. So many companies do not get design. They think of design as look and feel, as polish, as putting a coat of paint on the product. Design includes these things, but it is so much more. It is how it all works, it’s the whole experience, it has to be there from day one. (I can’t remember where I hear it, but the interface is the product, as far as the user is concerned). &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;True Collaboration&lt;/strong&gt;. One of the things we need to be careful of is a product manager who says “it has to be thus!”. If you are a product manager who is handing around wireframes, stop doing that. Product design and engineering need to be side by side. The single biggest source of innovation in a product are the engineers, particularly the lead engineer, the reason for this is they best understand the technology and what is possible. If you are just using your developers to code you are only getting half of their value. Product today is truly a collaboration. The product manager brings deep knowledge of the customer, the data, the market and your business. You need to combing these three, engineer, design and product.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Product culture&lt;/strong&gt;. It’s not about process, it’s about culture. You need rapid iteration, in terms of process it’s like religion. What matters is the culture. What happens when people disagree? In a good culture you don’t have endless meetings, you test. Data beats opinions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Embrace pivots&lt;/strong&gt;. We have to get good at distinguishing vision from illusion. If it needs to change, it needs to change. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;That was an amazing talk.&lt;/p&gt;

&lt;h2 id=&quot;tom-chitc---rapid-prototypinga-idtcrpa-toptop&quot;&gt;&lt;a href=&quot;http://unreasonableinstitute.org/profile/tchi/&quot;&gt;Tom Chi&lt;/a&gt; - Rapid prototyping&lt;a id=&quot;tcrp&quot;&gt;.&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;You need to be changing things every day. Fucking hell, they got the first working prototype of google glasses working on one day. It was a netbook hooked up to a plexiglass sheet, projecting on a heads up display. By the 4th day of work they had buy in from Page and Brin. &lt;/p&gt;

&lt;p&gt;They got the first prototype of “hand control” working in 45 minutes. Within an hour from that they created 5 different types of software that could work with this prototype. It was made from hair bands, connected to a slide projector control via fishing line. They were able to learn a tremendous amount from this rate of iteration. He called over 5 co-workers and tested this, and already learnt a couple things. People are lazy, they wanted to move as small an amount as possible. Within about a minute and a half he saw a set of behaviours, if your hands are above your heart you get exhausted within about 5 minutes. If you are hands are at the level of your heart or below, you don’t get tired. That was something you couldn’t learn without a working prototype. In the end this was the reason that they didn’t do this kind of interface. It breaks the interaction metaphor.&lt;/p&gt;

&lt;p&gt;He used wire, clay and paper to prototype google glasses. These materials move at the speed of thought. This prevented sinking huge amounts of time into building something that was uncomfortable to wear. He made sure that the clay weighed the same as all of the electronics that they knew they would be using in the product. Within an hour he could try loads of form factors. They figured out that the perception of weight is based on how much weight is carried on the nose. They learnt very quickly that you could use the ear as a pivot. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Rate based goals&lt;/strong&gt;. There is maybe a 5% chance that the things we are working on will succeed. You need to try 20 things, then the chance of success goes up to 64%. By the time you try 50 things your chance goes up to 92%. The phrase that is important is “by the time”. Try to maximise the rate of learning by minimizing the time to try things. You want tools that can move at the speed of thought. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Don’t guess, learn&lt;/strong&gt;. Most meetings are a guessathon. Just make the things already, and learn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Don’t fail, learn&lt;/strong&gt;. They made 15 hardware prototypes per week. Every Friday they would share what they had learned from all of the prototypes that week, and they would list out what they wanted to do the next week. It was never “this attempt was mostly a failure”. It was always “10% of this idea worked”. Now and again Tom saw his teams starting out on ideas that he knew were dead in the water, but since they were trying so many ideas, he didn’t try to stop them. In the end the ideas that he thought were going to be duds often produced really great insights. &lt;/p&gt;

&lt;p&gt;How do you find a path? In any hard problem you are starting with the unknown, and you want to get to the range of possible outcomes. To get to that range of possible outcomes, you need to do a lot of research to figure out how to get to the point where you can go narrow and deep to develop. In the research phase you need to go broad and shallow, 15 prototypes a week, the ones that work, you branch out on. The broad and shallow approach gives you loads of great ideas, you end up with many ‘stars’. If you tried to put them all into a product it would be a disaster. They developed a process called constellation - you look for combinations of those starred ideas, to see how you can make something that creates a coherent constellation. You want to have only a few things in there. If you find out 40 great ideas, and end up not doing 36 of them - that’s great. At the point where you constellate on those six ideas, then you know what you are going to build, then you can draw a Gantt chart. &lt;/p&gt;

&lt;h2 id=&quot;tom-hulmeth---is-purpose-the-new-pivota-idthppa-toptop&quot;&gt;&lt;a href=&quot;https://twitter.com/thulme&quot;&gt;Tom Hulme&lt;/a&gt; - Is purpose the new pivot&lt;a id=&quot;thpp&quot;&gt;?&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;He is talking about the shape in which he has seen startups pitching, business plans, lines of code, pre-sign-ups for unknown products, number of pivots, all of these are dead enders. The question is are we moving in the right direction?&lt;/p&gt;

&lt;p&gt;Startups, new products, go from ignorant optimism, informed pessimism through to informed optimism. If it was easy everyone would be doing it. &lt;/p&gt;

&lt;p&gt;The key takeaway from this talk is that purpose is really important, and equally important is having stories that hi-light the purpose. Great businesses evolve their purposes over time. The important thing is to continually reappraise why you are doing things. A good example of this is jawbone, it nearly died about 5 times. They started by trying to build voice activation. This led to noise cancellation, that led to blue tooth devices. &lt;/p&gt;

&lt;p&gt;When you are looking at your product or startup, it’s OK to for it to feel hard. If you want to scale you need to attract the best people. you are looking for an intersection between things that seem like a bad idea, are actually a good idea, and that actually matter.&lt;/p&gt;

&lt;p&gt;What is your products purpose? Why not stop for an hour a month to ask why we are doing what we are doing. If you had to explain to someone why what you are doing is important, what would you say?&lt;/p&gt;

&lt;p&gt;It is very easy to loose sight of your purpose, this happens if you dive straight into metrics. In design in products we often start to design for the wrong metric. A good example is business insider. They include sideshows on news stories. They are probably measuring page impressions. &lt;/p&gt;

&lt;p&gt;Another example is measuring facebook likes. A good example is a fb campaign on a Mini. Most of their 3M likes were from 18 - 21 yr-olds in Thailand, i.e. almost totally irrelevant. &lt;/p&gt;

&lt;p&gt;Paul Graham thinks through what metrics to ignore. One of the things he ignores is whether his startups get follow on funding (see &lt;a href=&quot;http://www.paulgraham.com/growth.html&quot;&gt;this post&lt;/a&gt;). Facebook is an example where Zuckerberg deliberately ignored revenue as a metric. This contrasts with Zynga. Do the metrics match up with the purpose that you have?&lt;/p&gt;

&lt;p&gt;On &lt;a href=&quot;http://www.openideo.com/&quot;&gt;OpenIdeo&lt;/a&gt; they have 37k users, but that’s not what matters. What matters is whether this initiative is having an effect on the ground. &lt;/p&gt;

&lt;p&gt;Most businesses are a bucket of three metrics, acquisition, engagement and purpose. Most people don’t have purpose as a metric. How would you quantify that for what you are doing?&lt;/p&gt;

&lt;p&gt;Purpose can be a really lovely design lens. ‘No’ is a great decision. When is the last time you did a product update where you take away features. &lt;/p&gt;

&lt;p&gt;Another example of this was basecamp. On one of the most recent updates, they faded the navbar into the background. &lt;/p&gt;

&lt;p&gt;He mentions an interesting idea, &lt;a href=&quot;http://en.wikipedia.org/wiki/Desire_path&quot;&gt;desire paths&lt;/a&gt;. For statups, &lt;a href=&quot;http://www.crazyegg.com&quot;&gt;CrazyEgg&lt;/a&gt; is a great tool for getting a first approximation for understanding the desire paths on your site. Design around these defaults. &lt;/p&gt;

&lt;p&gt;Never get distracted from your purpose. A great example of this is word for mac. Word 5 for mac was hailed as a genius product, word 6 for mac was derided as a terrible product. A great example is mobile. You should be matching the experience with the platform, not forcing people to have a uniform experience that ignores the context of the experience. &lt;/p&gt;

&lt;p&gt;Does your product convey your purpose? Does it re-enforce your purpose, or does it jar with it. &lt;/p&gt;

&lt;p&gt;As individuals we don’t scale. Recruitment is really important. &lt;/p&gt;

&lt;h2 id=&quot;john-earnerje---mirror-worlda-idjemwa-toptop&quot;&gt;&lt;a href=&quot;http://www.linkedin.com/pub/john-earner/0/101/76&quot;&gt;John Earner&lt;/a&gt; - Mirror world&lt;a id=&quot;jemw&quot;&gt;?&lt;/a&gt; (&lt;a href=&quot;#top&quot;&gt;top&lt;/a&gt;)&lt;/h2&gt;

&lt;p&gt;There is an interesting point, when you build a game, you know that it is going to fail, if you have 
a company building games, then you probably need to be building at least one new product a year.&lt;/p&gt;

&lt;p&gt;What is a game? You are not obligated to play a game. You are not offering needs, you are offering wants. Many web services are also wants and not needs. Often games are not explicitly productive, but they can be good at allowing people to learn, and to evoke emotions. Games always have an uncertain outcome. Games have rules. Games are fictions. A game has goals. The only one that is different in theses rules form life is the fictitious aspect.&lt;/p&gt;

&lt;p&gt;Games are a medium, like paint. There are two ways of applying this. Some people are artists. Games provide an amazing canvas for art. Artists don’t really care about the end user. Then there are entertainers. &lt;/p&gt;

&lt;p&gt;There is a really interesting part of this talk, about how production values increased with the capability of consoles. Man months went from ~60 hours to ~1400 hours to produce a game from 1994 to 2006. In order to make this transition, game studios that succeeded needed to introduce more process, and management of that process. &lt;/p&gt;

&lt;p&gt;This kind of scaling is going to happen on mobile too. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Going for gold, open access debate.</title>
   <link href="http://partiallyattended.com/2012/10/02/icoa-going-for-gold"/>
   <updated>2012-10-02T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/10/02/icoa-going-for-gold</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;, audio of the meeting is now &lt;a href=&quot;http://figshare.com/articles/Open_Access:_Going_for_Gold_/96158?utm_term=%23oa&amp;amp;utm_source=twitterfeed&amp;amp;utm_medium=twitter&quot;&gt;available on figshare&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Last Thursday I attended the &lt;a href=&quot;http://www3.imperial.ac.uk/humanities/sciencecommunicationgroup/scicomm%20forum&quot;&gt;SciCommForum&lt;/a&gt; debate “&lt;a href=&quot;http://www3.imperial.ac.uk/newsandeventspggrp/imperialcollege/eventssummary/event_5-9-2012-16-32-1&quot;&gt;Open access: going for gold?&lt;/a&gt;” held at Imperial College. Below are my notes from the event. The notes are fairly raw, and not comprehensive.&lt;/p&gt;

&lt;p&gt;The debate is going to be looking at open access in the context of the &lt;a href=&quot;http://www.rcuk.ac.uk/Pages/Home.aspx&quot;&gt;RCUK&lt;/a&gt; &lt;a href=&quot;http://www.rcuk.ac.uk/media/news/2012news/Pages/120716.aspx&quot;&gt;policy&lt;/a&gt;, it is being hosted by &lt;a href=&quot;https://twitter.com/Richvn&quot;&gt;Richard Van Noorden&lt;/a&gt; (RVN), &lt;a href=&quot;https://twitter.com/MarkRThorley&quot;&gt;Mark Thorley&lt;/a&gt; (MT) from RCUK, and &lt;a href=&quot;http://occamstypewriter.org/scurry/&quot;&gt;Stephen Curry&lt;/a&gt; (SC).&lt;/p&gt;

&lt;p&gt;MT opens by making the point that RCUK want to make research open to the largest number of people possible, including SMEs who might want to exploit the literature in order to drive innovation and growth. It’s clearly not just about being able to only read the literature. He mentions that the policy is being misinterpreted, in that some people say the policy says researchers must publish in Gold. They have a strong preference for Gold, but they don’t restrict publishing via the green route.&lt;/p&gt;

&lt;p&gt;MT says they are going to announce the amount of money that they will be making available in the Autumn (probably not tonight then). MT says RCUK will make publishing the funding information of the published paper a requirement. (I recommend using the &lt;a href=&quot;http://dtd.nlm.nih.gov/archiving/tag-library/3.0/n-mjv0.html&quot;&gt;funding-group&lt;/a&gt; tag within the NLM tag suite).&lt;/p&gt;

&lt;p&gt;SC steps up to discuss some of the potential issues about the policy. SC points out that most movements (EU, US), are mainly driving towards green (I didn’t know this). I think SC raises the reasonable question about wanting to know about the time-scale and costs for the transition. He does a good job of laying out the general contra argument.&lt;/p&gt;

&lt;p&gt;Time for questions.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;How will the money be paid?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The answer is pretty vague. The question of what happens when the money runs out also gets a pass. I suspect that the answers to these questions are just not known yet, but I think it is better to try this, then to not try it for lack of answers to some of these questions. MT stresses that the money will go to institutions, and those institutions will have the freedom to arrange matters as they see fit. It is noted that HEFCE is pro OA. OA is a very important thing that has to happen, and that there will be transition costs. They expect institutions to find the funding form within their research budgets. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;SC asks if people have thought about how to manage the transition costs?&lt;/strong&gt;. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;He points out that in the long run an APC model will be cheaper because the costs will be transparent. We will get better value for money. I think he is implying that the moral imperative of getting to a system that is more efficient in terms of costs, means we need to have a plan to get over the transition hump asap.  &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Jan Velterop says if Uk negotiates on a national scale on subscriptions, that you might be able to negotiate&lt;/strong&gt;.  &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;He says that if a librarian walks away from a negotiation from a publisher, the librarian is in trouble. If a country walks away form a negotiation with a publisher, the publisher might be in trouble. (on the point of people who know how to negotiate, I always find the Dutch very good at this). JV makes the point that if you could bulk negotiate, the savings from this could pay for the transition costs. MT says that all of the data will be made open and available on the costs for APCs and which publishers will be getting which funds.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;David Prosser asks &lt;strong&gt;If a researcher wants to publish in Journal X, and X is very expensive, and the researcher decides to go via the Green route, but the green option of that journal is not within the RCUK policy, then what happens?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;MT says its clear, the researcher must use a compliant route. MT says they want to create a market in the APC market, up to now it has been a free route, it seems to researchers like there is a money fairy. By exposing these fees you expose the market. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;There is a question about &lt;strong&gt;why they don’t tweak the policy to require Green after 6 months?&lt;/strong&gt; &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;MT says that there will be unintended consequences of any policy, but obviously they don’t know what those would be, otherwise they wound not be unintended. The current version of the policy is a start of a journey, they will review the policy, but now they are not in a position to start tweaking their policy. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;RVN says that in the UK there is no underlying green OA mandate.&lt;/strong&gt; &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;This differs from outside of the UK, and that is seems to be downplaying the importance of repositories. The NIH has the policy that everyone must have their research in a repository.(I would say that PMC is not really a good representative of a typical “repository”).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;MT says that he a Robert Kiley have written to the top 60 publishers, by volume of output from RCUK funding, to ask whether and how they will become compliant to the policy. About 50% have responded to date, and many have explained what they will do. Of those that have replied, 82% of the respondents will offer a CC-BY. One US publisher has said no to CC-BY, but will allow green after 6 months. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;em&gt;At this point in the evening I started to respond to some of the questions, so my notes do not give good coverage of the debate past this point.&lt;/em&gt; &lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;An astrophysics researcher mentions the ArXiV. IMO a key issue of the ArXiV is that it raises the question of what value do the &lt;a href=&quot;http://scoap3.org/&quot;&gt;scoap3&lt;/a&gt; charges actually provide. It seems naively obvious that they are only providing the stamp of peer reviewed publication, and that they are providing hardly any value on top of that. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;The issue of success or otherwise of the institutional repository movement is mentioned, and it is proposed that the repository movement has not succeeded due to it not being around for a long time, but the comment was made in the context of preprints and preprint servers in the life sciences. IMO that preprints in life sciences have not worked is due to social and not technical reasons. .&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;Will RCUK monitor the quality of the journals that research will be published in?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;No. It is not the role of the funder to check on this. It is up to researchers to publish in the most appropriate venues for their research. &lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;What of repositories?&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;MT: We are not downplaying the role of repositories. They have a crucial and long term role to play.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There were some more interesting points raised, but at this point I was unable to keep up with taking notes, I believe that the audio of the debate will be published online. &lt;/p&gt;

&lt;h2 id=&quot;my-conclusions&quot;&gt;My conclusions.&lt;/h2&gt;

&lt;p&gt;It seemed to me that two big questions came up throughout the debate. 1. what happens when the money runs out for supporting the policy? 2. What about repositories and green OA. &lt;/p&gt;

&lt;p&gt;I think 1 is not answerable, and I think that any answer given now would need to be changed according to changing circumstances, and according to how the policy works out. We might like to have a nice roadmap and answers laid out, but the world is a messy place. I applaud RCUK for making this push. They will learn a lot more by trying this, than by almost any other action that they could take. &lt;/p&gt;

&lt;p&gt;For 2, I have a hunch that what is going on here is that the decision comes out of a desire to create a transparent and more innovative market, ahead of almost any other concern. If one were to mandate green OA, out of the box, one would be putting an extreme distortion onto an existing marketplace, from outside. Now, I believe that this marketplace is ripe for disruption, and that STM publishers often fail to articulate exactly what value they bring to the table, but if you are a government that subscribes strongly to the view of market forces being the correct mechanism for driving innovation and efficiency, then you might want to look for a policy that expands the potential number of market players, and unleashes frees market competition to work effectively between the existing players. Mandating green OA does not place STM publishers in true competition with each other, in a way it meddles with an existing industry without offering robust alternatives, and it is possibly more interventionist that a conservative philosophy may stand to support.&lt;/p&gt;

&lt;p&gt;One of the problems that the new policy begins to get to the heart of is the non-open nature of the STM market. This market is not an open and fair one due to confidentiality clauses between publishers and libraries over subscription fees. Driving towards an APC model resolves this, and starts to put publishers in direct competition with each other on the APC fees. Now they have to explain exactly why publishing in their journal costs twice or three times that of publishing in a competitors journal. The scientists may never actually pay these fees themselves, but perhaps they will start thinking about them. &lt;/p&gt;

&lt;p&gt;Requiring content to be made CC-BY expands the potential numbers of players in the market who can offer services. I know that STM publishers have been working on bringing innovations to their content, but perhaps by having more players active, they will have to work a bit harder. The government has been making noises about the digital economy for a long time, and it might be no coincidence that this policy has opted for CC-BY licence while the UK is home to some of the best research groups on data mining, the semantic web, and has been the home of many innovative products in the STM space. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The slow web, more thoughtful experiences.</title>
   <link href="http://partiallyattended.com/2012/08/22/the-slow-web"/>
   <updated>2012-08-22T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/08/22/the-slow-web</id>
   <content type="html">&lt;p&gt;I’ve been concerned for a few years about the flow of data that we are producing, and how to handle the angst of not being able to keep up with everything, ever. I think it started when I became a very heavy user of google reader back in 2006 or so. &lt;/p&gt;

&lt;p&gt;There is little doubt that the web is moving more in this direction, Anil Dash recently &lt;a href=&quot;http://dashes.com/anil/2012/08/stop-publishing-web-pages.html&quot;&gt;called for people to stop creating web pages&lt;/a&gt;, and to start creating only streams.&lt;/p&gt;

&lt;p&gt;The angst of being awash in a stream of data is that you sometimes feel a little like you are drowning in it. For the last few years, I’ve been using twitter and more recently hacker news, as my main filters. If a link bubbles up enough times on either of those places it’s probably worth checking out, but it’s an inelegant solution. &lt;/p&gt;

&lt;p&gt;On the flip side, I’ve been concerned about the creation of artificial scarcity as a method of increasing impact factors and prices within the STM industry. By setting a high bar, for acceptance, you make it harder to get in, and you hope that exclusivity extends to getting more attention to the papers that make it in. &lt;/p&gt;

&lt;p&gt;So here I am worrying about both ends of the spectrum. It seems perhaps wrong to have an artificial bar on publishing science, as science is so important, and posterity is usually the best judge, but on the other hand throwing away the bar pitches you into the stream, and perhaps allows you to drown a little. &lt;/p&gt;

&lt;p&gt;We eLife I we are removing artificial scarcity in terms of having no limits on page numbers, or numbers of articles published per unit time, on the other hand, we are setting a very high bar in terms of quality. It’s fascinating to be at the heart of an initiative that is tackling these questions directly. I’m learning a lot.&lt;/p&gt;

&lt;p&gt;I don’t know what the answer is yet. I know I want to formulate the question in my own words a bit more, but in the last week a thread of a thought has intrigued me. I read a post about a new music service that has just launched. The service is called &lt;a href=&quot;http://www.thisismyjam.com/&quot;&gt;this is my jam&lt;/a&gt;, and the philosophy behind it is &lt;a href=&quot;http://www.alistapart.com/articles/everything-in-its-right-pace/&quot;&gt;beautifully described&lt;/a&gt; by one of the co-founders. &lt;/p&gt;

&lt;p&gt;The big idea is that they ask members to nominate one new song a week, no more. If you follow a dozen people, you will get the thoughtful recommendations of about an album’s worth of music a week, just the right amount to consume in that time. By thinking about the value of the content, and how long an ideal amount of time is to interact with that content, they have created a service which tries to give you the time to experience the content, they are trying to create a more thoughtful experience. &lt;/p&gt;

&lt;p&gt;Perhaps there are some lessons here on how we can create a curatorial experience for the research literature, perhaps not. One of the key differences here is that what I listen to from a musical point of view is highly optional. What I read in terms of the literature is deeply connected to the eventual outcomes of success as an academic. There are far fewer songs in the world than there are scientific publications (about an order of magnitude less). The rate of song creation is much lower than the rate of scientific article creation, so a slower approach to presenting the literature could end up damaging the researcher. On the other hand, the vast majority of research that is published is either wrong or irrelevant, or both.&lt;/p&gt;

&lt;p&gt;I want a system that supports researchers, that does not make them fearful of the vast quantity of information that is out there, that can deliver timely quality recommendations, and humane experiences for interacting with that information.  Interwebs, show me your ideas, throw me your suggestions, diffuse the solution towards me through tweets, the mailing lists, and news sites, craft the answer and allow it to emerge, partially formed, and ready to be moulded into a thing that we can make to help, to try to help. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>sharing documents with google apps for your domain</title>
   <link href="http://partiallyattended.com/2012/07/17/docs-and-apps-for-your-domain"/>
   <updated>2012-07-17T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/07/17/docs-and-apps-for-your-domain</id>
   <content type="html">&lt;p&gt;I’ve just rolled out google apps for your domain for eLife. At about the same time google rolled out gdrive. We were having difficulty figuring out how to share documents across the domain without having to invite people individually to the document. The document sharing options provide the ability to make documents findable by other members of the domain, but when we tried to search for these documents, we were not finding them.&lt;/p&gt;

&lt;p&gt;Finally I found the solution in a &lt;a href=&quot;http://support.google.com/a/bin/static.py?hl=en&amp;amp;ts=2404805&amp;amp;page=ts.cs&quot;&gt;support question&lt;/a&gt; form google, but it took me longer to find than I expected.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Sharing a document such that it automatically appears in the document lists for all users in the domain is not currently supported.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sharing a document or collection with a domain allows users in the domain to find the item by searching, but it doesn’t automatically add the document to all users’ document lists. &lt;font color=&quot;green&quot;&gt;To search for a document that has been shared with your domain, open Google Docs, type the relevant keywords into the search bar, then click the triangle on the right side of the search bar and choose Search [your domain] Docs.&lt;/font&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Alternately, you can share the document with a group that contains all users in the domain. Note that group members need to click the link in the notification email for the document to show up in their document lists.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Sharing a document such that it automatically appears in the document lists for all users in the domain is not currently supported. However, you can use the Documents List API to share the document explicitly with all users. This method ensures that the document shows up for all current users, but it requires familiarity with using APIs.&lt;/p&gt;
&lt;/blockquote&gt;

</content>
 </entry>
 
 <entry>
   <title>academic ghost towns, Google scholar and Mendeley</title>
   <link href="http://partiallyattended.com/2012/07/17/academic-ghost-towns"/>
   <updated>2012-07-17T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/07/17/academic-ghost-towns</id>
   <content type="html">&lt;p&gt;I’m on a mission to clear out my instapapper backlocg, so I’m going to be blogging olds rather than news. There was a &lt;a href=&quot;http://m.theatlantic.com/technology/archive/2012/05/how-Google-can-beat-facebook-without-Google-plus/257480/&quot;&gt;nice piece&lt;/a&gt; in the Atlantic last month talking about how Google could provide a better social experience by activating it’s latent networks, rather than mimicking facebook.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;But think about Scholar as a latent social network. Each paper contains its own social network that Google already crawls. Every bibliography is filled with other social networks. And people searching Google Scholar are likely to be as interested in connecting with the researchers who created those papers as they are with the papers themselves. Why isn’t Google making it easy to connect the searchers with the searched? And sure, build a whole other set of social tools on top of that, which make it easy to share with networks of researchers. You want every college kid in America to start engaging deeply with your social network? Make it easy for them to get their papers written&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;That’s &lt;a href=&quot;http://www.mendeley.com&quot;&gt;Mendeley&lt;/a&gt;, that’s exactly what we were trying to build. I think they will do it, I’ve been involved in a few products that ended up being kind of ghost towns, but the beauty of building around objects like papers is that they already come with a latent network of interest. It’s such a huge no-brainer, it hurts.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The cost of production</title>
   <link href="http://partiallyattended.com/2012/07/12/the-cost-of-production"/>
   <updated>2012-07-12T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/07/12/the-cost-of-production</id>
   <content type="html">&lt;p&gt;Last week an interesting discussion on &lt;a href=&quot;http://occamstypewriter.org/scurry/2012/07/02/open-access-who-pays-the-copy-editor/&quot;&gt;the cost of copy editing&lt;/a&gt; popped up over on Stephen Curry’s &lt;a href=&quot;http://occamstypewriter.org/scurry/&quot;&gt;blog&lt;/a&gt;. In addition the 
&lt;a href=&quot;http://comments.sciencemag.org/content/10.1126/science.1220395#comments&quot;&gt;comment thread&lt;/a&gt; at the recent Science &lt;a href=&quot;http://www.sciencemag.org/content/335/6074/1279&quot;&gt;editorial&lt;/a&gt; seems to make this post somewhat timely. I used to manage the copy editing of a good portion of physical science related content from Springer from 2002 – 2005. I’m also currently in the process of setting up a new online-only journal.&lt;/p&gt;

&lt;p&gt;Back in the early 2000s we were getting pages copy edited for about $20 per page. Right now we are looking at costs of between $10 and $35 dollars per page depending on the level of copy editing required, so for a 10 page article the cost could come in at about $350, or about 10% of the cost of an OA publication in an outlet like PLoS.&lt;/p&gt;

&lt;p&gt;High quality copy editing means significant work on grammar and clarity. The kind of functional checking for things like consistency in figure labeling, and so forth, is cheaper, and many typesetters have tools that can augment the checking for this kind of consistency: &lt;code&gt;s1,$/Figure/Fig\./&lt;/code&gt;.
If the burden of these costs were pushed back to authors, then authors who know that their English is sub-par, would have an incentive to get their language checked prior to submission. This certainly happens in some labs, and there are &lt;a href=&quot;http://webshop.elsevier.com/languageediting/&quot;&gt;many services&lt;/a&gt; available for authors to pay to get this work done.&lt;/p&gt;

&lt;p&gt;As we know most articles are not read much, and are cited less, even in journals such as Nature. If we could chose to on copy edit the items of the literature where it is going to provide significant value, I believe there would be an economy of effort. It is somewhat of a catch-22 in that one would want to apply the effort to articles that will attract attention, without knowing ahead of time which articles will attract attention. Wikipedia represents an interesting model for aligning effort and attention. There is a &lt;a href=&quot;https://strategy.wikimedia.org/wiki/Proposal:Journal_(A_peer-review_journal_to_allow/encourage_academics_to_write_Wikipedia_articles)&quot;&gt;proposal to create a wikipedia journal&lt;/a&gt;, and in such a scenario one would be able to do sub editing post-publication.&lt;/p&gt;

&lt;p&gt;I believe that the cost of copy editing should be placed on the authors, and that it does not represent an overly significant value add that publishers bring to the dissemination process. I feel that in terms of issues that we have with the scientific literature, lack of access to underlying data is a much bigger problem, than low-quality articles being difficult to read.&lt;/p&gt;

&lt;p&gt;In terms of the cost of production of scientific content, I feel the discussion around copy editing is a red herring. There are a couple of new initiatives that are really interesting. &lt;a href=&quot;http://peerj.com/&quot;&gt;PeerJ&lt;/a&gt; is trying a model of charging $100 per year per author, &lt;a href=&quot;https://www.scholasticahq.com/&quot;&gt;scholastica&lt;/a&gt; are charging $10 per submission. This question of where we will get to if charges normalise towards the $1500 dollar mark seems to me to be missing the point. Creating content on the web, especially where authors are not paid for their work, could be substantially reduced to the level of a few dollars per article. This would be disruptive for the existing publishing industry. As Jason Hoyt points out in a [recent presentation][ffd], this is also a model that the incumbents would be almost certainly unable to follow. 
[ffd]: http://www.slideshare.net/jasonhoyt/a-framework-for-disruption&lt;/p&gt;

&lt;p&gt;What about maintaining high quality? Well, there are a number of confounding factors with the current system. One of these factors is that the cost of production is usually separated from profits for STM content. One of the reasons for this is that the market is non-transparent. Contracts with libraries usually include a non-disclosure clause, so no one really knows how much other customers are paying for the same product. Vendors providing typesetting or hosting services have the same non-disclosure clauses for publishers, so publishers don’t know how much their competitors are paying for production costs. &lt;/p&gt;

&lt;p&gt;You can get rid of the first of these by having article processing fees, rather than a subscription model. You can get rid of the second of these if you invest in building your own publishing infrastructure, like scholastica have done, and PeerJ are doing. &lt;/p&gt;

&lt;p&gt;There is still the issue of reputation, and what we call quality of production. To get well structured research content one currently ideally wants the output to be in NLM XML, and that does require some processing of the input from the authors. I believe that structured editing tools can be built that will provide a compelling experience for authors, and that will create content that can be ready to be online immediately. We have been waiting for such tools for a long time, and there is a history of attempts to create such tools, but I remain optimistic. One of course needs appropriate incentives to authors to take up such tools, faster publication times, and cheaper publication costs may provide sufficient incentives. &lt;/p&gt;

&lt;p&gt;In this future, it may be possible to completely separate the cost of production from the activities that are associated with signification of high scientific quality, a grand un-bundling of the roles of the current STM publisher. This kind of scenario is already playing out in the print news media. I think it is an attractive future that offers benefits to research, and it is one that I look forward to.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>XMP wrangling on OS X</title>
   <link href="http://partiallyattended.com/2012/07/11/getting-to-grips-with-xmp-on-osx"/>
   <updated>2012-07-11T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/07/11/getting-to-grips-with-xmp-on-osx</id>
   <content type="html">&lt;h1 id=&quot;xmp&quot;&gt;XMP&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://www.adobe.com/products/xmp/&quot;&gt;XMP&lt;/a&gt; is the extensible metadata platform from Adobe. It can be used to embed structured metadata into a file. I think it’s most common usage is for storing image metadata in image files, but it also has a use in embedding metadata in PDF files. &lt;/p&gt;

&lt;p&gt;Adobe provide an &lt;a href=&quot;http://www.adobe.com/devnet/xmp.html&quot;&gt;SDK&lt;/a&gt; that you can use to start coding applications for working with XMP. They provide a guide for developers, and I’ve posted a &lt;a href=&quot;https://dl.dropbox.com/u/2270414/XMPProgrammersGuide.pdf&quot;&gt;copy&lt;/a&gt; so you can have a quick look if you are interested, without downloading the full SDK.&lt;/p&gt;

&lt;p&gt;In this post I will look at compiling the SDK on OSX 10.7.4 with Xcode 4.3.2, and run through getting one of the demo applications provided in the SDK working. This was my first time working with Xcode, so I have certainly done some stupid things with setting up the environment, however in the end it worked. YMMV.&lt;/p&gt;

&lt;h1 id=&quot;compiling-the-xmp-libraries-on-osx-1074-with-xcode-432&quot;&gt;Compiling the XMP libraries on OSX 10.7.4 with Xcode 4.3.2&lt;/h1&gt;

&lt;p&gt;I was unable to get the provided SDK to compile on my machine with Xcode 4.3.2. I kept running into issues that I just didn’t understand in how the distributed Xcode project was set up. I was bitching about this on Twitter and the amazing &lt;a href=&quot;https://twitter.com/mz2&quot;&gt;Matias Piipari&lt;/a&gt; offered to have a look. He said:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;They’d done this silly thing where they require you to download 3rd party code and place it inside the project root, and then they hard-code the relative paths to those 3rd party source files in the #includes. Both expat and zlib are actually available as part of the OSX SDK, but was easier to just download zlib and unpackage them both into that 3rd-party directory rather than fix the includes to use systemwide header search paths and to set up dynamic linking for expat and zlib.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;He modified the distributed project as described, and sent me a &lt;a href=&quot;https://www.dropbox.com/sh/gceyj2ieuvme1aa/9FONH2OF2b&quot;&gt;copy&lt;/a&gt;. Downloading this, and following the build instructions from the programmers guide compiles the libraries, raising about 54 warnings on my machine.&lt;/p&gt;

&lt;h1 id=&quot;building-a-demo-application-using-the-compiled-libraries-the&quot;&gt;Building a demo application using the compiled libraries. The&lt;/h1&gt;

&lt;p&gt;First step, we need to set up a project in Xcode.&lt;/p&gt;

&lt;h2 id=&quot;creating-an-xcode-project-to-read-xmp-metadata&quot;&gt;Creating an Xcode project to read XMP metadata&lt;/h2&gt;

&lt;p&gt;The following is based on the instructions from the developers guide, which start on page 62, however there are quite a few differences between the provided instructions, and what I did to get the sample code working.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create a new project &lt;code&gt;File &amp;gt; New &amp;gt; Project ...&lt;/code&gt; or ⇧⌘N&lt;/li&gt;
  &lt;li&gt;Select the &lt;code&gt;Command Line tool&lt;/code&gt; option.&lt;/li&gt;
  &lt;li&gt;Hit &lt;code&gt;next&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Name your product, pick your company name and choose &lt;code&gt;C++&lt;/code&gt; for the project type.&lt;/li&gt;
  &lt;li&gt;You will then be asked to chose where to save the project. I’m saving my project in &lt;code&gt;/Users/ian/code/private-code/xmp/XMP-Toolkit-SDK-5.1.2/samples/build/Xcode3/&lt;/code&gt;, with the project name &lt;code&gt;MyReadingXMP&lt;/code&gt;. Hit &lt;code&gt;save&lt;/code&gt;.
I have git installed on my system, and Xcode offers to place the project under source control, why not, let’s go with that.&lt;/li&gt;
  &lt;li&gt;In the project window, highlight the file main.cpp and delete it by choosing &lt;code&gt;Edit &amp;gt; Delete&lt;/code&gt; or ⌘⌫. In the
confirmation dialog select &lt;code&gt;Move to Trash&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Add a new file, there are many options for adding a new file, ⌘N works. This brings up the file template chooser.&lt;/li&gt;
  &lt;li&gt;Pick a &lt;code&gt;C++&lt;/code&gt; file, hit &lt;code&gt;Next&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Name the file &lt;code&gt;MyReadingXMP.cpp&lt;/code&gt;. The instructions in the programmers guide tell you to deselect the option to create a header file, however the version of Xcode that we are working with does not offer to create a header file, so you can ignore this step. &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;compiling-the-application&quot;&gt;Compiling the application.&lt;/h2&gt;

&lt;p&gt;Selecting the project in the left hand pane of Xcode will show the project info and build settings in the central pane:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/xcode-settings.jpg&quot; alt=&quot;Xcode settings&quot; title=&quot;Xcode settings&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For finding the various options in the build settings, the search field is convenient.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Select &lt;code&gt;Build Settings&lt;/code&gt; and under &lt;code&gt;Build Locations&lt;/code&gt;select &lt;code&gt;Per-configuration Build Products Path&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Insert &lt;code&gt;$(PROJECT_DIR)&lt;/code&gt;, you should see Xcode expand this to point to the directory that contains the project files. &lt;/li&gt;
  &lt;li&gt;Under &lt;code&gt;Search Paths&lt;/code&gt; select &lt;code&gt;Header Search Paths&lt;/code&gt;. The XMP developer documentation says to include &lt;code&gt;${SDKROOT}/public/include&lt;/code&gt;. This is where things started to go tits up for me. There is a &lt;a href=&quot;http://forums.adobe.com/message/3234962&quot;&gt;bug report&lt;/a&gt; on the adobe forums pointing out that the developer documentation is broken at this step, and that one should insert &lt;code&gt;&amp;lt;xmpsdk&amp;gt;&lt;/code&gt; in place of &lt;code&gt;${SDKROOT}&lt;/code&gt;, but I didn’t get it to work with this substitution either, so I started to hard code the paths. This is a bad practice, but it was the way that I got it to work. If I knew a little more about Xcode I am sure this would be trivial to fix, but for now I started to use &lt;code&gt;/Users/ian/code/private-code/xmp/XMP-Toolkit-SDK-5.1.2/&lt;/code&gt; in every place in the documentation where you are advised to use &lt;code&gt;${SDKROOT}&lt;/code&gt;, so we put in &lt;code&gt;/Users/ian/code/private-code/xmp/XMP-Toolkit-SDK-5.1.2/public/include&lt;/code&gt; for this variable.&lt;/li&gt;
  &lt;li&gt;Select Framework Search Paths and enter &lt;code&gt;/Users/ian/code/private-code/xmp/XMP-Toolkit-SDK-5.1.2/System/Library/Frameworks&lt;/code&gt;. When I finally got to the compile stage I was getting a warning that this directory didn’t exist, so I manually created that directory inside of the project.&lt;/li&gt;
  &lt;li&gt;Deselect &lt;code&gt;Precompiled Header Uses Files From Build Directory&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;Select Other Linker Flags and add the paths to both the XMP Toolkit SDK static libraries:
&lt;code&gt;/Users/ian/code/private-code/xmp/XMP-Toolkit-SDK-5.1.2/public/libraries/macintosh/debug/libXMPCoreStaticDebug.a&lt;/code&gt;
&lt;code&gt;/Users/ian/code/private-code/xmp/XMP-Toolkit-SDK-5.1.2/public/libraries/macintosh/debug/libXMPFilesStaticDebug.a&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;In Other Linker Flags, at the end of the paths to the static libraries enter the flag &lt;code&gt;-framework CoreServices&lt;/code&gt;. At this point I may have tried compiling the empty project, or I may have toggled some other interaction with Xcode, in any case Xcode began downloading the CoreServices framework.&lt;/li&gt;
  &lt;li&gt;Select &lt;code&gt;Preprocessor Macros&lt;/code&gt; and enter &lt;code&gt;MAC_ENV=1&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;The instructions provided direct you to set the Preprocessor Macros for the target, however in this version of Xcode when I looked, this setting carried over from the project setting, and I didn’t need to do anything.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I tried compiling the empty project, but ran into some bugs. I then cut and pasted the entire sample XMP reader code into the my empty project. I also manually linked the CoreServices library against the target using the &lt;code&gt;Build Phases&lt;/code&gt; option Xcode. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/set-services.jpg&quot; alt=&quot;Link Xcode target to CoreServices&quot; title=&quot;Link Xcode target to CoreServices&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I honestly don’t know what I am doing at this point, and I don’t know whether this helped, but on the next attempt to compile the project compiled fully, and I got an executable. &lt;/p&gt;

&lt;p&gt;It took me a while to find where the executable was located, but eventually I found it located in &lt;/p&gt;

&lt;pre&gt;&lt;code&gt;~/Library/Developer/Xcode/DerivedData/
MyXMPReader-dzqqlyrtudnrpsganqbsozskatkp/
Build/Products/Debug /Users/ian/code/
private-code/xmp/XMP-Toolkit-SDK-5.1.2/
samples/build/Xcode3/MyXMPReader
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Obviously I’ve made a typo in the name of the target, you can see that I have an extra space next to the &lt;code&gt;../Debug /..&lt;/code&gt; part of the path, and I had expected the executable to land in the project directory, rather than in the system Library, but we have the working executable ‘MyXMPReader’.&lt;/p&gt;

&lt;h2 id=&quot;running-the-application&quot;&gt;Running the application&lt;/h2&gt;

&lt;p&gt;It’s a command line application, and takes a path to a file as an argument. To run this, point it at a PDF like so:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;$ MyXMPReader test.pdf&lt;/code&gt; &lt;/p&gt;

&lt;p&gt;It produces some terminal output, and writes the XMP data into a local &lt;code&gt;XMPDump.txt&lt;/code&gt; file. I verified the tool works by running it against a nature communications pdf, and you can see some of the output here:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;$ head -40 XMPDump.txt 
Dumping XMPMeta object &amp;quot;&amp;quot;  (0x0)

   dc:  http://purl.org/dc/elements/1.1/  (0x80000000 : schema)
      dc:format = &amp;quot;application/pdf&amp;quot;
      dc:identifier = &amp;quot;
            doi:10.1038/ncomms1828&amp;quot;
      dc:creator  (0x600 : isOrdered isArray)
         [1] = &amp;quot;Zhong Yan&amp;quot;
         [2] = &amp;quot;Guanxiong Liu&amp;quot;
         [3] = &amp;quot;Javed M. Khan&amp;quot;
         [4] = &amp;quot;Alexander A. Balandin&amp;quot;
      dc:description  (0x1E00 : isLangAlt isAlt isOrdered isArray)
         [1] = &amp;quot;Nature Communications 3, 827 (2012). doi:10.1038/ncomms1828&amp;quot;  (0x50 : hasLang hasQual)
               ? xml:lang = &amp;quot;x-default&amp;quot;  (0x20 : isQual)
      dc:publisher  (0x200 : isArray)
         [1] = &amp;quot;Nature Publishing Group&amp;quot;
      dc:rights  (0x1E00 : isLangAlt isAlt isOrdered isArray)
         [1] = &amp;quot;&lt;span class=&quot;nt&quot;&gt;&amp;lt;C2&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;A9&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt; 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.&amp;quot;  (0x50 : hasLang hasQual)
               ? xml:lang = &amp;quot;x-default&amp;quot;  (0x20 : isQual)
      dc:title  (0x1E00 : isLangAlt isAlt isOrdered isArray)
         [1] = &amp;quot;Graphene quilts for thermal management of high-power GaN transistors&amp;quot;  (0x50 : hasLang hasQual)
               ? xml:lang = &amp;quot;x-default&amp;quot;  (0x20 : isQual)

   pdf:  http://ns.adobe.com/pdf/1.3/  (0x80000000 : schema)
      pdf:Producer = &amp;quot;Adobe PDF Library 7.0&amp;quot;

   prism:  http://prismstandard.org/namespaces/basic/2.0/  (0x80000000 : schema)
      prism:copyright = &amp;quot;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;C2&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;A9&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt; 2012 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.&amp;quot;
      prism:doi = &amp;quot;10.1038/ncomms1828&amp;quot;
      prism:eIssn = &amp;quot;2041-1723&amp;quot;
      prism:endingPage = &amp;quot;8&amp;quot;
      prism:publicationName = &amp;quot;Nature Communications&amp;quot;
      prism:rightsAgent = &amp;quot;permissions@nature.com&amp;quot;
      prism:startingPage = &amp;quot;827&amp;quot;
      prism:volume = &amp;quot;3&amp;quot;
      prism:publicationDate  (0x200 : isArray)
         [1] = &amp;quot;--&amp;quot;
      prism:url  (0x200 : isArray)&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I’ll explore some other tools that you can use to look at XMP data in pdfs in a later post, and I’ll also look at what we can find inside some recently published academic PDFs with an eye to deciding what we should be putting into the documents that we will be producing at &lt;a href=&quot;http://elifesciences.org/&quot;&gt;eLife&lt;/a&gt; (don’t forget to &lt;a href=&quot;http://submit.elifesciences.org/cgi-bin/main.plex&quot;&gt;submit&lt;/a&gt;).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>What use metaphor?</title>
   <link href="http://partiallyattended.com/2012/07/08/what-use-metaphor"/>
   <updated>2012-07-08T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/07/08/what-use-metaphor</id>
   <content type="html">&lt;p&gt;I watched a little of the q&amp;amp;a at CERN this week. One question stood out. A journalist, who didn’t want to be named, asked the panel a question along the following lines: “what were the panel’s favourite and least favourite metaphor for the Higgs boson, and what were their thoughts on the god-particle expression.” He pointed out that given such a complex story many who will b e explaining it to the general public will need to reach for metaphor, and when it comes to the god particle term, as much as some may not like it, it has to be recognised that it has entered public consciousness.&lt;/p&gt;

&lt;p&gt;The panel uniformly refused to give a metaphor, saying only that they really didn’t hve one.  One of them made a good point about the particle being deeply connected to the states of the universe, as it is so closely released to symmetry breaking, which leads the current universe to be configured as it is. &lt;/p&gt;

&lt;p&gt;Later another journalist asked how they could justify the spend on something like the LHC in the current economic climate. The director general Rolf Heuer was  happy to whip out a metaphor, and he talked about the hungry man who has one sack of corn. If he eats it all, or if he plants it all, he will surely starve, he must eat some and plant some for the future. The eaten corn, we were led to think of as being applied science, and the planted corn as entirely pure science. &lt;/p&gt;

&lt;p&gt;I think it’s likely that the interrelationship between financial instruments, global geopolitics, emerging markets and how research and development budgets get allocated is no less complex than the mathematics behind the Higgs boson. The money that goes into financial markets and military spending  dwarfs that going in to the LHC. &lt;/p&gt;

&lt;p&gt;Where he felt he needed to make a case to the public for support Rolf Heuer was happy to reach for a metaphor. When it came to describing the result at hand be was not at all happy to do so. &lt;/p&gt;

&lt;p&gt;Perhaps being so close to the details of a thing makes it hard to step back and be willing to lose precision for the sake of apparent simplicity. I would have loved to have heard their barmaid explanations, I think the boson deserves one. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Elio</title>
   <link href="http://partiallyattended.com/2012/07/02/elio"/>
   <updated>2012-07-02T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/07/02/elio</id>
   <content type="html">&lt;p&gt;As i write these words my son is a little under a day old. &lt;/p&gt;

&lt;p&gt;Everything changes, that’s what they tell you, all the friends who have started down this journey before us, our relatives, elders. &lt;/p&gt;

&lt;p&gt;There are emotions unlocked inside me, an almost physical new presence, sometimes quiescent, sometimes flooding over me, triggered by the banal miracles - the sound of a breath, a gurgle, just the telling of the story of the birth. &lt;/p&gt;

&lt;p&gt;I walked down Tottenham court road, late June summer shining. I felt displaced, I was not sharing the same world as all of these other people any more. Either I, or they, or the world itself - in it’s makeup, had shifted. In every aspect of being there I had to come to terms with those changes. &lt;/p&gt;

&lt;p&gt;The closest I’ve felt to this in the past was at the death of my father, then years later of my grandmother. Everything changes, everything is the same, and you go on having to deal with becoming a different person for the rest of your life. &lt;/p&gt;

&lt;p&gt;But joy, now, joy unconstrained. &lt;/p&gt;

&lt;p&gt;Perhaps it’s love that makes the end and the beginning of life feel so strangely similar. &lt;/p&gt;

&lt;p&gt;Everything changes, it transforms you, I’m filled with love for you, my Elio. &lt;/p&gt;

&lt;p&gt;And my love for my wife has been transformed too. She is the strongest person I know. I don’t have the words for her now, maybe I never will, but she is has grace of Helen, the control and poise of a Buddha, the strength of a superhero, and the heart of our family. &lt;/p&gt;

&lt;p&gt;The staff here at UCH are kindness, and have cared so wonderfully for us, I must thank them too. &lt;/p&gt;

&lt;p&gt;Elio, I tell you, you have come and changed our lives, and tomorrow, and all the days after, we will use our changed lives to help you create your own. I promise you tears and laughter, kindness and the sharing of sadnesses, but above all I promise you love. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://lh3.googleusercontent.com/-0mC72vFtFLE/T_DWOelxWpI/AAAAAAAAADk/HR6aoGP0YlM/s512/20120701-IMG_2580.jpg&quot; alt=&quot;Elio&quot; title=&quot;Elio&quot; /&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Did you just tell me to go fuck myself?</title>
   <link href="http://partiallyattended.com/2012/06/26/go-fuck-yourself"/>
   <updated>2012-06-26T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/06/26/go-fuck-yourself</id>
   <content type="html">&lt;p&gt;So this morning I had a scan with a consultant and he has diagnosed me with &lt;a href=&quot;http://en.wikipedia.org/wiki/Dupuytren&#39;s_contracture&quot;&gt;Dupuytren’s Contracture&lt;/a&gt;. I’ve been a climber since the summer of 1990, nearly 22 years now. It’s been amazing, I’ve gotten into some pretty &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/27167436/in/set-615345/&quot;&gt;special situations&lt;/a&gt;, and I’ve gotten pretty &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/5685460981/in/photosof-mulvanynet/&quot;&gt;fit&lt;/a&gt;. There is some &lt;a href=&quot;http://bjsm.bmj.com/content/39/9/639.full&quot;&gt;evidence&lt;/a&gt; that there is a higher incedence of Dupuytren’s Contracture amongst climbers. There is a great &lt;a href=&quot;http://www.ukclimbing.com/articles/page.php?id=1312&quot;&gt;write up&lt;/a&gt; about a climbers experience of this condition on &lt;a href=&quot;http://www.ukclimbing.com/&quot;&gt;ukclimbing&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;Anyway, I’m getting a bit off the point I wanted to make. I’m not very delighted about this. I’ve just wasted four months of staying away from training because I had a mis-diagnosis, one of the three longest layoffs I’ve had from climbing in the last two decades. I now fully expect that within the next ten years I’ll be looking at some level of surgical procedure. I’ve been avoiding writing blog posts in the last few months as I was afraid of tendon damage, basically I’m pretty much not very happy about this. &lt;/p&gt;

&lt;p&gt;I’m interested in finding out more about the condition, it seems that there is some process where the type of collagen in my hands will start to change from one type of collagen (the good collagen) to another type of collagen (from this point on to be referred to as the evil collagen). I’m mutating, but sadly I’ll not be shooting any threads of spider silk from my wrists, mores the pity. &lt;/p&gt;

&lt;p&gt;I’ve been a big fan of open access publishing, and now I have a very personal use case for wanting access to all of the literature. I tweeted about this earlier today, and I got the reply below from an Elsevier employee. &lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet tw-align-center&quot; data-in-reply-to=&quot;217549545201078272&quot;&gt;&lt;p&gt;@&lt;a href=&quot;https://twitter.com/IanMulvany&quot;&gt;IanMulvany&lt;/a&gt; Get well soon Ian. Your doctor will surely have access to relevant literature (unless you are planning to self treat).&lt;/p&gt;&amp;mdash; Andrew Miller (@EndoMetabPub) &lt;a href=&quot;https://twitter.com/EndoMetabPub/status/217551543141015552&quot; data-datetime=&quot;2012-06-26T09:35:04+00:00&quot;&gt;June 26, 2012&lt;/a&gt;&lt;/blockquote&gt;

&lt;p&gt;So, there is a great cartoon from &lt;a href=&quot;https://twitter.com/#!/jrecursive&quot;&gt;@jrecursive&lt;/a&gt; that pretty much sums up how I felt when I read that tweet: &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://browsertoolkit.com/fault-tolerance.png&quot; alt=&quot;go fuck yourself&quot; title=&quot;go fuck yourself&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There is just so much wrong with this response, I was gong to lob back a pithy response on twitter, but I just didn’t have it in my heart to do so, I was just astonished. &lt;/p&gt;

&lt;p&gt;There is so much wrong with the response, it assumes so much, it’s so condescending. I’ve been seeing a specialist, and it costs me about two hundred pounds a visit. I’m not going to be asking my specialist to do a literature search for me, I mean, for fuck’s sake, reading and digesting any tranche of literature is a very personal thing. I want the specialist to diagnose me, to do the scans, to give me medical advice. I don’t expect to have a student-librarian relationship with that person. &lt;/p&gt;

&lt;p&gt;The response assumes that I won’t want to find out for myself information about what might be affecting me. I’m scientifically literate, but I’m not in a research institution. It’s my body, it has been for a while, and it will be for a while longer. In so-far as I am deeply connected to my corporeal existence, I feel justified in wanting to know what’s going on with it.  &lt;/p&gt;

&lt;script src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>Some Thoughts on Peer Review and Altmetrics</title>
   <link href="http://partiallyattended.com/2012/06/18/some-thought-on-peerreview-and-altmetrics"/>
   <updated>2012-06-18T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/06/18/some-thought-on-peerreview-and-altmetrics</id>
   <content type="html">&lt;p&gt;The upcoming &lt;a href=&quot;http://altmetrics.org/altmetrics12/&quot;&gt;altmetrics&lt;/a&gt; meeting, and a submitted abstract by &lt;a href=&quot;http://www.csid.unt.edu/about/People/barr.html&quot;&gt;Kelli Barr&lt;/a&gt; prompted me to note down some of my own thoughts on peer review and altmetrics. I would love to make it over to the meeting, but with just a few days now before my first child is born, it ain’t gonna happen. &lt;/p&gt;

&lt;p&gt;I’ve not read Kelly’s paper, but after reading the abstract my take home message from it would be something along the lines of “don’t replace peer review with altmetrics because you will just replace one bias with another, and at least with peer review the bias is contained within the academic community”&lt;/p&gt;

&lt;p&gt;I personally don’t see any conflict between altmetrics and peer review. If anything, in a nutshell, I believe that altmetrics can help to create an augmented peer review, placing better information into the hands of those in the community who are making judgements on impact, on likelihood of future productivity, on who should get money.&lt;/p&gt;

&lt;p&gt;The abstract starts with&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;The altmetrics community, according to its manifesto, has grown around the assumption that the use of peer review as a filtering mechanism for quality scholarship has outlived its usefulness in the changing landscape of scholarly communication (Priem et al. 2010).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I would classify myself as part of this community, but my interest has not grown out of the assumption listed here. The idea that strongly motivates me is the following&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The web, and the processing power associated with it, should provide better information to those interested, about the impact of research, and the existence of relevant and related research to the question at hand to the researcher. In this way the web should be a tool to reduce informational asymmetry.&lt;/em&gt; &lt;/p&gt;

&lt;p&gt;The best current example of how this does not happen is the continued use of the impact factor as a proxy for impact. I think that it’s a case of since we can do this, and we can make systems that support the research process, we damn well should. There are many branches of thought that follow on from this: supporting peer review, recommendation of articles, graphing the flow of ideas within the literature, extending information about relevance to communities outside of the main research community for example patients. &lt;/p&gt;

&lt;p&gt;At it’s heart though, I’m a believer that as in other areas of human interaction, the web has the potential to help with some of the core activities of research, and not just by making it possible to read pdfs online.&lt;/p&gt;

&lt;p&gt;The abstract continues&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I argue that the altmetrics community should resist the attempt to supplant peer review with a host of altmetrics, no matter how diverse.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I totally agree with this. I think though, that peer review is not a single thing. It’s a description for a very variated process. When I was managing a number of journals I saw different types of peer review in process. Sometimes for small journals it consisted of getting the nod from the editor in chief. Sometimes it consisted of polling a large number of researchers where the work was felt to be potentially very problematic, leading in the end to the dismissal of the editor in chief (I’m talking here about different people). For some instantiations of what we could call peer review, I’m fully confident that a quite different approach could work just as well. &lt;a href=&quot;http://peerj.com/&quot;&gt;PeerJ&lt;/a&gt; may be a move in this direction. &lt;/p&gt;

&lt;p&gt;I’d make the analogy to code review. The reason for code review, within a programming organisation, is that humans are fallible. There are lots of different ways of doing code review, but at it’s heart, it’s always used as a sense check against human infallibility. I think this is one of the important aspects of peer review. Altmetrics can only help with this as by providing more information to the person doing the peer reviewing, there is a bigger chance that that person may be alerted either to potential errors, conflicts, or opportunities for interesting cross-pollination. &lt;/p&gt;

&lt;p&gt;My feeling on the following point&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Any evaluation scheme is simultaneously a system of incentives, and so assessing the impact of research according to a suite of altmetrics will inevitable steer research in particular directions, as peer review has done.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;is that the current data metrics: citations and the impact factor, are simply just very crude. The impact factor is a shit sandwich, and the only reason we continue to swallow it is that we don’t have open reproducible metrics. The impact factor itself if neither of these things. I think that projects like the &lt;a href=&quot;http://opencitations.wordpress.com/&quot;&gt;open citations&lt;/a&gt; are hugely important for helping to resolve this, and altmetrics itself. It’s early days, we have been talking about altmetrics since about the mid-2000’s, and early systems like &lt;a href=&quot;http://sourceforge.net/mailarchive/forum.php?forum_name=postgenomic-develop&quot;&gt;post-genomic&lt;/a&gt; gave an early taste, but I think it’s fair to say that systems that could really start to do something interesting have only been in existence for a little under five years now.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;but the judgments rendered will not be immune to the promotion of conventionality (i.e. groupthink, or cultural exclusivity on a larger scale), nor would it limit the volume of research published.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is a fair comment, but my hope will be that by promoting a variety of metrics people will be able to pick the groupthink that they most like, rather than all having to stick with one. One could then imagine applying meta-analysis to application of altmetrics to uncover these biases.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Augmented Peer Review</title>
   <link href="http://partiallyattended.com/2012/06/17/proposal-on-peer-review"/>
   <updated>2012-06-17T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/06/17/proposal-on-peer-review</id>
   <content type="html">&lt;p&gt;Last year I was asked to contribute to a special issue on the evolution of peer review. I got quite excited about doing this, but then realised that I really didn’t have the time to write a paper. I’m not a practicing academic, I build products, and while at Mendeley I really had far too much on my plate to find the time to write up a paper. However the topic does interest me, and I am a strong believer that web scale technologies can help with the scientific communication process though a large number of avenues. I was looking through my folder of draft blog posts, and I found the skeleton of the proposal that I had started to put together. I’m posting this up now, including the editoral comments I got on the very rough draft. I remain lucky enough to be in a position to continue to build out the parts of the infrastrucutre that I think can help with all of this. I’ll probably not get around to finishing my thoughts on this proposal in exactly the way that I had been thinking about it last year, but I might flesh out some related thoughts over the coming months. &lt;/p&gt;

&lt;h1 id=&quot;delivering-an-augmented-peer-review-system-one-piece-at-a-time&quot;&gt;Delivering an Augmented Peer Review System, one piece at a time.&lt;/h1&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Rather than trying to replace peer review, I will argue that we should create an augmented version of the system. I  propose that web scale technologies can be used to deliver this Augmented Peer Review. I will describe some of the functions of the peer review system and show some of these can already be helped with existing systems, and describe how some of the other functions may be helped in the near future. 
I will describe in detail how Mendeley has created a technology that can help with one core aspect of the peer review system, assisting in filtering the literature, and I will describe some of our upcoming plans to go further with this. I’ll describe some of the weaknesses of our approach and contrast these to weaknesses in the existing system. I will also describe some experiments that we are planning on running that may validate the predicative power of newly coined metrics. Finally I will argue that getting access to the citation and review graph is the biggest factor in holding back the improvement of the peer review system.&lt;/p&gt;

&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;There is little doubt that peer review is a topic of particular interest to academics. The Mendeley search catalog returns over 20 000 items with “peer review” in the title. There is a growing sentiment that “peer review is broken” (&lt;a href=&quot;http://www.the-scientist.com/templates/trackable/display/article1.jsp?a_day=1&amp;amp;index=1&amp;amp;year=2010&amp;amp;page=36&amp;amp;month=8&amp;amp;o_url=2010/8/1/36/1&quot;&gt;I hate your paper&lt;/a&gt; ), but broken or not, is it worth asking whether we can improve the current system in any way by applying social or technological changes to the practice of peer review? As a technologist I’m in the lucky position of working on systems that can have an impact on the peer review system from a technological point of view, and so those are the solutions that I will focus on in this paper. &lt;/p&gt;

&lt;h2 id=&quot;what-is-peer-review-anyway&quot;&gt;What is peer review anyway?&lt;/h2&gt;
&lt;p&gt;One of the great problems with offering solutions to the problem of peer review is that it is actually a many headed beast, a Hydra of a system. It is many different things to different people. Some of it’s core functions we can think of as being required, and others are more flexible depending on the policy of the peer review body. &lt;/p&gt;

&lt;p&gt;Generally Required:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A cross-check of correctness.
  We assume that once past peer review an article is telling us something that is true about the world.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;A cross-check of novelty.
  We assume that the work has not been presented before, or by other people.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Ensuring the correct link to related literature.
  We assume that the reviewer will inform the author of any missing credits that the author should have included in their paper to prior work.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The creation of a pre-filtered body of literature, though the understanding of the filtering is not necessarily clear to the reader.&lt;br /&gt;
  It is assumed that the literature that passes through the gate-keeping of peer review represents a special body of knowledge that can be depended upon for quality and accuracy. For the vast majority of content that passes peer review this is probably true, but not for all. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Providing a record of prestige for the author.
 Getting the “peer reviewd” hit is the cornerstone of building a career in academia. The more exclusive the journal, the better for the author. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Generally Optional:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Screening for suitability criteria for a given journal, either subject or impact based.
  Some journals will reject a work not because the work itself is in any way wrong, but because the work does not fit the subject space of the journal. Other journals, notable the Nature stable of journals, will reject a work if the editor of the journal does not feel that the work is of sufficient “impact” or of general enough of a nature. The main Nature journal also has a policy of publishing works that relate to the physical sciences, and so does not accept literature in the computational or mathematical sciences. PLoS One takes exactly the opposite view on impact, and checks only for rigour in the reporting, however it also has a strong subject bias and does not publish in areas of pure physics.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An opportunity to help improve the quality of the work.
  Though optional, many researchers put much time into helping to improve the quality of the manuscripts that they are reviewing. One of the main reported benefits of the peer review system is this improvement that authors feel of their work. This is almost entirely social, as there is rarely a published record of the reviewers comments.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;An opportunity to build or block the creation of social connections though contributed work.
  By contributing to the good peer reviewing of an article a researcher participates in the society of academia. This position can also be abused and used as a way to hinder the publication of competing researchers. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;## Augmenting parts of the functionality of Peer Review&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a cross-check of novelty&lt;/li&gt;
  &lt;li&gt;ensuring the correct link to related literature&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Both of these functions are under the pressure of the scale of the literature. In 2008 the Research Information Network assessed that researches in the UK read up to 260 articles each per year (Anon, 2008. Activities , costs and funding flows in the scholarly communications system in the UK Report commissioned by the Research Information Network ( RIN ) Full Report. , (May).). At this rate, assuming no further research were published, it would take a researcher approximately 77000 years to read their way through the items cataloged in PubMed. Nowadays even a well read well connected researcher can only hope to have a deep familiarity with a fraction of the literature, however even hundreds of millions of documents can be scalably compared with the kinds of data structures and algorithms that have been created for indexing the web, such as schema-less data stores like HBase, and algorithms like map-reduce.  &lt;/p&gt;

&lt;p&gt;The productisation of checking for similarity in the literature has already begun with the introduction of the &lt;a href=&quot;http://www.crossref.org/crosscheck.html&quot;&gt;cross check&lt;/a&gt; service from cross ref 
. Online services like the &lt;a href=&quot;http://www.biosemantics.org/jane/&quot;&gt;journal author name estimator&lt;/a&gt; can tell you what journals or articles are like the one you are currently writing . The next step will be to see such services integrated into the writing tools of the researcher. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;providing a record of prestige for the author&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is actually where the majority of this article will focus, and it discuss the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;altmetrics&lt;/li&gt;
  &lt;li&gt;the work of Bollen et al&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;graph theory applied to impact&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Tools for processing large graphs
The emergence of 3rd generation programming tools have driven the creation of libraries for managing graph structures that have realtivly humanly readable APIs. An example of this is &lt;a href=&quot;http://networkx.lanl.gov/&quot;&gt;networkx&lt;/a&gt;, a graph library in python. Robust scalable databases for processing large graphs have emerged, such as &lt;a href=&quot;http://neo4j.org/&quot;&gt;neo4j&lt;/a&gt;. The social web has driven the creation of very scalable systems for storing relational and non-relational data, such as &lt;a href=&quot;https://github.com/twitter/flockdb&quot;&gt;flockdb&lt;/a&gt;.  &lt;/li&gt;
&lt;/ul&gt;

&lt;ul&gt;
  &lt;li&gt;readership statics, and compare Mendeley readership statistics to those provided by services such as Connotea&lt;/li&gt;
  &lt;li&gt;the Mendely API and the type of queries that can be resolved on the back of it&lt;/li&gt;
  &lt;li&gt;plans for future work around individual impact based on Mendeley statistics&lt;/li&gt;
  &lt;li&gt;moving from a central data store to a distributed model, the web of linked data&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://altmetrics.org/manifesto/&quot;&gt;alt metrics manifesto&lt;/a&gt; &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.mendeley.com/research/diffusion-of-scientific-credits-and-the-ranking-of-scientists/&quot;&gt;Radicchi, F. et al., 2009. Diffusion of scientific credits and the ranking of scientists. Physical Review E, 80(5), p.11. Available at: http://arxiv.org/abs/0907.1050 [Accessed August 16, 2010].&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.mendeley.com/research/a-principal-component-analysis-of-39-scientic-impact-measures/&quot;&gt;Bollen, J. et al., 2009. A principal component analysis of 39 scientific impact measures. Methods, pp.1-19.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.mendeley.com/research/academic-search-engine-spam-google-scholar-s-resilience-against-it/&quot;&gt;Beel, J. &amp;amp; Gipp, B., 2010. Academic Search Engine Spam and Google Scholarâs Resilience Against it. Journal of Electronic Publishing, 13(3).&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.mendeley.com/research/nefarious-numbers/&quot;&gt;Arnold, D.N. &amp;amp; Fowler, K.K., 2010. Nefarious Numbers. , p.5. Available at: http://arxiv.org/abs/1010.0278 [Accessed October 6, 2010].&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;editorial-comments&quot;&gt;Editorial Comments&lt;/h2&gt;

&lt;p&gt;This abstract/outline contains a lot of highly relevant background and several good ideas and important observations. Services like Mendeley and Zotero are in a key position for providing the web-tools for realising open post-publication peer review. What I’m still missing in your outline is a coherent vision for how new papers can be openly evaluated by the community with these tools. Imagine you had infinite resources, what system for open evaluation of the scientific literature would you build?
I would like to invite you to contribute a full paper with the hope that you will describe a detailed vision for open evaluation (e.g. Mendeley users rating and reviewing papers and sharing their ratings and reviews). The vision should include a description of the required web-based infrastructure as well as mechanisms of motivating reviewers. Consider including a step-by-step description of the process by which a paper is evaluated. Make sure to address the design decisions listed in the email. Feel free to use figures to communicate the key concepts and processes of your vision. Please note that the innovative features that distinguish your approach from those described in other contributions to this special topic should be clearly communicated in the title, in the abstract, and through the headings and terminology used in the paper.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Super quick start guide to fluidinfo</title>
   <link href="http://partiallyattended.com/2012/06/17/getting-started-with-fish"/>
   <updated>2012-06-17T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/06/17/getting-started-with-fish</id>
   <content type="html">&lt;p&gt;This is a quick and dirty guide to getting started with fish, the command line tool for &lt;a href=&quot;http://www.fluidinfo.com&quot;&gt;fulidinfo&lt;/a&gt;. I did it by setting up a &lt;a href=&quot;http://pypi.python.org/pypi/virtualenv&quot;&gt;virtualenv&lt;/a&gt;, as I find it a lot easier to manage python dependancies that way.&lt;/p&gt;

&lt;p&gt;Setup a virtualenv:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkvirtual&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fi&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Open the virtual env session:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;workon&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fi&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Install httplib2:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;httplib2&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Install readline:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;readline&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Get fish, you can either get it from github and install from source, last time I checked that was:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;git&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;//&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;github&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;com&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;njr0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fish&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;em&gt;or&lt;/em&gt; you can just go ahead and:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pip&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fish&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Create a credentials file:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;touch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~/.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fluidinfocredentials&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Put your credentials in ~/.fluidinfocredentials as a simple two liner, username, then password.
If you signed in to fluidinfo with your twitter handle then you will need to create a password for your account, you can do this by going to the “Set password” option under your username in the web interface.&lt;/p&gt;

&lt;p&gt;Start fish:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fish&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;This&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fish&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;version&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;4.34&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Synchronizing&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Nothing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sync&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;Fluidinfo&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;synchronized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For further information on using fish have a look at the &lt;a href=&quot;http://fluiddb.fluidinfo.com/about/fish/fish/index.html&quot;&gt;documentation&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The Tractaus, a mini-review</title>
   <link href="http://partiallyattended.com/2012/05/08/tractatus"/>
   <updated>2012-05-08T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/05/08/tractatus</id>
   <content type="html">&lt;p&gt;This is the only book that &lt;a href=&quot;http://en.wikipedia.org/wiki/Ludwig_Wittgenstein&quot;&gt;Wittgenstein&lt;/a&gt; published in his lifetime. At the onset of the first world war Wittgenstein enlisted in the Austrian army. He was captured and served out the end of the war in a POW camp. It was here that the manuscript for the Tractatus was completed (footnote, I can’t recall where I read this, either in an encyclopaedia entry on Wittgenstein, or in Wittgenstein’s Poker, either way perhaps someone can otherwise confirm this statement?). I recently read that the work was highly influenced by &lt;a href=&quot;http://www.amazon.com/Gospel-Brief-Texts-Contexts/dp/0803294328&quot;&gt;The Gospel in Brief&lt;/a&gt; by Tolstoy (&lt;a href=&quot;http://www.amazon.com/House-Wittgenstein-Family-War/dp/0385520603&quot;&gt;&lt;em&gt;House Wittgenstein, a family a war&lt;/em&gt;&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;The book was first published in 1921 in in the periodical Annalen der Naturphilosophie. The first English translation was made by C. K. Ogden and his student &lt;a href=&quot;http://en.wikipedia.org/wiki/Frank_P._Ramsey&quot;&gt;F.P. Ramsey&lt;/a&gt; and appeared in 1922. My edition was first published in 1961 and translated by D.F Pears and B.F McGuinness working from notes that Wittgenstein had made about the Ogden and Ramsey translation. The copyright is currently held by Routledge.&lt;/p&gt;

&lt;p&gt;The book was used as his doctoral thesis for obtaining his Doctorate from Cambridge. This was really more of a formality. It was clear, by the time that Wittgenstein came to defend, that he was one of the most important philosophers in the world (a continuing mystery to his family). His viva was conducted by &lt;a href=&quot;http://en.wikipedia.org/wiki/Bertrand_Russell&quot;&gt;Bertrand Russell&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/G._E._Moore&quot;&gt;G. E. Moore&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the actual examiner’s report, Moore wrote “It is my personal opinion that Mr. Wittgenstein’s thesis is a work of genius; but, be that as it may, it is certainly well up to the standard required for the Cambridge degree of Doctor of Philosophy”.&lt;/p&gt;

&lt;p&gt;On the [Royal Institute of Philosophy] web page there is a very entertaining article entitled &lt;a href=&quot;http://www.sfu.ca/~jeffpell/Phil467/WittViva.pdf&quot;&gt;Wittgenstein’s Ph.D Viva - A Re-Creation&lt;/a&gt; (The author of this essay contends that had the examiners not been overawed by Wittgenstein’s personality then the Tractatus would have failed a viva.)&lt;/p&gt;

&lt;p&gt;The Tractatus is made up of n propositions, 7 major propositions with sub proposition following as 1.1, 1.11, 1.12, …  2, 2.01, 2.011 etc. Wittgenstein says, in the only footnote in the book, “the decimal numbers assigned to the individual propositions indicate the logical importance of the propositions, and the stress laid out on them in my exposition. The propositions n.1, n.2, n.3 etc. are comments on proposition n0. n: the proposition n.m1, n.m2, etc, are comments on proposition n.m; and so on.”&lt;/p&gt;

&lt;p&gt;In this way Wittgenstein attempts an axiomatic analysis of philosophy.&lt;/p&gt;

&lt;p&gt;The book is quite short, but dense. I have managed to get close to proposition 6, then I put the book down and pick it up and start from the beginning again. I’ve been doing this for a few years now. Far more has been written about the book, and I have read a lot more material about the book than I have read of the book. I did finally finish, and had one of those moments of absolute epiphany. It has escaped me now, and as I get older and as my days fill I am content with the knowledge that such a thing happened. I remember clearly the bench in Waverley station in Edinburgh where I picked the book up again, one more time. &lt;/p&gt;

&lt;p&gt;The first proposition reads “The world is all that is the case”, the last proposition “What we cannot speak of we must pass over in silence”.&lt;/p&gt;

&lt;p&gt;Before having completed the work I used to think Wittgenstein’s preface to the work gave a very clear indication of what he was about with the work. He tells us “The book deals with the problems of philosophy, and shows, I believe, that the reason why these problems are posed is that the [logic] of our language is misunderstood” The motto to the work is taken from &lt;a href=&quot;http://en.wikipedia.org/wiki/Ferdinand_K%C3%BCrnberger&quot;&gt;Kurnberger&lt;/a&gt; and states  “ … and whatever a man knows whatever is not mere rumbling and roaring that he has heard, can be said in three words”&lt;/p&gt;

&lt;p&gt;In proposition 4.116 Wittgenstein tells us “Everything that can be thought at all can be thought clearly. Everything that can be put into words can be put clearly.”&lt;/p&gt;

&lt;p&gt;I used to think that  his goal was to clarify what we mean when we speak. He believes that most, if not all, of the problems in philosophy are due to confusion, and if we could be clear about our terms it would become apparent that these are merely language [puzzle]s and not [problem]s of any merit whatsoever. He constantly tells us that a proposition shows it’s meaning. It cannot say anything, it can only display things (great advice for both script writer and UX designers).&lt;/p&gt;

&lt;p&gt;Broadly, the first third of the Tractatus sets out the terms of discourse about the [world], [facts], [objects] and their logical relation to one another. The second third of the book deals with [logical inference] and attempts to show how it is purely probabilistic matter based on the permutations of objects in the world and how we are limited by what we can say about these permutations. The last third speaks about what all of this may mean for our lives. &lt;/p&gt;

&lt;p&gt;The [logical positivist]s seem to have latched onto the earlier sections. They seem to have seen it as a template for reductionism. Wittgenstein himself saw the book as a work of ethics. Having completed the book, and thought about it for a few more years, I think I’ve changed my mind about what I think he was about. I used to think that he was about seeking that clarity of understanding about what we wish to speak about, but now I think that he was pointing the way to the unsayable. Pointing the way, and giving clarity to the idea that not all ideas are expressible. They can be shown, but not described. That the most important aspects of our experience in fact fall into these categories of things, and in this way philosophy can say very little about our state, if indeed it can say anything at all about our state.&lt;/p&gt;

&lt;p&gt;The entire work hinges on being able to identify atomic units of language. Wittgenstein later came to the conclusion that this is not possible, that language is created in a bootstrapping way, through use. This forms the theme of most of his later philosophy, though it does not affect much at all the underlying message of the work.&lt;/p&gt;

&lt;p&gt;Although the Tractatus might be wrong, it is still important. It is still thought provoking and it remains one of the most influential books on philosophy written. It also happens to be a very good book, though not an easy book.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Leaving Mendeley</title>
   <link href="http://partiallyattended.com/2012/05/05/leaving-mendeley"/>
   <updated>2012-05-05T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2012/05/05/leaving-mendeley</id>
   <content type="html">&lt;p&gt;I’m starting to draft this post on the train on the commute to my new job at &lt;a href=&quot;http://www.eLifesciences.org&quot;&gt;eLife&lt;/a&gt;. After almost two years I’ve taken the decision to move on from &lt;a href=&quot;http://www.mendeley.com&quot;&gt;Mendeley&lt;/a&gt;. They were without doubt the two best and most challenging years of my career to date. Working in a start up is an amazing, frustrating, enlightening, energising and rewarding experience.&lt;/p&gt;

&lt;p&gt;No single post can do justice to that time, and each time in the past weeks that I have drafted this post in my head it has had a slightly different timbre, so take this for what it is, a reflection in a moment. &lt;/p&gt;

&lt;p&gt;The mechanics of the decision are easy to describe, the decision itself one of the hardest that I’ve had to make. Unlooked for, an opportunity to work for eLife arrived. Its a big opportunity, working on the side of the angels. It was a big enough opportunity to make me even think about trying it out. Myself and my wife have a very personal project on the go, and in a few months we will be three. The new job let’s me try out working from home for two days a week. The mornings of the other days I have this beautiful and quiet commute out to Cambridge. &lt;/p&gt;

&lt;p&gt;A big change in your life often makes you reassess things, and I weighed up the pros and cons. In the end, I couldn’t get the idea of experimenting with what a journal could be out of my head. &lt;/p&gt;

&lt;p&gt;The idea of having the opportunity to bring web scale ideas to the dissemination process. That little “ear-worm” turned and turned, and now I’m on a train to Cambridge. The same desire to innovate, to try out the new, that was the desire that brought me to Nature a few years ago, to Mendeley two years ago, and now to eLife. &lt;/p&gt;

&lt;p&gt;I’ll be sure to write about what we ware going to be up to in future posts, but this is a time to reflect on what I have learnt over the past two years. A mini-retrospective.&lt;/p&gt;

&lt;p&gt;There are a few things that I am going to miss about Mendeley. I had the very great opportunity to work with great people in my time there. Working with such a dedicated development team was awesome. We built things that didn’t exist before. We ran into problems that other people in the industry have been looking at, and we came up with our own solutions. Every single person was trying as hard as they could to make a success of it. There’s a lot of passion there, many macro cycles of emotion as products come out, you find the bugs, sometimes you make compromises sometimes you surprise yourself. I learnt a lot about working with developers. Getting agreement on the spec is key, I could write a whole blog post about that. &lt;/p&gt;

&lt;p&gt;One of the other things that I will miss was the ability to experiment with process. Before working there I’d heard about agile project methodologies, one of the teams at Nature had started using bi-weekly sprints, but I’d only ever worked on projects in a waterfall approach. In my time at Mendeley I got to implement a number of different iterations on agile, saw where it worked, where it didn’t, really got a feel for it as a tool. In the end making the work visible, have agreed goals, and revising your understanding of your progress based on updated information were the core aspects that helped us. Kind of like applying the scientific method to project management. &lt;/p&gt;

&lt;p&gt;A great thing about working in a startup is that people are willing to change how you do things, if you can explain it. There is inertia, but it’s not been institutionalised in the way that it is at many bigger organisations. Of course, sometimes the need to change quickly can throw a spanner in the works of the tweak to the method that you are trying, but successes and  failures are understood quickly and can be addressed quickly. I don’t want to say that it’s painless, or that it’s a nirvana, but it does tend to lead to fast iteration, and as a vehicle for learning it’s pretty awesome. &lt;/p&gt;

&lt;p&gt;I had the sometimes daunting task of presenting to the board on progress (sometimes on lack of progress). They are laser focussed on the metrics that will make the company a success. They put a huge amount of faith in the management team, but it’s important to also understand that when talking to your board, when talking to any party who has a vested interested, but is not on the floor on a day to day basis, that you have to be focussed too in your communication with them. Whenever you have a number of very intelligent people in the room, they are going to dive into the subject matter in front of them. Make sure then, that the items on the agenda, and the information presented about those items, are focussed, clearly communicated, and that they tell a coherent story. Where there are problems, be specific about the impact, and the plans for resolution, but don’t go into the deep technical details (either software of project details). Where there are successes put them in context, celebrate them, but be realistic about the progress you have made, and the work that remains. &lt;/p&gt;

&lt;p&gt;The last thing that I want to mention is the impact that Mendeley has had. It’s astonishing to work on something that gets used by so many people. Over one and a half million people signed up for an account with Mendeley. In any given week we would have hundreds of thousands of people using the tools that we had built. My own background is in astronomy. I was used to dealing with big numbers, but small amounts of people. Any researcher can consider themselves lucky to get even a few citations. Most papers never get cited. The things we built had a big impact. A lot of the time, internally, we were not content with what we built. We knew the errors in the system, we knew the features that we really wanted to bring to our users. We were up close and examining each pixel. You had to remember to step back and look at the whole picture, look at the positive feedback. So many users benefiting from a workflow tool. A few months ago I was up in the peak district for a weekend of bouldering. We got dumped on with snow, and had to spend the night in a pub, the roads were impassable. There was a group of bedraggled students sitting in the corner of the pub, caught in the same storm as us. We got chatting, it turned out that one of the students was an enthusiastic Mendeley user. That kind of thing happened all the time (not the getting stranded in pubs, but meeting enthusiastic Mendeley users at the most unexpected junctures). &lt;/p&gt;

&lt;p&gt;With eLife I’m convinced there is an opportunity to make a contribution and an impact too. It’s in front of us now, and we have the opportunity to do something great. With Mendeley I feel a pride in having helped a great team of people build something that has been so beneficial to so many researchers. I know what they are planning in the future, and that future looks really exciting. I’m going to be cheering on, from the sidelines. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Mendeley, an investment branch of the citation bank.</title>
   <link href="http://partiallyattended.com/2012/01/18/mendeley-citebank"/>
   <updated>2012-01-18T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2012/01/18/mendeley-citebank</id>
   <content type="html">&lt;p&gt;The awesome &lt;a href=&quot;http://iphylo.blogspot.com/&quot;&gt;Rod Page&lt;/a&gt; has a great post on utilising Mendeley as a bank for citation data. He recommends that projects such as the &lt;a href=&quot;http://www.biodiversitylibrary.org/&quot;&gt;Biodiversity Heritage Library&lt;/a&gt; should build on top of the kind of infrastructure that we have already created at Mendeley. I’m a big fan of this as an idea, and indeed one of my goals for Mendeley is for us to create a system that makes it easier for others to build great tools for researchers. I began down a research career, but left it quite early. Making things that help researchers gives me a huge amount of personal satisfaction.&lt;/p&gt;

&lt;p&gt;I think there are three things that we should strive for that would really help with this.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Better example documentation on our API.&lt;/li&gt;
  &lt;li&gt;More clarity around the provenance of metadata on our catalog pages.&lt;/li&gt;
  &lt;li&gt;A more robust framework for storing, displaying and sharing PDFs where such sharing is allowed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I was fascinated in particular by the &lt;a href=&quot;http://worldcat.org/xissn/titlehistory&quot;&gt;Worldcat tool on displaying the historical changes of an ISSN&lt;/a&gt;. I aspire to being able to show provenance data on citation information in as clear a way as Worldcat have done here.&lt;/p&gt;

&lt;p&gt;Just things to keep in mind going forward.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>SOPA and PIPA stink, but the RWA is more dangerous to science.</title>
   <link href="http://partiallyattended.com/2012/01/17/sopa-pipia-rwa-dangers"/>
   <updated>2012-01-17T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2012/01/17/sopa-pipia-rwa-dangers</id>
   <content type="html">&lt;p&gt;There are three bills up for consideration in the US Government which if passed will have a significant negative impact 
on academic research. These are the Stop Online Piracy Act (SOPA), the Protect IP Act (PIPA), and the Research Works Act (RWA).&lt;/p&gt;

&lt;p&gt;SOPA and PIPA will have a negative impact by putting censorship controls into the hands of the entertainment industry, and permitting legal process to affect the underlying architecture of the web. These two acts are also &lt;a href=&quot;http://cameronneylon.net/blog/the-stupidity-of-sopa-in-scholarly-publishing/&quot;&gt;self defeating&lt;/a&gt; for scholarly publishing. The RWA act is damaging as it will attempt to limit the ability of researchers to publish in open access journals. The is &lt;a href=&quot;http://www.guardian.co.uk/science/2012/jan/16/academic-publishers-enemies-science&quot;&gt;naked greed&lt;/a&gt; on the part of the commercial publishers.&lt;/p&gt;

&lt;p&gt;The first two of these have led to a large reaction on the Internet, and this coming Wednesday a large number of popular sites, including wikipedia, will go black in protest. There is even initial evidence that the really bad parts of these bills may be deferred with the White House coming in against them, however the third of these, RWA, is getting much less coverage.&lt;/p&gt;

&lt;p&gt;SOPA and PIPA damage the economic interests of a large number of new industries. These industries have financial clout, high profile visibility and a lot of ground level support. There should be significant and effective opposition to SOPA and PIPA. RWA only has an impact on practicing researchers, the terminally ill, the students in developing economies. Where are the obscenely wealthy champions of science and truth? They are a rare breed indeed.  &lt;/p&gt;

&lt;p&gt;These three bills have been sponsored and heavily bank rolled by industries that are doing everything that they can to retain a hold on outdated business models. Elsevier in particular has &lt;a href=&quot;http://www.michaeleisen.org/blog/?p=807&quot;&gt;bankrolled the RWA act&lt;/a&gt;. Rather than playing fair in an open economy they are paying congress to tilt the law in their favour. There is nothing illegal about this so I refrain from using the term bribery, it’s just the way that congress works. &lt;/p&gt;

&lt;p&gt;SOPA and PIPA are a call to Silicon Valley to [get wise about the process of government][svuc] but I don’t see any natural champions to fight against the RWA act. The Open Access movement does not have enough big money behind it to pay off enough members of government to get the bill stopped that way, the impact on the browsing public will be too small to cause a huge public intervention on the act. I’m afraid that the outlook for this act is grim. &lt;/p&gt;

&lt;p&gt;What are the consequences if the RWA act passes?  &lt;/p&gt;

&lt;p&gt;My prediction is that this act will have a very negative long term impact on research coming out of North America. With researchers unable to disseminate their research properly, systems of research which allow the flow of information should become more fit more quickly in the information landscape. Countries that have an interest in catching up with the west, and that have less of an historic tie to overly strict interpretation of intellectual property and copyright, might find a great opportunity to definitively take the lead in the research world (go east young man!).  &lt;/p&gt;

&lt;p&gt;For the rest of us, we have to continue to build our systems in as &lt;a href=&quot;http://en.wikipedia.org/wiki/The_Open_Society_and_Its_Enemies&quot;&gt;open a way&lt;/a&gt; as we possibly can, and we have to continue to &lt;a href=&quot;http://www.mendeley.com/blog/academic-features/on-sharing-research-and-the-value-of-peer-review-mendeleys-response-to-sopa-and-the-research-works-act/&quot;&gt;voice our opposition&lt;/a&gt; to economically and intellectually harmful legislation. &lt;/p&gt;

&lt;p&gt;In the end the damning aspect of all three of these acts is that they promise &lt;a href=&quot;http://gigaom.com/2012/01/13/tim-oreilly-why-im-fighting-sopa/&quot;&gt;no economic benefit&lt;/a&gt;, in fact, they will actively harm the economies under whose jurisdiction they fall. I would love the hear a defence from the Scholarly Kitchen about the RWA act, because I certainly don’t understand how it could be a good thing at all.&lt;/p&gt;

&lt;p&gt;[Mendeley][mnd] will be joining the online protest on the 18th. Jonathan Eisen has called for a scholarly society &lt;a href=&quot;http://phylogenomics.blogspot.com/2012/01/calling-on-publishers-to-resign-from.html&quot;&gt;boycott of the Association of American Publishers&lt;/a&gt;. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Climbing Goals 2012, review 2011</title>
   <link href="http://partiallyattended.com/2012/01/08/climbing-goals-2012"/>
   <updated>2012-01-08T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2012/01/08/climbing-goals-2012</id>
   <content type="html">&lt;p&gt;Well, it’s been a while since I wrote up my &lt;a href=&quot;http://partiallyattended.com/2010/01/04/Climbing-Goals-2010-review-2009/&quot;&gt;climbing goals for 2010&lt;/a&gt;, and I totally missed doing this for last year, 
so as we ease our way into 2012 it’s high time that I do the same again.&lt;/p&gt;

&lt;p&gt;The key goals for 2010 were:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;redpoint fr 7a&lt;/li&gt;
  &lt;li&gt;boulder V5&lt;/li&gt;
  &lt;li&gt;trad E1&lt;/li&gt;
  &lt;li&gt;some trips to do some trad climbing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Well, since then I achieved the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;onsight 6c+ indoors&lt;/li&gt;
  &lt;li&gt;redpoint 6c outside&lt;/li&gt;
  &lt;li&gt;boulder V4&lt;/li&gt;
  &lt;li&gt;a few HVS’s &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, not quite breaking through to where I wanted to be, but there is a feeling of definite progress.&lt;/p&gt;

&lt;h1 id=&quot;hi-lights&quot;&gt;2011 hi-lights:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;font 6b, at fontainbleau &lt;/li&gt;
  &lt;li&gt;6c sport climb at Portland&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Alltogether it was an OK year even though I have still not sent La Marie Rose, but if you contrast my &lt;a href=&quot;http://www.ukclimbing.com/logbook/e.php?d=2012&amp;amp;u=41852&quot;&gt;training diary&lt;/a&gt; between 2010:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://picasaweb.google.com/lh/photo/oK47rfPQ8Et3ouZa96aZLNMTjNZETYmyPJy0liipFm0?feat=embedwebsite&quot;&gt;&lt;img src=&quot;https://lh5.googleusercontent.com/-xeSbDtLcsfI/Twok3TMJB7I/AAAAAAAAAuE/pnmoQnc6r8I/s144/screen-capture-1.jpg&quot; height=&quot;264&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;and 2011:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://picasaweb.google.com/lh/photo/tHGUcS8CNkulh-nGJ1XDSdMTjNZETYmyPJy0liipFm0?feat=embedwebsite&quot;&gt;&lt;img src=&quot;https://lh6.googleusercontent.com/-tnkZpwNAT7k/Twok31B4M1I/AAAAAAAAAuI/QhsfYB8WWeA/s400/screen-capture.jpg&quot; height=&quot;264&quot; width=&quot;400&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;you can see a big hole in the middle of 2011 where I took time off to refit my kitchen. The second half of 2012 will also be very distrupted from a climing point of view 
(though with some very good reasons that I am very much looking forward to). &lt;/p&gt;

&lt;p&gt;Today at the Castle I maanged to fire off a 6c, and 6c+, the 6c+ being on-sight. I’ve decided that my:&lt;/p&gt;

&lt;h1 id=&quot;goals-for-2012-are-as-follows&quot;&gt;Goals for 2012 are as follows:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;remain injury free&lt;/li&gt;
  &lt;li&gt;significantly reduce the amount of alcohol that I consume&lt;/li&gt;
  &lt;li&gt;fall off at least 10 routes of 6c or harder/month&lt;/li&gt;
  &lt;li&gt;redpoint 7a, but don’t stop trying harder things&lt;/li&gt;
  &lt;li&gt;get three campus board sessions or power hand sessions into my training per month&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the most part what I have realised is that what I have control over are the things I choose to do when I go training. If I can keep focussed on 
making sure that I don’t have any anxiety about what I am trying to climb, and that I am really pushing myself and my body, then the grades and routes will
come naturally. I want to climb hard, but I don’t want to set goals that will lead me to focus on that one climb, rather I want to focus on making
the journey and the process a good journey, that is using my time in a very efficient way.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>example title</title>
   <link href="http://partiallyattended.com/2011/11/21/zanran-google-for-data"/>
   <updated>2011-11-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2011/11/21/zanran-google-for-data</id>
   <content type="html">&lt;p&gt;Back in 2010 I was pointed at &lt;a href=&quot;http://www.zanran.com/&quot;&gt;zanran&lt;/a&gt;, a search engine that looks for data in graphs.&lt;/p&gt;

&lt;p&gt;I’ve been playing around with some sample searches, and decided to try &lt;a href=&quot;http://www.zanran.com/q/drowning_deaths_swimming_pool&quot;&gt;drowning deaths swimming pool&lt;/a&gt;. Incidentally all of the results that came back were figures for young children. I guess this is because that is the group where there is the most concern, and so there is more published data about this group.&lt;/p&gt;

&lt;p&gt;There are some interesting broad figures that come out from the data:&lt;/p&gt;

&lt;p&gt;Figures come in on average at about 2 per 100,000 population, or 0.00002%&lt;/p&gt;

&lt;p&gt;This is about the same chance as drowning in natural water, but at 66% more likely than drowning in a bathtub &lt;/p&gt;

&lt;p&gt;of drownings:
(natural water 25%)
(swimming pool 24%)
(bathtub 15%)&lt;/p&gt;

&lt;p&gt;Cars are about 4–5 times more dangerous than swimming pools.
Guns are about 10 times less dangerous.&lt;/p&gt;

&lt;p&gt;If you are a boy in Australia, you are more than twice as likely to drown in a swimming pool than if you are a girl. I guess that this is a combination of boys being encouraged to be more reckless and girls being supervised more.&lt;/p&gt;

&lt;p&gt;Over a year on and the site is still up. It looks like it’s still in beta, has more data than a year ago, and is registered in London.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Update on MathJax</title>
   <link href="http://partiallyattended.com/2011/11/20/update-on-mathjax"/>
   <updated>2011-11-20T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2011/11/20/update-on-mathjax</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.mathjax.org/&quot;&gt;MathJax&lt;/a&gt; has come a long way since I last looked at it. There is now a CDN hosting the js files, which makes calling it 
really really easy. It’s being adopted by GiHub for their wiki engine.&lt;/p&gt;

&lt;p&gt;Using it with markdown can cause a few bumps, but there seems to be a bunch of ways around this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://doswa.com/2011/07/20/mathjax-in-markdown.html i&quot;&gt;mathjax in markdown&lt;/a&gt; using some mathjax configuration and custom css&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://notepag.es/latexdemo&quot;&gt;amazing implimentation&lt;/a&gt; in a notetaking app&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.leancrew.com/all-this/2010/09/php-markdown-extra-math-mathjax-and-wordpress/&quot;&gt;php, mathjax and wordpress&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Writing a block of %%\LaTeX%% like this&lt;/p&gt;
&lt;pre&gt;
$$
\begin{aligned}
\dot{x} &amp;amp; = \sigma(y-x) \\
\dot{y} &amp;amp; = \rho x - y - xz \\
\dot{z} &amp;amp; = -\beta z + xy
\end{aligned} 
$$
&lt;/pre&gt;

&lt;p&gt;will render like this&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[

\begin{aligned}
\dot{x} &amp;amp; = \sigma(y-x) \\
\dot{y} &amp;amp; = \rho x - y - xz \\
\dot{z} &amp;amp; = -\beta z + xy
\end{aligned} 
 %]]&gt;&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>Converting between dates and unix time in Python</title>
   <link href="http://partiallyattended.com/2011/10/13/managing-unix-time-in-python"/>
   <updated>2011-10-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/10/13/managing-unix-time-in-python</id>
   <content type="html">&lt;h1 id=&quot;going-from-a-date-to-a-unix-time&quot;&gt;Going from a date to a unix time:&lt;/h1&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mktime&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;date&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2011&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;26&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mktime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timetuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;mf&quot;&gt;1316991600.0&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1 id=&quot;going-from-a-unix-time-to-a-date&quot;&gt;Going from a unix time to a date:&lt;/h1&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strftime&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;datetime&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datetime&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromtimestamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;1284101485&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;strftime&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;%Y-%m-&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%d&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; %H:%M:%S&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;&amp;#39;2010-09-10 07:51:25&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Nature, Whiskey and me</title>
   <link href="http://partiallyattended.com/2011/10/07/nature-whiskey-and-me"/>
   <updated>2011-10-07T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/10/07/nature-whiskey-and-me</id>
   <content type="html">&lt;p&gt;In my earlier &lt;a href=&quot;http://partiallyattended.com/2011/10/03/megajournals/&quot;&gt;post on Megajournals&lt;/a&gt; I hinted that I felt that there could be a future in which this business model provided sufficient funds to allow a publishing house like &lt;a href=&quot;http://www.nature.com/npg_/index_npg.html&quot;&gt;NPG&lt;/a&gt; to make it’s flagship journal Nature an open access journal.&lt;/p&gt;

&lt;p&gt;This topic came up late one evening at &lt;a href=&quot;http://www.oaspa.org/coasp/&quot;&gt;coasp&lt;/a&gt; and I ended up making a bet with &lt;a href=&quot;https://twitter.com/#!/mz2&quot;&gt;Matias Piipari&lt;/a&gt;. I bet that within 10 years Nature would become a fully open access journal. I win three fine bottles of scotch. The date that the bet matures on Wed Sep 22, 2021. I’ve just sent the following message to the Editor in Chief at Nature:&lt;/p&gt;

&lt;pre&gt;
Subject: Scientific Reports, Nature, Open Access and a future of fine whiskey.

Dear Dr. Campbell,

I am writing to congratulate you on the recent launch of Scientific Reports. 
I had the pleasure to see Sara Grimme give an excellent overview of the genesis 
of the title at the recent COSAP conference on open access publishing 
(http://www.oaspa.org/coasp/).

During the course of the event a discussion arose on the potential future 
impact of the Megajournal on top tier titles such as Nature. I professed hope 
that a vehicle such as Scientific Reports could grow in time to support a 
business model in which Nature itself could be run as an open access journal.

There was some disagreement on my prediction, the outcome of which is that 
I now have a standing bet with Matias Piipari. If Nature becomes Open Access 
on or before Wed Sep 22, 2021, ten years from now, I will win three fine bottles 
of scotch.

I will continue to keep an interested eye on the development of Scientific Reports 
and I wish Nature Publishing Group the best of luck with it.

Sincerely yours,

- Ian Mulvany
&lt;/pre&gt;

</content>
 </entry>
 
 <entry>
   <title>Hindawi have an awesome reviewing system.</title>
   <link href="http://partiallyattended.com/2011/10/06/hindawi-reviewing"/>
   <updated>2011-10-06T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/10/06/hindawi-reviewing</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.hindawi.com/&quot;&gt;Hindawi&lt;/a&gt; publishers is a really interesting outfit. They are an open access only publisher based in Egypt. They combing a fantastic use of technology with the ability to afford a large amount of human curation over the data that they use to streamline their publication and reviewing systems.&lt;/p&gt;

&lt;p&gt;One of their publishing vehicles is called the &lt;a href=&quot;http://www.isrn.com/journals/&quot;&gt;International Scholarly Research Network&lt;/a&gt; and at the recent &lt;a href=&quot;http://www.oaspa.org/coasp/&quot;&gt;coasp&lt;/a&gt; conference Paul Peters gave an overview of how their peer review system works, I think it’s genius. They take a received manuscript, look at all of the references in that manuscript, and then computationally compare overlap of the cited works with the works cited by their panel of potential reviewers. They identify up to five potential referees who have the closest discipline match, but with whom there is no conflict of interest. A review request is sent out, and the reviewers are asked should the work be published according to the ISRN criteria, or if not why not. If a qoura of reviewers accepts then the paper is published. If there is a disagreement, they all get to see each other’s comments and they have to come to an agreement on the final decision.&lt;/p&gt;

&lt;p&gt;When a paper is published the reviewers who supported the decision have their names published along side the paper so that the community can see the provenance of the peer review.&lt;/p&gt;

&lt;p&gt;When the decision is split I love the fact that they can see each other’s comments before making a final decision. This makes it easier for the community of reviewers to come to a concencus over what standard of reviewing to apply for the submissions to ISRN. &lt;/p&gt;

&lt;p&gt;It’s a beautiful system, and it’s one where cantankerous reviewers can be identified quickly, and removed form the review request queue.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Megajournals</title>
   <link href="http://partiallyattended.com/2011/10/03/megajournals"/>
   <updated>2011-10-03T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/10/03/megajournals</id>
   <content type="html">&lt;p&gt;The idea of megajournals had not really formalised in my head before, but at the &lt;a href=&quot;http://www.oaspa.org/coasp/&quot;&gt;COASP&lt;/a&gt; meeting the talk was all about “&lt;em&gt;Megajournals&lt;/em&gt;”. [PLoSOne][plosone] is the archetype for this kind of journal, and it had not really struck me before as a huge revolution in the publishing industry, but after listening to a couple of days worth of talks on the topic I’m convincible. &lt;/p&gt;

&lt;p&gt;Megajournals are so called because they are structured to be able to publish many more articles than has been the normal practice with traditional journals. By my count there are currently about thirty five thousand academic titles. The vast majority of these titles are not indexed for impact, many of them are homebrew, and most of them are niche. They may publish a few issues per year, they may have a handful of articles per issue, and each one is mostly supported by a small community of researchers.&lt;/p&gt;

&lt;p&gt;The big boy journals; IOP titles, Nature, Science, Genetics, NEJM and so on, have productionised the process of publishing articles. They employ a large number of people to mange the journals and sometimes to do in-house peer review. They publish their issues weekly with a constant rolling online first systems. The big publishers have applied this model to bundle publishing across many titles. However all of these venues retain the sense of an issue. In addition many of them have explicit policies around the taste or flavour of the articles that they wish to publish. &lt;/p&gt;

&lt;p&gt;We live in a world of selectivity in academic publishing. The journals want articles that are constrained by size, or content, or topic or perceived impact. Every journal sets it’s stall on a combination of these criteria.&lt;/p&gt;

&lt;p&gt;The result is a high rejection rate. The work is not an appropriate topic, not impactfull enough, too long, to theoretical, not written be a friend of the editorial board, etc, etc. Nature’s rejection rate is famously greater than 98%. When a researcher gets rejected from a journal they generally have to go through the entire submission process again at another venue. It can take months for an article the make it’s way through the publishing pipeline before it gets to the final rejected state. Sometimes it can take years. Each time an article is submitted it needs to be reviewed. Reviewers need to be found, and they need to spend their time reading and commenting on that paper. If the article had been submitted to another journal before and rejected, then these reviewers are repeating the work that someone else had done. Waste waste waste waste, it’s a huge waste of time. &lt;/p&gt;

&lt;p&gt;This is a problem both for research (delayed time to publication, multiplication of reviewing effort), and a problem for journals with very high rejection rates as costs for maintaining a high rejection rate are large composed of the maintenance of a professional staff and the processing costs of dealing with a high number of manuscripts that the journal in the end is not actually going to publish.&lt;/p&gt;

&lt;p&gt;For a long time now people have been talking about innovating the peer review system. People have been talking about how open access is going to solve all of these issues. In the end I think really pragmatic approach is going to have a big impact, and that is the approach taken by the megajournal.&lt;/p&gt;

&lt;p&gt;The approach of the megajournal is simple to describe. They remove the pretence of having issues, and they radically simplify the criteria for publication, asking for the most part only that the paper is scientifically rigourous. (Think about that for a moment, these journals are asking only that the papers that they publish advance our knowledge about the universe around us, not asking that they do so according to some predefined criteria. They are looking to ensure that the articles pass scientific muster, and allowing posterity to take care of the impact).i&lt;/p&gt;

&lt;p&gt;By significantly lowering the rejection rate by not rejection based on taste, but only on correctness, you dramatically increase the efficiency of getting knowledge published. If you tie that to a business model where you generate revenue as a function of the volume of articles that you publish (author pays open access for example), then you create a nice scalable revenue stream. This worked to move PLoS into the black on the back of PLoS One. &lt;/p&gt;

&lt;p&gt;The high impact journals have taken notice, and Nature’s &lt;a href=&quot;http://www.nature.com/srep/index.html&quot;&gt;Scientific Reports&lt;/a&gt; is an explicit move to create a megajournal that can be used to publish content that gets rejected from the selective Nature branded titles. I think this is brilliant. If the authors are willing, then for their part they can rapidly get their work published without having to endure a long resubmission process. Nature already has a large volume of content that is being submitted that they are not publishing, so the new journal should not have a cold start of submissions. The content that goes on in this new journal will be OA, leading to an increase in OA content, and one could imagine a future in which this revenue stream could supplant the traditional subscription model for nature publishing group.&lt;/p&gt;

&lt;p&gt;There are a few interesting trends emerging around megajournals. &lt;/p&gt;

&lt;p&gt;The first is that they by no means imply low quality as measured by the impact factor. PloS One has a rejection rate of somewhere between 25 and 30% and an initial impact factor of 4.3. That’s very good, in fact submissions more or less tripled after it received an impact factor.&lt;/p&gt;

&lt;p&gt;Next is that when a top tier journal creates a magajournal vehicle then the reviewers of the new journal really need to be educated about what the acceptance criteria are for the new journal. Publishers from Nature, Hindawi and The Genetics Society of America all described how their reviewers continued to reject articles on the bases of more than just scientific correctness. If it’s going to work you have to be willing and able to publish work that is clearly low impact, but demonstrably correct.&lt;/p&gt;

&lt;p&gt;Lastly, for some of these submissions are continuing to grow at a healthy pace. PLoS One now publishes something like 1.5 % of all academic articles, and it’s share is growing quarter on quarter. The implication in my mind is clear, that if this trend continues many of the small titles will be cannibalised. I asked at the conference if there was any actual evidence of this happening yet. The audience were clear to say that none have seen any impact on their journals, that there seems to be no broader evidence for such a trend, that globally the entire number of articles is growing annually at a few percent, so that so far one would not expect to see an effect. However I predict that this trend will lead to an impact on many small niche journals, and I look forward to the state of the publishing landscape in five years from now.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The rude health of Open Access Publishing.</title>
   <link href="http://partiallyattended.com/2011/10/03/coasp-impressions"/>
   <updated>2011-10-03T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/10/03/coasp-impressions</id>
   <content type="html">&lt;p&gt;TL;DR OA publishing is maturing with a scalable business model that all the big publishers are jumping all over. Money will be made (but less than before), and more content will be more open. The poor lamentable nay-sayers who carp on unheard in the darkness will be forgotten, and their Cassandra-like predictions will fade to be recalled as little more than the mutterings of fools (OK, that last bit is probably opinion).&lt;/p&gt;

&lt;p&gt;Just over a week ago I had the great pleasure to present some thoughts &lt;a href=&quot;http://altmetrics.org/manifesto/&quot;&gt;alt-metrics&lt;/a&gt; to the &lt;a href=&quot;http://www.oaspa.org/coasp/&quot;&gt;3rd Conference on Open Access Publishing&lt;/a&gt;. The talks were recorded and my talk will be posted in time. &lt;/p&gt;

&lt;p&gt;I wanted to write up a few thoughts that spun up out of my experience of meeting with that community and seeing what’s going on there. 
It seems like there is a upswell of coverage on open access right now. In the week that was in it Princeton asked it’s researchers &lt;a href=&quot;http://theconversation.edu.au/princeton-bans-academics-from-handing-all-copyright-to-journal-publishers-3596&quot;&gt;not to hand over copyright&lt;/a&gt; (&lt;a href=&quot;https://docs.google.com/viewer?url=http%3A%2F%2Fwww.cs.princeton.edu%2F~appel%2Fopen-access-report.pdf&quot;&gt;statement&lt;/a&gt;), a call to &lt;a href=&quot;http://cr.yp.to/writing/ieee.html&quot;&gt;not publish with IEEE&lt;/a&gt; got picked up by Hacker News and the Times Higher Education posted a call for academics to &lt;a href=&quot;http://www.timeshighereducation.co.uk/story.asp?sectioncode=26&amp;amp;storycode=417576&amp;amp;c=1&quot;&gt;not peer review for non-OA journals&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;One could be forgiven for thinking that something is afoot. &lt;/p&gt;

&lt;p&gt;Open access also got picked up in some national press, a fact that was &lt;a href=&quot;http://scholarlykitchen.sspnet.org/2011/09/22/london-calling-open-access-pr-wends-its-way-from-london-into-a-major-us-newspaper/&quot;&gt;lamented by the Scholarly Kitchen&lt;/a&gt; (What’s up with the Scholarly Kitchen anyway? I’ve had to be moderately careful about what I wrote in this paragraph to not stray over into mocking or insulting, but the core of my feeling on the topic is that when it comes to discussing open access publishing they are, and specifically Kent Anderson is, disingenuous about their coverage of OA in a highly negative way. I’ve met some of the contributors and they seem like nice intelligent people, so this continuos editorial stance makes me think of them as somewhat akin to the Daily Mail in the UK). &lt;/p&gt;

&lt;p&gt;The main sentiment from the conference was that OA publishing as an industry is flourishing. There were representatives form many traditional scientific publishers, and the discussion was all about revenues, peer review models and the enormous growth that all of these titles were seeing in submissions. The biggest point of discussion over the few days of the conference was about the rise of the megajournal, more of which in a subsequent post. &lt;/p&gt;

&lt;p&gt;What as also very clear was the diversity of philosophical approach to what OA meant from a publisher point of view. &lt;a href=&quot;http://www.plos.org/publications/journals/&quot;&gt;Plos&lt;/a&gt; focussed on their ethical standards, &lt;a href=&quot;http://www.hindawi.com/&quot;&gt;Hindawi&lt;/a&gt; talked about their scale at creating titles and running peer review over those titles in a scalable way.&lt;/p&gt;

&lt;p&gt;Some of these trends were raised by &lt;a href=&quot;http://www.sdsc.edu/~bourne/&quot;&gt;Phil Bourne&lt;/a&gt; in his keynote. It’s clear that the academic has a different view from the publisher. There is still a desire to see more use of CC0 licences, and to allow wide ranging data mining on the artefacts that Open Access can produce. Phil again called for a more integrated eco system of derivative objects created on top of the literature. It’s not clear whether publishers will be in a position to do this, but OA objects should allow a competitive market place of these kinds of things to emerge. (Of course the great promise is that they &lt;em&gt;should&lt;/em&gt; and it is by no means a given that they will).&lt;/p&gt;

&lt;p&gt;Phil had been involved in a summer workshop on moving beyond the PDF and some of their output can be seen at the &lt;a href=&quot;https://sites.google.com/site/futureofresearchcommunications/force11-tools-framework&quot;&gt;FORCE11&lt;/a&gt; site. Slowly we move in the right direction, slowly, slowly, but surely.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://twitter.com/#!/p_binfield&quot;&gt;Pete Binfield&lt;/a&gt; was busy telling everyone that within three years up to 50% of all content that is freshly published may be open access. Heady predictions, but form the submission figures that he showed for PloSONE not a prediction that is impossible to believe in.&lt;/p&gt;

&lt;p&gt;Overall there was a feeling that we will see a continued and strong growth in OA published content. Back of the envelope figures were being mentioned as if they were the accepted norm and people felt that the academic publishing industry might reduce in global value from it’s current nine billion in turnover per year to a more modest two to three billion, with savings coming from the more sane cost structure that comes along with Open Access publishing. Of course the only way to tell if a change like that is going to happen is to wait it out and see.&lt;/p&gt;

&lt;p&gt;It seems like enough traditional publishers are willing to get a toe in the water.&lt;/p&gt;

&lt;p&gt;In the end, over the past couple of weeks the best comment I’ve seen on the current state of the OA movement has come from the inestimable &lt;a href=&quot;http://del-fi.org/jtw&quot;&gt;John Willbanks&lt;/a&gt; who pointed out that it’s &lt;a href=&quot;http://del-fi.org/post/10561649700/open-access-is-infrastructure-not-religion&quot;&gt;no longer a question of religion but of infrastructure&lt;/a&gt;. &lt;/p&gt;

&lt;object width=&quot;560&quot; height=&quot;315&quot;&gt;&lt;param name=&quot;movie&quot; value=&quot;http://www.youtube.com/v/GMIY_4t-DR0?version=3&amp;amp;hl=en_US&quot; /&gt;&lt;param name=&quot;allowFullScreen&quot; value=&quot;true&quot; /&gt;&lt;param name=&quot;allowscriptaccess&quot; value=&quot;always&quot; /&gt;&lt;embed src=&quot;http://www.youtube.com/v/GMIY_4t-DR0?version=3&amp;amp;hl=en_US&quot; type=&quot;application/x-shockwave-flash&quot; width=&quot;560&quot; height=&quot;315&quot; allowscriptaccess=&quot;always&quot; allowfullscreen=&quot;true&quot; /&gt;&lt;/object&gt;
</content>
 </entry>
 
 <entry>
   <title>SOLO11, day1, morning sessions.</title>
   <link href="http://partiallyattended.com/2011/09/02/solo11-day1-morning-sessions"/>
   <updated>2011-09-02T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/09/02/solo11-day1-morning-sessions</id>
   <content type="html">&lt;h1 id=&quot;session-on-engaging-with-peer-review&quot;&gt;Session on engaging with peer review&lt;/h1&gt;

&lt;p&gt;This is a very nice panel discussion. For my money there are a number of key points that arose during the discussion:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;discussions with the public needs to happen where the public is&lt;/li&gt;
  &lt;li&gt;being half assed about engaging the public discourse around papers, and then hiding behind peer review when you run into criticism is really bad, as for example what happened with the arsenic story nasa and science&lt;/li&gt;
  &lt;li&gt;the public needs to be educated that peer review is not binary&lt;/li&gt;
  &lt;li&gt;peer review comments should be made public (not everyone agrees)&lt;/li&gt;
  &lt;li&gt;where we have representations of papers we should look to link to conversations about those papers (trackbacks and so forth)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There is a very interesting comment in the Q&amp;amp;A from [Martin Fenner][mf] about peer review in clinical medicine. Peer review is not as important in clinical medicine as I had assumed, far more iportant are conferences and clinical trials, and there have been cases of drugs getting approval before the peer review system completes. I found that really interesting. &lt;/p&gt;

&lt;p&gt;One of the other interesting things about this discussion is that it avoided discussion on how long the peer review system can take.&lt;/p&gt;

&lt;h1 id=&quot;npg-api-session&quot;&gt;NPG API session&lt;/h1&gt;

&lt;p&gt;Interesting, lot’s of interest in the API session. It looks like [NPG][npg] is going to be working with &lt;a href=&quot;http://www.mashery.com&quot;&gt;Mashery&lt;/a&gt; to improve the interface to their APIs. I hope some of these people make it to the dev session that is being planned for &lt;a href=&quot;http://lanyrd.com/2011/solohack11/&quot;&gt;Sunday&lt;/a&gt;. It looks at the moment that they are making a portal for some of their opensearch infrastructure, which is a nice thing. From the perspective of NPG, being able to see what happens through issuing API keys is a good thing, but of course it adds one layer between the developer and the data. On the whole I think it’s probably a sensible approach in today’s world as it gives you the ability to control against DDOS attacks, and when you have content that &lt;em&gt;could&lt;/em&gt; be considered controversial by any sector of society (think climate change, think evolution), you have to be careful at some level.&lt;/p&gt;

&lt;p&gt;I wonder if they are going to also pull in info about the open social APIs that Nature Network sits on top of? I was quite involved with rolling those out while I was still at Nature so they have a place in my heart.&lt;/p&gt;

&lt;p&gt;Ah, interesting, NPG are putting their data onto a triple store. I &lt;em&gt;think&lt;/em&gt; this could be important, but I just don’t know many people consuming triples compared to consuming JSON (and I say that somewhat tongue in cheek at the moment). My point though is rather that someone who is interested in institutional impact probably wants examples of some simple queries and does not really want to negotiate a triple store. &lt;/p&gt;

&lt;p&gt;Interestingly NPG is also going to be including blog data through their APIs. They have an example of visualisations of Neuroscience blog citations. The nice thing about this data set is that it is not journal specific. I could imagine mashing this API up with the &lt;a href=&quot;http://dev.mendeley.com&quot;&gt;mendeley api&lt;/a&gt; and getting a comparison between &lt;/p&gt;

&lt;p&gt;The dev portal will be at &lt;a href=&quot;http://developers.nature.com&quot;&gt;http://developers.nature.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;(It’s a bit weird writing this post with &lt;a href=&quot;https://twitter.com/#!/spanx&quot;&gt;@spanx&lt;/a&gt; looking over my shoulder, - he just pointed out a typo, does that make this pair blogging?). &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Science Online London Keynote, Michael Nielson on Open Sciecne</title>
   <link href="http://partiallyattended.com/2011/09/02/solo11-day1-keynote"/>
   <updated>2011-09-02T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/09/02/solo11-day1-keynote</id>
   <content type="html">&lt;h1 id=&quot;michael-nielsonmn-keynote-on-open-science&quot;&gt;&lt;a href=&quot;http://michaelnielsen.org/blog/michael-a-nielsen/&quot;&gt;Michael Nielson&lt;/a&gt; Keynote on Open Science&lt;/h1&gt;

&lt;p&gt;He rightly points out that he is probably going to be talking to the converted, so his talk is aimed at looking for resources that can help us to find answers about how to make open science works. He starts talking about an example of failure in open science. his example is an open notebook science from Tobias J Osbourne. He built up a readership of about 100 readers on a highly technical field, but he was not getting much participation, and very little feedback. He was putting in a lot of effort but was not getting much value out of the exercise. His reason, we are in a local optimum and he felt we needed a global change.&lt;/p&gt;

&lt;p&gt;In other areas of the world we have had examples of where making a collective change has been implemented. Sweden changed the side of the road that people drive on on one day in the 1950s.&lt;/p&gt;

&lt;p&gt;The concept, is that there is some action where if everyone changed it would be better for everyone, but you need everyone to change at the same time. There are incentives for people not to participate because there is some cost involved in changing for the individual but if the individual does not change, they get the benefit anyway from everyone else changing. This is the same kind of problem that we have with the move to open data. &lt;/p&gt;

&lt;p&gt;This is known as the problem of &lt;a href=&quot;http://en.wikipedia.org/wiki/Collective_action&quot;&gt;Collective Action&lt;/a&gt;, and the definitive work on this was published in the 1960s and is 
&lt;a href=&quot;http://www.amazon.com/Logic-Collective-Action-printing-appendix/dp/0674537513&quot;&gt;The Logic of Collective ACtion&lt;/a&gt; by &lt;a href=&quot;http://en.wikipedia.org/wiki/Mancur_Olson&quot;&gt;Mancur Olsen&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The problem of open science is also an example of the difficulty of providing a public good (or for an economist a club good).&lt;/p&gt;

&lt;p&gt;A case study is regulation in the airline industry, another example is the creation of trade unions. It is difficult to exclude non-union workers from gaining from the goods brought about by a union (for example introduction of better safety measures). This means that members have an incentive to avoid paying dues. How did unions form in the first place? Historically they didn’t form in one big go, but rather small groups tended to self organise within an organisation and started bargaining with management, and the second stage was agglomeration between these groups, and between groups across companies. &lt;/p&gt;

&lt;p&gt;Incentives changed at different scales.&lt;/p&gt;

&lt;p&gt;Another example is facebook, there is another public good problem here, the information that you share on facebook has many of the characteristics of a public good. The way that a successful social network grows is very similar to the way that a trade union grows. You see the same pattern in successful open science projects, the &lt;a href=&quot;http://arxiv.org/&quot;&gt;ArXiV&lt;/a&gt; displays the same characteristics. The ArXiV started in two very small fields, and slowly expanded into other fields. &lt;/p&gt;

&lt;p&gt;Narrowness is a feature and not a bug when you are getting started.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Elinor_Ostrom&quot;&gt;Elinor Ostrom&lt;/a&gt; (nobel prize) in her work &lt;a href=&quot;http://www.amazon.co.uk/Governing-Commons-Evolution-Institutions-Collective/dp/0521405998&quot;&gt;Governing the Commons&lt;/a&gt; really extended Olson’s work. She is interested in looking at how you manage the commons. She noticed that in most cases the &lt;a href=&quot;http://en.wikipedia.org/wiki/Tragedy_of_the_commons&quot;&gt;Tragedy of the Commons&lt;/a&gt; tends not to happen, but rather communities tend to self-govern. She asked what principles were at work in these cases? &lt;/p&gt;

&lt;p&gt;She has a list of rules that seem to emerge. Nielson highlights three of these, and provides an example from farmland and water usage outside in small farms in the vicinity of Valencia where one expects that water usage could be a significant problem.&lt;/p&gt;

&lt;p&gt;They have been developing a system that deals with this commons for about 1000 years, from the middle of the 15th century. It is organised into 7 syndics each one originally related to a canal or water resource. Each of these has an elected head who is responsible for monitoring problems. These people meet every Tuesday and chat, and talk about problems that have arisen. These problems are resolved by vote, and where appropriate sanctions are applied. &lt;/p&gt;

&lt;p&gt;There is an example that is similar in the ArXiV. There is a page telling people explicitly how you should cite ArXiV documents. (every open science project needs a page like this). This is a prerequisite for monitoring and sanctions.&lt;/p&gt;

&lt;p&gt;Nielson gives a good example on how ArXiV citations are treated in physics, and he mentions that there are different expectations in different fields about how to use these citations, some fields strongly expect them, some are indifferent, some journals tend to be hostile.&lt;/p&gt;

&lt;p&gt;In summary open science is a collective action problem. A lot is known on how to solve these problems in other contexts, e.g. initially focus on small groups, have a collective agreement in place, have sanctions in place for breaking these collective agreements. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Talkfest, science and community</title>
   <link href="http://partiallyattended.com/2011/09/01/solo11-talkfest"/>
   <updated>2011-09-01T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/09/01/solo11-talkfest</id>
   <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;So this is a short &lt;a href=&quot;http://www.biochemistry.org/PublicAffairs/Events/TalkfestSeptember2011.aspx&quot;&gt;TalkFest&lt;/a&gt; event looking at the public, communities and online science. I’m sure there will be plenty of online discussion around this topic, below are some &lt;em&gt;very&lt;/em&gt; rough notes that I took during the event. It was very enjoyable.&lt;/p&gt;

&lt;p&gt;The people on the panel are D. Amy Sanders from the Welcome Trust, &lt;a href=&quot;http://orbitingfrog.com/&quot;&gt;Rob Simpson&lt;/a&gt;, (a.k.a &lt;a href=&quot;http://orbitingfrog.com/&quot;&gt;OrbitingFrog&lt;/a&gt;), &lt;a href=&quot;http://www3.imperial.ac.uk/people/linda.davies&quot;&gt;Linda Davies&lt;/a&gt; and &lt;a href=&quot;http://www3.imperial.ac.uk/people/s.curry&quot;&gt;Stephen Cury&lt;/a&gt;. 
The panel was convened by &lt;a href=&quot;http://doctoralicebell.blogspot.com/&quot;&gt;Alice Bell&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The audience is filled with the usual suspects.&lt;/p&gt;

&lt;h1 id=&quot;are-community-groups-based-around-hobbies-a-good-way-to-reach-new-audiences&quot;&gt;Are community groups based around hobbies a good way to reach new audiences?&lt;/h1&gt;

&lt;p&gt;Amy is giving a little bit of information about some projects that connected scientists with some offline 
community groups. One of the main benefits of getting involved with a hobby group is that this group is usually engaged in a social activity, and so you can engage them during their time when they are open to engagement. That’s the main takeaway. It doesn’t have to be online, being face to face and being really social can be a good thing.&lt;/p&gt;

&lt;h1 id=&quot;galaxy-zoogz&quot;&gt;&lt;a href=&quot;http://www.galaxyzoo.org/&quot;&gt;Galaxy Zoo&lt;/a&gt;&lt;/h1&gt;

&lt;p&gt;I almost don’t have anything to say about galaxy zoo other than that it is awesome. I’m sure that most of the people here know about Galaxy Zoo. The main theme off all of the projects that have been spawned from this is to help the public help researchers. Many of the new projects are no longer astronomy projects, they cover the moon (moonzoo.org), old weather (oldweather.org), star formation in the milky way (looking within our own galaxy rather than at other galaxies, so it should fell that much closer to home (they also look at other bits in the images and they have so far found about 40 previously unknown galaxies), looking at light curves to find exoplanets (planethunters.org), papyri getting reassembled (ancientlives.org), (if you had an app that helped users to describe the nature of community science projects would that be galazyzoo-zoo, or one that helped identify the locations of zoos: zoozoo.org?).&lt;/p&gt;

&lt;h1 id=&quot;linda-talking-about-the-opal-project-i-dont-know-anything-about-this&quot;&gt;Linda talking about the OPAL project (I don’t know anything about this)&lt;/h1&gt;

&lt;p&gt;OPAL is a community-driven research program, Linda had a hobby looking at lichens. There is an exploded pie chart, I personally am a fan of exploded pie charts. One of the big aims of the project is to get members of the public out into nature and get them naming things. This gives you an educated population and greatly increases your base for observers. They are using a host of methods to train people, new tech, a lot of work with schools. There is a lot of time spent connecting local authorities, people and scientists. They have had over 1/2 million people participating, and they have had millions of recordings. There are scientific teams across the country, those teams can lead off different research projects, these projects could be driven by the research group interest or by the community environment, e.g. one project has been looking for hedgehogs. This is very cool. They have created 40 hedgehog champions in hull who go out tagging hedgehogs (I guess she means virtually tagging them, and not spraying them with graffiti, thought that might be an interesting outcome of the project)&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.opalexplorenature.org/&quot;&gt;OPAL&lt;/a&gt; stands for Open Air Laboratories.&lt;/p&gt;

&lt;p&gt;This is a very very cool project, and it is coordinating resources from across the UK, it’s just brilliant. &lt;/p&gt;

&lt;h1 id=&quot;stephen-curry---blogger&quot;&gt;Stephen Curry - blogger!&lt;/h1&gt;

&lt;p&gt;Is Stephen a hobbiest blogger or not? Alice asks the question. He hates the word “hobby”, the things that people do in their spare time for fairly mild amusement? What scientists have time to do this in their spare time? An yet at the same time his hobby is blogging about science. One way to think about blogging is that it is writing in public for free, not quite as bad as masturbating in public, but sometimes it comes close (he admits that this is rather a caricature). He mentions that it is something that he does in his spare time, but something he feels compelled to do and that he enjoys doing. It sounds like William Rowan Hamilton’s justification for his poetry. It’s important to note that he does not yet feel at liberty to do this during his professional time, but that the environment is getting better. It is a good way of generating a discussion, and some of these discussion topics are of interest to his colleagues as well as to the community that he interacts with through the blog community. &lt;/p&gt;

&lt;h1 id=&quot;qa&quot;&gt;QA&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Moderation and quality of the data collected.
Interesting, there was a recent project that involved some community participation but in the end the quality of the data for the money spent could have been replicated by on RA. Rob mentions that they try to design experiments to be robust. For Linda the OPAL project is not just about gathering data, but also about getting people to get out into nature. Within OPAL they also try to design the experiments in a robust way, e.g. get people to report number of earth worms found, rather than reporting on species type. (Rob mentioned that galaxy zoo currently has 150 equivalent full time people involved as volunteers).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stephen Curry mentions that by engaging a lot of people you have more public impact.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What access do the public have to the databases?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For OPAL all of the project data post clean up, goes onto the national database. The live data is also immediately available (free data, yay!!).
Galaxy Zoo now has data.galaxyzoo.org where all of the data is available. &lt;/p&gt;

&lt;p&gt;Alice asks if published papers are tied back to the data, and generally the answer is yes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What are the kinds of people who participate?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;OPAL asks some personal questions, they target areas of deprivation (this is just getting cooler and cooler). They have two social scientists who are working on the project who will start publishing on this data.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;question for Amy - do you choose the hobby or the people first?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The examples she talked about today was focussed on the people first, and used the hobbies as a way of reaching specific communities, e.g. wanted to engage with elderly people, ended up working with a crafts group.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;did media coverage lead to identifiable bumps in increased participation?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the OPAL project, simply yes.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Question for Stephen (from Cameron), do we have an ethical framework that can help us answer the question for what should be farmed out and what is the role of the professional researcher.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Stephen has no problem with that. His contract says something like 37.5 hours per week, but this is laughable, and anyone who works in a university knows that this is a legal fiction. &lt;/p&gt;

&lt;p&gt;Hmm, no answer to that question. &lt;/p&gt;

&lt;p&gt;Robb has an interesting answer, but I’m too tired to do his answer justice as it overlaps too much with some ideas that I’ve had about this topic. &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;what does the panel feel about the protein folding project? surely participation is it’s own reward?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ah, the discussion is all kick off now, about people doing things for free, people who are doing &lt;/p&gt;

&lt;p&gt;An example of where this has gone wrong, an arts graduate in Ireland asked knitters to create A4 pieces of knitting, but knitters said no. &lt;/p&gt;

&lt;p&gt;(I mention the incentives thing again).&lt;/p&gt;

&lt;p&gt;FarmVille does not educate anyone about agriculture&lt;/p&gt;

&lt;p&gt;The 1 millionth lichen record was listed by an amateur, ecology and astronomy have a long history of amateur participation. &lt;/p&gt;

&lt;p&gt;The term democratic is emerging in the discussion. &lt;/p&gt;

&lt;p&gt;Actual amateur scientists have not been mentioned in this discussion yet, like the bio-hackers. Rupert Sheldrake is being mentioned (someone I also don’t know). &lt;/p&gt;

&lt;p&gt;Someone mentions the polymath project. (I don’t think that the polymath example is representative, but I think the reason that I don’t think it is representative is because of an opinion that I’ve read somewhere and not because I’ve thought about it too much).&lt;/p&gt;

&lt;p&gt;Is there scope to allow the amateur’s to level up with the main scientists?&lt;/p&gt;

&lt;p&gt;When a new zooniverse app launches, does that lead to a drop of the other sites, Rob says that on the day of launch the other sites drop by bout 10%, but then gradually grow back to their orginial levels, there is very little canabalisation. &lt;/p&gt;

&lt;p&gt;Someone mentions the question of what is science for, doing science in your garage may not help the world, as it may not get out of your garage. &lt;/p&gt;

&lt;p&gt;Jack Stilgo .. oh, hey, we are finished now, and off to the pub!!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>ArXiV at 20, a brief review.</title>
   <link href="http://partiallyattended.com/2011/08/30/arxiv-20-years-on-review"/>
   <updated>2011-08-30T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/08/30/arxiv-20-years-on-review</id>
   <content type="html">&lt;p&gt;I just read the brief article by &lt;a href=&quot;http://en.wikipedia.org/wiki/Paul_Ginsparg&quot;&gt;Paul Ginsparg&lt;/a&gt; about &lt;a href=&quot;http://www.nature.com/nature/journal/v476/n7359/full/476145a.html&quot;&gt;20 years of the ArXiV&lt;/a&gt;. I think the article is a must read 
for anyone who is thinking about scientific communication. It’s short, and very readable.&lt;/p&gt;

&lt;p&gt;The things that stand out for me from this article are the following:&lt;/p&gt;

&lt;h1 id=&quot;there-are-real-costs-associated-with-running-services-on-the-web&quot;&gt;There are real costs associated with running services on the web.&lt;/h1&gt;

&lt;p&gt;Ginsparg originally imagined that the service that he created could run automatically and that he would be able to get back to his research projects very quickly. The enterprise ended up being a full time job for 20 years. The overhead implicit in doing peer review, or even minimal quality filtering had prevented the addition of features into the site. This is not much to the disadvantage of the ArXiV, as Ginsparg points out it is perfectly OK for such services to live outside of the ArXiV, but yet be tightly coupled to it.&lt;/p&gt;

&lt;h1 id=&quot;what-we-can-do-on-the-web-has-been-well-imagined-for-a-long-time-we-just-dont-seem-to-be-doing-it&quot;&gt;What we can do on the web has been well imagined for a long time, we just don’t seem to be doing it.&lt;/h1&gt;

&lt;p&gt;The ArXiV is still running some of the original software. The core of the services has not changed radically over the past 20 years, but still, some of the original ideas that Ginsparg had all that time ago have not been widely adopted on the web of scientific communication yet. These ideas are easy to state - interactive data graphs, automated filtering and peer review, semantic markup, the end of the journal, web structured documents that go beyond print originated formats. Perhaps this revolution in scientific communication, in spite of the advance of web frameworks, is a long cycle revolution.&lt;/p&gt;

&lt;h1 id=&quot;in-spite-of-researcher-anxiety-these-tools-bring-real-value&quot;&gt;In spite of researcher anxiety, these tools bring real value.&lt;/h1&gt;

&lt;p&gt;Fields which slowly and cautiously adopted the preprint system have never looked back, and have prospered because of it. His point about fields where a researcher can get gazumped after announcing a result at a conference but getting tied up in the peer review system to lose out to a rival who publishes faster based on the conference result screams of a disfunction in some areas of science. It might not be a revolution that we are engaged in so much as a gently, but persistent, annealing of the system. Bring it on say I.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Serendipity, a chance encounter (obviously)</title>
   <link href="http://partiallyattended.com/2011/08/08/serendipity-sames"/>
   <updated>2011-08-08T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/08/08/serendipity-sames</id>
   <content type="html">&lt;p&gt;Tonight there was a lovely &lt;a href=&quot;http://sameas.us/&quot;&gt;sameas&lt;/a&gt; event on the topic of serendipity. I’d stared a blog post about this back in May as a response to to a post that &lt;a href=&quot;http://occamstypewriter.org/blog/author/fnorman/&quot;&gt;Frank Norman&lt;/a&gt; wrote about &lt;a href=&quot;http://occamstypewriter.org/trading-knowledge/2011/05/17/the-challenge-of-going-beyond/&quot;&gt;enablining serendipidous discovery in the digital library&lt;/a&gt;. Well, that post kind of lingered, malingered in my drafts directory, so I thought I’d best get on get something out there, spurred on by the event tonight.&lt;/p&gt;

&lt;p&gt;I studied in Edinburgh for a few years, it’s a beautiful city, and in the heart of the old town Victoria Street sweeps 
in a steep curve down to the cowgate. &lt;/p&gt;

&lt;p&gt;On the corner there used to be a curiosity shop and I remember so well it’s opening times, painted in a cursive script on the side of the building “Open by Serendipidy”. It logdged strongly in my imagination, I can remember the first time I passed by when the shop was open. Inside I discovered an emporium filled with victorian glass eyes, 1940 photographic equipment salviged from fighter aircraft, a thousand pieces of bric a brac, each with it’s own personal history, a little hidden from us now. &lt;/p&gt;

&lt;p&gt;I never had the chance to find that gem in that shop that triggered some hidden or half forgotten connection, but the place was filled with that magic of possability. You couldn’t help but feel all of those stories waiting to be rediscovered. &lt;/p&gt;

&lt;p&gt;Serendipitous discovery has at it’s heart has a little of that magic. It tickles some part of our brain, it feels like a little revelation, a personal discovery, a moment where previously unaligned things in the world sit now in a new relationship to each other.&lt;/p&gt;

&lt;p&gt;I’m not a researcher, but I was very fortunate to spend some days with some very smart people thinking about this topic. We looked at how one could &lt;a href=&quot;http://eprints.ecs.soton.ac.uk/17000/&quot;&gt;use social media to introduce serendipidous connections between peoplae&lt;/a&gt;, but the findings are quite general. What’s might be neat is that there is a formula for serendipidy, and you can measure it in WoW’s! &lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://ilab.usc.edu/surprise/&quot;&gt;The formula&lt;/a&gt; came out of research into machine vision, and it uses a nice applicaiton of Bayes’ Theorm to take into account how we re-adjust to the new and how a change in a stimulus fades as it becomes familliar. The original paper looked images, and tried to determine what chagne in an image would be considered most surprising by an observer. I thought that the same mechanisim should surely be applicable to netowrks. If you could weight the informaiton content of a network by appying some measrue to the connections, then this formulat might be able to tell you which rewiring of the network for a given node would be the most surprising connection for that node. &lt;/p&gt;

&lt;p&gt;Our social netowrks are not composed of simple connections. We have many different connections of many different types. I wondered whether one could mine into the hidden or partially obsured ties between people and bring out the make clear to them the surprising kinds of connections. For example, at a conference about a particular topic, there is no surprise that all of the people there are interested in that topic, but where some of those people are connected by some link that has nothing to do with the topic at hand, you might be able to bring out a surprising connection, you might be able to enable a seridipitous moment. This would not be discovery, not saying to someone somethng they might reasonably know, but rather uncovering a hidden, perhaps even an uncanny link between people, perhaps even a link they may prefer to remain hidden or uncovered?&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://sameas.us/events/serendipity&quot;&gt;discussion tonight&lt;/a&gt; was really fun. I had thought about this topic a lot over the past few years, but only thorugh the lens that I’ve laid out in this post. The talk tonight made me think a little afresh about this. Unsurprisingly, of course, it’s complicated. That beautiful equation is only a model. These netoworks that we build online again only models. The mathematical structures are loose nets, shaow representations of social realities, capturing only whisps of the structures they aim to represent. &lt;/p&gt;

&lt;p&gt;We like to be surpried (when the surprises are pleasant ones). We like to tell stories, to find the narratives of ours and others lives. Serendipity has a powerfull hold over our imaginations, and I think perhaps because it is the making of a very good story. That connection that instantly brings us closer to another person. And yet what are we doing when we talk to people, other than probing, looking in a very directed way (though perhaps unconcsiouly) though the shape of what they tell us for a connection, a moment where we can go “ah-ha”. We pass over the mundane and find our way quickly to the delightful, the conneciton, the turn in the story, the revelation. &lt;/p&gt;

&lt;p&gt;My thinking about all of this started with a desire to find ways to &lt;a href=&quot;http://www.slideshare.net/IanMulvany/integrating-everyting-presentation&quot;&gt;use technology to make people happy&lt;/a&gt;. I’m sure that is still a goal we can aspire to, perhaps by progromatically intorducing a little more chaos into our lives. I’ll have to leave now, these threads to others to follow up. Perhaps I’ll be surprised by what I find out here in a few years.  &lt;/p&gt;

&lt;p&gt;I think that the web is in good hands. &lt;a href=&quot;http://isiosf.isi.it/~cattuto/&quot;&gt;Ciro Cattuto&lt;/a&gt;, and researchers like him, are doing amzing work looking at how people are connected in meatspace, on the web. &lt;a href=&quot;http://lanyrd.com/&quot;&gt;Lanyrd&lt;/a&gt; arrived like that, out of nowhere, out of a honeymoon. These people are building some very powerfull ways of brining people together. They are doing it with a dash of delight. I hope that over the next few years there will be many many places on the web that will be a little like that shop I still remember so fondly from my days in Edinburgh.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Robert Bunsen's Birthday</title>
   <link href="http://partiallyattended.com/2011/03/31/bunsen"/>
   <updated>2011-03-31T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/03/31/bunsen</id>
   <content type="html">&lt;p&gt;Google’s homepage cartoon today tells me that it’s &lt;a href=&quot;http://en.wikipedia.org/wiki/Robert_Bunsen&quot;&gt;Robert Bunsen’s&lt;/a&gt; birthday. He is famous for the invention of the burner named after him, but his contribution to our
understanding of the universe around us runs much much deeper than that. He co-created the science of spectroscopy with Gustav Kirchhoff. This is something I learned about
when I was living for a while in Heidelberg, one of the university building’s along the Hauptstrasse is named after Bunsen.&lt;/p&gt;

&lt;p&gt;The invention of spectroscopy was a huge step in unlocking the structure of the universe at the largest and smallest scales. It led to the experiments that laid the foundation
of atomic theory. It enabled us to see what the stars are made from. Before spectroscopy we could see the stars, but in a way, after it we were able to taste them, to understand 
their properties and compositions.&lt;/p&gt;

&lt;p&gt;The philosopher Aguste Compte wrote in 1835 that:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;On the subject of stars, all investigations which are not ultimately reducible to simple visual observations are…necessarily denied to us… We shall never be able by any means to study their chemical composition.&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;It was spectroscopy that blew away that limit. Spectroscopy is the science that is used to determine the red-shift of galaxies, and so it is also used to measure the extent of the wider universe. It turned light from a pure substance to a code of substances. &lt;/p&gt;

&lt;p&gt;I often wonder now about the limits of knowledge, about whether we can ever understand experience in an analytic way, whether the Hubble horizon of the visible universe shields from us strangeness that we can never know about, whether as we look at the universe on smaller and smaller scales information truly becomes the only thing of matter, whether the complexity expressed in every simple act in the changing of the seasons is a complexity too much for us to bear.&lt;/p&gt;

&lt;p&gt;I’m often tempted to side with the view of there being ultimate unknowables. And then I think a little about spectroscopy, and how such a simple change in our point of view changed so much of what we could view and understand, and I hold back a little more. &lt;/p&gt;

&lt;p&gt;Happy birthday Robert Bunsen!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Sits meeting notes, November 2010.</title>
   <link href="http://partiallyattended.com/2011/03/30/sits-notes"/>
   <updated>2011-03-30T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/03/30/sits-notes</id>
   <content type="html">&lt;p&gt;2010-11-04 sits&lt;/p&gt;

&lt;p&gt;Right, the meeting is starting, it’s an open meeting, so we don’t have
a specific agenda, but as the day goes on topics for discussion will
emerge, and these will be time-boxed for discussion.&lt;/p&gt;

&lt;p&gt;As the participation list is available on the &lt;a href=&quot;http://sits-dlf.eventbrite.com/&quot;&gt;eventbrite&lt;/a&gt; site,
I’m not going to capture that here.&lt;/p&gt;

&lt;h1 id=&quot;some-topics-from-the-last-meeting&quot;&gt;Some topics from the last meeting&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;signatures on digital objects&lt;/li&gt;
  &lt;li&gt;correct identifiers on digital objects&lt;/li&gt;
  &lt;li&gt;author identifiers&lt;/li&gt;
  &lt;li&gt;lightweight languages&lt;/li&gt;
  &lt;li&gt;toolsets&lt;/li&gt;
  &lt;li&gt;sword, sword2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;&lt;/p&gt;

&lt;h1 id=&quot;some-potential-topics-for-this-meeting&quot;&gt;Some potential topics for this meeting&lt;/h1&gt;
&lt;ul&gt;
  &lt;li&gt;authentication and access control&lt;/li&gt;
  &lt;li&gt;rdf and linked data within institutions and repositories&lt;/li&gt;
  &lt;li&gt;data curation&lt;/li&gt;
  &lt;li&gt;reasonable workflow components, best practices&lt;/li&gt;
  &lt;li&gt;lightweight tool sharing&lt;/li&gt;
  &lt;li&gt;web archiving&lt;/li&gt;
  &lt;li&gt;sustainable storage&lt;/li&gt;
  &lt;li&gt;tool sharing&lt;/li&gt;
  &lt;li&gt;data curation, big data, and what the concept of curation means for
repositories&lt;br /&gt;
&amp;lt;/br&amp;gt;
# Actual topics discussed&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#auth&quot;&gt;Authentication&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#link&quot;&gt;Linked data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#arch&quot;&gt;Web Archiving&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#id&quot;&gt;Identifiers for people&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#ms&quot;&gt;Microservices&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#seo&quot;&gt;SEO and search engine optimisation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#light&quot;&gt;Lightweight Languages&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;&lt;/p&gt;

&lt;h1 id=&quot;topic-discussions&quot;&gt;topic discussions&lt;/h1&gt;

&lt;h2 id=&quot;auth&quot;&gt;Authentication&lt;/h2&gt;

&lt;p&gt;The first option that is discussed is shibboleth. Generally authentication breaks down according on one of the following mechanisms:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;shib&lt;/li&gt;
  &lt;li&gt;non-shib&lt;/li&gt;
  &lt;li&gt;ip based&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;One of the questions is how does service host have trust in 3rd party
services, and understand whether that other provider is doing a good
job?&lt;/p&gt;

&lt;p&gt;A problem with ldap is that groups within ldap could go out of date.&lt;/p&gt;

&lt;p&gt;:question: has shibboleth provided support for services yet?
:answer: it’s an interesting question&lt;/p&gt;

&lt;p&gt;Are there approaches on service to service authentication that have worked
3 concrete examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;j2k service, it retrieves content over http&lt;/li&gt;
  &lt;li&gt;integrating with JOVE, pass in to it a url source, and if that content
is protected it will be the same issue&lt;/li&gt;
  &lt;li&gt;fedora&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So there are social, and technological problems&lt;/p&gt;

&lt;p&gt;How does one manage individual level access on a lightweight basis,
for instance, allowing people to pass something off to an iPhone. How
do you enable content owners to set the access permissions of their
own data.&lt;/p&gt;

&lt;p&gt;If you deliver all of your content with Drupal, you can just hook into
drupal’s authentication systems, and this makes it look to the end
user that they are just managing a part of their site.&lt;/p&gt;

&lt;p&gt;So there are a couple of things going on here:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;institute to institute&lt;/li&gt;
  &lt;li&gt;institute to end users around content held by the institute&lt;/li&gt;
  &lt;li&gt;data owner within institute to 3rd party applications for that user,
e.g. iPhone apps&lt;/li&gt;
  &lt;li&gt;data owner within institute setting permissions around their own data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An interesting use case is how you allow anonymous local users on a
campus wide system to access content.
Shib2 has a way of allowing an ip address to skip the authentication
step, it’s a pretty static list.
This use case was designed for kiosk machines&lt;/p&gt;

&lt;p&gt;There are &lt;a href=&quot;http://www.oclc.org/ezproxy/&quot;&gt;ezproxy&lt;/a&gt; campuses and non-ezproxy campuses. This use case is
slightly different from the normal experience of a web user because
when they go to a 3rd party service we need to figure out a way that
would enable them to assert the university rights at that end point.&lt;/p&gt;

&lt;h3 id=&quot;takeaways-from-this-talking-point&quot;&gt;takeaways from this talking point:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;think about pushing the authentication down into the stack, so that
the front layer can be plugged into a number of different areas? (I
didn’t capture that point well)&lt;/li&gt;
  &lt;li&gt;articulate how openauth does or does not work within institutions
(what does &lt;a href=&quot;http://en.wikipedia.org/wiki/Security_Assertion_Markup_Language&quot;&gt;saml&lt;/a&gt; give you that &lt;a href=&quot;http://oauth.net/&quot;&gt;oauth&lt;/a&gt; does not give you?)&lt;/li&gt;
  &lt;li&gt;are there any examples of universities that are using &lt;a href=&quot;http://openid.net/&quot;&gt;openid&lt;/a&gt;?&lt;/li&gt;
  &lt;li&gt;think about creating a microservices driven layer for
multi-authentication systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;&lt;/p&gt;

&lt;h2 id=&quot;link&quot;&gt;Linked data&lt;/h2&gt;

&lt;p&gt;What is happening and what is not happening, what could easily happen,
and why is it not happening?&lt;/p&gt;

&lt;p&gt;In &lt;a href=&quot;http://projectblacklight.org/&quot;&gt;blacklight&lt;/a&gt; search repositories there is a lot of content
aggregating there, and these could be exposed as &lt;a href=&quot;http://www.w3.org/RDF/&quot;&gt;rdf&lt;/a&gt;. I ask what is
the advantage or disadvantage of rdf over &lt;a href=&quot;http://www.opensearch.org/Home&quot;&gt;opensearch&lt;/a&gt;. This is answered
quite nicely, linked data is about known content, and opensearch is
about finding content when you don’t know exactly where it might be.
Think of linked data a bit like rss.&lt;/p&gt;

&lt;p&gt;Another question, is there other content that we should be thinking
about pushing out too, is there local content, what would that look
like, and how would that help in the open world?&lt;/p&gt;

&lt;p&gt;Is there a spec for exposing triples as linked data. There are
hundreds of specs, and many different ontologies. The best thing to do
might be to wait and see what the big players are doing. A good
example is Google’s recent adoption of &lt;a href=&quot;http://www.heppnetz.de/projects/goodrelations/&quot;&gt;GoodRelations&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One thing that really bit Southampton is to think about how it is
going to be consumed, and ideally consume it yourself.  A good analogy
is to create a user interface, and never use that user interface
yourself.  It’s the only way where one will find the minor but really
annoying errors.&lt;/p&gt;

&lt;p&gt;Something to look for are javascript tools and restful apis for
playing with the semantic web. &lt;a href=&quot;http://www.jenitennison.com/blog/&quot;&gt;Jenny Tennison&lt;/a&gt; is working on some of
these tools like &lt;a href=&quot;http://code.google.com/p/rdfquery/&quot;&gt;redfquery&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Another issue is what namespace do you link to, and where is the
trust.  (I’m in sameas, yay!
&lt;a href=&quot;http://sameas.org/html?q=ian+mulvany&amp;amp;x=0&amp;amp;y=0)&quot;&gt;http://sameas.org/html?q=ian+mulvany&amp;amp;x=0&amp;amp;y=0&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;How do you decide what you want to link to?  &lt;/p&gt;

&lt;h2 id=&quot;some-ontologies-that-might-be-useful&quot;&gt;some ontologies that might be useful&lt;/h2&gt;

&lt;p&gt;The BIBO ontology seems to be a good first place to look, and here are a bunch:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://SemanticOverflow.com&quot;&gt;SemanticOverflow&lt;/a&gt; is a good ontology&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://bibliontology.com/&quot;&gt;bibontology&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.heppnetz.de/projects/goodrelations/&quot;&gt;Good Relations&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.w3.org/2001/sw/hcls/&quot;&gt;HCLE&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://sindice.com/&quot;&gt;Sindice&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://sameas.org/&quot;&gt;SameAs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.freebase.com/&quot;&gt;Freebase&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dbpedia.org/About&quot;&gt;DBPedia&lt;/a&gt;  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;action-items&quot;&gt;Action Items&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;have noted that we need to identify promising formats and vocabularies&lt;/li&gt;
  &lt;li&gt;a low hanging fruit is to have a community effort to identify, even
at the predicate level, what terms to use (there is a lot of
discussion going on in the UK between various groups, but there is no
formal …&lt;/li&gt;
  &lt;li&gt;we will set up a freebase page for collecting ideas around this&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;&lt;/p&gt;

&lt;h2 id=&quot;arch&quot;&gt;Web Archiving&lt;/h2&gt;

&lt;p&gt;From the &lt;a href=&quot;http://www.mementoweb.org/news/&quot;&gt;maemento&lt;/a&gt; perspective, an archive is no different from the
rest of the web, it just has content from the rest of the web.  That
includes CMS’s, these are just archives systems, as they have the
content from the past sitting in their databases.&lt;/p&gt;

&lt;h2 id=&quot;issues&quot;&gt;Issues:&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;versioning requirements&lt;/li&gt;
  &lt;li&gt;accessibility&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a starting point it would be interesting to see what the Duraspace
people are thinking.&lt;/p&gt;

&lt;p&gt;It seems like making a repository a time gate for itself is a great
idea.  Dspace, however, does not do versioning. As a part of the
re-architecting there is a hope to get versioning into Dspace via the
fedora component, but it is a little way off.&lt;/p&gt;

&lt;p&gt;Hydra would be dependant on the fedora component, but it is not
implemented at a high level yet.&lt;/p&gt;

&lt;p&gt;What % of revisions in repository systems at the moment are ones that
could be exposed, compared to ones that are just typos?&lt;/p&gt;

&lt;p&gt;This is a decision that one has to make in general, there may be legal
restrictions, for instance. But if you do expose them, then doing so
in a way that is browsable is probably a good idea.&lt;/p&gt;

&lt;p&gt;An interesting question, if something like google becomes maemento
aware then it’s likely that this will take care of this issue.&lt;/p&gt;

&lt;p&gt;There seems a lot of years between now, and when google is going to
provide time aware content.&lt;/p&gt;

&lt;p&gt;There is a difference between doing a historic search, and currently
available history.&lt;/p&gt;

&lt;p&gt;An interesting thing might be to be able to get a list of recent uris
from an archive, and find a way to preserve the content at those uris.&lt;/p&gt;

&lt;p&gt;There is a “wayn” protocol for handing over web archives from one
place to another.&lt;/p&gt;

&lt;p&gt;A question comes up for how do you archive rapidly moving web sites.
There is no good approach for this yet. Transactional archiving is an
approach that might be investigated.&lt;/p&gt;

&lt;h2 id=&quot;action-items-1&quot;&gt;Action Items&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;if you want to be well behaved, it can be hard to archive social
media sites (one could look at consuming feeds)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;
# Lunch&lt;/p&gt;

&lt;p&gt;Now we have a discussion about what we will talk about in the evening session.  &lt;/p&gt;

&lt;h2 id=&quot;id&quot;&gt;Identifiers for people&lt;/h2&gt;

&lt;p&gt;In terms of author identifiers, Southampton have gone for a local
approach, and are creating linked data identifiers. Where two people
are the same, use sameas to link them. They do make them available.&lt;/p&gt;

&lt;p&gt;The ORCID project is going to go and push ORCIDs onto people that
publishers know about. This won’t happen immediately, but will get
better as time goes on. Disambiguating authors is costly, so there is
a large advantage from doing this as early in the publication process as you can.&lt;/p&gt;

&lt;p&gt;ORCID will also act as a registry, so one can lookup things like a
REPEC and other identifiers that an author might have.&lt;/p&gt;

&lt;p&gt;The big question is whether ORCID should just be an identifier, or
whether it should contain information like bibliographies. The issue
is if it is an identifier service only, how will it get paid for.&lt;/p&gt;

&lt;p&gt;Right now thee is a testbed, the code from Thompson has been
submitted, does not cover every use case yet.&lt;/p&gt;

&lt;p&gt;There is a hope that this will be available in 2011 at some level.
There is a big stakeholders group meeting in London on November 18th.&lt;/p&gt;

&lt;p&gt;There will be APIs for deposit and search, as well as a web protocol&lt;/p&gt;

&lt;p&gt;Independent researchers will be able to register themselves.&lt;/p&gt;

&lt;p&gt;There will be provenance for who made different assertions, whether,
for example, a publisher or an institution the independent researcher.&lt;/p&gt;

&lt;p&gt;Some questions: has there been any discussion around assuming that
this needs to be a central vs distributed blob of information?&lt;/p&gt;

&lt;p&gt;isni is another initiative, it’s an iso standard. A number of music.
isni’s require that you have published something that people consider
to be authoritative. The names project seems to be working with the
isni project.&lt;/p&gt;

&lt;p&gt;There is work ongoing to test ORCIDs against Dspace.&lt;/p&gt;

&lt;h3 id=&quot;resources&quot;&gt;Resources&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.orcid.org/&quot;&gt;ORICD&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://readermeter.org&quot;&gt;ReaderMeter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://namesproject.wordpress.com/&quot;&gt;NAMES&lt;/a&gt;  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.isni.org/&quot;&gt;ISNI&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;lt;/br&amp;gt;
 &amp;lt;h2 id=&quot;ms&quot;&amp;gt;Microservices&amp;lt;/h2&amp;gt;&lt;/p&gt;

&lt;p&gt;What do we mean by micro-services? It’s becoming a buzz word because
it is identifying an emerging pattern.&lt;/p&gt;

&lt;p&gt;There seems to be some confusion over microservices as just being the
CDL implementation in contrast to a general architectural approach.&lt;/p&gt;

&lt;p&gt;I’m going to skip out and talk to my wife now ;)
OK, I’m back from the conversation with my wife.&lt;/p&gt;

&lt;h2 id=&quot;resources-1&quot;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cdlib.org/services/uc3/curation/&quot;&gt;CDLIB&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We are now onto the final session.&lt;/p&gt;

&lt;h2 id=&quot;seo&quot;&gt;SEO and search engine optimisation&lt;/h2&gt;

&lt;p&gt;Dspace is working with google scholar, and Anurag at google.
Essentially there are a list of tags that google scholar wants, and if
you fill those out then google scholar will give you more coverage.&lt;/p&gt;

&lt;p&gt;Scholar has a citation meta-tag schema, and so the exercise is to map
dublin core to that schema. Many of the local repositories (what they
really want are the pdfs, and have metadata around those pdfs).  What
google scholar want is totally different from what Google news wants,
and what the main google search engine wants.&lt;/p&gt;

&lt;p&gt;They already had google site maps, but google scholar don’t use those.&lt;/p&gt;

&lt;p&gt;You ask scholar to crawl your site. You email Anurag.&lt;/p&gt;

&lt;p&gt;An interesting question is how much traffic comes in from google,
there is data that about 90% of the repo traffic comes in from google
scholar, and more and more of the faculty are now using google scholar
over web of science, so this is really really important.&lt;/p&gt;

&lt;p&gt;What’s interesting is that google scholar are trying to encourage
people to use the de-facto Google Scholar standard&lt;/p&gt;

&lt;p&gt;An interesting use of testing is to use cucumber and a subject
specific expert to write tests like:&lt;/p&gt;

&lt;p&gt;“when I search for blah”
“I should get back search result blah”&lt;/p&gt;

&lt;p&gt;There is an interesting conversation about how would this community
propose as a better way to organise metadata on the web, and
potentially look to propose something in RDF.&lt;/p&gt;

&lt;h2 id=&quot;resources-2&quot;&gt;Resources&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://drupal.org/node/641580&quot;&gt;Drupal&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.ghastlyfop.com/blog/2008/05/meta-analysis.html&quot;&gt;Publishing Tags&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://scholar.google.com/intl/en/scholar/publishers.html&quot;&gt;Google Scholar for Publishers&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://scholar.google.com/intl/en/scholar/inclusion.html&quot;&gt;Inclusion in Google Scholar&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;actions&quot;&gt;Actions&lt;/h2&gt;

&lt;p&gt;Perhaps take this issue to NISO, to determine whether there is space
for publishers and repositories to push back against google for
adoption of better metadata tags. An example would be to propose
possibly RDFa (perhaps under the bibo ontology)&lt;/p&gt;

&lt;h2 id=&quot;light&quot;&gt;Lightweight Languages&lt;/h2&gt;

&lt;p&gt;A discussion ensues about adopting new tools, and how to convince IT
managers to adopt new tools.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;security holes will almost always come from customisations&lt;/li&gt;
  &lt;li&gt;setting expectations, and having a regular patch cycle&lt;/li&gt;
  &lt;li&gt;ensure that there is a good shared install base with the same dependancy trees&lt;/li&gt;
  &lt;li&gt;can you turn something old off&lt;/li&gt;
  &lt;li&gt;log inbound requests for software stacks&lt;/li&gt;
  &lt;li&gt;bundle your stuff as a war file and make it pretend that it’s a java program&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We have not talked about developer retraining. Why should people learn
a new language?&lt;/p&gt;

&lt;h2 id=&quot;resources-3&quot;&gt;Resources&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.squid-cache.org/&quot;&gt;Squid-cache&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>mini-review of "Measuring the User Experience on a Large Scale"</title>
   <link href="http://partiallyattended.com/2011/03/29/measuring_ux"/>
   <updated>2011-03-29T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2011/03/29/measuring_ux</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.mendeley.com/research/measuring-user-experience-large-scale-usercentered-metrics-web-applications/&quot;&gt;Measuring the User Experience on a Large Scale:
User-Centered Metrics for Web Applications&lt;/a&gt; by Kerry Rodden, Hilary Hutchinson, and Xin Fu&lt;/p&gt;

&lt;p&gt;Rodden, Hutchinson and Fu describe &lt;a href=&quot;http://www.mendeley.com/research/measuring-user-experience-large-scale-usercentered-metrics-web-applications/&quot;&gt;a framework for measuring the user experience of web apps through mining server logs&lt;/a&gt;. Since they are based at Google one assumes that the framework that they are describing has been battle tested. &lt;/p&gt;

&lt;p&gt;They focus on metrics that measure user centric aspects of the online experience, in contrast to business centric (such as PULSE metrics: Page-views, Uptime, Latency, Seven day actives, Earnings). They maintain that the metrics they propose are better suited to products that have been launced, rather than being used in the design stage. They maintain that these metrics should be used in conjunction with other measures, such as direct user studies. &lt;/p&gt;

&lt;p&gt;They name their metrics HEART metrics: Happiness, Engagement, Adoption, Retention, and Task success. &lt;/p&gt;

&lt;p&gt;Happiness is measured through user surveys. An interesting insight is that the iGoogle team introduced a new design, and saw a drop in happiness scores with the design, but these improved over time, indicating that the initial drop was due to change aversion. They measure this score weekly through in-app surveys that can be deployed at scale, and so they have a historic record of user happiness.&lt;/p&gt;

&lt;p&gt;Engagement is some activity per volume of users, such as average number of visits or actions per user over a time frame. This is best reported on an average per user basis.&lt;/p&gt;

&lt;p&gt;Adoption and retention are rather self-evident metrics. &lt;/p&gt;

&lt;p&gt;Task success seems more problematic to track, as one needs to set up the metric around task success beforehand, and then A/B test a set of potential variable scenarios. &lt;/p&gt;

&lt;p&gt;Overall this is a nice little paper that articulates well the challenges around understanding user interaction with one’s site. The clear challenge remains deciding what one’s goals are, and then coming to an agreement about what the signals are that can be tracked that will inform you about whether your goals are being met. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Our gospels define us</title>
   <link href="http://partiallyattended.com/2011/02/27/our-gospels-define-us"/>
   <updated>2011-02-27T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2011/02/27/our-gospels-define-us</id>
   <content type="html">&lt;p&gt;I’m reading a fascinating book about the Wittgenstein family. It’s called &lt;a href=&quot;http://www.amazon.com/House-Wittgenstein-Family-War/dp/0385520603&quot;&gt;House Wittgenstein, a family a war&lt;/a&gt;. The book main focuses on Paul Wittgenstein, the left armed concert pianist, nonetheless there are many things detailed in this book that have dramatically informed my opinion on both Ludwig Wittgenstein and his philosophy. &lt;/p&gt;

&lt;p&gt;Two things I want to mention here, firstly much of Ludwig’s approach to life was influenced by Tolstoy’s work &lt;a href=&quot;http://www.amazon.com/Gospel-Brief-Texts-Contexts/dp/0803294328&quot;&gt;The Gospel in Brief&lt;/a&gt;
(The parallels between the two works are drawn out very nicely &lt;a href=&quot;http://www.the-philosopher.co.uk/witty.htm&quot;&gt;here&lt;/a&gt;), secondly Wittgenstein’s close family constantly refer to him as being a saint in their personal correspondences. &lt;/p&gt;

&lt;p&gt;When you read the &lt;a href=&quot;http://www.amazon.com/Tractatus-Logico-Philosophicus-Ludwig-Wittgenstein/dp/1440424217/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1298848312&amp;amp;sr=1-1&quot;&gt;Tractatus&lt;/a&gt; it’s hard not to notice the rather spiritual aspects of the work. I was originally introduced to the work in the context of the logical positivists and the Vienna Circle. Back then I recall that Wittgenstein himself didn’t have a great deal of time for that movement, and seeing where part of his main influence has come from this no longer surprises me.&lt;/p&gt;

&lt;p&gt;By the account in this book, Wittgenstein seemed to attract a rather cult like following at Cambridge. His family thought of him as being the rather slow and stupid sibling, and were rather embarrassed that England had taken him to heart as a great philosopher.&lt;/p&gt;

&lt;p&gt;On another note &lt;a href=&quot;http://thehistoryofrome.typepad.com/&quot;&gt;The history of Rome&lt;/a&gt; podcast presented a very interesting point of view a few episodes ago on one of the driving motivations for the spread of Christianity. This happened within the context of a roman culture where most of the population were slaves. Christianity offered salvation to all people, including slaves, and so for a time when there was great uncertainty in the world, and no other structured religion really offering anything to many people, Christianity spread rapidly. The times drove the adoption of their gospel.&lt;/p&gt;

&lt;p&gt;I think now to the last 80 years. Wittgenstein’s work is a powerful one, and the author displayed aspects of sainthood in his persona, yet his work has not gained widespread dissemination. His fame has, but not so much his work. One of the most widely spreading “Gospels” of this age is that of scientology, which seems to be a fame driven message. I believe that the gospels being chosen now are a good reflection of the times we live in.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Rat in the Snow</title>
   <link href="http://partiallyattended.com/2011/02/06/rat-in-the-snow"/>
   <updated>2011-02-06T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2011/02/06/rat-in-the-snow</id>
   <content type="html">&lt;p&gt;I’s a beautiful morning in New York, the sun is shining, and the snow blankets central park. Yeserday the rain and mist made it feel like a bit of a shit-house, but today it’s a fantastic day.&lt;/p&gt;

&lt;p&gt;I brought my climbing boots on this trip just in case I might find a few hours to squeeze in an attempt on the polish traverse on rat rock, and this morning I had my chance to get up and see what state the rock was in. Sadly the polish traverse problem had a thick covering of snow on most of the holds, and the other holds were wet. &lt;/p&gt;

&lt;p&gt;Around the corner the slightly overhanging wall on rat rock wa in the sun, and there were three desperate, but dry holds.&lt;/p&gt;

&lt;p&gt;I messed around a little on the polish traverse, even though the holds were wet, and to my delight the key rail on the crux felt much nicer than it had ever before. The shape conforms very well to the mid-sized campus rungs that I’m training on at the moment, and so my right hand on the rail felt really comfortable probably fr the first time ever. Pity that the rest of the route was totally unclimbable. &lt;/p&gt;

&lt;p&gt;I trotted around to the sunny side, and having a little bit of time to kill I pulled on my climbing shoes and strarted playing on those three desperate holds. They are pretty despreate for me, and there is an established start to a problem on that side that involves pulling on two of them and making a slap to a flat jug. I hadn’t been able to do that start that last time I was here in August of 2010, but since I didn’t have any options for trying anything else I just stood there in the sun working those two holds.&lt;/p&gt;

&lt;p&gt;I had been able to do that start when I lived in New York, back in 1999 - 2001, but only every now and again, and only when the conditiions were pretty perfect. &lt;/p&gt;

&lt;p&gt;It was georgeous, just standing there in the sun, pulling on every few minutes. After the fith try I could get some movement on them, they had gone from feel totally unusable, to actually not that bad. After about ten tries I got the move. If more of the face had been in condition I would have usually stopped trying after a handfull of moves. It was a really great lesson in focus, and in persistene. &lt;/p&gt;

&lt;p&gt;All that rock, only those three holds usable, and a little bit of a relaxed approach brough a nice little start to my day :) &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://farm9.staticflickr.com/8522/8586850299_bdb83ede18_c.jpg&quot; alt=&quot;fooling around on rat rock, central park&quot; title=&quot;rat rock, February 2011&quot; /&gt;  &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Turning the Physics ArXiV into an Open Peer Review System.</title>
   <link href="http://partiallyattended.com/2011/01/04/arxiv.org-open-peer-review-proposal"/>
   <updated>2011-01-04T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2011/01/04/arxiv.org-open-peer-review-proposal</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://math-www.uni-paderborn.de/~axel/&quot;&gt;Axel Boldt&lt;/a&gt; posted an interesting &lt;a href=&quot;http://arxiv.org/pdf/1011.6590v1&quot;&gt;short paper&lt;/a&gt; discussing how to turn the physics ArXiV into an open peer review system. It’s a short read, about three pages, but if you are familiar with the problems around peer review then you can just jump to part three of the paper which is a little under a page.&lt;/p&gt;

&lt;p&gt;The solution proposed is to create a new role of editor on the ArXiV, and allow anyone to propose their paper for review.  An open, almost endless, review process could ensue if scientists wanted to contribute time to review items. The editor has to choose who gets to review the paper, and this layer of peer review would require some maintenance. An extension to the idea might be to allow anyone to peer review a paper that was in the “reviewing pool”, and then attach reviewing profiles to the people who had done reviews. Those profiles could include information about the connections between reviewers and reviwees, and one could imagine an editor refusing the peer review stamp if those explicit connections between reviewer and reviewee were too close. With another tweak, one could imagine assigning points to the reviewers, and if one has enough review points, then you get to somehow jump the queue when you submit a paper for review.&lt;/p&gt;

&lt;p&gt;I’d say Axel’s idea is a good starting point. Many of the social gaming features that you would want to incorporate into a site that allows social reviews are understood, and if you built it right it could work. I think the success would depend on getting an initial stable or high-quality editors associated with a “journal brand”, that would attract submissions, and in addition you would want to build a fairly seemless system, but it’s not implausible to see that such a system could be built.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Cancelled :( Drinks with Chris Wiggins.</title>
   <link href="http://partiallyattended.com/2010/12/20/drinks-with-chris-wiggins"/>
   <updated>2010-12-20T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/12/20/drinks-with-chris-wiggins</id>
   <content type="html">&lt;h2&gt;&lt;font face=&quot;Impact&quot; color=&quot;Red&quot;&gt;CANCELLED&lt;/font&gt;&lt;/h2&gt;

&lt;font face=&quot;Impact&quot; color=&quot;Red&quot;&gt;Due to flight cancellations out of NY, Chris won&#39;t be making it over to this side of the pond, so sadly we will be calling the event off.&lt;/font&gt;

&lt;p&gt;London is a great city to live in if you are interested in technology. It has to be one of the best cities in the world for people working on the interface between science, tech and te web.  Tonight I’ll be going to the awesome &lt;a href=&quot;http://sameas.us/&quot;&gt;Same As Christmass Quiz&lt;/a&gt;, and tomorrow night &lt;a href=&quot;http://www.columbia.edu/~chw2/&quot;&gt;Chris Wiggins&lt;/a&gt; will be passing through from New York, and there will be a chance to meet up with him for a pint and a chat.&lt;/p&gt;

&lt;p&gt;Chris and I met a couple of years ago while I was still working at Spriner. I was visiting my old haunt at Columbia University, and I dopped in to see my old professor &lt;a href=&quot;http://www.astro.columbia.edu/~eas/&quot;&gt;Ed Spiegel&lt;/a&gt;. Ed told me about Chris, and I dropped in to say hi. Chris has done some &lt;a href=&quot;http://www.mendeley.com/profiles/chris-wiggins/&quot;&gt;brilliant work&lt;/a&gt; on networks and their application in the biological sciences. He has also helped run some of the &lt;a href=&quot;http://network.nature.com/profile/wiggins&quot;&gt;New York Nature Network&lt;/a&gt; events, and earlier this year he ran a &lt;a href=&quot;http://techcrunch.com/2010/10/10/hacknys-student-hackathon/&quot;&gt;hack day for students&lt;/a&gt; in New York.&lt;/p&gt;

&lt;p&gt;He’ll be in London for one night only, and is interested in meeting up with London based Data Geeks. If you are around and you want to pop in for a pint and a chat, we will be propping up the bar at the &lt;a href=&quot;http://www.beerintheevening.com/pubs/s/66/666/Jeremy_Bentham/Bloomsbury&quot;&gt;Jeremey Bentham&lt;/a&gt; on University Street from about 7pm onwards tomorrow night.&lt;/p&gt;

&lt;iframe width=&quot;300&quot; height=&quot;300&quot; frameborder=&quot;0&quot; scrolling=&quot;no&quot; marginheight=&quot;0&quot; marginwidth=&quot;0&quot; src=&quot;http://maps.google.com/maps?f=q&amp;amp;source=s_q&amp;amp;hl=en&amp;amp;geocode=&amp;amp;q=31,+University+St,+London,+WC1E+6JL&amp;amp;sll=51.500152,-0.126236&amp;amp;sspn=0.652277,1.779785&amp;amp;ie=UTF8&amp;amp;hq=&amp;amp;hnear=31+University+St,+Camden+Town,+Greater+London+WC1E+6,+United+Kingdom&amp;amp;ll=51.523538,-0.135612&amp;amp;spn=0.015861,0.025749&amp;amp;z=14&amp;amp;iwloc=A&amp;amp;output=embed&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;small&gt;&lt;a href=&quot;http://maps.google.com/maps?f=q&amp;amp;source=embed&amp;amp;hl=en&amp;amp;geocode=&amp;amp;q=31,+University+St,+London,+WC1E+6JL&amp;amp;sll=51.500152,-0.126236&amp;amp;sspn=0.652277,1.779785&amp;amp;ie=UTF8&amp;amp;hq=&amp;amp;hnear=31+University+St,+Camden+Town,+Greater+London+WC1E+6,+United+Kingdom&amp;amp;ll=51.523538,-0.135612&amp;amp;spn=0.015861,0.025749&amp;amp;z=14&amp;amp;iwloc=A&quot; style=&quot;color:#0000FF;text-align:left&quot;&gt;View Larger Map&lt;/a&gt;&lt;/small&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Wrangling image metadata</title>
   <link href="http://partiallyattended.com/2010/12/13/wrangling-image-metadata"/>
   <updated>2010-12-13T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/12/13/wrangling-image-metadata</id>
   <content type="html">&lt;p&gt;I’m trying to move away from iPhoto because I have lost too many pictures over the years from having multiple versions of an image lying around, from metadata being plopped all over the place. It is time to move to a more sustainable simple way of naming foldering and tagging my image archive.&lt;/p&gt;

&lt;p&gt;In the course of looking at this I have been playing around with Lightroom, and I want to ensure that I can add tags at a system level on my mac, and have them show up in Lightroom, and at the same time have Lightroom tags discoverable through spotlight searches.&lt;/p&gt;

&lt;p&gt;There are obviously many strategies.&lt;/p&gt;

&lt;p&gt;What I have discovered so far is the following:&lt;/p&gt;

&lt;p&gt;When you write metadata to a file from Lightroom, it writes that metadata into an associated xmp file.&lt;/p&gt;

&lt;p&gt;When Lightroom reads metadata from a file it will read it straight from the exif profile in the file.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.sno.phy.queensu.ca/~phil/exiftool/&quot;&gt;exiftool&lt;/a&gt; by Phil Harvey is the best commandline tool for interrogating and manipulating metadata at a low level. &lt;/p&gt;

&lt;p&gt;If I add a keywork in Picassa to a Raw file, nothing happens on disk, until I save my changes, and then Picassa creates a jpg version of the Raw file, and adds the keywords into the exif under both the “Subject” and “Keyword” tags. I guess I should just not use Picassa to edit keywords for a while. In fact from &lt;a href=&quot;http://groups.google.com/group/Picasa/web/original-photo-files&quot;&gt;this description&lt;/a&gt; you see that Picassa does some hiding of the original versions of the files and you can’t see the originals anymore. I don’t really like this. &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Video workflow with a mac using iMovie and capturing with a Lumix GF1</title>
   <link href="http://partiallyattended.com/2010/11/14/mac-gf1-video-workflow"/>
   <updated>2010-11-14T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/11/14/mac-gf1-video-workflow</id>
   <content type="html">&lt;p&gt;I’m figuring out the best way to shoot video with my Lumix GF1 on a mac using iMovie.  The GF1 offers two main options for video capture, HD JPEG, and AVCHD.  There is a great post describing the pros and cons of these two formats here [], and based on that I decided to experiment with AVCHD. After playing around a little I found a few oddities.
JPEG capture writes the files onto the device as .MOV files inside the relevant directory, along with any images that you capture.  By manually looking through the memory card from my camera I found these files in /DCIM/102_PANA, where the number before the _PANA will be specific to which set of images you are capturing. &lt;/p&gt;

&lt;p&gt;When I tried adding the .MOV files directly to iMovie by opening the camera as an attached device from within iMovie iMovie didn’t see these .MOV files. I was only able to add these files to iMovie, either manually, via image capture, or via adding these videos first to iPhoto. &lt;/p&gt;

&lt;p&gt;On the other hand, when I look at the device from iMovie, iMovie does see the videos that I captures as AVCHD, and imports them.  From the post that I read to see what the differences are between these two formats I was expecting videos that were captures as AVCHD to be much smaller that JPEG videos, but on first examination that was not the case. I shot about one minute of the same scene in both formats, and I got the following file sizes:&lt;/p&gt;

&lt;p&gt;JPEG HD capture: sample.MOV 293 MB
ACHVD capture, after import to iMovie: sample.mov 383.7 MB&lt;/p&gt;

&lt;p&gt;The ACHVD file is on the camera device in the following folder: /PRIVATE/AVCHD/BDMV/STREAM/sample.MTS and has a size of 129 MB.&lt;/p&gt;

&lt;p&gt;There is obviously some conversion going on during the iMovie import. iMovie will also not directly import the .MTS file, but needs to be looking at the camera as an attached device. &lt;/p&gt;

&lt;p&gt;I decided to try converting the .MTS file via handbrake, and import the converted file.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;original sample.MTS 129MB&lt;/li&gt;
  &lt;li&gt;handbrake converted file sample.mp4 20.6 MB&lt;/li&gt;
  &lt;li&gt;iMovie imported mp4 file sample_converted_imported.mov 368.6 MB&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So I gained a little, but not very much at all.&lt;/p&gt;

&lt;p&gt;Taking this clip and exporting it as a HD movie using iMovie I get the following file: imove_export.mov 119.1 MB, and this is actually pretty close in size to the original .MTS file stored on the camera. I can use handbrake again on this file to get an mp4 file of the size 20.9 MB.&lt;/p&gt;

&lt;p&gt;I don’t know what is going on under the hood when iMovie makes it’s internal conversion from the .MTS format to the .MOV format, so I don’t know whether going straight into iMovie from the camera, or going via a conversion with Handbrake will end up with a better quality movie at the end or not.  I’m lazy, so I’ll probably use the following workflow, suck up files using iMovie, at the same time store the .MTS files locally in case I want to clear out the iMovie archive, and work on the originals later. That seems to give me the best balance between a low friction workflow, and having manageable files. When I get some sample video out, I’ll post some of them on this blog.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>San Francisco, and science hack day discussions</title>
   <link href="http://partiallyattended.com/2010/11/02/science-hack-day-discussions"/>
   <updated>2010-11-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/11/02/science-hack-day-discussions</id>
   <content type="html">&lt;p&gt;(This was from Sunday)&lt;/p&gt;

&lt;p&gt;In an attempt to get over the jet lag, myself and Dave headed over to San Francisco yesterday, we had a good walk around, got lost twice, and then met pup with the lovely Ariel Waldman. I had to drop off some mendeley schwag for the upcoming &lt;a href=&quot;http://sf.sciencehackday.com/&quot;&gt;San Francisco science hack day&lt;/a&gt; that Ariel is organising (we are giving a little sponsorship, yay!). It’s going to take place in two weeks, and it looks lie it’s going to be an awesome event.&lt;/p&gt;

&lt;p&gt;These &lt;a href=&quot;http://sciencehackday.com/&quot;&gt;science hack days&lt;/a&gt; grew out of a panel discussion that Ariel let at the last south by southwest conference. Jeremey Keith organized the first one that took place in London.  I was at the London event, and that rocked, &lt;/p&gt;

&lt;p&gt;Some key things for hack days,  not too much sugar, keep the beer for later, near the presentations and find a good way to capture some of the context from which the hacks emerge, the description of the hacks from the London event are a good reminder if you were there, but not so great for people looking in from the outside.&lt;/p&gt;

&lt;p&gt;We got chatting, and of course that just threw up a whole bun of people that both Ariel and know, she was about to have dinner that evening with argon smith, I’d just met him two weeks ago in oxford, small small world.&lt;/p&gt;

&lt;p&gt;After that Dave and I headed around San Fran for a bit of exploring (science fiction and fantasy bookshops, climbing walls, comic sea lions, and antediluvian coin operated fortune telling machines all featured in a rather event packed evening), then back on the cal train to our hotel and a minor battle with the jet lag.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>DLF opening keynote, beyond buckets and boxes</title>
   <link href="http://partiallyattended.com/2010/11/02/dlf2010-keynote"/>
   <updated>2010-11-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/11/02/dlf2010-keynote</id>
   <content type="html">&lt;p&gt;(notes taken yesterday)&lt;/p&gt;

&lt;p&gt;The keynote is starting, the DLF has grown by 15 new member organisations, and this is one of the best attended events that they have run, the room is packed, i didn’t realise that there were so many people in the hotel, its looking like its going to be an interesting meeting.&lt;/p&gt;

&lt;p&gt;The original vision for this group is to create a national digital library, they have been talking about this since 1994 (goodness, so much that needs to be cut through to get to where we know we need to get to). &lt;/p&gt;

&lt;p&gt;An interesting point from the speaker is that making a metric based on transactional numbers may not be the best way to look at things in a networked world, collaboration is far more important now, than just an impact factor (i cant agree strongly enough with this sentiment). &lt;/p&gt;

&lt;p&gt;(Ahh, the famous &lt;a href=&quot;http://www.plosone.org/article/slideshow.action?uri=info:doi/10.1371/journal.pone.0004803&amp;amp;imageURI=info:doi/10.1371/journal.pone.0004803.g005&quot;&gt;click stream image&lt;/a&gt; is on the screen now (funny that the last time I saw this it was in a talk by &lt;a href=&quot;http://www.davidmccandless.com/&quot;&gt;David Mccandless&lt;/a&gt;, and he was giving out about these ball and stick pictures, of course in the context of this audience, they really have the background understanding to get a lot out of that image, these visualisations have been haunting me for years)&lt;/p&gt;

&lt;p&gt;So that was the introduction to the meeting, the keynote speaker is starting now, it’s been given by Charles Henry, the president of &lt;a href=&quot;http://www.clir.org&quot;&gt;CLIR&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;beyond-buckets-and-boxes&quot;&gt;Beyond buckets and boxes.&lt;/h1&gt;

&lt;p&gt;The speaker is going to look at higher education and look at the things that tend to get in the way of realising the vision.&lt;/p&gt;

&lt;h2 id=&quot;general-overview&quot;&gt;General overview&lt;/h2&gt;

&lt;p&gt;Ok, these notes are going to be very schematic. One of the problems is that there are thousands of libraries and institutions, and the higher education landscape is one of competition. This world is demarked by solitary comporting entities, the network has no place at all, so these institutions are antithetical to the nature of the networks with which academics deal&lt;/p&gt;

&lt;p&gt;Funding patterns, much of huger education has been built project by project, funded projects always have an end, and long term sustainability is hard in this landscape. Yet we know that collaborative grants are going to grow. &lt;/p&gt;

&lt;h2 id=&quot;coherence-of-design&quot;&gt;Coherence of design&lt;/h2&gt;
&lt;p&gt;An example is the digitisation of mediaeval manuscripts, there are a number of interesting projects going on, but when they started they didn’t talk to each other. The funding agencies are beginning to understand that they may have been part of the problem over the past 10years.&lt;/p&gt;

&lt;p&gt;Another problem is collaboration across disciplines. &lt;/p&gt;

&lt;p&gt;Emerging disciplines also present an issue, the Internet brings people together naturally, but it’s hard to sustain that as the people engaged are in traditional departments.&lt;/p&gt;

&lt;p&gt;A great example is the hemispheric study of the history of intoxication.&lt;/p&gt;

&lt;p&gt;Digital versions do not replicate analog models, and yet we try to make them, and this may be due to the conservative streak in higher education.&lt;/p&gt;

&lt;p&gt;Economies, the products of education are public goods, we need to rethink the way we make and save money.&lt;/p&gt;

&lt;h2 id=&quot;clr-mission&quot;&gt;clr mission&lt;/h2&gt;
&lt;p&gt;Well the challenge is there in front of us, and we need people to do this, the goal must be to rethink the traditional model of what a university and university service level is, by collaborating.  Institutions need to become wilfully dependant upon each other.&lt;/p&gt;

&lt;p&gt;Discovery, reconstitution, publishing, sharing, augmenting.&lt;/p&gt;

&lt;p&gt;The components of knowledge need to be brought into this (there is a bit of a dig at the academic publishing industry).&lt;/p&gt;

&lt;p&gt;Presses don’t want to publish unknown scholars, as they don’t sell (agggggg, makes one want to scream). The old model of publication is bankrupt (that is my phrase). &lt;/p&gt;

&lt;p&gt;Areas of focus: Coordinated and shared staff, resources, IT.&lt;/p&gt;

&lt;p&gt;There are some projects coming up now. 
West, dpla, &lt;a href=&quot;http://2cul.org/&quot;&gt;2cul&lt;/a&gt;, oapen&lt;a href=&quot;http://www.oapen.org/xtf/home?brand=oapen&quot;&gt;oaopen&lt;/a&gt;, &lt;a href=&quot;http://www.cdl.edu/cdl_home&quot;&gt;cdl&lt;/a&gt;, &lt;a href=&quot;http://www.hathitrust.org/&quot;&gt;HathiTrust&lt;/a&gt; are some examples.&lt;/p&gt;

&lt;p&gt;These projects are efficient, and also disruptive. Disruption can well mean loosing some staff, where some of that expertise is scaled and shared across institutions. &lt;/p&gt;

&lt;h2 id=&quot;the-role-of-dlf&quot;&gt;The role of DLF&lt;/h2&gt;

&lt;p&gt;The DLF is a great place to discuss these ideas, to incubate them, and it may be that this idealised future can’t come to fruition without DLF. Looking at some of the goals of the DLF, they fit ideally within the context of the landscape that has been pointed out.&lt;/p&gt;

&lt;p&gt;I got stuck in the Twitter back channel, the closing call for action seems to me to lead to a world that needs quite a lot of structure. If one really wants to take advantage of web scale technologies I think one would need to take risks, but will people be willing to risk their cultural and scholarly artefacts? In the startup scene it’s ok to fail, there will always be another startup coming along, I think that this level of risk does not sit well within the library community, so understanding what we can experiment with, and perhaps just experimenting where we can without thinking about it too much, will tell us more than thinking about it, the university of &lt;a href=&quot;http://www.ckan.net/package/hud-library-usagedata&quot;&gt;Huddersfield experiments&lt;/a&gt; are a great example of this.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Arriving in Paulo Alto for the DLF fall forum</title>
   <link href="http://partiallyattended.com/2010/11/02/arriving-for-the-dlf"/>
   <updated>2010-11-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/11/02/arriving-for-the-dlf</id>
   <content type="html">&lt;p&gt;(I’m posting some of these posts a few days after writing, but you’ll get that, won’t you)&lt;/p&gt;

&lt;p&gt;It’s five in the morning, and I’m well and truly jet lagged, but after the past week this is not the strangest I’ve been feeling so, it’s not too bad (the immunisation shots for my trip to Mexico left me in an entertainingly woozy state Friday evening).&lt;/p&gt;

&lt;p&gt;I’m over to cover the digital library federation meeting, and the satellite SITS meeting on thursday. I’ve been sent along with David Challis from Douthhampton, and allthough we took the same flight we didn’t meet up until we had both made it to the hotel here in paulo alto. &lt;/p&gt;

&lt;p&gt;One of the good lessons that came up in our conversation over dinner was that if you running a system that produces a lot of metadata, then it’s really important to be a consumer of your own system, because most of the other consumers of Thea system are not automatically going to alert you when there are errors in your metadata records.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>save mailfolder messages to a file using applescript</title>
   <link href="http://partiallyattended.com/2010/10/18/save-mailfolder-messages-to-a-file-using-applescript"/>
   <updated>2010-10-18T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/10/18/save-mailfolder-messages-to-a-file-using-applescript</id>
   <content type="html">&lt;p&gt;I’ll just start by explaining that I hate applescript. I wanted to create a script that would take a specific folder withing the script and save each message from that folder to a text file on my machine for post-processing.&lt;/p&gt;

&lt;p&gt;This is what I came up with.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-applescript&quot; data-lang=&quot;applescript&quot;&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileRoot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Macintosh HD:Users:path:&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;tell&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;application&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Mail&amp;quot;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;mailbox&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;mailbox name&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;account&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;account&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;application&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Mail&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;repeat&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileNum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileRoot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;mailcontent&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileNum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;.txt&amp;quot;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;POSIX&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt;
		&lt;span class=&quot;nb&quot;&gt;do shell script&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;touch &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;p&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open for access&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;permission&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageText&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
		&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
		&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;\n&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
		&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageText&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
		&lt;span class=&quot;nb&quot;&gt;close access&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;repeat&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;tell&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It breaks down like this, the following script sets a list to be the messages in our names mailbox folder. We can then iterate over that array, getting attributes of each message, such as the message content or the sent date of the message:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-applescript&quot; data-lang=&quot;applescript&quot;&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;tell&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;application&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Mail&amp;quot;&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;messages&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;mailbox&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;mailbox name&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;account&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;account&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;application&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;Mail&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;repeat&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageList&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageText&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;repeat&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;tell&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Taking the creation of the file root out of the loop, and also adding a looping variable out of the loop the content inside the loop now looks like:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-applescript&quot; data-lang=&quot;applescript&quot;&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileNum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileRoot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;mailcontent&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileNum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;.txt&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;POSIX&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;do shell script&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;touch &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open for access&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;permission&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageText&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;\n&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageText&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;close access&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Looking in a bit more detail, we convert the counter (an int) into a string. We set the filepath to a base filename, the string version of the counter, and a file extension.  In order to ensure that the file exists we pass this path to a shell script, and “touch” the file. That’s right, in order not to get fucked over by applescripts error handling, I’ve just called out to the system shell as the most useful way of creating a filehandler to a file that might not extist. Jesus.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-applescript&quot; data-lang=&quot;applescript&quot;&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileNum&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileRoot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;mailcontent&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;fileNum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;.txt&amp;quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;POSIX&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;path&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;do shell script&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;touch &amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;p&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The second part of the loop now creates the file handler, writes some of the properties of the mail message into the file, closes the file handler, and iterates our loop counter.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-applescript&quot; data-lang=&quot;applescript&quot;&gt;&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;open for access&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFilePath&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;permission&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageText&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;content&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;date&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theMessage&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as &lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;string&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sent&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&amp;quot;\n&amp;quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;write&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;messageText&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;starting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;eof&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;close access&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;theFileReference&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Citation Style Language</title>
   <link href="http://partiallyattended.com/2010/09/24/CSL"/>
   <updated>2010-09-24T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/09/24/CSL</id>
   <content type="html">&lt;p&gt;Martin Fenner asked me to comment on Mendeley’s relationship with the Citation Style Language, so I thought I would pop up my thoughts on the blog too. &lt;a href=&quot;http://blogs.plos.org/mfenner/2010/09/24/citation-style-language-an-interview-with-rintze-zelle-and-ian-mulvany/&quot;&gt;Martin’s post&lt;/a&gt; below is the original message that I sent over to him.&lt;/p&gt;

&lt;p&gt;Hi Martin, thanks for getting in touch and asking about Mendeley’s relationship with CSL.  There are basically three aspects of citation styling that I’d like to discuss, the first is about Mendeley’s involvement, the second is about the use of citation styling in the community, and amongst publishers, and the third is about how we identify things in academia, and how we format those identifiers.&lt;/p&gt;

&lt;p&gt;We have been using the Citations Style Language for quite a while now.  We think it is an amazing project and we are very strongly committed to working with the CSL community in encouraging uptake.  We get a lot of feedback from our users and one area that they constantly run into problems with is the need to be able to format a citation in just such a manner.  The CSL project is the best way for us to be able to support the needs of our users with these kinds of requests.  Our developers have been pushing patches upstream to the citeproc-js project, particularly &lt;a href=&quot;http://www.mendeley.com/profiles/carles-pina/&quot;&gt;Carles Pina&lt;/a&gt;.  We have also just added a cut and paste stylebox on our article pages.  If you have a look at a &lt;a href=&quot;http://www.mendeley.com/research/karhunenloeve-eigenvalue-problems-cosmology-we-tackle-large-data-sets/&quot;&gt;sample paper&lt;/a&gt; you will now see a little citeproc-js driven box that lets you cut and paste styles in one of the eight most popular citation formats that get used within Mendeley: APA, BibTeX, Cell, Chicago, Harvard, MLA, Nature and Science.  We have also been supporting the creation of a &lt;a href=&quot;http://bitbucket.org/csledit/csl-wysiwyg-editor&quot;&gt;WISYWIG citation style editor&lt;/a&gt;.  The status of the project is that most of the code is complete and we just need to work on getting it integrated into our client, and figuring out the best way to manage the creation of more styles, and how that will work with the CSL community.  &lt;/p&gt;

&lt;p&gt;One of the things that we have been discussing with Bruce D’Arcus is how to manage the redistribution of new styles, and how to make sure that there corrupt styles don’t propagate, and that people get the style that they are looking for.  We have been discussing the creation of a styles commons or public repository, the final plans are not completely in place yet.  If people want to contribute there is a lot of activity on the &lt;a href=&quot;https://lists.sourceforge.net/lists/listinfo/xbiblio-devel&quot;&gt;mailing list&lt;/a&gt;.  One thing we thing we hope Mendeley can help with is reporting usage statistics on specific style files, so at least people can find the most popular version of a CSL file for a given style. I think it would also be awesome if publishers started authoring definitive CSL styles for their journals.&lt;/p&gt;

&lt;p&gt;That leads me nicely to talk about the second thing that interests me about citations.  After working for many years at Springer, and then Nature, I was well aware that most large publishers just push submitted manuscripts out to companies in India where the formatting of the paper happens.  The input format is really for the most part of no importance to the publisher, and also the citation formatting really doesn’t matter to most publishers.  They just tear the submitted manuscript to pieces and rebuild it in their chosen XML schema.  However, most people using citations are not actually submitting manuscripts for publication, but rather are writing term papers, or theses, or reports.  Someone from the Open University recently told me that tutors there can end up docking up to 10% off the marks of a paper if the citations are mis-formatted, and in many cases those tutors have their very own preferred version of a specific citation that they want their students to adhere to.&lt;/p&gt;

&lt;p&gt;So the weird thing is that citations started off as a required identifier for the literature.  Google scholar and HTTP URI’s have almost totally made formatted citations redundant as identifiers, and yet there is still a huge user need to be able to format citations according to a huge variety of styles, and since that need is going to continue for quite a long time, it’s a need that we have to support.&lt;/p&gt;

&lt;p&gt;This kind of leads me to my last point, which is a bit of a lament for the state of informational waste in the academic publishing system.  As I pointed out the big publishers don’t care about the submission format, but they have not really done a good job of communicating that to their editorial boards.  Smaller publishers don’t have the resources to totally format submissions, and beyond academic publishing there are a huge number of people who just need to format citations.  There is a huge waste of people’s time in reformatting papers for submissions, in fixing styles according to changing requirements from departments, and just trying to get the styling correct, when what should matter is the content.  I’d love to get to a point where every publisher accepted the same type of XML input, and our authoring tools all created content conforming to that input.  Citations should be a HTTP URI that can be rendered into the appropriate format using CSL and and API.  Imagine if you had to resubmit a manuscript to a different publisher, and all you had to do was resubmit the same file, just imagine!  I’ve been thinking things should work like this since about 2002 when I first started working in the publishing industry.  &lt;/p&gt;

&lt;p&gt;One of the things I really like about CSL is that is abstracts the form of the citation from the content of the citation. May more and more of our tools do the same!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The Future of Knowledge Organisation on the Web, a one day conference.</title>
   <link href="http://partiallyattended.com/2010/09/14/linked-data-london-meeting"/>
   <updated>2010-09-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/09/14/linked-data-london-meeting</id>
   <content type="html">&lt;p&gt;I’m attending this event today, and I’m going to keep some notes as the day progresses.  There are a couple of oddities about the event:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;No Coffee. That’s a bit of a pity&lt;/li&gt;
  &lt;li&gt;No power outlets in the conference room. Not many conferences have that, but one would think that it is a no brainer, especially for any meeting about the web, and in particular linked data. &lt;/li&gt;
  &lt;li&gt;To add to that, there also seems to be no public wifi.  There may well be but we have not been told about it yet.&lt;/li&gt;
  &lt;li&gt;It also seems that there may be construction happening on the roof later.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On the flip side, the speaker line up looks pretty good, so I’m anticipating learning quite a bit today. There is a huge representation from the BBC.  One obviously tends to think of the BBC as an entertainment and news organisation, but at it’s core is an enormous flow of information.  There are something like 20 people listed on the attendee sheet from the BBC.  I imagine that linked data is pretty important for them.  On the flip side, there are very few academic publishers represented, just one as far as I can see, Nature Publishing Group.  Their offices are around the corner, and I’ve just bumped into &lt;a href=&quot;http://twitter.com/tonyhammond&quot;&gt;@TonyHammond&lt;/a&gt;, who has done a huge amount of work in the past on linking repository systems.&lt;/p&gt;

&lt;p&gt;There is a packed room &lt;img src=&quot;/images/iskos.jpg&quot; alt=&quot;room&quot; /&gt;. &lt;/p&gt;

&lt;p&gt;So we get going!&lt;/p&gt;

&lt;h1 id=&quot;nigel-shadbolt-on-government-linked-data-a-tipping-point-for-the-semantic-web&quot;&gt;Nigel Shadbolt on Government Linked Data, a Tipping Point for the Semantic Web&lt;/h1&gt;

&lt;p&gt;Wants to talk about policy, the UK is providing a huge opportunity to put Semantic Web to good use. Argues the open government data is a killer sector (in lieu of killer app).  Is talking about the importance of local government data, in the new government there remains a clear commitment to transparency in open data.  &lt;/p&gt;

&lt;p&gt;Interesting point that the scale and scruffy nature of the web has a tendency to catch you out.  Hard core AI work often does not scale.  The substrate is linked data.  (It look likes there is still an attempt in the SemWeb to implement the very bottom of the stack proposed in 2010).  &lt;/p&gt;

&lt;p&gt;Linked data sets have the same kind of power spectrum as the open way, scale free with a heavy tail.  Some resources are very heavily linked to, e.g. some core facts in DBPedia and government boundary data.&lt;/p&gt;

&lt;p&gt;As a community we should consider government data as a gift. &lt;/p&gt;

&lt;p&gt;The first set of data that prompted opening data was the bicycle accident data.  It was opened because someone working in No 10 had a friend who had been killed in a cycling accident.  They were astonished when after opening up the data led to apps that had been created by developers.  Before this Government didn’t realise the potential in a citizenry that have the tools at their disposal to manipulate that data.  &lt;/p&gt;

&lt;p&gt;(One of the key points emerging out of this talk is that “interesting data” is the data that has some hook.)&lt;/p&gt;

&lt;p&gt;They have created a new Crown Licence that covers data release of government data&lt;/p&gt;

&lt;p&gt;They are working towards a definition of what public data is.  Basically this is any information that is non-personal and is collected in the course of public service delivery.  If this became an entrenched principle then one could imagine finding it easier to hold public services better to account, and could see the creation of innovative apps around that data. (This leads to the question of the power of the citizenry, how does one ensure equality of access to that data, or at least reduce the barriers to the general public for being able to render and work with that data.) &lt;/p&gt;

&lt;p&gt;Interestingly he points to &lt;a href=&quot;http://www.elbatrop.com/ukdentists&quot;&gt;NHS dentists&lt;/a&gt;, and that’s an app that I used to find my dentist! He also mentions &lt;a href=&quot;http://www.asborometer.com/&quot;&gt;ASBOrometer&lt;/a&gt;, an app for looking at the ASBO level of your local area.&lt;/p&gt;

&lt;p&gt;He mentions the postcode paper, I was at the Guardian developer day that produced that!! When that developer day happened the Ordinance Survey data was not available, and post codes were a paid for service, but those data sets are now available.  &lt;/p&gt;

&lt;p&gt;Another example is train and bus time tables.  The franchises that run these services don’t have any feeling that information they produce, like the time tables, should be opened.  These franchises are running with public money on behalf of the public, and so there is an argument that they should make data of this kind available, rather than just as a paid for iPhone app. An example is &lt;a href=&quot;http://whatis.spotlightonspend.org.uk/&quot;&gt;Spotlight on Spend&lt;/a&gt; which hi-lights government spending.&lt;/p&gt;

&lt;p&gt;From January every council will have to publish everything they spend over 500 pounds (I’ll be interested in looking at data from Hackney Council).&lt;/p&gt;

&lt;p&gt;One of the strongest arguments for creating “five star” linked data is that it builds a robust national digital infrastructure.  If you give a school a robust URI, then every data set that uses that namespace can be reconciled. &lt;a href=&quot;map.psi.enakting.org/how&quot;&gt;Enakting&lt;/a&gt; is a Southhampton demo of linking disparate data resources together.&lt;/p&gt;

&lt;h1 id=&quot;antoine-isaac-skos-and-linked-data&quot;&gt;Antoine Isaac, SKOS and Linked Data&lt;/h1&gt;

&lt;p&gt;Antoine is from the Frije Universitat, Amsterdam. He is working in &lt;a href=&quot;http://www.europeana.eu/portal/&quot;&gt;Europeana&lt;/a&gt;, and is co-charing the W3C Library Linked Data group.  Previously he worked on the W3C group that produced the SKOS specification.  His main focus is on cultural assets.  &lt;a href=&quot;http://www.w3.org/2004/02/skos/&quot;&gt;SKOS&lt;/a&gt; is the Simple Knowledge Organization System.  The scope is to represent information around systems such as thesauri and dictionaries in RDF.  It is not a language for representing formal semantics, in contrast to OWL.  It is possible to turn Knowledge Organisation Systems into ontologies, but it’s kind of hard.  They have soft semantics, but that does not mean that they are not interesting.  It can be useful for things such as semantic search and annotation systems.&lt;/p&gt;

&lt;p&gt;This is my first time in a talk about SKOS.  It seems that it underpins something like a thesaurus with terms such as “related”, “broader”, “preferred label” and other terms that give a relationship between terms.  These relations are pinned down using RDF and URI’s.  This then allows you to bridge different thesauri, as the underpinning relationships in both are underpinned with the SKOS vocabulary.  I guess there are tools out there that assist in applying the SKOS vocabulary onto a thesaurus.  Interestingly the SKOS vocabulary is extensible, and I wonder whether there has been any move to joig up SKOS and &lt;a href=&quot;http://swan.mindinformatics.org/ontology.html&quot;&gt;SWAN&lt;/a&gt;? &lt;/p&gt;

&lt;p&gt;There are some basic constraints in order to try to avoid chaos.  One of these is that any concept can only have one preferred label per language.  Inference is supported by the concept of “broader” and “narrower” links, and these are inverses of each other, allowing back inference.  &lt;/p&gt;

&lt;p&gt;There is a minimal semantic commitment, pinning the meaning on the existing information system.&lt;/p&gt;

&lt;p&gt;There is an interesting example using library of congress subject headings, which also bring in links to similar concepts from other vocabularies.  They &lt;a href=&quot;http://www.cs.vu.nl/STITCH/&quot;&gt;stitched&lt;/a&gt; together vocabularies from the US, France and Germany.&lt;/p&gt;

&lt;p&gt;They have a &lt;a href=&quot;http://www.w3.org/2001/sw/wiki/SKOS/Datasets&quot;&gt;list of linked data sets&lt;/a&gt; that have used SKOS. These include New York Times subject headings and a number of sources from the physical sciences. (I wonder how useful it would be to try to extract interesting terms from scientific articles and link them to New York Times subject headings). &lt;/p&gt;

&lt;p&gt;Antoine is starting to run out of time and the convener is standing up and looking leery. Now, time for coffee, yay!&lt;/p&gt;

&lt;h1 id=&quot;ricard-wallis-from-talis-on-the-linked-data-journey&quot;&gt;Ricard Wallis from Talis on The Linked Data Journey&lt;/h1&gt;

&lt;p&gt;“Observations of a fellow traveller”&lt;/p&gt;

&lt;p&gt;I recently saw Richard talk at Science Online London, and he gave a great talk there, so I’m looking forward to this.  &lt;/p&gt;

&lt;p&gt;“Semantic technology has a reputation for being really useful until you add the second user”.&lt;/p&gt;

&lt;p&gt;This is very close to the talk that Ricard gave at Science Online, so I’m not going to write up this talk in much detail.  &lt;/p&gt;

&lt;p&gt;Some interesting lessons coming from the talk, one of the powerful arguments that got government to open up data was to point out to them that the data may well be subject to freedom of information requests.  These are very time expensive, and can be totally avoided by publishing the data up front.&lt;/p&gt;

&lt;p&gt;When the New York Times published their subject headings they got some vitriolic feedback because of the way that they assigned ownership of heading terms.  This was just the result of the naive application of the ontology, but the community got quite upset.&lt;/p&gt;

&lt;p&gt;The BBC edit information in Wikipedia for use on their sites. They pull in the data using RDF, and the information goes out into a resource that can be reused by many other people.  &lt;/p&gt;

&lt;p&gt;Some interesting links:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A site that shows all UK &lt;a href=&quot;http://www.legislation.gov.uk/&quot;&gt;legislation&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://data.nytimes.com/&quot;&gt;New York Times data&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Animals!&lt;img src=&quot;http://www.bbc.co.uk/nature/species/lion&quot; alt=&quot;animals&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://uk-postcodes.com/postcode&quot;&gt;Postcodes!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;“&lt;a href=&quot;http://www.sameas.org&quot;&gt;Same as&lt;/a&gt;” resources &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://winspark.net/2009/11/25/microsoft-pivot-a-new-internet-browser-from-live-labs/&quot;&gt;Pivot&lt;/a&gt; browser from Microsoft&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;steve-dale-linked-data-in-local-government-the-knowledge-hub&quot;&gt;Steve Dale, Linked Data in Local Government: The Knowledge Hub&lt;/h1&gt;

&lt;p&gt;So, what is the “Knowledge Hub”? They are trying to solve the problem of the proliferation of sources of information.  There are also a proliferation of community web sites.  Conversations are becoming more granular, and increasingly dis-aggregated.  At the same time there is a growth in data, and data availability.  However there is very little connectivity.  Wow, he has just pulled up an overview of the proposed architecture.  They want to aggregate information from many different sources, add a semantic layer, and create an API an apps store on top of this.  They then want to be able to set up a push notification service to users based on context.  I don’t believe that this is practically possible at the moment, but if they do build this, then it might well be an interesting innovation.&lt;/p&gt;

&lt;p&gt;This general schema is one that could be applied to pushing notifications based on context around many potential contexts, but I don’t believe that we have a good experience for ambient information available to us yet.  Aardvark and Foursquare have started to scratch the surface for this, and Tim O’Reilly’s idea for an intelligent phone book are pointing in the direction that we may be heading to, but I think we are very far from that.&lt;/p&gt;

&lt;p&gt;This idea seems to me to be lacking in specific measurable gals around success.  I notice that they also want to create their app platform on top of the google gadgets platform, so the big question that they have not answered is how to get user and developer engagement.  They are starting development now, using an agile methodology they want to get to a live product in early 2011.  Good luck to them!&lt;/p&gt;

&lt;h1 id=&quot;prof-dr-martin-hepp-linked-data-in-e-commerce-the-goodrelations-ontology&quot;&gt;Prof. Dr. Martin Hepp, Linked Data in E-Commerce, The GoodRelations Ontology&lt;/h1&gt;

&lt;p&gt;From Universität der Bundeswehr München. (Wow, you can really hear the hammering on the roof).  In Market economies finding partners for trade is important.  This selection process is sometimes done implicitly.  The effort for keeping this exchange alive in a market economy is estimated to be more that 50% of GDP in the US.  This includes search for suppliers, the banking system, anything that is needed to sustain a market beyond a trivial barter economy.  (This seems like a strange analysis, for instance many service industries though probably included in this figure, are also ends in themselves).  A key driver for search is specificity of the goods.  How much you loose when you can’t use a good for what it was designed.  &lt;/p&gt;

&lt;p&gt;In 1920 Merck had a catalog of everything that could be traded.  There were 5158 items that were relevant for a typical business owner.  We are now consuming rather a larger number of types of good.  Now in a bakery, for instance, you can get 30 variations of bread!  As items proliferate, the search space increases.  The effort for advertising, and for searching, for specific items increases with specificity.  (I just posted the wrong power cable along with a hard drive, that I recently sold on e-bay!).  The web has decreased the search cost, and yet we still spend a lot of time of searches.  And yet the web is one of the largest data shredder in history.  Often data starts out in a structured way, for instance the producer has a database containing information about the production process.  When you transfer this to the web all of this extra data gets stripped.  &lt;/p&gt;

&lt;p&gt;Linked Data is Data Linked!  Preserving the structure of the data on the web, clustering links by meaning, linking data elements represented by documents and reducing the lookup effort for getting hold of metadata for an element.  These are the four big things that the linked data world are going to bring into the filed of data management. &lt;/p&gt;

&lt;p&gt;Preserving the structure is key, and so the quality of the vocabularies/schemas/ontologies that you use will have an impact on the reusability of the data.  Interestingly may shops update data very quickly.  Crawling the data does not work if the data is changing hourly, as the cache will be invalid quickly.  He makes an interesting point about how a technology will get adopted.  It should get adopted when the perceived benefit outweighs the perceived costs.  If you have to go out and beg people to use linked data, then there is something wrong with the model.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.heppnetz.de/projects/goodrelations/&quot;&gt;GoodRelations&lt;/a&gt; is a schema for commerce on the web.  It has been developer over the past 10 years.  You need to realise that an ontology is not just for publishing data, but is also for the structure for reusing the data.  It works by getting suppliers to put a payload of RDFa with structured data into a webpage.  &lt;/p&gt;

&lt;p&gt;When creating an ontology one needs to make it as simple as possible, but no simpler.  Getting this balance correct is very important. For instance interestingly in this ontology a price is not a property of a product, but rather of an offer.  Stores and business entities are distinct.  A product is distinct from a product model.&lt;/p&gt;

&lt;p&gt;The basic structure is that there is an Agent who makes a Promise around an Object.  &lt;/p&gt;

&lt;p&gt;His closing point about making use of RDFa over SPARQl endpoints is brilliant.  As he says, connecting 80 databases using a line call is something any middleware vendor could have done in the 1980’s, how do you convince thousands of shop owners to do this? The answer is that you don’t.  &lt;/p&gt;

&lt;h1 id=&quot;andy-powell-eduserv-linked-data---the-long-and-winding-road&quot;&gt;Andy Powell, Eduserv, Linked Data - the long and winding road.&lt;/h1&gt;

&lt;p&gt;This is a somewhat more sceptical approach, not totally sceptical. If we believe that linked data is the future of the web, then what we are really saying is that RDF is the future of the web.  Looking at one community we can perhaps learn some lessons, let’s look at the Dublin Core community.  The key-points of this talk are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DC is originally 15 metadata elements&lt;/li&gt;
  &lt;li&gt;in actual fact its more like 60 properties and classes, that is maintained reasonably well&lt;/li&gt;
  &lt;li&gt;this is all declared using RDF/RDFS&lt;/li&gt;
  &lt;li&gt;it started in 1995, a very librarian-centric view, thinking one could still catalog all of the web pages
    &lt;ul&gt;
      &lt;li&gt;embedded in meta tags&lt;/li&gt;
      &lt;li&gt;expose this to search engines&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;One of the consequences is that there is a record-centric approach&lt;/li&gt;
  &lt;li&gt;so that you can ship them from one application to another&lt;/li&gt;
  &lt;li&gt;the record is the mechanism for tracking provenance&lt;/li&gt;
  &lt;li&gt;the original elements were thought to be 15 fuzzy buckets
 	* this was a feature, not a bug&lt;/li&gt;
  &lt;li&gt;the data modelling was very naive, e.g. author name was an item in a DC record rather than thinking about it being a property of a person who was the author&lt;/li&gt;
  &lt;li&gt;strings vs. things, a separation between entities, and the labels of those entities was not properly resolved&lt;/li&gt;
  &lt;li&gt;little abstraction of the model from the syntax of the underlying model&lt;/li&gt;
  &lt;li&gt;&lt;/li&gt;
  &lt;li&gt;Challenges&lt;/li&gt;
  &lt;li&gt;Even still a discussion about adopting an RDF model&lt;/li&gt;
  &lt;li&gt;need to argue towards Open, in that you don’t want to be in a silo&lt;/li&gt;
  &lt;li&gt;you need to recognise that everyone can catalog stuff, and for the more traditional cataloging community this can be hard to accept&lt;/li&gt;
  &lt;li&gt;the ‘http’ URI problem. 
    &lt;ul&gt;
      &lt;li&gt;people stil think that http URI’s are only for locating web pages, need to conceptually get across that you can use them to identify anything&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;modelling
    &lt;ul&gt;
      &lt;li&gt;modelling is hard, they also need to gain traction within a community&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blogs.ecs.soton.ac.uk/webteam/2010/09/02/the-modeler/&quot;&gt;the modeller&lt;/a&gt; is a great post highlighting some of the issues&lt;/li&gt;
  &lt;li&gt;linked data must be a success on the web if it is to play a future on the web, that means RDF needs to be a success on the web&lt;/li&gt;
  &lt;li&gt;so far it has not been a success on the web, which is not to say that it won’t in time.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So far this has been the best talk of the day, it’s really great as an overview.&lt;/p&gt;

&lt;h1 id=&quot;john-goodwin-from-ordinance-survey-linking-to-geographic-data&quot;&gt;John Goodwin from Ordinance Survey, Linking to Geographic Data&lt;/h1&gt;

&lt;p&gt;Research Scientist with OS.  At OS they are very good at saying where stuff is, but not what stuff is.  Geo data is important, there are still confusing records around place names, e.g. Hampshire.  The OS has decided to open an &lt;a href=&quot;http://opendata.ordnancesurvey.co.uk/&quot;&gt;authoritative set of linked data&lt;/a&gt;, e.g.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;boundary-line esri-shape file&lt;/li&gt;
  &lt;li&gt;code-point&lt;/li&gt;
  &lt;li&gt;gazetteer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How do you get that out as linked data when the formats are complex and sometime proprietary?&lt;/p&gt;

&lt;p&gt;They have now converted this into linked data.  RDF is not very good for spatial data, but you can do some qualitative relations, and you can put in topological relations, such as containment, and boundary relations.  This administrative info is on the web now.  (The postcode paper gets another mention, yay, go PostCodePaper!!)  &lt;/p&gt;

&lt;h1 id=&quot;andreas-blaumer-poolpartypoolskos-thesaurus-management-utilising-linked-data&quot;&gt;Andreas Blaumer, &lt;a href=&quot;http://www.poolparty.punkt.at/demozone&quot;&gt;PoolParty&lt;/a&gt;:SKOS Thesaurus Management utilising Linked Data&lt;/h1&gt;

&lt;p&gt;from punkt.net Services. &lt;/p&gt;

&lt;p&gt;This talk starts off by re-iterating the power of the web.  It looks like many apps are beginning to sit on top of web scale information, and not being based on heay ontologies.  As Jim Hendler says “A little semantic goes a long way”.  For a system that seems to be being based on the topology of a large scale network I’m surprised that no-one has been talking about the implications or details of the structure of the network.  No power spectra in this conference yet.  It was alluded to a little by the person who was talking about GoodShopping.&lt;/p&gt;

&lt;p&gt;Andreas thinks that SKOS could introduce Web2.0 mechanisms to the Web of Data.  When they developed Pool Party, then the question is how can any person publish information or knowledge, as linked data?  (sounds a bit like the Drupal extension).  &lt;/p&gt;

&lt;p&gt;The tool seems to be a web interface that allows for markup and concept tagging of documents.  Can connect to a corporate thesaurus.  Wow, we are going to get a live demo.&lt;/p&gt;

&lt;p&gt;They start by taking a text and counting terms. Then they look for terms from DBPedia, as well as calls to a thesaurus for economics.  They also look for related terms based on completing trigrams, and use these to generate a SPARQL query to get even extra terms.  These terms are then presented as a set of possible tags that can be used to semantically mark up the text.  They have a cross-language dictionary that helps cross-tag across languages.  They have exact and close match in searching.  They don’t use “sameas”.  You can also do a matching between concept schemas.  They can import a number of different kinds of info, N3, N-Triples, RDF etc.  Output is possible in a number of different XML formats.  &lt;/p&gt;

&lt;p&gt;He mentions the &lt;a href=&quot;http://lod2.eu/&quot;&gt;LOD2&lt;/a&gt; project from the EU. This is a 4-year EU project. Good luck with that. This is an FP7 project.  The EU is making a lot of data available, perhaps there will be scientifically interesting data sets being made available. &lt;/p&gt;

&lt;h1 id=&quot;bertrand-vatant-porting-terminologies-to-the-semantic-web&quot;&gt;Bertrand Vatant, Porting terminologies to the Semantic Web&lt;/h1&gt;

&lt;p&gt;a.k.a. the Semiotic Web (you can tell that the speaker is French, I think I have only ever heard the word Semiotic being used by French people).  On the slide there is a reference to the “quick off” of &lt;a href=&quot;http://datalift.org&quot;&gt;datalift&lt;/a&gt;. (he means “kick off”, but it’s a pretty cute error).&lt;/p&gt;

&lt;p&gt;He has just said that a resource as in ‘URI’ has become more abstract over the last 20 years. It is now a resource if it is identifiable and worth speaking about (mind you most things that are addressable are really not worth talking about, certainly not most things that are on the web).  He really is talking about semiotics and semiotic triangles.  And this is the last talk of the day.  (The open web, in a way, wallows in it’s own existence without too much care for the signifiers.  It’s a dynamical process, an infrastructure, along which meaning travels.  Stopping to pin URI’s on the evolving mechanisms of the web may not be a viable strategy.  The implication for this is that systems such as twitter will never emerge on the semantic web as the semantic web will not be able to evolve at the scale that a system like twitter can evolve.  That’s not a bad thing, it just means that we need to be clear about the potential for these kinds of tools, and to be aware of the correct domains where they should be applied.)&lt;/p&gt;

&lt;p&gt;And at this point it’s time for a glass of wine. &lt;/p&gt;

&lt;h1 id=&quot;links-mentioned-in-this-post&quot;&gt;links mentioned in this post&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://twitter.com/tonyhammond&quot;&gt;http://twitter.com/tonyhammond&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.elbatrop.com/ukdentists&quot;&gt;http://www.elbatrop.com/ukdentists&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.asborometer.com/&quot;&gt;http://www.asborometer.com/&lt;/a&gt; &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://whatis.spotlightonspend.org.uk/&quot;&gt;http://whatis.spotlightonspend.org.uk/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://map.psi.enakting.org/how&quot;&gt;http://map.psi.enakting.org/how&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.legislation.gov.uk/&quot;&gt;http://www.legislation.gov.uk/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://data.nytimes.com/&quot;&gt;http://data.nytimes.com/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.bbc.co.uk/nature/species/lion&quot;&gt;http://www.bbc.co.uk/nature/species/lion&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://uk-postcodes.com/postcode&quot;&gt;http://uk-postcodes.com/postcode&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.sameas.org&quot;&gt;http://www.sameas.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://winspark.net/2009/11/25/microsoft-pivot-a-new-internet-browser-from-live-labs/&quot;&gt;http://winspark.net/2009/11/25/microsoft-pivot-a-new-internet-browser-from-live-labs/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.heppnetz.de/projects/goodrelations/&quot;&gt;http://www.heppnetz.de/projects/goodrelations/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://blogs.ecs.soton.ac.uk/webteam/2010/09/02/the-modeler/&quot;&gt;http://blogs.ecs.soton.ac.uk/webteam/2010/09/02/the-modeler/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://opendata.ordnancesurvey.co.uk/&quot;&gt;http://opendata.ordnancesurvey.co.uk/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.poolparty.punkt.at/demozone&quot;&gt;http://www.poolparty.punkt.at/demozone&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://lod2.eu/&quot;&gt;http://lod2.eu/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>Slides from APS Talk, August, 2010</title>
   <link href="http://partiallyattended.com/2010/09/13/slides-from-aps-talk"/>
   <updated>2010-09-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/09/13/slides-from-aps-talk</id>
   <content type="html">&lt;p&gt;Back at the beginning of August I gave a talk at the &lt;a href=&quot;http://www.apsnet.org/Pages/default.aspx&quot;&gt;American Phytopathological Society&lt;/a&gt;. It was a great opportunity to talk to some really interesting scientists. My talk slides are below.&lt;/p&gt;

&lt;div style=&quot;width:477px&quot; id=&quot;__ss_4973186&quot;&gt;&lt;strong style=&quot;display:block;margin:12px 0 4px&quot;&gt;&lt;a href=&quot;http://www.slideshare.net/IanMulvany/aps-talk-aug2010nc-4973186&quot; title=&quot;Unveiling the web, making the implicit explicit.&quot;&gt;Unveiling the web, making the implicit explicit.&lt;/a&gt;&lt;/strong&gt;&lt;object id=&quot;__sse4973186&quot; width=&quot;477&quot; height=&quot;510&quot;&gt;&lt;param name=&quot;movie&quot; value=&quot;http://static.slidesharecdn.com/swf/doc_player.swf?doc=apstalkaug2010nc-100815081621-phpapp02&amp;amp;stripped_title=aps-talk-aug2010nc-4973186&quot; /&gt;&lt;param name=&quot;allowFullScreen&quot; value=&quot;true&quot; /&gt;&lt;param name=&quot;allowScriptAccess&quot; value=&quot;always&quot; /&gt;&lt;embed name=&quot;__sse4973186&quot; src=&quot;http://static.slidesharecdn.com/swf/doc_player.swf?doc=apstalkaug2010nc-100815081621-phpapp02&amp;amp;stripped_title=aps-talk-aug2010nc-4973186&quot; type=&quot;application/x-shockwave-flash&quot; allowscriptaccess=&quot;always&quot; allowfullscreen=&quot;true&quot; width=&quot;477&quot; height=&quot;510&quot; /&gt;&lt;/object&gt;&lt;div style=&quot;padding:5px 0 12px&quot;&gt;View more &lt;a href=&quot;http://www.slideshare.net/&quot;&gt;documents&lt;/a&gt; from &lt;a href=&quot;http://www.slideshare.net/IanMulvany&quot;&gt;Ian Mulvany&lt;/a&gt;.&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Connecting Scientific Resources, Slides</title>
   <link href="http://partiallyattended.com/2010/09/07/solo10-presentation-slides"/>
   <updated>2010-09-07T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/09/07/solo10-presentation-slides</id>
   <content type="html">&lt;p&gt;On Friday I hosted a session at Science Online London. Michael Habibi, Richard Wallis and Chris Taylor all gave great presentations. &lt;a href=&quot;http://mchabib.com/2010/09/06/presentation-connecting-publications-and-data-connecting-scientific-resources-breakout-science-online-london-2010/&quot;&gt;Michael’s presentation&lt;/a&gt; and &lt;a href=&quot;http://www.slideshare.net/rjw/the-linked-data-publishing-threestep&quot;&gt;Richards’s presentation&lt;/a&gt; are both online, and when the organisers post the other talks I’ll link to Chris’s presentation too.&lt;/p&gt;

&lt;h4 id=&quot;michael-taking-us-through-his-talk&quot;&gt;Michael, taking us through his talk&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://farm5.static.flickr.com/4104/4967211138_f1224717f7.jpg&quot; alt=&quot;Michael Habib presenting&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;richard-has-a-rapt-audience&quot;&gt;Richard has a rapt audience&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://farm5.static.flickr.com/4132/4966608997_4f9acd7ecf.jpg&quot; alt=&quot;Richard Wallis presenting&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;chris-getting-passionate&quot;&gt;Chris, getting passionate&lt;/h4&gt;
&lt;p&gt;&lt;img src=&quot;http://farm5.static.flickr.com/4084/4966609049_1b175e3b8f.jpg&quot; alt=&quot;Chris Taylor presenting&quot; /&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>science scraping with YQL</title>
   <link href="http://partiallyattended.com/2010/09/06/science-scraping-with-yql"/>
   <updated>2010-09-06T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/09/06/science-scraping-with-yql</id>
   <content type="html">&lt;p&gt;Last Saturday at Science Online London I gave a quick tutorial on &lt;a href=&quot;http://developer.yahoo.com/yql/&quot;&gt;YQL&lt;/a&gt;, and how it might be used to mash up scientific data sets.  Below I list some of the sample queries that I was playing with.  Before you get started with the &lt;a href=&quot;http://developer.yahoo.com/yql/console/&quot;&gt;console&lt;/a&gt; have a look through the documentation.  I got a lot of milage out of the part about &lt;a href=&quot;http://developer.yahoo.com/yql/guide/filters.html&quot;&gt;filters&lt;/a&gt; and &lt;a href=&quot;http://developer.yahoo.com/yql/guide/joins.html&quot;&gt;joins&lt;/a&gt;.  The blog post by Paul Hogan on &lt;a href=&quot;http://www.paulhagon.com/blog/2009/12/09/yql-mashups-for-libraries/&quot;&gt;using YQL for library maships&lt;/a&gt; was also very helpful.&lt;/p&gt;

&lt;p&gt;In my presentation I was originally looking at extracing data from a &lt;a href=&quot;http://sbr.ipmpipe.org/cgi-bin/sbr/county_info.cgi?date=2010-07-13&amp;amp;pest=soybean_rust&amp;amp;host=All%20Legumes/Kudzu&quot;&gt;report on soy bean rust spread&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here are a few sample queries to get you started&lt;/p&gt;

&lt;p&gt;1:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;&amp;quot;http://sbr.ipmpipe.org/cgi-bin/sbr/county_info.cgi?date=2010-07-13&amp;amp;pest=soybean_rust&amp;amp;host=All%20Legumes/Kudzu&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This query just pulls all of the HML from the page. &lt;a href=&quot;http://developer.yahoo.com/yql/console/#h=select%20*%20from%20html%20where%20url%3D%22http%3A//sbr.ipmpipe.org/cgi-bin/sbr/county_info.cgi%3Fdate%3D2010-07-13%26pest%3Dsoybean_rust%26host%3DAll%2520Legumes/Kudzu%22%0&quot;&gt;Open in console&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;2:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;&amp;quot;http://sbr.ipmpipe.org/cgi-bin/sbr/county_info.cgi?date=2010-07-13&amp;amp;pest=soybean_rust&amp;amp;host=All%20Legumes/Kudzu&amp;quot;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;//table&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This query extracts only the table element from the page. &lt;a href=&quot;http://developer.yahoo.com/yql/console/#h=select%20*%20from%20html%20where%0Aurl%3D%22http%3A//sbr.ipmpipe.org/cgi-bin/sbr/county_info.cgi%3Fdate%3D2010-07-13%26pest%3Dsoybean_rust%26host%3DAll%2520Legumes/Kudzu%22%0Aand%20xpath%3D%27//table%27%0A&quot;&gt;Open in console&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;3:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;&amp;quot;http://sbr.ipmpipe.org/cgi-bin/sbr/county_info.cgi?date=2010-07-13&amp;amp;pest=soybean_rust&amp;amp;host=All%20Legumes/Kudzu&amp;quot;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;//table/tr/td[2]&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This query pulls the second item from each row of the table. &lt;a href=&quot;http://developer.yahoo.com/yql/console/#h=select%20*%20from%20html%20where%0Aurl%3D%22http%3A//sbr.ipmpipe.org/cgi-bin/sbr/county_info.cgi%3Fdate%3D2010-07-13%26pest%3Dsoybean_rust%26host%3DAll%2520Legumes/Kudzu%22%20and%20xpath%3D%27//table/tr/td%5B2%5D%27&quot;&gt;Open in console&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;4:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;html&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;where&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;&amp;quot;http://www.mulvany.net/files/ipmsemanticpipe.html&amp;quot;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xpath&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;//table/tr/td[@id=&amp;quot;status&amp;quot; and p=&amp;quot;Confirmed&amp;quot;]/..&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;For this query I copied the table onto my own server and added some basic proto-semantic markup to the column descriptors.  I could then call out specific columns from the table. &lt;a href=&quot;http://developer.yahoo.com/yql/console/#h=select%20*%20from%20html%20where%0Aurl%3D%22http%3A//www.mulvany.net/files/ipmsemanticpipe.html%22%0Aand%20xpath%3D%27//table/tr/td%5B@id%3D%22status%22%20and%20p%3D%22Confirmed%22%5D/..%27&quot;&gt;Open in console&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;5:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-sql&quot; data-lang=&quot;sql&quot;&gt;&lt;span class=&quot;k&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;csv&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;&amp;quot;http://www.mulvany.net/files/ipmpipe.csv&amp;quot;&lt;/span&gt; 
&lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;date,place,status&amp;#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;status&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;&amp;#39;Confirmed&amp;#39;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;With this query I converted the table into a csv file.  This demonstrates YQL’s ability to query against csv files.  &lt;a href=&quot;http://developer.yahoo.com/yql/console/#h=select%20*%20from%20csv%20WHERE%0Aurl%3D%22http%3A//www.mulvany.net/files/ipmpipe.csv%22%0Aand%20columns%3D%27date%2Cplace%2Cstatus%27%0Aand%20status%3D%27Confirmed%27&quot;&gt;Open in console&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Connecting Scientific Resources</title>
   <link href="http://partiallyattended.com/2010/08/27/connecting-scientific-data"/>
   <updated>2010-08-27T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/08/27/connecting-scientific-data</id>
   <content type="html">&lt;p&gt;I’m going to be hosting a session at &lt;a href=&quot;http://www.scienceonlinelondon.org/&quot;&gt;science online London&lt;/a&gt; next weekend, I’m excited. I’ve been interested in the issues of connecting scientific data for a long time.  In the last six months I’ve become particularly excited about the potential of web based tool like &lt;a href=&quot;http://developer.yahoo.com/yql/&quot;&gt;Yahoo Query Language&lt;/a&gt;.  I was hoping to talk a little about that, but I’ve been lucky to get some amazing people to come and share their experiences about linking data, so I’m going to cede the floor to them.  I might be able to get some YQL hackery into one of the unconference slots that will be knocking around.  Science online is shaping up to be a pretty awesome event, and you can check out the &lt;a href=&quot;http://www.scienceonlinelondon.org/programme.php&quot;&gt;conference program&lt;/a&gt; to see what you will be missing out on!&lt;/p&gt;

&lt;p&gt;Here is the spiel and speaker bios for the section that I’m going to be running:&lt;/p&gt;

&lt;h1 id=&quot;connecting-scientific-resources&quot;&gt;Connecting Scientific Resources&lt;/h1&gt;

&lt;p&gt;Do you have data? Have you decided that you want to publish that data in a friendly way? Then this session is for you. Allowing your data to be linked to other data sets is an obvious way to make your data more useful, and to contribute back to the data community that you are a part of, but the mechanics of how you do that is not always so clear cut. This session will discuss just that. With experts from the publishing world, the liked data community, and scientific data services, this is a unique opportunity to get an insight into how to create linked scientific data, and what you can do with it once you have created it.&lt;/p&gt;

&lt;h2 id=&quot;about-the-panel&quot;&gt;About the Panel&lt;/h2&gt;

&lt;h3 id=&quot;ian-mulvany-vp-new-product-development-mendeley&quot;&gt;Ian Mulvany, VP New Product Development, Mendeley&lt;/h3&gt;
&lt;p&gt;Ian Mulvany is VP of New Product Development for Mendeley.com where he is responsible for ensuring that the tools being built really respond to the needs of researchers and scientists. He spends much of his time examining the implications of emerging web technologies for the practice and communication of science, and he is excited by the untapped potential in linking and exposing data.&lt;/p&gt;

&lt;h3 id=&quot;michael-habib-product-manager-scopus-ux--workflow&quot;&gt;Michael Habib, Product Manager, Scopus UX + Workflow&lt;/h3&gt;
&lt;p&gt;His specialty and passion is designing interactive and social experiences around content and metadata. Michael is currently focused on improving the Scopus user-experience by pursuing tight and seamless integration of Scopus and Scopus data (APIs, etc.) into the STM literature research workflow.&lt;/p&gt;

&lt;h3 id=&quot;richard-wallis-technology-evangelist-talis&quot;&gt;Richard Wallis, Technology Evangelist Talis&lt;/h3&gt;
&lt;p&gt;As Technology Evangelist at Talis, he is at the forefront in promoting, explaining, and applying new and emerging web, semantic web and linked data technologies. Richard is a well known speaker at conferences and events, providing entertaining and informative insights in to Web 2.0 and the Semantic Web and their influence upon real world situations.&lt;/p&gt;

&lt;h3 id=&quot;chris-taylor-senior-software-engineer-for-proteomics-service-ebi&quot;&gt;Chris Taylor, Senior Software Engineer for Proteomics Service, EBI&lt;/h3&gt;
&lt;p&gt;As Senior Software Engineer, Chris plays a key role in the The Proteomics Services Team, providing databases and tools for the deposition, distribution and analysis of proteomics and proteomics-related data. The team contribute to the development of community standards for proteomics data in the context of the HUPO Proteomics Standards Initiative (PSI), and develop reference implementations for these standards. Chris is also involved with the isainfrastructre project, a tool to assist in the annotation and local management of experimental metadata.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Passing arguments in liquid templates.</title>
   <link href="http://partiallyattended.com/2010/08/23/passing-arguments-in-liquid-templates"/>
   <updated>2010-08-23T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/08/23/passing-arguments-in-liquid-templates</id>
   <content type="html">&lt;p&gt;I’ve recently moved my blog over to hosting on github using the Jekyll templating system.  I was intrigued by the ability of Jekyll to create a listing for related posts, but in the end the quality was poor.  There are two methods avilable, the more robust uses latent semantic indexing, but this is not supported by github.  I can understand this, as the processing required is a bit too much of an overhead for a lightweight hosting service.  The other method is a fast method, but for all of the posts that I tried it against it only ever produced the last three posts that I had created.&lt;/p&gt;

&lt;p&gt;I really liked the idea of having some related content after each post, so I decided to pull out posts that were related by tags. I like tags a lot.  In order to do this I needed to iterate over each set of posts for each category from the categories for the given page.  This looks something like:&lt;/p&gt;

&lt;pre&gt;
&amp;#123;% highlight html %&amp;#125; 
&amp;#123;% for category in page.categories %&amp;#125;
  do stuff
&amp;#123;% endfor %&amp;#125;
&amp;#123;% endhighlight %&amp;#125;
&lt;/pre&gt;

&lt;p&gt;The problem that I was having is trying to figure out how to pass the value of ‘category’ to the next loop.  I didn’t find any documentation, but after trying out some random syntax hit on the following, which seems to work:&lt;/p&gt;

&lt;pre&gt;
&amp;#123;% for category in page.categories %&amp;#125;
  &amp;#123;% for post in site.categories.[category] %&amp;#125;
	do stuff
  &amp;#123;% endfor %&amp;#125;
&amp;#123;% endfor %&amp;#125;
&lt;/pre&gt;

&lt;p&gt;The important line is:
&lt;code&gt;
  &amp;#123;% for post in site.categories.[category] %&amp;#125;
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And the piece of syntax that make is work is encasing category in brackets &lt;code&gt;[category]&lt;/code&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Testing Code Hilighting</title>
   <link href="http://partiallyattended.com/2010/08/15/testing-code-hilighting"/>
   <updated>2010-08-15T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/08/15/testing-code-hilighting</id>
   <content type="html">&lt;h1 id=&quot;testing-ruby&quot;&gt;testing ruby&lt;/h1&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&amp;#39;foo&amp;#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1 id=&quot;testing-python&quot;&gt;testing python&lt;/h1&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nice&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;how interesting&amp;quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h1 id=&quot;testing-latex&quot;&gt;testing latex&lt;/h1&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-latex&quot; data-lang=&quot;latex&quot;&gt;&lt;span class=&quot;sb&quot;&gt;\[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;\sum&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;_{n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;}^&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\infty&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\frac&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;}{n} &lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;\text&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;{ is divergent, but } &lt;/span&gt;
&lt;span class=&quot;nv&quot;&gt;\lim&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;_{n &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\to&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\infty&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;} &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\sum&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;_{i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;}^n &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\frac&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;}{i} &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\ln&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt; n &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;\text&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;{exists.} &lt;/span&gt;
&lt;span class=&quot;s&quot;&gt;\]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>Notes from JISC activity streams workshop</title>
   <link href="http://partiallyattended.com/2010/07/14/raw-notes-jiscad"/>
   <updated>2010-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/07/14/raw-notes-jiscad</id>
   <content type="html">&lt;h2 id=&quot;dave-jennings-giving-the-opening-talk-httpwwwslidesharenetdavidjennings&quot;&gt;Dave Jennings giving the opening talk, http://www.slideshare.net/davidjennings&lt;/h2&gt;

&lt;p&gt;abundance of content without structure is not to be feared, example comes from music.
uses a Medneley slide to talk about the lastfm – Medneley bridge.
talks about the amazon collaborative filter
mentions how this can lead to a dystopia, Googlezon, the big brother of recommender system.
talks about the future of pervasive recommender systems, and brain matching to content matching. 
john cage - my favourite music the music I haven’t heard yet.&lt;/p&gt;

&lt;p&gt;search
browsing
monitoring
wait for interesting things to pass by you&lt;/p&gt;

&lt;p&gt;there is a social aspect, you see the tracks that others have left
there is a bandwagon effect (the network clustering effect)
black sheep element - people like to be individuals&lt;/p&gt;

&lt;p&gt;Another dystopia, tower of babylon, how do you organise this?
 (take a leaf out of the anarchists book)&lt;/p&gt;

&lt;p&gt;flickr does this with the use of interestingness 
	(I like his description of this as a first part in a dialog)&lt;/p&gt;

&lt;p&gt;Jenning’s law “people make most of their discoveries elsewhere” 
	(serendipitous, algorithmic recommendation, word of mouth)&lt;/p&gt;

&lt;p&gt;Feyerabend - the conquest of abundance&lt;/p&gt;

&lt;p&gt;In what way are the organisation represented in this room different from more commercial organisations? &lt;/p&gt;

&lt;p&gt;The academic operation is not framed around a totally production oriented model, and this is one big way in which these are different.&lt;/p&gt;

&lt;h2 id=&quot;dave-pattern-university-of-huddresfield&quot;&gt;Dave Pattern University of Huddresfield,&lt;/h2&gt;
&lt;p&gt;These guys are using usage data. &lt;/p&gt;

&lt;p&gt;a path though the history of information in supermarkets:&lt;/p&gt;

&lt;p&gt;history of user data in retail
- stamps with prices
- barcode 
- stock control
- then there were loyalty cards for data mining across transaction history
	- customer profiling
	(will libraries ever do this kind of customer profiling, at the moment they don’t)&lt;/p&gt;

&lt;p&gt;what they do at huddersfield
- 22k students
- 2k staff
- 300k books
- 3M borrowing records&lt;/p&gt;

&lt;p&gt;not much had been done with this data, they stared playing around with this data
- people who borrowed this borrowed that
- initially they didn’t know if this would be useful
	a librarian dissed this as something that amazon does to sell books, not the kind of thing that a libarary should do.
- logged in giving users a history of what they borrowed recently
- show lending paths, which books got borrowed with books 
	(that’s brilliant,)&lt;/p&gt;

&lt;p&gt;they were also able to create new book lists for the entire library (lists of new books coming in to the library)&lt;/p&gt;

&lt;p&gt;they profiled the borrowing of students from a course, based on dewey numbers. as new books with those dewey numbers com in to the library, these get pushed to that class (also genius)&lt;/p&gt;

&lt;p&gt;on the front page of library catalog, they pushed in the most popular keywords onto the front page as a tag cloud. this seeded a spike at the start of the year on those keywords for new searches&lt;/p&gt;

&lt;p&gt;they can also push related keywords along with keyword search
	[[ this came up in the meeting on our new universal search bar ]] &lt;/p&gt;

&lt;p&gt;they have clickstream data, but they don’t know what to do with this yet.&lt;/p&gt;

&lt;p&gt;they know what they most popular keywords are that lead to a specific book, but they don’t know what to do with this data yet.&lt;/p&gt;

&lt;h1 id=&quot;measuring-the-impact&quot;&gt;measuring the impact&lt;/h1&gt;

&lt;p&gt;from 2005 their range of unique titles that are being borrowed go up from 65k to 80k in 2009, trend continues to rise, this comes from the layer of serendipity &lt;/p&gt;

&lt;p&gt;it’s not clear how much of this increase comes from these new tools, but certainly it’s not driving to a homologous self similar borrowing behaviour&lt;/p&gt;

&lt;p&gt;also average number of books per student is going up
	[[ how was that number calculated, as a student average, or based on per student numbers ]]&lt;/p&gt;

&lt;p&gt;more book-loans correlate with better grades &amp;lt;- this is very interesting. &lt;/p&gt;

&lt;h1 id=&quot;sharing-data&quot;&gt;sharing data&lt;/h1&gt;

&lt;p&gt;giving the data to students in a BA design course, and creating interesting visualisations &lt;/p&gt;

&lt;p&gt;at the end of 2008 they released book circulation recommendation data. 
it’s important to attach a licence with the data, they are using an opendata licence, public domain,&lt;/p&gt;

&lt;p&gt;within a couple of days someone created a semantic representation of the data. &lt;/p&gt;

&lt;p&gt;“the coolest thing to do with your data will be thought of by someone else” - Rufus Pollock. &lt;/p&gt;

&lt;h1 id=&quot;summary&quot;&gt;summary&lt;/h1&gt;

&lt;h1 id=&quot;qa&quot;&gt;QA&lt;/h1&gt;

&lt;p&gt;Q what kind of conversations have you had with your academics
A the attitude was less why should we, and more why shouldn’t we, academic feedback has been positive&lt;/p&gt;

&lt;p&gt;Q from paul walk, data needs to be managed because raw low quality data is not useful&lt;/p&gt;

&lt;p&gt;Q Richard Geddis, OUP, Counter, and something else
	would it be less easy to do recommendation for journal articles than for books, 
	talking about&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[[ how many books with dewey codes are represented in our catalog? ]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;theres-something-going-on-title-of-the-first-debate&quot;&gt;There’s something going on, title of the first debate&lt;/h2&gt;

&lt;h1 id=&quot;ken-chad&quot;&gt;ken chad&lt;/h1&gt;
&lt;p&gt;point is “how can libs make better us of the data that they have, great rich bibliographic data”.&lt;/p&gt;

&lt;p&gt;it’s not an ‘it’, the data is valuable, is libs don’t use this, then perhaps someone else will (facebook). &lt;/p&gt;

&lt;h1 id=&quot;paul-millar&quot;&gt;paul millar&lt;/h1&gt;
&lt;p&gt;have been concentrating on measuring activity in the systems that libs have, but perhaps been missing the context. as we get a point where we can do something interesting with activity data, perhaps we won’t need it as we will have other ways of getting recommendations.&lt;/p&gt;

&lt;p&gt;with social networks people are becoming the entry points into … ? what? 
how do we accommodate social networks into libs approach going forward&lt;/p&gt;

&lt;p&gt;business intelligence needs context to be useful. 
context is not easily derived from a single system
there needs to be ways of adding context from different systems
	[[ perhaps one should mention the work being done by Ciro’s group?? ]]&lt;/p&gt;

&lt;p&gt;user should have control, the ability to add value to a system
he mentions that there are risks involved, anonymity can be reverse engineered
	(reminds me of paper on network anonymity)&lt;/p&gt;

&lt;p&gt;who should own the attention data?	
	[[ mention pubsubhubbub ]]
	an open licence
	a trusted party
	the government
	google?&lt;/p&gt;

&lt;p&gt;is afraid that we will go through a centralised service, like facebook, initially &lt;/p&gt;

&lt;h1 id=&quot;richard-nurse&quot;&gt;richard nurse&lt;/h1&gt;
&lt;p&gt;approach it from a business intel point of view, rather that the user data. &lt;/p&gt;

&lt;p&gt;is it in the best interest of the institution?&lt;/p&gt;

&lt;p&gt;essential message is that institutions need to be more pro-active.&lt;/p&gt;

&lt;p&gt;four key reasons for why institutions should get involved&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;diversity of users&lt;/li&gt;
  &lt;li&gt;direction though data, navigation through that data&lt;/li&gt;
  &lt;li&gt;degree of control &lt;/li&gt;
  &lt;li&gt;duty of service, because of public investment &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;there are risks, privacy, legal etc, but these also depend on institutional policy&lt;/p&gt;

&lt;p&gt;need selectivity on which users institutions address&lt;/p&gt;

&lt;p&gt;if institutions don’t build an understanding on this information, then others may step in and create services in their stead (could end up working in partnership, but at least institutions need to have a seat at that table.)&lt;/p&gt;

&lt;p&gt;Q&amp;amp;A session for this debate:&lt;/p&gt;

&lt;p&gt;Joy Patten from MIMAS
	do institutions have the level of data that huddersfield have
		some have and some don’t (TILES project)
	then at what point do you need to look at a national strategy
	what do we know of the goldmine of data?
	(that seems like a silly point)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A: informed by the maturity of systems
	(I would say that it has to related to the prevalence and openness of identifiers)
Paul Millar opposed the idea of aggregating this kind of data.
is afraid of having the data cornered by commercial institutions
this leads to him wanting to see the data centralised and control

[[ send notes to David Kay ]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;debate-2-love-data-hate-silos&quot;&gt;debate 2, love data, hate silos&lt;/h2&gt;

&lt;p&gt;open university case study&lt;/p&gt;

&lt;p&gt;most students are not on campus, they are not registered with the LMS&lt;/p&gt;

&lt;p&gt;Richard Nurse leads a discussion about the kind of systems that students use, leads a discussion about what kind of information students might interact with, listed on whiteboard 
	[[ take a photo of this ]]&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;there are a huge number of sources for data
	e.g. 
	reading lists
	borrowing systems
	site access
	access control systems
	VLE data

	uk borders agency have a requirement to know what points of contact people  on student visas have with the institute? (need 10 per year)

an interesting question is how accessible is this data
	people have a day job, and getting the data out requires time

someone asks &quot;why are libraries collecting this data?&quot;
if it is used for business intel for institutions
  
Q: do these data exist in a way that can be pulled together?
	- yes, but there is a ?? on showing that one can be trusted with this data
	Manchester Metropolitan have created uniview (a students record driven data set, they are now starting to mash that up with VLE click data, and that is giving interesting information on success, 
	e.g. don&#39;t fiddle with the VLE area
	if staff put too much information into a VLE there is a negative impact on student performance

	context is everything for interpreting this data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;there is a lot of evidence that students prefer to interact with others and teachers through 3rd spaces, social networking spaces, such as facebook.&lt;/p&gt;

&lt;p&gt;students like groups, but they don’t want the institutional activity to appear directly on their spaces on facebook&lt;/p&gt;

&lt;p&gt;interesting questions:
	would any of these people consider opening up some more of this data as “open data”
	(somewhat of a stunned silence)&lt;/p&gt;

&lt;p&gt;interesting point, will government enthusiasm for open data affect universities 
	- teaching quality information should be made available, for instance&lt;/p&gt;

&lt;p&gt;OU have started thinking about mining this, using SFX for instance
one of the big problems is getting access to that data, the structures that manage things like the VLE are not directly involved in doing this investigation, so you need to get high enough up on their agenda.&lt;/p&gt;

&lt;p&gt;one could go an look at user generated content, book reviews from amazon, for instance.&lt;/p&gt;

&lt;p&gt;have started to use google apps, are thinking about building custom apps for their users&lt;/p&gt;

&lt;p&gt;my comment - identifiers are key&lt;/p&gt;

&lt;p&gt;other comment - data warehouses are hugely valuable.
	comment: these are mainly being built at the moment for institutions to make institutional decisions&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;not currently being thought of as being used to drive student services, but one could get that in via the back door.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;debate-4-appropriate-or-inappropriate-use-legal-issues&quot;&gt;debate 4, appropriate or inappropriate use, legal issues&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;privacy is not the issue, control is&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;some opening remarks, &lt;/p&gt;

&lt;p&gt;the landscape of the data is not simple, all of these cases will apply, open/closed legal/illegal appropriate/inappropriate &lt;/p&gt;

&lt;p&gt;often some of this is related to catalog entries, who creates the catalog entry.&lt;/p&gt;

&lt;p&gt;all of the data under discussion is currently under the control of institutions.&lt;/p&gt;

&lt;p&gt;there are clear legal provisions
	17 yo students are children
		adds requirements to what you can do with data&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;privacy

access
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;comment, legal requirements can change. 
mentions the downstream dilemma, &lt;/p&gt;

&lt;p&gt;naomi klein – works on IP, and has looked at IP and bibliographic information. &lt;/p&gt;

&lt;p&gt;mentioned that the information commissioner has issued a guidance that you should treat any such information as personal information&lt;/p&gt;

&lt;p&gt;jisc legal mentioned some guidelines&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;need to keep personal data secure&lt;/li&gt;
  &lt;li&gt;there is a danger of triangulation &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;question what are we risking by not doing something with this data?&lt;/p&gt;

&lt;p&gt;a: we risk missing opportunities to cross reference data, and to create new connections.&lt;/p&gt;

&lt;p&gt;conversation reverts to legal FUD discussions&lt;/p&gt;

&lt;p&gt;one risk in not doing anything is getting labelled that ones institution is not innovating, and hence not providing value for money.&lt;/p&gt;

&lt;h2 id=&quot;feedback-from-two-evening-debates&quot;&gt;feedback from two evening debates&lt;/h2&gt;

&lt;p&gt;questions about evidence and whether we should “just do it”&lt;/p&gt;

&lt;p&gt;Elib was the 1000 flowers bloom approach&lt;/p&gt;

&lt;p&gt;there is a fear here that funding is going to be reduced, so not doing this is going to be a road to ruin,&lt;/p&gt;

&lt;p&gt;doing these things is going to be a need to do thing, in order to enhance the learning experience.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;increase student satisfaction&lt;/li&gt;
  &lt;li&gt;increase student progression&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;this means service delivery, and learning enabling need to focus on tools (?) that can drive satisfaction and progression.&lt;/p&gt;

&lt;h2 id=&quot;afternoon-session&quot;&gt;afternoon session&lt;/h2&gt;

&lt;p&gt;interm report on mosaic&lt;/p&gt;

&lt;p&gt;they are looking to build a version built on lucene, hadoop and linked data.&lt;/p&gt;

&lt;p&gt;mark@headtech.com&lt;/p&gt;

&lt;h2 id=&quot;mark-toole-director-of-stirling-information-services-richard-korn-ou-naomi-klein-legal&quot;&gt;mark toole (director of stirling information services), richard korn OU, naomi klein legal&lt;/h2&gt;

&lt;h1 id=&quot;mark-toole&quot;&gt;Mark Toole&lt;/h1&gt;
&lt;p&gt;some benefits 
	is a fascinating area
	could see some things that could be made&lt;/p&gt;

&lt;p&gt;some costs
	biggest cost is priority, working on this stops him working on other things. 
	how do the benefits from this contribute more than resources put into other efforts, buying more books, for instance.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;in the end, there is not enough quantifiable evidence, we need more real case studies.

comment: challenge the idea that there is not enough evidence. 
	there is a large body of existing data, e.g. known algorithms, amazon, understanding of privacy issues. it might be outside of the sector at the moment, perhaps we need within sector examples [[ our expert finder could be a good example within this context ]]
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;richard-korn-open-university&quot;&gt;richard korn, open university&lt;/h1&gt;

&lt;pre&gt;&lt;code&gt;nice quotes from wall-mart, google, and ms, data should be used to change the services that produce the data, not simply seen as a by-product of the data.

mentions SFX, are thinking of playing around with an api to improve this.

nice example from search results. 

Telstar is using SFX to link to resources

linked data for OU content, Lucero

slideshare.net/richardnurse
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&quot;naomi-klein-getting-business-intelligence-from-user-activity-data-legal-challenges&quot;&gt;naomi klein, getting business intelligence from user activity data, legal challenges&lt;/h1&gt;

&lt;p&gt;areas of law that touch on this&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;DP act 1998&lt;/li&gt;
  &lt;li&gt;human rights act&lt;/li&gt;
  &lt;li&gt;right of privacy&lt;/li&gt;
  &lt;li&gt;database rights&lt;/li&gt;
  &lt;li&gt;contract law&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;with minors there are further issues&lt;/p&gt;

&lt;p&gt;there may be IP rights associated with a ‘mere fact’ if it is collated in a DB, or if it has been enhanced through a process, e.g. recommended &lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;built a tool hosted by jisc legal that gives info on IP rights on bibliographic data&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;the data may be provided under contract from a 3rd party, you may be bound by those contractual obligations.&lt;/p&gt;

&lt;p&gt;Data Pretension act in a nutshell:
	if the individual can be identified it is classed as personal data&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;there are a a few debates about this issue

if it is personal data, you need consent

JISC legal is publishing a report on consent management

institutions may have a get out clause, regarding requirement to provide services (was that right?)

look at web2rights toolkit
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mentions cultural fear in the face of data protection issues, very good point, one should not be frozen into inaction, with the appropriate information it is possible to navigate these issues.&lt;/p&gt;

&lt;p&gt;when might activity data be personal data?&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;- cloud computing and personal data
	if the information is processed externally, and can be tracked back to an individual

- use of social networking

- google and usage data, e.g. search data.
	triangulation

- library activity data
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;recommendation
	- any info that provides an indication of a users’ online activity should be treated as peronal data, even if individual can\t be identified&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;role of passing on user data to 3rd bpodies
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the role of the institution:&lt;/p&gt;

&lt;p&gt;bottom line
	need to ensure that you have consent before processing personal data&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;anonymous data still needs to be checked against risk of triangulation.
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;evening-session-making-recommendations-for-jisc-activity-on-a-national-level&quot;&gt;evening session making recommendations for JISC activity on a national level,&lt;/h2&gt;

&lt;p&gt;we need to give some concrete suggestions on a national level:&lt;/p&gt;

&lt;p&gt;davep produced data, and the world didn’t end 
data model from jisc mosaic project
there is potential for legal advice&lt;/p&gt;

&lt;p&gt;is next step then is to encourage the creation of more services??
clarify what we have&lt;/p&gt;

&lt;p&gt;thinking nationally, what is the case?&lt;/p&gt;

&lt;p&gt;can we give more compelling business cases,
mosaic project ran into trouble with senior stakeholder buy-in&lt;/p&gt;

&lt;p&gt;again the connection between item usage and performance indicators is hi-lighted as being hugely important. &lt;/p&gt;

&lt;p&gt;the performance data is contained in something like a VLE, &lt;/p&gt;

&lt;p&gt;HESA data provides something in the public record, though it may be in a somewhat convoluted form.&lt;/p&gt;

&lt;p&gt;many systems are not even collecting data at the moment, they sort of need to collect the data if they want to use it at some point.&lt;/p&gt;

&lt;h2 id=&quot;recommendations&quot;&gt;recommendations&lt;/h2&gt;

&lt;h1 id=&quot;national-infrastructure&quot;&gt;national infrastructure&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;find a way to test the hypothesis that extending the data towards a national level could provide value&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;get institutions to start tracking this data, for if they don’t they can’t use the data in the future, should they wish to&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;learning--research-recommendations&quot;&gt;learning &amp;amp; research recommendations&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;cookbooks for VLES, how do you get activity data out of these vendor systems&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;who are the stakeholders that need to be won over? involve them, they may have some experience to lend to the issue&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;researchers are a problem, they go about community building in a totally different way, they may be looking to things like Medneley to get information about research communities, rather than something like the VLE&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;library-and-local-collections&quot;&gt;library and local collections&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;concern of duplication of effort, need and a desire to share knowledge, so for example methods for getting data out of systems can be shared&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;need some case studies that could support the anecdotal stories&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;concern that we don’t know what data we are going to share, address this with a survey to see what’s been done, and what can be done in library systems. &lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;who is the authority on this, if it’s not dave, who is it?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;something about this and books, and numbers of books, missed that bit.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;discussions around reading lists, and how useful students find these to be, some lecturers have IP around their reading lists, making this difficult to share.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;specific recommendations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;need to profile student behaviour in terms of e-resources, not just books&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;need strong evidence that library services are integral to learning, and not just an addon.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;open source systems&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;if we share our data others will find the interesting things within the data. &lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;end-comments&quot;&gt;end comments&lt;/h1&gt;

&lt;p&gt;this community needs to be accountable, usage stats and services built around that can be one way to do that &lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Read mail in intervals on OS X</title>
   <link href="http://partiallyattended.com/2010/07/05/checking-mail-infrequently"/>
   <updated>2010-07-05T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/07/05/checking-mail-infrequently</id>
   <content type="html">&lt;p&gt;In order to check mail less frequently than the options available, following a hint from macosxhints:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;set up an applescript to tell mail to check for mail.&lt;/li&gt;
  &lt;li&gt;put that script under a launchd deamon with an interval&lt;/li&gt;
  &lt;li&gt;use lingon to setup the deamon&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;so far it seems to be working, yay!&lt;/p&gt;

&lt;p&gt;http://www.macosxhints.com/article.php?story=20010427022452992&lt;/p&gt;

&lt;p&gt;use &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>my first post</title>
   <link href="http://partiallyattended.com/2010/07/03/my-very-first-test-post-with-jekyll"/>
   <updated>2010-07-03T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/07/03/my-very-first-test-post-with-jekyll</id>
   <content type="html">&lt;h1 id=&quot;im-trying-to-understand-jekyll-here&quot;&gt;I’m trying to understand jekyll here&lt;/h1&gt;

&lt;p&gt;It &lt;em&gt;seems&lt;/em&gt; to be quite nice, let’s see how we get on!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>hackney are fuckers.</title>
   <link href="http://partiallyattended.com/2010/05/12/hackney-are-fuckers"/>
   <updated>2010-05-12T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/05/12/hackney-are-fuckers</id>
   <content type="html">http://www.whatdotheyknow.com/request/31711/response/79454/attach/html/3/1%202181984%2020100407%204th%20Tier%20List.xls.html&lt;br /&gt;&lt;br /&gt;fast food in hackney&lt;br /&gt;http://www.whatdotheyknow.com/request/27794/response/68154/attach/html/3/1%201952373%20Information%20Sheet.xls.html
</content>
 </entry>
 
 <entry>
   <title>Edinburgh, first draft</title>
   <link href="http://partiallyattended.com/2010/05/04/Edinburgh,-first-draft"/>
   <updated>2010-05-04T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/05/04/Edinburgh,-first-draft</id>
   <content type="html">I don&#39;t post my poetry often, indeed I don&#39;t write often, but I thought this one came out OK. Written over the past weekend for a good friend on the occasion of her birthday.&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;br /&gt;Edinburgh, first draft, 01/05/2010&lt;br /&gt;&lt;br /&gt;for andrea.&lt;br /&gt;&lt;br /&gt;Was it in Summer, when I lost myself among the graveyards?&lt;br /&gt;The moss covered steps of Greyfriars green and gleaming.&lt;br /&gt;&lt;br /&gt;Or was it someone&#39;s winter night along cobbled streets, &lt;br /&gt;where buildings wear a sharp puritan cut to their overcoats?&lt;br /&gt;Hightailing it though the cold from one warm pub to the next.&lt;br /&gt;&lt;br /&gt;Could it have been an Edinburgh Spring?&lt;br /&gt;Beltaine roared along High Street in the gloaming&lt;br /&gt;The burning processing smoking up the back of Calton Hill&lt;br /&gt;A firebreather bellowed,&lt;br /&gt;Gouts of flame framed faces.&lt;br /&gt;&lt;br /&gt;If not in these times, &lt;br /&gt;then it must have been an Autumn loamy wet and windswept afternoon.&lt;br /&gt;Sitting in the back of an Elephant,&lt;br /&gt;last light out of the west washing against the castle.&lt;br /&gt;&lt;br /&gt;It threaded itself, wound round us,&lt;br /&gt;as we wandered Whitehouse Loan,&lt;br /&gt;High Riggs, West Port, and up the Vennel Steps. &lt;br /&gt;&lt;br /&gt;In such moments that city passed beyond us being there,&lt;br /&gt; and into our dreams.&lt;br /&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>A mini rant about LaTeX</title>
   <link href="http://partiallyattended.com/2010/04/29/A-mini-rant-about-LaTeX"/>
   <updated>2010-04-29T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/04/29/A-mini-rant-about-LaTeX</id>
   <content type="html">&lt;p&gt;&lt;br /&gt;Here is a comment I&#39;ve just posted to a comment thread about LaTeX over here: http://blogs.nature.com/farhat/2010/04/16/collaborative-editing-with-latex. One of the commenters asked &quot;Why not just use a word processor&quot;&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;Just using a word processor simply does not cut it when it comes to expressing complex mathematical ideas. LaTeX, and it&#39;s precursor TeX, have evolved to be the only tools that can currently express the richness of the ideas within advanced mathematics. Whether this is a good thing or not is moot, it&#39;s simply the case, so that&#39;s one reason to use LaTeX.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;A huge advantage of using a text only tool is keeping different versions of a document, and diffing between versions, is much easier than the horror that is &quot;Track Changes&quot; on most editors. Many groups I know keep their papers as LaTaX files in a code repository and use a system such as SVN for collaboration. This is not a benefit of LaTeX specifically, and is way beyond what most people would do with it, however the need for this kind of ability with the objects upon which we collaborate is painfully clear, and is only starting to be address in the &quot;rich document&quot; space with services such as Google Wave and Google Docs.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;Ideally one would like to be able to write one&#39;s equations directly into the computer. For the time being LaTeX provides an expressive syntax from the keyboard that translates into mathematics on the screen. The iPad may well change this, but I suspect that any solution that takes handwriting and converts it to marked up mathematics will be built on top of the excellent codebase that is the LaTeX framework. This would be an excellent example of the DRY formalism (don&#39;t repeat yourself), build it on top of that which already works. For an example of a web app that does this already have a look at: &lt;br /&gt;http://detexify.kirelabs.org/classify.html.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;Richard is right that not separating the semantics from the presentation is a weakness. Sadly one issue is that a single equation or symbol can actually mean different things. The closest tool there is to encapsulate the semantics of mathematics is the semantic version of MathML. No one writes this by hand. The best tools for producing semantic MathML (as opposed to the presentation version of MathML), do so by translating from human input in the form of, yes you guessed it, LaTeX.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;In spite of being semantically dumb there are a couple of interesting web services that build on top of the fact that there is a huge community of people out there who speak LaTeX. http://www.mathtran.org/formulas/ allows people to share formulas. http://www.latexsearch.com/ allows you to search through Springer&#39;s archive of mathematics. Springer has the most extensive archive of mathematical literature in the world, so that is no mean feat.&lt;br /&gt;&lt;/p&gt;&lt;p&gt;&lt;br /&gt;The last thing I will say is that LaTeX is just awesome. It produces beautiful documents. It is akin to learning a programming language, but then, if you are doing serious mathematics, it&#39;s just another symbol set, it&#39;s not that hard, really. I guess if you are doing something soft and not so well defined, then a word processor is going to be good enough for you.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>creating a tumblog</title>
   <link href="http://partiallyattended.com/2010/04/13/creating-a-tumblog"/>
   <updated>2010-04-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2010/04/13/creating-a-tumblog</id>
   <content type="html">After a few conversations with @zzgavin, I&amp;#39;ve come to the conclusion&lt;br&gt;that there is a place for a tumblog in the toolkit of those who like&lt;br&gt;to post content onto the web. There are often pieces of content that I&lt;br&gt;want to call out, but don&amp;#39;t have either the time or the interest to&lt;br&gt;write a longer blog post about.  For a while I thought that would be a&lt;br&gt;good use of Twitter, but in the end that type of behaviour just&lt;br&gt;pollutes your twitter feed. Indeed, posting a link to an image is&lt;br&gt;never as immediate as posting the image itself.&lt;p&gt;This blog will remain a repository when I want to say something&lt;br&gt;coherent that is about 140 characters. My twitter feed will continue&lt;br&gt;to respond to the question of what it is that I am doing, combined&lt;br&gt;with it&amp;#39;s use as a lightweight communication network. My tumblelog&lt;br&gt;will henceforth be an online digital clipboard of links, quotes and&lt;br&gt;images that tickle my fancy.&lt;p&gt;If you are so interested you may check it out at:&lt;p&gt;&lt;a href=&quot;http://attention-deficit.tumblr.com/&quot;&gt;http://attention-deficit.tumblr.com/&lt;/a&gt;
</content>
 </entry>
 
 <entry>
   <title>The three ages of Elvis in potatoes!</title>
   <link href="http://partiallyattended.com/2010/03/22/The-three-ages-of-Elvis-in-potatoes!"/>
   <updated>2010-03-22T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/03/22/The-three-ages-of-Elvis-in-potatoes!</id>
   <content type="html">&lt;div style=&quot;float: right; margin-left: 10px; margin-bottom: 10px;&quot;&gt;&lt;a href=&quot;http://www.flickr.com/photos/gioia/4449671797/&quot; title=&quot;photo sharing&quot;&gt;&lt;img src=&quot;http://farm3.static.flickr.com/2702/4449671797_23009e7dfd_m.jpg&quot; alt=&quot;&quot; style=&quot;border: solid 2px #000000;&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span style=&quot;font-size: 0.9em; margin-top: 0px;&quot;&gt;&lt;a href=&quot;http://www.flickr.com/photos/gioia/4449671797/&quot;&gt;potato_3stagesElvis 004&lt;/a&gt;&lt;br /&gt;Originally uploaded by &lt;a href=&quot;http://www.flickr.com/people/gioia/&quot;&gt;gioia_&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;On Saturday we went to a party thrown by some friends of ours. It was kind of a delayed St. Patrick&#39;s day party, and everyone had to bring along a potato dressed up as a celebrity, or some such.&lt;br /&gt;&lt;br /&gt;We created our potato after the Father Ted episode &quot;Competition Time&quot;, in which Ted, Dougal and Jack dress up as the three ages of Elvis. The third age in this little diorama is made up from mashed spud in a sock.&lt;br /&gt;&lt;br /&gt;After an intense voting round, we were finally pushed out of 3rd place by St Patrick. The winner was Spudward, which looked disconcertingly like the pop group with it represented.&lt;br clear=&quot;all&quot; /&gt;
</content>
 </entry>
 
 <entry>
   <title>Kierkegaard, forgetting and existence</title>
   <link href="http://partiallyattended.com/2010/03/17/Kierkegaard,-forgetting-and-existence"/>
   <updated>2010-03-17T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/03/17/Kierkegaard,-forgetting-and-existence</id>
   <content type="html">Reading though the excellent introduction to Kierkegaard&amp;#39;s philosophy&lt;br&gt;in the Guardian&lt;br&gt;(&lt;a href=&quot;http://www.guardian.co.uk/commentisfree/belief/2010/mar/15/kierkegaard-philosophy-existentialism&quot;&gt;http://www.guardian.co.uk/commentisfree/belief/2010/mar/15/kierkegaard-philosophy-existentialism&lt;/a&gt;),&lt;br&gt;it is pointed out that one of the key underlying principles of his&lt;br&gt;philosophy is that we have forgotten what it means to exist, and that&lt;br&gt;the cause of this forgetting is the ever growing amount of knowledge&lt;br&gt;in the world (a state of affairs that is now ever more apparent even&lt;br&gt;than in his time).&lt;p&gt;I am dubious about this claim.  I think it likely that we have always&lt;br&gt;been forgetting this questions.  In the trials of agrarian society the&lt;br&gt;question is pushed aside by concerns of the harvest.  In the hold of a&lt;br&gt;religious society such questions are givens and not open to&lt;br&gt;inspection. It&amp;#39;s always a hard question, and I&amp;#39;m sure that modernism&lt;br&gt;causes it&amp;#39;s disappearance more than any other state.  Of course I&lt;br&gt;could be wrong.
</content>
 </entry>
 
 <entry>
   <title>Python PEP for a graph API</title>
   <link href="http://partiallyattended.com/2010/02/19/Python-PEP-for-a-graph-API"/>
   <updated>2010-02-19T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/19/Python-PEP-for-a-graph-API</id>
   <content type="html">I just stumbled across this&lt;br&gt;&lt;a href=&quot;http://wiki.python.org/moin/PythonGraphApi&quot;&gt;http://wiki.python.org/moin/PythonGraphApi&lt;/a&gt;. I think it&amp;#39;s great. The&lt;br&gt;discussion has actually been going on since Aug 2004, so I don&amp;#39;t know&lt;br&gt;what the status of this PEP is. I would love to see something come out&lt;br&gt;of it eventually.&lt;p&gt;tags: graph, PEP, python</content>
 </entry>
 
 <entry>
   <title>Probabilistic language models, auto-correction tools and scientific discovery.</title>
   <link href="http://partiallyattended.com/2010/02/10/Probabilistic-language-models-auto-correction-tools-and-scientific-discovery"/>
   <updated>2010-02-10T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/10/Probabilistic-language-models-auto-correction-tools-and-scientific-discovery</id>
   <content type="html">Probabilistic language models, auto-correction tools and scientific discovery.&lt;br /&gt;&lt;br /&gt;&quot;Durgesh Kumar Dwivedi&quot;:http://network.nature.com/people/U56CB3E51/profile over on Nature Network just asked &quot;Does anyone have any software or web address which corrects English grammar, preposition, edit and shortened the paragraphs?&quot;. This question brought to mind and idea that I had a few years ago.&lt;br /&gt;&lt;br /&gt;The idea is simple enough, use a large corpus of pre-vetted grammatically correct text as a training tool to compare sentences against. If you have enough example sentences, then every occurrence of every word in a given sentence will have a certain likelihood of occurring. Errors, and new word formulations will have low probabilities of occurring. Compare a manuscript that is being prepared for submission against the corpus and the machine should be able to point out the parts that may be either wrong or novel. Some kind of a Bayseian model would seem to be appropriate.&lt;br /&gt;&lt;br /&gt;Now for natural language it is probably the case that there are not enough overlaps of complete sentences (though there may well be of phrases). However if you look at the academic literature then the scope of language used is very much reduced. The scientific literature in particular adopts an inbred subset of the English language, it&#39;s very own ghetto. One could image, for instance, taking all of the content of all articles published by Nature over the past 30 years, and use this as the control corpus. The person submitting a manuscript would get, on return of submission, a markup of where in their text there may be errors, with in addition perhaps, the most common forms of sentences that are found in their place. &lt;br /&gt;&lt;br /&gt;I don&#39;t imagine that such a service would come into existence any time soon, but I think it would be cool. One could also use something like this to automatically recommend references or related papers. The &quot;Journal Author Name Estimator&quot;:http://www.biosemantics.org/jane/ already does something like this for abstracts. &lt;br /&gt;&lt;br /&gt;There is a wealth of research on probabilistic language models (see below), but I don&#39;t think anyone has tried out the idea proposed here.&lt;br /&gt;&lt;br /&gt;It came to me after a few years working in a copy editing department of a scientific publisher. Again and again we would see the same kinds of corrections happening, and it just seems like an area ripe for automation. &lt;br /&gt;&lt;br /&gt;&quot;Using a probabilistic translation model for cross-language information retrieval&quot;:http://eprints.kfupm.edu.sa/74398/&lt;br /&gt;&lt;br /&gt;&quot;Language Analysis and Understanding&quot;:http://cslu.cse.ogi.edu/HLTsurvey/ch3node2.html&lt;br /&gt;&lt;br /&gt;&quot;A Parallel Training Algorithm for Hierarchical Pitman-Yor Process Language Models&quot;:http://www.cstr.ed.ac.uk/downloads/publications/2009/sh_interspeech09.pdf&lt;br /&gt;&lt;br /&gt;A Bayesian network coding scheme for annotating biomedical information presented to genetic counseling clients &quot;doi:10.1016/j.jbi.2004.10.001&quot;:http://dx.doi.org/10.1016/j.jbi.2004.10.001&lt;br /&gt;&lt;br /&gt;&quot;Phrase-Based Statistical Language Modeling from Bilingual Parallel Corpus&quot;:http://www.springerlink.com/content/b4ujx41571p47082/&lt;br /&gt;&lt;br /&gt;&quot;Bayesian Modeling of Dependency Trees Using Hierarchical Pitman-Yor Priors&quot;:http://videolectures.net/icml08_wallach_bmd/&lt;br /&gt;&lt;br /&gt;&quot;Using language models for tracking events of interest over time&quot;:http://boston.lti.cs.cmu.edu/callan/Workshops/lmir01/WorkshopProcs/Papers/mspitters.pdf</content>
 </entry>
 
 <entry>
   <title>4 ways to set the heigth of your open social gadget</title>
   <link href="http://partiallyattended.com/2010/02/08/4-ways-to-set-the-heigth-of-your-open-social-gadget"/>
   <updated>2010-02-08T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/08/4-ways-to-set-the-heigth-of-your-open-social-gadget</id>
   <content type="html">You have a couple of options for setting the height of your gadget. I&#39;ll run through four methods that seem to work. First two words of caution, if you are using the eclipse plugin to develop on, you won&#39;t see the second method described here working. I don&#39;t know why, but the code works in iGoogle, so it must be something to do with the eclipse OSDE env. The second word of warning is that the syntax hilighter I&#39;m using on this post chokes on CDATA tags, so the CDATA tags in the code examples are wrong. I&#39;ve posted links to the sample gadgets at the end of this post, and you can get the samples there if you like. With those caveats, let us press on:&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;1. Don&#39;t do anything&lt;/h2&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;a href=&quot;http://open-social-experiments.appspot.com/static/t1.xml&quot;&gt;sample 1 gadget code&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;The basic code below gives no specification for height. The container will default to 200px. &lt;br /&gt;&lt;br /&gt;&lt;pre class=&quot;brush: html&quot;&gt; &lt;br /&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;br /&gt;&lt;Module&gt;&lt;br /&gt;    &lt;ModulePrefs&lt;br /&gt;            title=&quot;t1&quot;&lt;br /&gt;            author_email=&quot;ian.mulvany@gmail.com&quot;&gt;&lt;br /&gt;        &lt;Require feature=&quot;opensocial-0.8&quot; /&gt;&lt;br /&gt;    &lt;/ModulePrefs&gt;&lt;br /&gt;    &lt;Content type=&quot;html&quot; view=&quot;profile,home&quot;&gt;&lt;br /&gt;    &lt;br /&gt;    &lt; ![CDATA[&lt;br /&gt;&lt;br /&gt;&lt;div id=&quot;container&quot;&gt;&lt;br /&gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;br /&gt;&lt;br /&gt;...&lt;br /&gt;&lt;br /&gt;Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.&lt;br /&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;    ]]&gt;&lt;br /&gt;    &lt;/Content&gt;&lt;br /&gt;&lt;/Module&gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;All of the code after the content div in these examples is the same, so I&#39;m omitting in  the rest of the examples below.&lt;br /&gt;&lt;br /&gt;&lt;h2&gt;2. Hardcode the height.&lt;/h2&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;a href=&quot;http://open-social-experiments.appspot.com/static/t2.xml&quot;&gt;sample 2 gadget code&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;Pretty simple, tell the container exactly how big you content is going to be. For this example I knew that 400px was not going to be bog enough for the content that I wanted to display, so I added a scrollbar, easy!&lt;br /&gt;&lt;br /&gt;&lt;pre class=&quot;brush: html&quot;&gt; &lt;br /&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;br /&gt;&lt;Module&gt;&lt;br /&gt;    &lt;ModulePrefs title=&quot;t2&quot; &lt;br /&gt;   author_email=&quot;ian.mulvany@gmail.com&quot; &lt;br /&gt;   height=&quot;400&quot; &lt;br /&gt;   scrolling=&quot;true&quot;&gt;&lt;br /&gt;        &lt;Require feature=&quot;opensocial-0.8&quot; /&gt;&lt;br /&gt;    &lt;/ModulePrefs&gt;&lt;br /&gt;    &lt;Content type=&quot;html&quot; view=&quot;profile,home&quot;&gt;&lt;br /&gt;&lt;br /&gt;    &lt; ![CDATA[    &lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;3. Use the OpenSocial dynamic-height library&lt;/h3&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;a href=&quot;http://open-social-experiments.appspot.com/static/t3.xml&quot;&gt;sample 3 gadget code&lt;/a&gt;&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;Require the dynamic-height library, and then create a javascript function in your content section that calls the api. I&#39;ve added in a handler that works on the window onload event, but this is probably not the best use of this method. You probably want to be doing it in response to some other event that will dynamically be changing the content of the gadget.&lt;br /&gt;&lt;br /&gt;&lt;pre class=&quot;brush: html&quot;&gt; &lt;br /&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;br /&gt;&lt;Module&gt;&lt;br /&gt;    &lt;ModulePrefs&lt;br /&gt;            title=&quot;t3&quot;&lt;br /&gt;            author_email=&quot;ian.mulvany@gmail.com&quot;&gt;&lt;br /&gt;        &lt;Require feature=&quot;opensocial-0.8&quot; /&gt;&lt;br /&gt;        &lt;Require feature=&quot;dynamic-height&quot;/&gt;&lt;br /&gt;    &lt;/ModulePrefs&gt;&lt;br /&gt;    &lt;Content type=&quot;html&quot; view=&quot;profile,home&quot;&gt;&lt;br /&gt;&lt;br /&gt;    &lt; ![CDATA[&lt;br /&gt;    &lt;br /&gt;        &lt;script type=&quot;text/javascript&quot;&gt; &lt;br /&gt;            function resize() {&lt;br /&gt;                gadgets.window.adjustHeight();&lt;br /&gt;            };&lt;br /&gt;            window.onload=resize;&lt;br /&gt;        &lt;/script&gt;&lt;br /&gt;&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;h3&gt;4. Use the OpenSocial-jquery library&lt;/h3&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;a href=&quot;http://open-social-experiments.appspot.com/static/t4.xml&quot;&gt;sample 4 gadget code&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;Almost exactly the same as method 3, except we use the opensocial-jquery library. If you are doing more with javascript this library seems to offer the simplicity of the jquery syntax, so for people who prefer this dialect of javascript it may be a very good option.&lt;br /&gt;&lt;br /&gt;&lt;pre class=&quot;brush: html&quot;&gt; &lt;br /&gt;&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;br /&gt;&lt;Module&gt;&lt;br /&gt;    &lt;ModulePrefs&lt;br /&gt;            title=&quot;t4&quot;&lt;br /&gt;            author_email=&quot;ian.mulvany@gmail.com&quot;&gt;&lt;br /&gt;        &lt;Require feature=&quot;opensocial-0.8&quot; /&gt;&lt;br /&gt;   &lt;Require feature=&quot;dynamic-height&quot; /&gt;&lt;br /&gt;    &lt;/ModulePrefs&gt;&lt;br /&gt;    &lt;Content type=&quot;html&quot; view=&quot;profile,home&quot;&gt;&lt;br /&gt;    &lt;br /&gt;    &lt; ![CDATA[&lt;br /&gt;    &lt;br /&gt;    &lt;script type=&quot;text/javascript&quot; src=&quot;http://scripts.lrlab.to/opensocial-jquery-1.3.2.5.min.js&quot;&gt;&lt;/script&gt;&lt;br /&gt;    &lt;script type=&quot;text/javascript&quot;&gt; &lt;br /&gt;        jQuery(function($) {&lt;br /&gt;            $(window).adjustHeight();&lt;br /&gt;        });&lt;br /&gt;    &lt;/script&gt;&lt;br /&gt;   &lt;br /&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>What's the right amount to charge for phone content?</title>
   <link href="http://partiallyattended.com/2010/02/04/What's-the-right-amount-to-charge-for-phone-content%3F"/>
   <updated>2010-02-04T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/04/What's-the-right-amount-to-charge-for-phone-content?</id>
   <content type="html">Having a discussion earlier today with one of my colleagues, we were&lt;br&gt;discussing pricing models for iPhone applications. I buy a lot of apps&lt;br&gt;on my iPhone, but the content that we were discussing pricing for is&lt;br&gt;academic article content. This traditionally sells online for tens of&lt;br&gt;dollars per unit. If one wants to sell such content on an iPhone, but&lt;br&gt;at the same time retain the apparent value of the content how do you&lt;br&gt;price it?&lt;p&gt;It&amp;#39;s a tough question, and unless you have a large stable of journals&lt;br&gt;of differential quality, it&amp;#39;s going to be hard to run a series of&lt;br&gt;experiments to test change in sales volume based on price&lt;br&gt;differentials.&lt;p&gt;My gut feeling is that to drive large, or even modest volumes, of&lt;br&gt;sales on a device like the iPhone the content has to be priced below&lt;br&gt;the level at which the buyer is even considering the economics of the&lt;br&gt;purchase. It has to pass my &amp;quot;is it less than a cup of coffee&amp;quot; test. If&lt;br&gt;it is then I&amp;#39;m not even going to think about the opportunity cost for&lt;br&gt;purchase. Of course this is where it gets problematic for academic&lt;br&gt;content. You could only sell minor academic content cheaply (like news&lt;br&gt;coverage), or content with a reduced fucntionality, or you could try&lt;br&gt;and go for some sweet spot pricing (the cost of a large latte with&lt;br&gt;extra cream and caramel topping kind of thing).&lt;p&gt;The iPad is likely to allow academic publishers to go ahead and just&lt;br&gt;try to sell their content at the prices that they think they can&lt;br&gt;charge for on the web, but I&amp;#39;d still love to see a radical re-think of&lt;br&gt;pricing for at least some types of content on handheld platforms.&lt;p&gt;tags: iphone, ipad, publishing, science, pricing, coffee
</content>
 </entry>
 
 <entry>
   <title>Identity systems, science and the internet</title>
   <link href="http://partiallyattended.com/2010/02/04/Identity-systems,-science-and-the-internet"/>
   <updated>2010-02-04T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/04/Identity-systems,-science-and-the-internet</id>
   <content type="html">I just posted the following on a forum&lt;br&gt;(&lt;a href=&quot;http://network.nature.com/groups/orcid/forum/topics/6547&quot;&gt;http://network.nature.com/groups/orcid/forum/topics/6547&lt;/a&gt;) on Nature&lt;br&gt;Network, I thought it was interesting enough to repost:&lt;p&gt;&lt;p&gt;Bruce Schneier yesterday posted a very &amp;quot;interesting&lt;br&gt;article&amp;quot;:&lt;a href=&quot;http://www.schneier.com/blog/archives/2010/02/anonymity_and_t_3.html&quot;&gt;http://www.schneier.com/blog/archives/2010/02/anonymity_and_t_3.html&lt;/a&gt;&lt;br&gt;that gets to the heart of identity systems on the web. The bottom line&lt;br&gt;of the article is that anonymity will always be a given as the price&lt;br&gt;for introducing verification or coining systems will always be too&lt;br&gt;high, and even if present they won&amp;#39;t be effective. Of course it is&lt;br&gt;just exactly such a system that ORCID is proposing to introduce. I&lt;br&gt;think there is a chance that it will work, as I believe that the&lt;br&gt;incentive system in science is stacked in favour or real identities,&lt;br&gt;however it does point to the idea that rather than real identities,&lt;br&gt;when we deal with online transactions (be they knowledge transactions&lt;br&gt;or social transactions), it is rather the scientific persona that we&lt;br&gt;should be supporting rather than nessecarrily the real identity of the&lt;br&gt;person.&lt;p&gt;That idea ties in with a discussion that has been going on in network&lt;br&gt;about whether we should allow personyms, and I read this other &amp;quot;very&lt;br&gt;good piece&amp;quot;:&lt;a href=&quot;http://jonathanstray.com/identity-anonymity-and-controlling-trolls&quot;&gt;http://jonathanstray.com/identity-anonymity-and-controlling-trolls&lt;/a&gt;&lt;br&gt;on that topic in the past week too which supports the idea of allowing&lt;br&gt;personyms, so long as they can be ascribed a trust score, but baulks&lt;br&gt;at the idea of forcing users to use their real identity.&lt;p&gt;For the good foreseeable future scientific identities are going to be&lt;br&gt;tied to real identities, but does anyone know of cases where&lt;br&gt;scientists have done good, acknowledged work under a pseudonym? Could&lt;br&gt;we imagine such a thing happening in the future? I know that sounds a&lt;br&gt;bit far fetched, but it&amp;#39;s happened already in the open source&lt;br&gt;community a number of times, notably with &amp;quot;why the lucky&lt;br&gt;stiff&amp;quot;:&lt;a href=&quot;http://en.wikipedia.org/wiki/Why_the_lucky_stiff&quot;&gt;http://en.wikipedia.org/wiki/Why_the_lucky_stiff&lt;/a&gt;.&lt;p&gt;tags: identity, science, ORCID
</content>
 </entry>
 
 <entry>
   <title>Cost benefit of publishing academic books,</title>
   <link href="http://partiallyattended.com/2010/02/04/Cost-benefit-of-publishing-academic-books"/>
   <updated>2010-02-04T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/04/Cost-benefit-of-publishing-academic-books</id>
   <content type="html">Nature has just published an editorial (&lt;a href=&quot;http://www.nature.com/nature/journal/v463/n7281/full/463588a.html&quot;&gt;http://www.nature.com/nature/journal/v463/n7281/full/463588a.html&lt;/a&gt;) promoting the idea of writing text books (&lt;a href=&quot;http://dx.doi.org/10.1038/463588a&quot;&gt;http://dx.doi.org/10.1038/463588a&lt;/a&gt;).&lt;br /&gt;Having worked for a number of years as a commissioning editor for a&lt;br /&gt;major academic publisher, responsible for more that 20% of academic&lt;br /&gt;book output, I have to say that the cost-benifit analysis for&lt;br /&gt;publishing books ends up saying that it just does not justify the&lt;br /&gt;effort for academics to write monographs. You probably won&#39;t see more&lt;br /&gt;than a few hundred sales, citations to the work will be slow in&lt;br /&gt;coming. Early career academics in particular are wasting valuable time&lt;br /&gt;that should be spent on getting publications out. That said there are&lt;br /&gt;three situations in which it might be OK to be involved in producing a&lt;br /&gt;book:&lt;p&gt;1. You are at an advanced stage in your career and you want to codify&lt;br /&gt;your vision of a particular subject. In such a case the work is a&lt;br /&gt;labour of love, you have your laurels and now you want to produce an&lt;br /&gt;artefact that synthesises your view on a topic. This is a highly&lt;br /&gt;valuable exercise, look at the works of Chandrasekhar for an extreme&lt;br /&gt;example of this. Of course, such an individual is going to go ahead&lt;br /&gt;and do this anyway.&lt;/p&gt;&lt;p&gt;2. You have been instructing a class and have put together a detailed&lt;br /&gt;set of instructional notes, especially for advanced classes in&lt;br /&gt;graduate school. For a little more effort you can convert a large&lt;br /&gt;batch of work that you have already done into another artefact that&lt;br /&gt;can increase your academic reputation, go for it!&lt;/p&gt;&lt;p&gt;3. You are involved in a large consortium or working group. The act of&lt;br /&gt;putting together a chapter for a book can cement working&lt;br /&gt;relationships. What tends to be more important here though is the&lt;br /&gt;collaborative process, more-so than the final artefact. The question&lt;br /&gt;to be asked should be whether working with the given group of&lt;br /&gt;academics is worth the time, rather than whether the final book will&lt;br /&gt;be worth the time involved.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Banks and Credit Card companies are fuckers</title>
   <link href="http://partiallyattended.com/2010/02/04/Banks-and-Credit-Card-companies-are-fuckers"/>
   <updated>2010-02-04T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/04/Banks-and-Credit-Card-companies-are-fuckers</id>
   <content type="html">Via Bruce Schneir&amp;#39;s blog there is a link to a paper about a new&lt;br&gt;security system that credit card companies are rolling out; a single&lt;br&gt;sign on system. The paper is here:&lt;br&gt;&lt;a href=&quot;http://www.cl.cam.ac.uk/~rja14/Papers/fc10vbvsecurecode.pdf&quot;&gt;http://www.cl.cam.ac.uk/~rja14/Papers/fc10vbvsecurecode.pdf&lt;/a&gt;. The&lt;br&gt;bottom line is that the system is pretty insecure, but it is&lt;br&gt;incentivised by making the customer sign up to additional terms and&lt;br&gt;conditions that puts more liability on them than on the banks or&lt;br&gt;credit card companies. It seems a bit like adding a shrink wrap&lt;br&gt;licence around credit card usage. I think I would not mind if they&lt;br&gt;were increasing my security, but as outlined in the paper linked to&lt;br&gt;here, they are not. I recently had to use this system, and it seemed&lt;br&gt;very phishy to me, so I avoided it as much as I could, but for the&lt;br&gt;time being it looks like there is not going to be a way to avoid it in&lt;br&gt;future. Fuckers.&lt;p&gt;tags: online security, banks, single sign on.
</content>
 </entry>
 
 <entry>
   <title>what makes a chocolate "cheeky"</title>
   <link href="http://partiallyattended.com/2010/02/02/what-makes-a-chocolate-%22cheeky%22"/>
   <updated>2010-02-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/02/02/what-makes-a-chocolate-"cheeky"</id>
   <content type="html">I&amp;#39;m eating a chocolate bar which contains, I&amp;#39;m told, a &amp;#39;cheeky caramel&lt;br&gt;layer&amp;#39;. It&amp;#39;s shit like this that makes me despair of our modern&lt;br&gt;civilisation. According to the dictionary &amp;#39;cheeky&amp;#39; means &amp;#39;impudent;&lt;br&gt;insolent&amp;#39;, and it has the synonyms &amp;#39;saucy, audacious, bold&amp;#39;. I guess&lt;br&gt;that I am to feel that I have made a bold choice in opting for the&lt;br&gt;opulence provided by that extra caramel, but I can&amp;#39;t raise the&lt;br&gt;enthusiasm to believe so.
</content>
 </entry>
 
 <entry>
   <title>opensocial development on eclipse, starting the web server</title>
   <link href="http://partiallyattended.com/2010/01/29/opensocial-development-on-eclipse,-starting-the-web-server"/>
   <updated>2010-01-29T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/01/29/opensocial-development-on-eclipse,-starting-the-web-server</id>
   <content type="html">Unable to retrieve spec for http://localhost:8080/test/gadget.xml. HTTP error 404
</content>
 </entry>
 
 <entry>
   <title>quick thoughts on the iPad</title>
   <link href="http://partiallyattended.com/2010/01/28/quick-thoughts-on-the-iPad"/>
   <updated>2010-01-28T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/01/28/quick-thoughts-on-the-iPad</id>
   <content type="html">I just commented over on the digatilist:&lt;p&gt;I&amp;#39;m in two minds, but on balance I&amp;#39;m optimistic. What they are&lt;br&gt;delivering is not a product, but a new platform, and one who&amp;#39;s&lt;br&gt;limitation has the potential to drive innovation in the open web. What&lt;br&gt;I really don&amp;#39;t like about what has been delivered is how closed the&lt;br&gt;system is, and how much this is not a tool that a developer could use.&lt;br&gt;I am in no way the target market for this product, but I don&amp;#39;t care&lt;br&gt;that I&amp;#39;m not a market, I care about what I care about. The kinds of&lt;br&gt;things that I would want to do with such a device I can&amp;#39;t do, however&lt;br&gt;applications on the web, in particular cloud storage + html 5&lt;br&gt;applications with local data storage, are fast moving to the point&lt;br&gt;where I could start coding in the cloud. My language of choice is&lt;br&gt;Python, there is already a toy implementation of a python interpreter&lt;br&gt;through a web interface (&lt;a href=&quot;http://try-python.mired.org/&quot;&gt;http://try-python.mired.org/&lt;/a&gt;). The Mozilla&lt;br&gt;foundation have a really advanced cloud based code editor&lt;br&gt;(&lt;a href=&quot;https://bespin.mozilla.com/&quot;&gt;https://bespin.mozilla.com/&lt;/a&gt;). Coding is about the biggest thing that&lt;br&gt;this device does not allow the power user to do. If those things are&lt;br&gt;close to being do-able in the cloud, then anything is possible.&lt;p&gt;What I do like about the device is the potential speed. We don&amp;#39;t need&lt;br&gt;computers with fast processors. We need computers that feel fast. This&lt;br&gt;platform could really drive computer-human interactions towards the&lt;br&gt;cloud based model. It could really be a boost for rich web&lt;br&gt;applications (no need to go through the app store), and it could&lt;br&gt;really drive innovation in software and content delivery on the web.&lt;br&gt;It&amp;#39;s almost a blank canvas upon which we may write or create the&lt;br&gt;interfaces that will define how people will interact with the content&lt;br&gt;or services we wish to deliver, and that&amp;#39;s going to be a big deal.&lt;p&gt;tags: cloud, iPad, speed, web applications, html5
</content>
 </entry>
 
 <entry>
   <title>Usage of graph layouts on Biostor</title>
   <link href="http://partiallyattended.com/2010/01/20/Usage-of-graph-layouts-on-Biostor"/>
   <updated>2010-01-20T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/01/20/Usage-of-graph-layouts-on-Biostor</id>
   <content type="html">&lt;a href=&quot;http://biostor.org/&quot;&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://iphylo.blogspot.com/&quot;&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://biostor.org/reference/4485&quot;&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;http://biostor.org/author/2176&quot;&gt;&lt;/a&gt; (co-author graph example)&lt;br /&gt;inspired by &lt;a href=&quot;http://inkdroid.org/journal/2009/12/22/hacking-oreilly-rdfa/&quot;&gt;&lt;/a&gt;</content>
 </entry>
 
 <entry>
   <title>Climbing Goals 2010, review 2009.</title>
   <link href="http://partiallyattended.com/2010/01/04/Climbing-Goals-2010-review-2009"/>
   <updated>2010-01-04T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2010/01/04/Climbing-Goals-2010-review-2009</id>
   <content type="html">Looking back at my &lt;a href=&quot;http://www.partiallyattended.com/2008/12/review-of-climbing-goals-for-2008.html&quot;&gt; goals for 2009&lt;/a&gt;, I&#39;ve not done very well, however my current level of fitness is pretty good, so I think 2010 is going to be a good year.&lt;br /&gt;&lt;br /&gt;The main factors in holding back my climbing in 2009 were taking a few months off to get married and not being able to rent a car. Getting married was absolutely worth it, and the level of organisation and stability I have in my life now due to being married will only help in the long run. Although I got a driving licence last year, I was not able to rent a car in 2009 as I hadn&#39;t my licence for long enough, that will change now in 2010, and I should be able to make it out and about around the UK to get some cragging in. &lt;br /&gt;&lt;br /&gt;So my goals for end of 2010 will be:&lt;br /&gt;&lt;br /&gt;- fr 7a redpoint indoors&lt;br /&gt;- V5 (I&#39;ve done a few V4&#39;s towards the tail end of last year)&lt;br /&gt;- a font 6a in font, preferably &lt;a href=&quot;http://bleau.info/cuvier/2128.html&quot;&gt;la marie rose&lt;/a&gt; (trip to font planned for April) &lt;br /&gt;- Trad E1 (I&#39;ve lowered this goal as I&#39;ve had so little trad experience in the past number of years)&lt;br /&gt;- A few trips to do some trad climbing.&lt;br /&gt;&lt;br /&gt;I just got &lt;a href=&quot;http://davemacleod.blogspot.com/2009/12/9-out-of-10-climbers-has-arrived.html&quot;&gt;9 out of 10 climbers make the same mistakes&lt;/a&gt;, and I hope that will give me some good training motivation for early in the year.
</content>
 </entry>
 
 <entry>
   <title>dreaming of snow</title>
   <link href="http://partiallyattended.com/2009/12/01/dreaming-of-snow"/>
   <updated>2009-12-01T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/12/01/dreaming-of-snow</id>
   <content type="html">&lt;div style=&quot;float: right; margin-left: 10px; margin-bottom: 10px;&quot;&gt;&lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/3245280059/&quot; title=&quot;photo sharing&quot;&gt;&lt;img src=&quot;http://farm4.static.flickr.com/3483/3245280059_d906d3b9ea_m.jpg&quot; alt=&quot;&quot; style=&quot;border: solid 2px #000000;&quot; /&gt;&lt;/a&gt;&lt;br /&gt;&lt;span style=&quot;font-size: 0.9em; margin-top: 0px;&quot;&gt;&lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/3245280059/&quot;&gt;DSC00458&lt;/a&gt;&lt;br /&gt;Originally uploaded by &lt;a href=&quot;http://www.flickr.com/people/mulvanynet/&quot;&gt;Ian Mulvany&lt;/a&gt;&lt;/span&gt;&lt;/div&gt;I just got some great feedback on this picture from someone on flickr, it was taken back in February when I was on a skiing holiday in Switzerland. The house was built by my wife&#39;s grandfather, and we came to it, it buried in a drift, the air as sharp as the icicles. It was a magical week, and I&#39;m keen to return. At this time of the year thoughts turn to such things.&lt;br clear=&quot;all&quot; /&gt;
</content>
 </entry>
 
 <entry>
   <title>Keeping Dopplr and iCal in two way sync.</title>
   <link href="http://partiallyattended.com/2009/12/01/Keeping-Dopplr-and-iCal-in-two-way-sync."/>
   <updated>2009-12-01T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/12/01/Keeping-Dopplr-and-iCal-in-two-way-sync.</id>
   <content type="html">I don&amp;#39;t know if the following is going to work, but I&amp;#39;m going to try&lt;br /&gt;it. Dopplr allows you to subscribe to your trips in iCal from a link&lt;br /&gt;from the trips page. You can also publish a calendar locally to the&lt;br /&gt;Dopplr servers that Dopplr will pull trips from. I&amp;#39;ve set up two&lt;br /&gt;calendars in my iCal, one for pushing into Dopplr, and another for&lt;br /&gt;pulling all Dopplr trips from. I hope this will let me add different&lt;br /&gt;trips to Dopplr via different mechanisms, and retain the connection to&lt;br /&gt;the push calendar from iCal without breaking it. That just gives me&lt;br /&gt;more options for getting stuff into the one place.&lt;p&gt;The best option would be to have complete bi-directional sync, I&amp;#39;m&lt;br /&gt;sure it will happen at some point, but in the meantime I&amp;#39;m not going&lt;br /&gt;to sweat it.&lt;p&gt;tags: iCal, dopplr, organisation
</content>
 </entry>
 
 <entry>
   <title>Strange anxiety dream</title>
   <link href="http://partiallyattended.com/2009/11/20/Strange-anxiety-dream"/>
   <updated>2009-11-20T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/11/20/Strange-anxiety-dream</id>
   <content type="html">Last night I had a strange anxiety dream. I&amp;#39;m not usually prone to&lt;br&gt;blogging this kind of thing, but it was pretty odd. I dreamt that I&lt;br&gt;had been given command line access to a particle accelerator that was&lt;br&gt;embedded in that antarctic ice sheet. I&amp;#39;d run some kind of a job and&lt;br&gt;forgotten about it. Two weeks later I got a bill for &amp;#163;216, 000. I&amp;#39;m&lt;br&gt;not sure if that was the bill for the data that was generated, or for&lt;br&gt;the cost of the electricity for running the accelerator.&lt;p&gt;&lt;br&gt;tags: dream, particle accelerator, antarctic
</content>
 </entry>
 
 <entry>
   <title>Notes from the Google Wave London roadshow</title>
   <link href="http://partiallyattended.com/2009/10/31/Notes-from-the-Google-Wave-London-roadshow"/>
   <updated>2009-10-31T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/10/31/Notes-from-the-Google-Wave-London-roadshow</id>
   <content type="html">Gtug blog post&lt;br /&gt;&lt;br /&gt;On Monday I was at the London Google wave roadshow  presented by Lars and Stephanie. The previous Friday I had helped to run a hack day for science applications in wave,  so with that experience fresh in my mind I was particularly interested to see what they would say about a few particular topics.&lt;br /&gt;&lt;br /&gt;We had a few problems in the hack day which could be summarised as follows:&lt;br /&gt;&lt;br /&gt;- hard to debug with many points of failure when developing robots.&lt;br /&gt;- the wave client is a hard interface for keeping track of conversations happening in the wave, and the document at hand.&lt;br /&gt;&lt;br /&gt;If you could customize your client, and you could develop locally against your own server and robot endpoints, and the APIs were stable, then that would solve all the problems that we faced on Friday.&lt;br /&gt;&lt;br /&gt;With that in mind I went into the meeting wanting to find out about the following&lt;br /&gt;&lt;br /&gt;- status of open sourcing the client and server&lt;br /&gt;- future api extensions&lt;br /&gt;- usability improvements&lt;br /&gt;- ability to deploy robots to non-appengine endpoints&lt;br /&gt;&lt;br /&gt;All of these, and more, were discussed. It is an evolving platform, and Steph and Lars were very clear on their desire for community feedback to help target the dev resource that they have. &lt;br /&gt;  &lt;br /&gt;- status of open sourcing the client and server&lt;br /&gt;&lt;br /&gt;Lars gave some detail on this. They intend to open source the server totally, they have already open sources the hardest part of the software in the server. They don&#39;t want to start opening up the client until the server specification is totally pinned down, as the server client protocol is currently changing a lot. There are also issues around opening up the client as parts of the client as it currently exist depend on proprietary Google technology, particularly search in the client. Lars said that they expect they will begin by progressively opening up parts of the client, for example the editor first. &lt;br /&gt;&lt;br /&gt;I would like to see a library of units that could be dropped into a page to create a client. I would love to be able to redirect parts of a wave to different parts of the screen. One could then have a &quot;Document&quot; part of a wave and next to it a conversation part of the wave. One could also make something akin to a site specific browser for wave that could display a zoomed out view of the wave where you could see where every participant was at any one point. I guess that these kinds of interfaces would be possible. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;- future api extensions&lt;br /&gt;&lt;br /&gt;There were lots of tantalising bits and pieces mentioned throughout the talk. They were clear thy they want to extend the number if hooks that can be programmed against a wave. In no particular&lt;br /&gt;order the following were mentioned. &lt;br /&gt;&lt;br /&gt;A notification api so that changes in waves can be propagated out into other systems. &lt;br /&gt;&lt;br /&gt;Very exciting was discussion of a regex hook. You could register your robot with this hook an instead of surfer (I guess that&#39;s the appropriate term for a wave user) adding a robot, on a regex triggering, the robot could be auto-added. One can think of many pitfalls with this, as well as many advantages, and they did say that they are taking their time and being very careful about how they implement this. &lt;br /&gt;&lt;br /&gt;They are not working in integrating with email. This is the biggest requested feature, however they want to concentrate on making the wave experience great. They did look at this somewhat, but said that it changes the experience of using wave significantly. They expect other people to use the provided API&#39;s to figure it out but they are definitely not working on it themselves. &lt;br /&gt;&lt;br /&gt;At the moment with a gadget that displays a view to something like a map, if one person moves the map all of the people can see that. They are thinknig about introducing a &quot;wave view&quot; and an &quot;edit view&quot;. They are also thinking about tying the ability to change views in gadgets to the edit state of the surrounding blip. This makes a lot of sense, and I think is one of those things that only became apparent after a lot of people started using the system.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;- usability improvements&lt;br /&gt;&lt;br /&gt;Lots of discussion about various improvements. Things are rolled out to the sandbox first and then onto the main wave server. They will implement a draft mode, and introduce settings that can be used to set things like the level of spelling correction. Rosy is going to be coming, but probably only for short blips, in order to aid with conversation. I can&#39;t remember the other things that were mentioned right now.&lt;br /&gt;&lt;br /&gt;Soon you will be able to remove people from waves, but I guess they want to make it a polite kind of a thing. Could lead to tit for tat behaviour. &lt;br /&gt;&lt;br /&gt;They are working on wave gardening, where you can merge, split, concatenate, and generally de-threat the blips in a wave. This is going to be awesome of they can get both the protocol and UX right.&lt;br /&gt;&lt;br /&gt;- ability to deploy robots to non-appengine endpoints&lt;br /&gt;&lt;br /&gt;Definitely coming, probably before end of 2010. They are taking care with this, they want to be able to address issues such as what to do when the robot changes without a surfer knowing. This could be a security issue, and so they want to get this right.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Some other titbits:&lt;br /&gt;&lt;br /&gt;They have on the order of 100s k users&lt;br /&gt; &lt;br /&gt;Public waves are only .5% of all the waves created so far. (I guess lots of people kick open a few waves before even realising that they can make them public)&lt;br /&gt;&lt;br /&gt;Largest wave is 100kb, this is a limit imposed by the system. &lt;br /&gt;&lt;br /&gt;They have a list of top gadgets. They track usage, and are thinking about making a gadget gallery to increase discoverability of extensions and robots.&lt;br /&gt;&lt;br /&gt;They are going to open up the embed api so that at some point in the future non-wave account holders can interact with waves through that api (on a web page for instance). They are not releasing this right now as they don&#39;t want to have the system slashdotted. From what I gather that all works, they are just waiting to scale.&lt;br /&gt;&lt;br /&gt;The last two notes are that their developer resource is scaled according to how many people use the app. So if you want to see it developed more quickly, use it more! (If this is a general Google policy then they must run a pretty tight ship, as right now wave has 100s of thousands of users, and it&#39;s clear the dev team are having to make tough choices over what to build).&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Shift + enter is your friend. Play with it when you are trying out editing and replying to waves!
</content>
 </entry>
 
 <entry>
   <title>Django models vs. Pickling objects for object persistence.</title>
   <link href="http://partiallyattended.com/2009/10/19/Django-models-vs.-Pickling-objects-for-object-persistence."/>
   <updated>2009-10-19T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/10/19/Django-models-vs.-Pickling-objects-for-object-persistence.</id>
   <content type="html">&lt;p&gt;&lt;br /&gt;I do a bit of code hacking and I often find myself putting objects into pickle files, and reading and writing them in order to fake object persistence. It&#39;s easy, but messy and it begins to leave lot&#39;s of pickle files sitting around in your path. I&#39;ve decided to finally make the switch towards using a more grown up persistent object solution. I&#39;ve decided to try out Django + SQLite. The former because I code in python, and &lt;a href=&quot;http://simonwillison.net/&quot;&gt;Simon Willison&lt;/a&gt; uses it. The latter because I want to keep my system MySQL install pristine for another application that I am playing around with. I&#39;m hoping that Django will hide the DB interface well away from me.&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;One of the key benefits that I hope to get out of this approach is to force myself into rigorously  using Class based representations of model data, rather than naive python objects. I hope this will lead to cleaner and better documented code on my part. I also hope that a quick by-product will be to allow me to quickly prototype ideas onto the web via Google app engine.&lt;/p&gt;&lt;p&gt; We shall see.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>An interesting invitation</title>
   <link href="http://partiallyattended.com/2009/10/03/An-interesting-invitation"/>
   <updated>2009-10-03T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/10/03/An-interesting-invitation</id>
   <content type="html">Last week an interesting invitation popped up in my email box, I got a&lt;br&gt;message from Richard Sterling asking if I would be interested in&lt;br&gt;previewing the program that the government are rolling out as part of&lt;br&gt;their open data project. They have set up a google group for&lt;br&gt;developers, and I guess I&amp;#39;m on the waiting list, or something. I&amp;#39;m&lt;br&gt;going to be interested to see what data sources surrounding science,&lt;br&gt;funding, teaching and publishing will be available there. I&amp;#39;m pretty&lt;br&gt;busy at the moment thinking about ways to improve Nature&amp;#39;s online&lt;br&gt;offerings and make them more functionally useful, this might represent&lt;br&gt;an important path for that work.&lt;p&gt;The message says:&lt;p&gt;&amp;quot;It&amp;#39;s really important to us that you are all comfortable with what we&lt;br&gt;are doing and how we are doing it, so let us know if there is anything&lt;br&gt;we can do to improve things.&amp;quot;&lt;p&gt;I like that, sounds like a good approach.
</content>
 </entry>
 
 <entry>
   <title>Comparing Windmill to Safariwatir</title>
   <link href="http://partiallyattended.com/2009/08/25/Comparing-Windmill-to-Safariwatir"/>
   <updated>2009-08-25T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/08/25/Comparing-Windmill-to-Safariwatir</id>
   <content type="html">the post seems to be missing :/
</content>
 </entry>
 
 <entry>
   <title>Cron, python and Google Wave</title>
   <link href="http://partiallyattended.com/2009/08/17/Cron,-python-and-Google-Wave"/>
   <updated>2009-08-17T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/08/17/Cron,-python-and-Google-Wave</id>
   <content type="html">Documentation on getting a google wave robot written in python working with the Cron functionality is still a little sparse. &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Getting a cron job into the capabilities.xml file. &lt;br /&gt;&lt;br /&gt;Add the following directive to the main function of your python program:&lt;br /&gt;&lt;br /&gt;    myRobot.RegisterCronJob(&#39;/path&#39;,60)&lt;br /&gt;&lt;br /&gt;When you look at you capabilities.xml file you should now see a new node in the file:&lt;br /&gt;&lt;br /&gt;&lt;w:crons&gt; &lt;br /&gt;  &lt;w:cron path=&quot;/path&quot; timerinseconds=&quot;60&quot;/&gt; &lt;br /&gt;&lt;/w:crons&gt; &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
</content>
 </entry>
 
 <entry>
   <title>Why I think the Drake equation is a crock of shit.</title>
   <link href="http://partiallyattended.com/2009/08/13/Why-I-think-the-Drake-equation-is-a-crock-of-shit."/>
   <updated>2009-08-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/08/13/Why-I-think-the-Drake-equation-is-a-crock-of-shit.</id>
   <content type="html">I had a brief discussion with a good friend and colleague this evening about the Drake equation. He has recently come to think that the equation can provide a good handle on understanding how many communicating civilizations exist in the universe, and how that reflects on the fragility of life on earth. A long time ago I had dismissed the Drake equation, feeling that it had very little to tell us about these matters. In face of his enthusiasm I thought it prudent to look again. I still feel that there is little of analytic value in this tool. &lt;br /&gt;&lt;br /&gt;Before getting on, I will say that there are two very good aspects to the conversation about the equation. Firstly the question being tackled is a difficult one, and the idea of breaking it down into smaller more manageable components is an appropriate way to tackle such a complex issue.  Secondly life on earth, all life, is fragile and precious, and taken far too much for granted by us, the only apparently self-reflecting species on the plant, as we sleepwalk our way from one human caused disaster to another. Anything at all that can bring the attention to the loneliness of our position in the cosmos, and perhaps through that engender a sense of solidarity in the face of a silent universe, is a good thing. Even if that thing is chimera, a vision beyond substance, an ideal.&lt;br /&gt;&lt;br /&gt;That out of the way, I continue to feel that there is little informational value in the Drake equation. My sense is that our current limited understanding of many of the core components that make up the equation render it no better than guesswork. Moreover, the components could equally be divided in other groups without affecting how well the principle functions. I may well be out of date in my knowledge of what science can say about these questions. That would be wonderful. Let&#39;s go through  the equation term by term. I&#39;ll try to argue that for each an order of magnitude difference in either direction could hold in the answer, and as such the range of possible answers provided by the equation as it is constituted is too broad to support much.&lt;br /&gt;&lt;br /&gt;The equation is &lt;br /&gt;&lt;br /&gt;&lt;pre lang=&quot;eq.latex&quot;&gt;&lt;br /&gt;N = R^{*} \times f_{p} \times n_{e} \times f_{l} \times f_{i} \times f_{c} \times L   \\&lt;br /&gt;R^{*} -- the rate of galactic star formation&lt;br /&gt;f_{p} -- fraction of stars with planets&lt;br /&gt;n_{e} -- average number of life supporting planets&lt;br /&gt;f_{l} -- fraction of these that go on to support life&lt;br /&gt;f_{i} -- the fraction of these that go on to create intelligent life&lt;br /&gt;f_{c} -- fraction of those civilizations that become communicative&lt;br /&gt;L -- the length of time they hang around sending signals&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;OK, let&#39;s go through these one by one:&lt;br /&gt;&lt;br /&gt;&lt;pre lang=&quot;eq.latex&quot;&gt;&lt;br /&gt;R^{*} -- the rate of galactic star formation&lt;br /&gt;-- usually interested in sun like stars, as big start&lt;br /&gt;-- dwarfs, which have a long incubation period, can capture/create planets&lt;br /&gt;&lt;br /&gt;-- g type stars&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;This is given importance because the assumption here is that life has to be supported by planets. We could argue that life could arise in nebula where stars are almost formed, which are rich in heavy elements. I admit that this would still be functionally dependent on the star formation rate, but it would change the dependence of the final figure on the star formation rate by a considerable amount. It is quite far fetched to think of life like this, and it is clear that the bias in the equation is to find DNA based life like ours, liquid water, probably an oxygen atmosphere. I&#39;m not sure that this is fair. We know from extremophiles on earth that it is possible for sulphur based life to exist on earth. It may be that what is needed is not a specific set of chemical elements, but rather the proper available energy transfer paths in a system so that a sufficient degree of local order can emerge. Of all the elements in the equation this is the one that I think is strongest candidate, and yet I&#39;m not 100% convinced that it&#39;s effects can be simply determined.&lt;br /&gt;&lt;br /&gt;&lt;pre lang=&quot;eq.latex&quot;&gt;&lt;br /&gt;f_{p} -- fraction of stars with planets&lt;br /&gt;&lt;br /&gt;increase - binary systems can support more planets than we assumed&lt;br /&gt;there are more - tight binaries&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;n_{e} -- average number of life supporting planets&lt;br /&gt;f_{l} -- fraction of these that go on to support life&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;I&#39;m going to roll these three into one discussion here. As far as I can tell, we don&#39;t know how life originated on earth. We do know the relative abundance of the building blocks of carbon based life in the universe. From studying line emissions we can see that relatively complex molecules, such as alcohol, and the bases that form DNA are pretty common, so the soup that formed life could be expected to be in quite a lot of places. I remember recalling that self-replicating forms of molecules were often low-energy states, boosting the likelihood of the emergence of such forms in a random process than one might naively think, but without a model for how to make the kind of life that we know we are yet to be able to put a lower bound on this figure. Then there are all of the potential non-carbon based life&#39;s that might emerge, driving this number upwards.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre lang=&quot;eq.latex&quot;&gt;&lt;br /&gt;f_{i} -- the fraction of these that go on to create intelligent life&lt;br /&gt;f_{c} -- fraction of those civilizations that become communicative&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Another approach might be to look at the cross section of what &lt;br /&gt;I haveMy feeling is that the underlying assumption of what could life  subcomponents &lt;br /&gt;&lt;br /&gt;In discussing this briefly with Adam this afternoon I thought it would be good to go over my thoughts on this again. &lt;br /&gt;&lt;br /&gt;OK, it&#39;s not that bad. 
</content>
 </entry>
 
 <entry>
   <title>Swine flu t-shirts</title>
   <link href="http://partiallyattended.com/2009/07/29/Swine-flu-t-shirts"/>
   <updated>2009-07-29T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/07/29/Swine-flu-t-shirts</id>
   <content type="html">I&amp;#39;m sitting at home in London with a head cold. For the dew minutes it  &lt;br&gt;took me to check my temperature (37 thank you very much) I was  &lt;br&gt;wondering whether it might be the old swine flu, but no, just a normal  &lt;br&gt;head cold.&lt;p&gt;Made me think, someone should make a t-shirt with a biometric sensor  &lt;br&gt;that checks on true wearers&amp;#39; temperature. No fever and it would say  &lt;br&gt;&amp;quot;don&amp;#39;t worry it&amp;#39;s only a cold&amp;quot;. Fever and, well there are lots of  &lt;br&gt;things it could say.
</content>
 </entry>
 
 <entry>
   <title>Fluid Dynamics in the Browser</title>
   <link href="http://partiallyattended.com/2009/06/11/Fluid-Dynamics-in-the-Browser"/>
   <updated>2009-06-11T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/06/11/Fluid-Dynamics-in-the-Browser</id>
   <content type="html">The Navier-Stokes equations:&lt;br /&gt;&lt;br /&gt;&lt;pre lang=&quot;eq.latex&quot;&gt;&lt;br /&gt;\frac{\partial \mathbf{v}}{\partial t} + ( \mathbf{v}\cdot\nabla ) \mathbf{v} = -\nabla p + \nu\Delta \mathbf{v} +\mathbf{f}(\boldsymbol{x},t)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;pre lang=&quot;latex&quot;&gt;&lt;br /&gt;\frac{\partial \mathbf{v}}{\partial t} + ( \mathbf{v}\cdot\nabla ) \mathbf{v} = -\nabla p + \nu\Delta \mathbf{v} +\mathbf{f}(\boldsymbol{x},t)&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Describe the flow of an incompressible fluid. The equations are non-linear and are notoriously difficult to solve. I&#39;ve always found them to be very beautiful and the fact that &lt;a href=&quot;http://en.wikipedia.org/wiki/George_Gabriel_Stokes&quot;&gt;Sr George Stokes&lt;/a&gt; was an Irishman probably had some effect on my taking to the subject when I was an undergrad. &lt;br /&gt;&lt;br /&gt;There are many subtleties hidden in the equations, notably the issue of conservation of momentum and the appearance of turbulence. The subject inspired the following rather fun ditty:&lt;br /&gt;&lt;br /&gt;&lt;quote&gt;&lt;br /&gt;Big whorls have little whorls&lt;br /&gt;  That feed on their velocity,&lt;br /&gt;And little whorls have lesser whorls&lt;br /&gt;  And so on to viscosity.&lt;br /&gt;&lt;br /&gt;  -- Lewis F. Richardson&lt;br /&gt;&lt;/quote&gt;&lt;br /&gt;&lt;br /&gt;When I was an undergrad I spent some time playing with a Cray supercomputer running simulations of fluid flow on a sphere. A supercomputer. A big one. In my grazing of the online new sources today I saw a link to &lt;a href=&quot;http://nerget.com/fluidSim/&quot;&gt;Oliver&#39;s fluid dynamics simulation&lt;/a&gt; which provides a Navier - Stokes solver in the browser in javascript. It&#39;s pretty, and it&#39;s damn impressive. &lt;br /&gt;&lt;br /&gt;It doesn&#39;t solve the actual equations, but a diffusive model optimized for stability, speed and aesthetics based on &lt;a href=&quot;http://www.dgp.toronto.edu/people/stam/reality/Research/pdf/GDC03.pdf&quot;&gt;this paper&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;It really shows the potential of the browser as a tool for the teaching of science. Being able to make changes to your code and test the results right there, nice!
</content>
 </entry>
 
 <entry>
   <title>unknown post</title>
   <link href="http://partiallyattended.com/2009/05/20/unnamed"/>
   <updated>2009-05-20T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/05/20/unnamed</id>
   <content type="html">&lt;p&gt;In February 2009 a mac security update broke my perl installation. You can read more about that on this &lt;a href=&#39;http://developers.slashdot.org/article.pl?sid=09/02/18/143522&#39;&gt;Slashdot article&lt;/a&gt; (http://hivelogic.com/articles/view/top-10-programming-fonts) , ulimatly forcing me to reinstall my entire system. One of the main reasons for this is that I had a hevily customized perl setup as part of installing Connotea and I based this on top of the system perl. This was a bad idea, but was the quickest way to get Connotea up and running on my local machine at the time.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Having learnt my lesson I decided to set up Connotea on a totally sepearte perl install. The following instructions assume a totally clean machine to begin with. You will need to have the &lt;a href=&#39;http://developer.apple.com/Tools/&#39;&gt;Apple Developer Tools&lt;/a&gt; installed.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;For installing on a clean &lt;em&gt;nix please follow the instructions in the main README file.&lt;/em&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Connotea is written in perl and uses mod_perl under apache to talk to a MySQL datastore. The code uses memcached to help with preformance. It uses a large number of perl modules that need to be installed before the software can run. This guide will run through setting up all of the required depedancies.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Before getting to installing Connotea let&amp;#8217;s set up our dependancies.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;a_word_on_macports_vs_compiling_your_own&#39;&gt;A word on MacPorts vs compiling your own.&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Bauhaus has a very nice description on how to set up a &lt;a href=&#39;http://bauhouse.wordpress.com/2008/06/28/setting-up-a-development-environment-in-mac-os-x/&#39;&gt;dev environment in OS X&lt;/a&gt;, however the description here depends hevily on &lt;a href=&#39;http://www.macports.org/&#39;&gt;MacPorts&lt;/a&gt;. MacPorts is an easy way to install software onto your mac, and it will do so in a way that will not conflict with system installs, however it provides the wrong architecture for perl for Connotea, so you will have to install perl and all of the perl dependancies seperatly. This is a bit of a shame, as installing the dependancies is much faster under MacPorts than it is under &lt;a href=&#39;http://www.cpan.org/&#39;&gt;CPAN&lt;/a&gt;. We can install some of the required architecture under MacPorts and that is what we will do. One last note about MacPorts. It will install a very large amount of dependancies onto your system. This is expected, though scary, behaviour. Don&amp;#8217;t worry.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;In order to use MacPorts you can install an &lt;span&gt;application&lt;/span&gt;&lt;a href=&#39;http://www.macports.org/install.php&#39;&gt;portsapp&lt;/a&gt;. After installing you can get the port version of a given piece of software with hte following command:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre class=&quot;console&quot;&gt;&lt;br /&gt;$ sudo port install port-name&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;where port-name is the software you want to install. MacPorts creates it&amp;#8217;s own path system and will install into&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$ /opt&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;mysql&#39;&gt;MySQL&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Download the package from the &lt;a href=&#39;http://www.mysql.com/&#39;&gt;MySQL site&lt;/a&gt; and follow the instructions for installation. For a quick cheat sheet of common commands for MySql under OS X there is a great &lt;a href=&#39;http://www.comentum.com/mysql-administration.html&#39;&gt;MySQL Reference for OS X&lt;/a&gt; over at Comentum.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;After installing the most important commands are to set an admin password, to start the server and to stop the server.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;setting the root password: $ /usr/local/mysql/bin/mysqladmin -u root password sniggle&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;starting and stopping from the command line: $ sudo /usr/local/mysql/bin/mysqld_safe &amp;#8211;user=mysql &amp;amp;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;If you wish to set preferennces for MySQL when it is running you can create a conf file. This should be under /etc and should be called my.cnf.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;make_sure_you_know_where_your_socks_are&#39;&gt;Make sure you know where your socks are.&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is a &lt;a href=&#39;http://www.linuxforums.org/forum/servers/1451-what-mysql-sock-file.html&#39;&gt;known issue with MySQL under OS X&lt;/a&gt; in that the location for the socket file is not where OS X thinks it is. There are a number of solutions to this. &lt;br /&gt;Edit the my.cnf file so that the mysql server creates a sock file in a location of your choosing. Reccomended like so:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;span&gt;mysqld&lt;/span&gt; socket=/tmp/mysql.sock&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Now if you are using a perl installed via MacPorts and you want to use a non-mac ports version of mysql then you might encounter the following problem with the DBI module.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;blockquote&gt;&lt;br /&gt;&lt;p&gt;failed: Can&amp;#8217;t connect to local MySQL server through socket &amp;#8216;/opt/local/var/run/mysql5/mysqld.sock&amp;#8217;&lt;/p&gt;&lt;br /&gt;&lt;/blockquote&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;What is going on here is that the DBI module is reading a setting telling it that the mysql socket should be found in &amp;#8216;/opt/local/var/run/mysql5/mysqld.sock&amp;#8217;. I&amp;#8217;m not sure where it gets this setting from but there are a couple of options.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;br /&gt;&lt;li&gt;Use a mac ports version of mysql. See&lt;/li&gt;&lt;br /&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;http://www.hennessynet.com/blog/?p=40&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;&lt;li&gt;http://www.martinoflynn.com/blog/2008/08/13/installing-mysql-on-mac-os-x-105/&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;&lt;li&gt;http://2tbsp.com/content/install_and_configure_mysql_5_macports&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;br /&gt;&lt;li&gt;Specifically tell the DBI module where to look for the socect. In any perl scripts that call the DBI module you can use the following command to specify the location of the socket file:&lt;/li&gt;&lt;br /&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$ENV{MYSQL_UNIX_PORT}=&amp;#8217;/tmp/mysql.sock&amp;#8217;;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Place this in your script after you call the DBI module.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;br /&gt;&lt;li&gt;You can alias your actual sock file to the location that the DBI module is expecting it, via:&lt;/li&gt;&lt;br /&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$ sudo ln -s /tmp/mysql.sock /opt/local/var/run/mysql5/mysqld.sock&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;you may have to create the /opt/local/var/run/mysql/ directory.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You may wish to create an alias so that this link does not get removed on server start up.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;apache2&#39;&gt;Apache2&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This is where MacPorts comes in handy. To install apache2 all you need to do is&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$sudo port install apache2&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This will install a number of dependancies on your system, and it will install apace2 into /aop/local/apace2. You can start apache2 and ensure that it starts at next startup with the follwoing command:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$sudo launchctl load -w /Library/LaunchDaemons/org.macports.apache2.plist&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You can test that it works by pointing your browser at http://localhost/ and you should get an &amp;#8220;It Works!&amp;#8221; message!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;If you want to start and stop apache2 while working on the configuration of the server, or to check your sanity then you can use the following cammands:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$ sudo /opt/local/apache2/bin/apachectl stop $ sudo /opt/local/apache2/bin/apachectl start&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;memcached&#39;&gt;memcached&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Using the Macports version this is pretty easy.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;blockquote&gt;&lt;br /&gt;&lt;p&gt;sudo port install memcached&lt;/p&gt;&lt;br /&gt;&lt;/blockquote&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;a_few_words_about_cpan&#39;&gt;A few words about CPAN&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is a comprehensive description of life under &lt;a href=&#39;http://sial.org/howto/perl/life-with-cpan/&#39;&gt;CPAN on OSX&lt;/a&gt; however I decided to wing it. I dislike CPAN. It is a very attention demanding program that has a tendancy to want a lot of attention. It is nice to know that you can install modules from the command line with the following syntax:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$sudo cpan -i -f URI::QueryParam&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This means if you can get a list of dependancies together then you can semi-automate the process of install them all. I understand that the preferred method of managing a large selection of perl dependancies to is create a CPAN Bundle, but I didn&amp;#8217;t manage to do this, mainly due to a lack of familliarity with CPANishness. It is also worth noting that if CPAN is not able to install a module you can always have a go at downloading and installing the modeule from source. This is often quite straightforward.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;perl&#39;&gt;perl&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;As mentioned earlier, MacPorts do not porvide the correct type of perl for running Connotea. Connotea requires &amp;#8216;PerlOptions +Parent&amp;#8217; in the Apache configuration file. This requires a multithreaded perl. MacPorts only provides a perl without threads. This means you have to build your own perl. You can check which version of perl you have installed with the following command&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$perl -V&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;What you want to end up with is the following:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Platform: osname=darwin, osvers=9.6.0, archname=darwin-thread-multi-2level&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Go ahead and grab a copy of &lt;a href=&#39;http://www.perl.org/&#39;&gt;Perl&lt;/a&gt;. You pretty much want to follow the instructions given in the README.macosx file. You want to make sure that you build perl with multithreaded support. I followed a lot of instructions for passing arguments to the Configure script without much success. In the end I think that my mistake was passing the &amp;#8216;-de&amp;#8217; flag which tells the script to accept the default settings. Don&amp;#8217;t do this, just go through the interrogation and at some point you will be asked if you want to build with multithreaded support. Say YES!!. Hopefully you will end up with a perl now installed in /usr/local/bin/perl. This will be independant from the system perl and you will no longer be sucseptible to Apple fucking you over (allbeit unintentionally). Now when you build anything on top of this perl it will have the same architectural support (I believe), so you can now make mod_perl on top of this perl. One tip for speeding up the process, if you have a multi-core machine you can pass an argument to make which will tell it to use the number of cores that you pass it to, so&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$make -j 2&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;will make twice as fast as make.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;mod_perl&#39;&gt;mod_perl&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Get a copy of &lt;a href=&#39;http://perl.apache.org/download/index.html&#39;&gt;mod_perl&lt;/a&gt;. Go into your mod_perl source directory and from there do the following:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$perl Makefile.PL MP_APXS=/opt/local/apache2/bin/apxs $make &amp;amp;&amp;amp; make test&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;after a lengthy build process you should be ready to install with:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$sudo make install&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;In /opt/local/apache2/modules you should now find mod_perl.so. We can now test our mod_perl to see if everyting is OK. Have a look at the &lt;a href=&#39;http://perl.apache.org/docs/2.0/user/intro/start_fast.html&#39;&gt;fast guide to getting started with mod_perl&lt;/a&gt; and follow the instructions there.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;To set up a test of mod_perl we need to edit apache&amp;#8217;s httpd.conf file which can be found: /opt/local/apache2/conf/httpd.conf&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Add the mod_perl module by adding the following line to the conf file&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;LoadModule perl_module modules/mod_perl.so&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Stop and restart your apache2 server and take a peek at the error log, you should get a line like the following:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$tail /opt/local/apache2/logs/ &lt;span&gt;Thu Apr 23 14:59:22 2009&lt;/span&gt; Apache/2.2.11 (Unix) mod_ssl/2.2.11 OpenSSL/0.9.8j DAV/2 mod_perl/2.0.4 Perl/v5.8.9 configured &amp;#8211; resuming normal operations&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;yay!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;perl_dependancies&#39;&gt;perl dependancies&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;OK, Connotea requies a lot of dependancies, most of which can be installed through CPAN, a few which need to be manually installed. I&amp;#8217;ve provided a file 1.8.extended.deplist.txt that contains what I believe to be the current set of modules that Connotea requires. If you pass the list of names into check-modules.py then you can check whether these modules have been installed. Passing any argument into the script will produce verobse output. Passing no arguments will just list the modules that have not been installed.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;For the time being please ignore the following modules:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Apache2 Apache::Const Apache::File File::Touch Net::OpenID::JanRain::Consumer&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$more 1.8.extended.deplist.txt | ./check-modules.py verbose&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You can generate a shell script to install non-installed modules via CPAN with the following command:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$more 1.8.extended.deplist.txt | ./check-modules.py | awk &amp;#8216;{print &amp;#8220;sudo cpan -i &amp;#8221; $1}&amp;#8217; &amp;gt; install-modules.sh&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;and then:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$chmod u+x install-modules.sh $sudo ./install-modules.sh&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This will take some time. The CPAN interface is slow and requires a lot of intervention. If you get stuck with CPAN for a given module, then download the module and install from source.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I had to manually install Authen::Captcha http://search.cpan.org/dist/Authen-Captcha/Captcha.pl&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;connotea_code&#39;&gt;Connotea code&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The most recent public version of the Connotea code is now on GitHub under the name &lt;a href=&#39;http://github.com/IanMulvany/connotea-public/tree/master&#39;&gt;connotea-public&lt;/a&gt;. The main working branch is still under darcs, however we are in the process of switching over to git as the time to upload local patches to the dev server is becomming prohibitive. We may move to mercurial at some point in time, but for the time being the public facing snapshot will remain in git. Head on over and grab a copy. The main files of interest for continuing the setup will be in /connotea-public/sql/, /connotea-public/README, and /connotea-pulic/config&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;setup_mysql_databases_and_permissions&#39;&gt;Setup MySQL databases and permissions&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Connotea uses a four databases. The main content database, the search database which is a replica of the content database, a click tracking database and the wiki database. The content database is a MyISAM database, and the search database is an InnoDB database. The schema for the content database is provided by schema.sql in the sql directory. To generate the search database do the following:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$perl mkschema_search &amp;lt; schema.sql &amp;gt; schema_search.sql&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Now set up the schema of the content database and the search database:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$mysql -u root -p &amp;lt; schema.sql $mysql -u root -p &amp;lt; schema_search.sql $mysql -u root -p &amp;lt; clicks.sql&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You need to set up the search database to be a slave of the content database. This is done in the MySQL conf file by adding the following directives:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;code&gt;  [mysqld]&lt;br /&gt;  # local replication of bibliotech to bibliotech_search:&lt;br /&gt;  server-id=1&lt;br /&gt;  log-bin=mysql-bin&lt;br /&gt;  binlog-do-db=bibliotech&lt;br /&gt;  replicate-same-server-id=1&lt;br /&gt;  replicate-rewrite-db=bibliotech-&amp;gt;bibliotech_search&lt;br /&gt;  replicate-do-db=bibliotech_search&lt;br /&gt;  master-host=localhost&lt;br /&gt;  master-user=search_repl&lt;br /&gt;  master-password=pass&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You may want to add the folloing directive too:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre&gt;&lt;code&gt;  # change stopwords in support of bibliotech freematch feature:&lt;br /&gt;  #ft_stopword_file=/etc/mysql_stopwords.txt&lt;br /&gt;  ft_min_word_len=2&lt;br /&gt;  ft_max_word_len=255&lt;br /&gt;  # allow packing of queries&lt;br /&gt;  group_concat_max_len=8192&lt;/code&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You now need to set up the appropriate permissions form within MySQL for the following users &amp;#8216;conwiki&amp;#8217;, &amp;#8216;search_repl&amp;#8217; and &amp;#8216;connotea&amp;#8217;:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;mysql&amp;gt; GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, CREATE TEMPORARY TABLES, ALTER ON bibliotech_search.* TO -&amp;gt; connotea@localhost identified by &amp;#8216;secret&amp;#8217;;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;mysql&amp;gt; GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, CREATE TEMPORARY TABLES, ALTER ON bibliotech.* TO -&amp;gt; connotea@localhost identified by &amp;#8216;secret&amp;#8217;;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;mysql&amp;gt; GRANT REPLICATION SLAVE, REPLICATION CLIENT ON &lt;em&gt;.&lt;/em&gt; TO -&amp;gt; search_repl@&amp;#8217;localhost.localdomain&amp;#8217; IDENTIFIED BY &amp;#8216;secret&amp;#8217;;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;We now need to set up the wiki database. This is done through the following command:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;mysql&amp;gt;CREATE DATABASE conwiki; mysql&amp;gt;GRANT ALL ON conwiki.* TO conwiki@localhost IDENTIFIED BY &amp;#8216;secret&amp;#8217;;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;To set up the schema we just let wiki-toolkit-setupdb have at it:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;$/usr/local/bin/wiki-toolkit-setupdb &amp;#8211;type mysql \ &amp;#8211;name conwiki \ &amp;#8211;user conwiki \ &amp;#8211;pass secret \ &amp;#8211;host localhost&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Remember to populate the &amp;#8220;COMPONENT WIKI&amp;#8221; block of your configuration file with the wiki database details.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Connotea will be informed of the database that it needs to connect to in the conf file. I would say that it goes without saying that the passwords all need to be congruent, but I keep messing up that part, so I&amp;#8217;m not going to say that.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;setup_apache_directives_and_paths_to_the_code&#39;&gt;Setup Apache directives and paths to the code.&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Ok, now we have mysql sitting there waiting to act as a data store. We have the connotea code. We just need to connect these together and to the outside world through the magic of apace and mod_perl.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You need to add a directive like the following to your apace conf file. Remeber, that file should be in /opt/local/apache2/conf/httpd.conf&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;change_the_document_root_as_we_are_going_to_host_connotea_from&#39;&gt;change the document root, as we are going to host connotea from&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;a_more_traditional_location&#39;&gt;a more traditional location&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;documentroot_optlocalapache2htdocs&#39;&gt;DocumentRoot &amp;#8220;/opt/local/apache2/htdocs&amp;#8221;&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;DocumentRoot &amp;#8220;/var/www/html&amp;#8221;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;ensure_that_we_can_follow_symlinks&#39;&gt;ensure that we can follow symlinks:&lt;/h1&gt;&lt;br /&gt;&lt;pre class=&#39;markdown-html-error&#39; style=&#39;border: solid 3px red; background-color: pink&#39;&gt;REXML could not parse this XML/HTML: &lt;br /&gt;&amp;lt;Directory &amp;quot;/var/www/html&amp;quot;&amp;gt;&lt;br /&gt;    #&lt;br /&gt;    # Possible values for the Options directive are &amp;quot;None&amp;quot;, &amp;quot;All&amp;quot;,&lt;br /&gt;    # or any combination of:&lt;br /&gt;    #   Indexes Includes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViews&lt;br /&gt;    #&lt;br /&gt;    # Note that &amp;quot;MultiViews&amp;quot; must be named *explicitly* --- &amp;quot;Options All&amp;quot;&lt;br /&gt;    # doesn&amp;apos;t give it to you.&lt;br /&gt;    #&lt;br /&gt;    # The Options directive is both complicated and important.  Please see&lt;br /&gt;    # http://httpd.apache.org/docs/2.2/mod/core.html#options&lt;br /&gt;    # for more information.&lt;br /&gt;    #&lt;br /&gt;    Options Indexes FollowSymLinks&lt;br /&gt;&lt;br /&gt;    #&lt;br /&gt;    # AllowOverride controls what directives may be placed in .htaccess files.&lt;br /&gt;    # It can be &amp;quot;All&amp;quot;, &amp;quot;None&amp;quot;, or any combination of the keywords:&lt;br /&gt;    #   Options FileInfo AuthConfig Limit&lt;br /&gt;    #&lt;br /&gt;    AllowOverride None&lt;br /&gt;&lt;br /&gt;    #&lt;br /&gt;    # Controls who can get stuff from this server.&lt;br /&gt;    #&lt;br /&gt;    Order allow,deny&lt;br /&gt;    Allow from all&lt;br /&gt;&lt;br /&gt;&amp;lt;/Directory&amp;gt;&lt;/pre&gt;&lt;br /&gt;&lt;h1 id=&#39;add_directives_for_connotea&#39;&gt;add directives for connotea&lt;/h1&gt;&lt;br /&gt;&lt;pre class=&#39;markdown-html-error&#39; style=&#39;border: solid 3px red; background-color: pink&#39;&gt;REXML could not parse this XML/HTML: &lt;br /&gt;&amp;lt;VirtualHost 127.0.0.1&amp;gt;&lt;br /&gt;        ServerName local.connotea.com&lt;br /&gt;        ServerAlias *local.connotea.com&lt;br /&gt;        ServerAdmin ian@mulvany.net&lt;br /&gt;        DocumentRoot /var/www/html/connotea&lt;br /&gt;        PerlOptions +Parent&lt;br /&gt;        PerlSwitches -I/var/www/perl/connotea&lt;br /&gt;        PerlModule Bibliotech::Apache&lt;br /&gt;        PerlModule Bibliotech::AuthCookie&lt;br /&gt;        &amp;lt;Location /&amp;gt;&lt;br /&gt;          SetHandler perl-script&lt;br /&gt;          PerlHandler Bibliotech::Apache&lt;br /&gt;          PerlAuthenHandler Bibliotech::AuthCookie::authen_handler&lt;br /&gt;          AuthName Bibliotech&lt;br /&gt;          AuthType basic&lt;br /&gt;          require valid-user&lt;br /&gt;          #ErrorDocument 503 /paused.html&lt;br /&gt;          #ErrorDocument 503 /readonly.html&lt;br /&gt;          ErrorDocument 503 /unavailable.html&lt;br /&gt;        &amp;lt;/Location&amp;gt;&lt;/pre&gt;&lt;pre class=&#39;markdown-html-error&#39; style=&#39;border: solid 3px red; background-color: pink&#39;&gt;REXML could not parse this XML/HTML: &lt;br /&gt;&amp;lt;/VirtualHost&amp;gt;&lt;/pre&gt;&lt;br /&gt;&lt;p&gt;In your /etc/hosts file add the following line:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;ol&gt;&lt;br /&gt;&lt;li&gt;&lt;br /&gt;&lt;li&gt;&lt;br /&gt;&lt;li&gt;1 local.connotea.com&lt;/li&gt;&lt;br /&gt;&lt;/li&gt;&lt;br /&gt;&lt;/li&gt;&lt;br /&gt;&lt;/ol&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This means you can point your browser at local.connotea.com and see the local installation.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;in /var/www create perl, html and site&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;in /var/www/site create the directory connotea and place the source code in there.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;create the following symlinks:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;/var/www/perl/connotea -&amp;gt; ../site/connotea&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;and&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;/var/www/html/connotea -&amp;gt; ../perl/connotea/site/npg&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Make sure that the paths to the code is readable by apache. That also means that the full paths have to be readable by apache.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;set_up_the_connotea_conf_file&#39;&gt;Set up the connotea conf file.&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;copy /connotea-code/confi to /etc/bibliotech.conf&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The most important declarations to set up are the following:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;DOCROOT = &amp;#8216;/var/www/perl/connotea_code/site/default&amp;#8217; LOCATION = &amp;#8216;http://www.mydomain.com/&amp;#8217; DBI_CONNECT = &amp;#8216;dbi:mysql:bibliotech&amp;#8217; DBI_USERNAME = &amp;#8216;user&amp;#8217; DBI_PASSWORD = &amp;#8216;secret&amp;#8217;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;just_the_database_name_of_the_replicated_myisam_fulltextenabled_database&#39;&gt;just the database name of the replicated MyISAM FULLTEXT-enabled database&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;DBI_SEARCH = &amp;#8216;bibliotech_search&amp;#8217;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;for_debugging_purposes_set_explain_http_codes_to_true&#39;&gt;for debugging purposes set EXPLAIN_HTTP_CODES to true&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;set_it_to_false_when_you_have_everything_running&#39;&gt;set it to false when you have everything running.&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;it_causes_application_errors_to_be_printed_to_the_requesting_page&#39;&gt;It causes application errors to be printed to the requesting page.&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;EXPLAIN_HTTP_CODES = true&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;CLICKS { # options regarding click tracking # database connection details DBI_CONNECT = &amp;#8216;dbi:mysql:clicks&amp;#8217; DBI_USERNAME = &amp;#8216;user&amp;#8217; DBI_PASSWORD = &amp;#8216;secret&amp;#8217; }&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;COMPONENT WIKI { #DBI_CONNECT = &amp;#8216;dbi:mysql:conwiki&amp;#8217; #DBI_USERNAME = &amp;#8216;conwiki&amp;#8217; #DBI_PASSWORD = &amp;#8216;secret&amp;#8217; #ADMIN_USERS = &lt;span&gt;&amp;#8216;admin&amp;#8217;&lt;/span&gt; #LOCK_TIME = &amp;#8216;10 MINUTE&amp;#8217; #ALLOW_EDIT = true #HOME_NODE = &amp;#8216;System:Home&amp;#8217; # page size limit is in characters #MAX_PAGE_SIZE = 40000 # maximum external hyperlink count, cuts down on spam #MAX_EXT_LINKS = 75 # scan: 1 means check text against ANTISPAM &amp;gt; TAG_REALLY_BAD_PHRASE_LIST # scan: 2 means check text against ANTISPAM &amp;gt; WIKI_BAD_PHRASE_LIST+TAG_REALLY_BAD_PHRASE_LIST #SCAN = 1 # to admit the spam rule that rejects wiki text, set this to true: #SAY_SPAM_RULE = false }&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h1 id=&#39;sendmail_needs_to_be_set_to_the_os_x_path&#39;&gt;sendmail needs to be set to the OS X path.&lt;/h1&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;SENDMAIL = &amp;#8216;/usr/sbin/sendmail&amp;#8217;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;final_adjustments&#39;&gt;Final adjustments&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Ensure that antispam_score.csv is writable by connotea.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;turn_it_on&#39;&gt;Turn it on.&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You should be able to run the application now.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;h2 id=&#39;gotchas&#39;&gt;Gotcha&amp;#8217;s&lt;/h2&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;In a previous installaion I had problems getting the perl GD module installed&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;You need to downgrade LWP, use the following to find out which version of a perl module you have installed. Follow the instructions at this site to get this installed:&lt;/p&gt;&lt;br /&gt;&lt;/body&gt;&lt;/html&gt;&lt;br /&gt;
</content>
 </entry>
 
 <entry>
   <title>Another great example of how being lazy can reap great rewards</title>
   <link href="http://partiallyattended.com/2009/04/16/Another-great-example-of-how-being-lazy-can-reap-great-rewards"/>
   <updated>2009-04-16T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/16/Another-great-example-of-how-being-lazy-can-reap-great-rewards</id>
   <content type="html">Last year I got really obsessed with the idea of making my google email contacts list, my phone list and my desktop address book all sync together. I couldn&amp;#39;t find a simple to use free application that would do all of this for me. For a while I was using Spanning Sync to keep calendars in sync. I had a Nokia N95, my desktop machine is a mac and my online life is mediated by Google. I thought about expending energy to write my own solution, and would think about it from time to time, but today I am happy to announce that I needn&amp;#39;t have bothered. Now with my iPhone and &amp;lt;a href=&amp;quot;&lt;a href=&quot;http://www.google.com/mobile/apple/sync.html&quot;&gt;http://www.google.com/mobile/apple/sync.html&lt;/a&gt;&amp;quot;&amp;gt;Google mobile sync&amp;lt;/a&amp;gt; everything seems to just work, at least for the time being. I&amp;#39;m pretty happy about this right now. &lt;div&gt; &lt;br&gt;&lt;/div&gt;&lt;div&gt;tags: iphone, google, contacts, sync, lazy&lt;/div&gt; 
</content>
 </entry>
 
 <entry>
   <title>notes on "Classes of complex networks deﬁned by role-to-role connectivity proﬁles"</title>
   <link href="http://partiallyattended.com/2009/04/14/notes-on-%22Classes-of-complex-networks-de%EF%AC%81ned-by-role-to-role-connectivity-pro%EF%AC%81les%22"/>
   <updated>2009-04-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/14/notes-on-"Classes-of-complex-networks-deﬁned-by-role-to-role-connectivity-proﬁles"</id>
   <content type="html">Looking for algorithms to do community detection (there are a bunch  from the famous Girvan-Newman algorithm &lt;a href=&quot;http://dx.doi.org/10.1073/pnas.122653799&quot;&gt;doi:10.1073/pnas.122653799&lt;/a&gt; which seems to have gained popularity through being very simple, effiencet and usually pretty powerfull, through to a method &lt;a href=&quot;http://dx.doi.org/10.1103/PhysRevE.71.046117&quot;&gt;doi:10.1103/PhysRevE.71.046117&lt;/a&gt; by Ziv, Middendorf and Wiggins. I have to admit I don&#39;t understand that paper yet, but hope to come back to it.) I was pointed to a paper by Guimera, Sales-Pardo and Amaral. In looking for the paper the first one that I found was Classes of complex networks deﬁned by role-to-role connectivity proﬁles on &lt;a href=&quot;http://dx.doi.org/10.1038/nphys489&quot;&gt;DOI:10.1038/nphys489&lt;/a&gt;. It turns out that they describe their algorithm in the &lt;a href=&quot;http://dx.doi.org/10.1038/nature03288&quot;&gt;doi:10.1038/nature03288&lt;/a&gt;, but as I encountered the nautre physics aritcle I may as well read my way through that and give you the skinny on it.&lt;br /&gt;&lt;br /&gt;The main story in this paper is that real networks are complicated, and that the properties of modules in the network are not reflected by the average properites of the entire network. The implication would seem to be that models for generating netowrks do note capture importnat properties of real world netowrks. That&#39;s not really a great surprise, however I guess that it is nice that someone has sone an explicit comparison.&lt;br /&gt;&lt;br /&gt;One interesting idea in the paper is that they try to classify modules according to how the average connectivity of the connecting nodes in the modules (the nodes that bridge out to other modules) is distributed among the other modules. The classes they describe are non-hubs, with non-hubs being further described into ultra-peripheral nodes, peripheral nodes, satellite connectors and kinless nodes. Hubs get broken out into connector hubs, global hubs and provincial hubs. &lt;br /&gt;&lt;br /&gt;These descriptions are tightly defined in terms of properties of the identified modules. The claim in the paper is that global properties of real networks, specifically some degree-degreee correlations, can only be reconstructed by taking into account this modular structure. The new property is called the &quot;Participation Function&quot;.&lt;br /&gt;&lt;br /&gt;There is another imporant aspect to this picture. If we think of the modules as building blocks, this paper is saying that the kinds of building block of the network are key to understanding the properties of the network. In addition, how those building blocks tend to connect to each other is an equally important aspect of this picture and can be measured by looking at the likelihood of a connection between two blocks in a given network in contrast to a random connection probablility.&lt;br /&gt;&lt;br /&gt;An illuminating example is given by describing the differences between Cincinnati airport and Johannesburg airport. The two have the same degree distribution, but you can fly to the latter from most major airports in the world and not the former. This is described by noting that Joberg is the most connected city in it&#39;s region, but the same does not hold true for Cincinnati (trivia, this city was named after a roman dictator).&lt;br /&gt;&lt;br /&gt;This is mainly a descriptive paper, but the authors suggest that the differences may arise in real world networks depending on whether they are transportation networks that are constrained by conservation laws, as opposed to signialling networks that face no such constrainsts. (I&#39;m not sure, without thinking about it further, that you wouldn&#39;t be able to define some kind of a conservation law on a signalling network, given that there will tend to be some constrainst, e.g. attention time/information processing capacity of the reciever nodes).&lt;br /&gt;&lt;br /&gt;It seems from the paper that they use simulated annealing to determing modularity. &lt;br /&gt;&lt;br /&gt;&lt;hr /&gt;&lt;br /&gt;&lt;br /&gt;The math bit&lt;br /&gt;&lt;br /&gt;The modularity of a partition $\mathcal{M} \left( \mathcal{P} \right)$ is defined as&lt;br /&gt;&lt;pre lang=&quot;eq.latex&quot;&gt;&lt;br /&gt;\mathcal{M} \left( \mathcal{P} \right)  = \sum_{s=1}^{N_{M}} \left[ \frac{l_{s}}{L} - \left(  \frac{d_{s}}{2L} \right)^{2} \right]&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;Where $L$ is the number of links in the network, $N_{M}$ is the number of non-empty modules in the partition, $l_{s}$ is the number of links in a module $s$ and $d_{s}$ is the sum of degrees in a module $s$. &lt;br /&gt;&lt;br /&gt;Pick your favorite algorithm (I don&#39;t have one yet!) to find a partition to your liking.&lt;br /&gt;&lt;br /&gt;Modules roles are determined by looking at where the modules fall in the $z$ - $P$ plane where $z$ is the relative within module degree and $P$ is the participation coefficient. I&#39;ll have a look at these two metrics in a later post.</content>
 </entry>
 
 <entry>
   <title>Why measure scientists and their work?</title>
   <link href="http://partiallyattended.com/2009/04/14/Why-measure-scientists-and-their-work"/>
   <updated>2009-04-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/14/Why-measure-scientists-and-their-work</id>
   <content type="html">I&#39;m interested in using graph theory to develop tools to improve science (whether I manage to do this is  a moot point, I believe that someone will, and that such tools will be useful). One of the questions raised by any effort to introduce new  systems that may be used to compare and contrast the work of scientists is whether such systems can have any net benefit when weighed against the potential pressure that they may place on working scientists. A large amount of discussion has taken place in the &lt;a href=&quot;http://network.nature.com/groups/citation-science/forum/topics&quot;&gt;Citations in Science&lt;/a&gt; forum. Other places where there is a discussion about the kinds of tools that are being considered is the &lt;a href=&quot;http://repinf.pbwiki.com/&quot;&gt;International Repositories Infrastructure wiki&lt;/a&gt;, and again over at Nature Network Martin Fenner is asking &lt;/a&gt; &lt;a href=&quot;http://network.nature.com/people/mfenner/blog/2009/04/13/a-few-questions-about-author-identifiers&quot;&gt;a few questions about author identifiers&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Themes that frequently bubble up are:&lt;br /&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;	&lt;li&gt;awarding credit, particularly for non-journal writing contributions&lt;/li&gt;&lt;br /&gt;        &lt;li&gt;disambiguating the literature, especially for non-ascii authors&lt;/li&gt;&lt;br /&gt;        &lt;li&gt;tracking trends in the literature&lt;/li&gt;&lt;br /&gt;        &lt;li&gt;matching grant funding to research output&lt;/li&gt;&lt;br /&gt;        &lt;li&gt;opening the monopoly of authority held by large journals and citation indexing services&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;			&lt;br /&gt;There are other themes too, and I may amend this post as those themes come to me.&lt;br /&gt;&lt;br /&gt;posterity vs a living wage&lt;br /&gt;&lt;br /&gt;inbound vs outbound effects on the scientist. </content>
 </entry>
 
 <entry>
   <title>Neat blog on Sankey diagrams.</title>
   <link href="http://partiallyattended.com/2009/04/14/Neat-blog-on-Sankey-diagrams"/>
   <updated>2009-04-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/14/Neat-blog-on-Sankey-diagrams</id>
   <content type="html">I just noticed a very nice blog dedicated to &lt;a href=&quot;http://www.sankey-diagrams.com&quot;&gt;Sankey diagrams&lt;/a&gt;. As Phineas mentions in one post: &lt;a href=&quot;http://www.sankey-diagrams.com/sankey-diagrams-are-directed-weighted-graphs/&quot;&gt;Sankey diagrams are directed graphs&lt;/a&gt;.</content>
 </entry>
 
 <entry>
   <title>Why I'm setting up this blog</title>
   <link href="http://partiallyattended.com/2009/04/13/Why-Im-setting-up-this-blog"/>
   <updated>2009-04-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/13/Why-Im-setting-up-this-blog</id>
   <content type="html">Right, well, I&#39;m pretty interested in graph theory. I work in publishing for the journal Nature on new web products, and I need a focussed way of getting my thoughts together on a range of topics that touch on science. I wanted a space that was more focussed than my &lt;a href=&quot;http://www.partiallyattended.com/&quot;&gt; personal blog&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;I have a few specific aims for this blog. &lt;br /&gt;&lt;br /&gt;&lt;li&gt;Get some of my thoughts on publishing, science and the philosophy of science out of my head and into an archived public space&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Make notes on any academic papers that I read that touch on my area of interests&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Motivate me to take all the cruddy code that I have lying around and push it public&lt;/li&gt;&lt;br /&gt;&lt;li&gt;I&#39;d like to use this blog as a driver to learning how to visualize and extract sense out of large graphs&lt;/li&gt;&lt;br /&gt;&lt;br /&gt;I&#39;m hoping to perhaps get to grips to &lt;a href=&quot;http://processing.org/&quot;&gt;Processing&lt;/a&gt; as a means for the last of these three.&lt;br /&gt;&lt;br /&gt;In regards to the first of these three, I do intend to draw a dotted line between my personal opinions and bits of science that I find interesting, and projects that I am involved in at work. I like the &lt;a href=&quot;http://the.taoofmac.com/space/Disclaimer&quot;&gt;tao of mac disclaimer&lt;/a&gt;, and I hope to tend more towards following this advice than not, however it is not clear to me that I would wish to refrain from commenting on aspects of the work that I do, especially those that reside very much in the public domain. &lt;br /&gt;&lt;br /&gt;That said, all opinions voiced here are strictly my own.</content>
 </entry>
 
 <entry>
   <title>Moving over to the googleverse</title>
   <link href="http://partiallyattended.com/2009/04/13/Moving-over-to-the-googleverse"/>
   <updated>2009-04-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/13/Moving-over-to-the-googleverse</id>
   <content type="html">&lt;p&gt;&lt;br /&gt;Well, today I finally made a switch that I had been thinking about for a long time, I moved the hosting of my personal domain to google app engine with email being managed by google apps for my domain. &lt;a href=&quot;http://www.mulvany.net&quot;&gt;http://www.mulvany.net&lt;/a&gt; is now a google app engine site. At the moment there is not much content there, but the google app engine tool allows me to run a perfect cop of my site off line, and to edit locally and then push live. That&#39;s really nice, and I liked this interaction model while I was creating my wedsite (wedding website). Prior to this my site was running on Zope. To be honest, editing it was a pain in the ass. &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;My google app engine setup is using the standard out of the box Django setup. To be honest, getting uri&#39;s connected to funtions or to content is not as transparently easy as with &lt;a href=&quot;http://www.sinatrarb.com/&quot;&gt;sinatra&lt;/a&gt; on ruby, but it&#39;s pretty nifty, so I&#39;m a happy bunny.&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;I was worried about email, but the MX records took about 30 mins to switch over, so no sweat, it was pretty smooth.&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;There is one downside, i&#39;m hosted on networksoloutions, and it&#39;s looking like those bastards don&#39;t allow proper 301 redirects, so I may not be able to get http://mulvany.net to point to &lt;a href=&quot;http://www.mulvany.net&quot;&gt;http://www.mulvany.net&lt;/a&gt;. I&#39;ve gotten a domain renewal until 2013, so I might just have to suck it up. There is a discussion over at &lt;a href=&quot;http://blogging.nitecruzr.net/2007/11/vagaries-of-publishing-your-blog-to.html&quot;&gt;http://blogging.nitecruzr.net/2007/11/vagaries-of-publishing-your-blog-to.html&lt;/a&gt; pointing out some of the problems about this.&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;I also set up a, well, I&#39;m hesitant to call it work related, let&#39;s call it a blog about the stuff that I&#39;m interested in that&#39;s not totally random, but that does have a relationship to my interests in science. It&#39;s over at &lt;a href=&quot;http://directedgraph.blogspot.com/&quot;&gt;Directed Graph&lt;/a&gt;, it&#39;s a bit new, and it probably won&#39;t be updated any more frequently than this blog, but I&#39;m going to try to keep the content over there a bit more focussed on topics around science, graph theory and publishing.&lt;br /&gt;&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Grave of the reverend Thomas Bayes</title>
   <link href="http://partiallyattended.com/2009/04/13/Grave-of-the-reverend-Thomas-Bayes"/>
   <updated>2009-04-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/13/Grave-of-the-reverend-Thomas-Bayes</id>
   <content type="html">&lt;p class=&quot;mobile-photo&quot;&gt;&lt;a href=&quot;http://3.bp.blogspot.com/_iEDaPT5RT9U/SeQxSrOurUI/AAAAAAAAAIE/xsFDQUwuoB8/s1600-h/photo-794447.jpg&quot;&gt;&lt;img src=&quot;http://3.bp.blogspot.com/_iEDaPT5RT9U/SeQxSrOurUI/AAAAAAAAAIE/xsFDQUwuoB8/s320/photo-794447.jpg&quot;  border=&quot;0&quot; alt=&quot;&quot; id=&quot;BLOGGER_PHOTO_ID_5324434856370679106&quot; /&gt;&lt;/a&gt;&lt;/p&gt;I visited bunhill fields at the weekend. It&amp;#39;s a non conformist  &lt;br&gt;graveyard just off of moorgate in London. Over the course of it&amp;#39;s  &lt;br&gt;active life over 120,000 people were buried there, in a space a little  &lt;br&gt;under four acres. Notable residents include Daniel Defoe and William  &lt;br&gt;Blake, but the occupant I was most intrigued to see was Thomas Bayes,  &lt;br&gt;the founder of Bayseian statistics. The large tomb contains  &lt;br&gt;thebesmains of many members of the Bayes family. It reminded me of a  &lt;br&gt;time when I passsed by the grave of Stokes on a graveyard in  &lt;br&gt;Edinburgh, also old and greened and sentinalled by ancient trees. So  &lt;br&gt;many great minds have fed the soil of this little island.
</content>
 </entry>
 
 <entry>
   <title>Directed Graph blog setup.</title>
   <link href="http://partiallyattended.com/2009/04/13/Directed-Graph-blog-setup"/>
   <updated>2009-04-13T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/13/Directed-Graph-blog-setup</id>
   <content type="html">I&#39;ve decided to use &lt;a href=&quot;http://alexgorbatchev.com/wiki/SyntaxHighlighter&quot;&gt;syntaxhiligher2&lt;/a&gt; to do syntax hi-lighting and a call to &lt;a href=&quot;http://www.yourequations.com/&quot;&gt;Yourequations.com&lt;/a&gt; for rendering latex on the blog. &lt;a href=&quot;http://www.botcyb.org/2008/10/rendering-latex-in-blogger.html&quot;&gt;Bot Cyborg&lt;/a&gt; has a good description of how to get this to work on blogger.&lt;br /&gt;&lt;br /&gt;The main advantage of this approach is that the pseudo code is written in the blog posts in plain encased in a pre statement, and the equations are also just vanilla latex in a pre statement. So if we wanted to think about the betweenness centrality of a graph we have the equation: &lt;br /&gt;&lt;br /&gt;
\[
C_B(v)= \sum_{s \neq v \neq t \in V \atop s \neq t}\frac{\sigma_{st}(v)}{\sigma_{st}}
\]
&lt;br /&gt;&lt;br /&gt;and in python for a given graph object we could use the excellent &lt;a href=&quot;http://networkx.lanl.gov/preview/index.html&quot;&gt;networkx&lt;/a&gt; package to calculate it like so&lt;br /&gt;&lt;br /&gt;&lt;pre class=&quot;brush: py&quot;&gt;&lt;br /&gt;import networkx as nx #import networkx&lt;br /&gt;G=nx.read_adjlist(&quot;graph.adjlist&quot;)  # read in a graph graph&lt;br /&gt;nodes_betweenness_centrality = nx.betweenness_centrality(G) # returns a dictionary&lt;br /&gt;for node_betweenness_centrality in nodes_betweenness_centrality:&lt;br /&gt;    print node_betweenness_centrality&lt;br /&gt;&lt;/pre&gt;</content>
 </entry>
 
 <entry>
   <title>testing latex and syntax hilighting on blogger</title>
   <link href="http://partiallyattended.com/2009/04/12/testing-latex-and-syntax-hilighting-on-blogger"/>
   <updated>2009-04-12T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/12/testing-latex-and-syntax-hilighting-on-blogger</id>
   <content type="html">Some python code &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;some links &lt;br /&gt;http://www.ramymostafa.com/?p=99&lt;br /&gt;http://alexgorbatchev.com/wiki/SyntaxHighlighter&lt;br /&gt;http://www.botcyb.org/2008/10/rendering-latex-in-blogger.html&lt;br /&gt;http://blog.yourequations.com/&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Syntaxhiligher2 (unreliable)&lt;br /&gt;&lt;pre class=&quot;brush: py&quot;&gt;&lt;br /&gt;&lt;br /&gt;def AuthenticateSession(username,password):&lt;br /&gt;     blogger_service = service.GDataService(username,password)&lt;br /&gt;     blogger_service.source = &#39;mulvanynet-BloggerTagger-1.0&#39;&lt;br /&gt;     blogger_service.service = &#39;blogger&#39;&lt;br /&gt;     blogger_service.server = &#39;www.blogger.com&#39;&lt;br /&gt;     blogger_service.ProgrammaticLogin()&lt;br /&gt;     return blogger_service&lt;br /&gt;&lt;br /&gt;def PrintUserBlogInfo(blogger_service):&lt;br /&gt;     query = service.Query()&lt;br /&gt;     query.feed = &#39;/feeds/default/blogs&#39;&lt;br /&gt;     feed = blogger_service.Get(query.ToUri())&lt;br /&gt;     blog_id = feed.entry[0].GetSelfLink().href.split(&quot;/&quot;)[-1]&lt;br /&gt;     print feed.title.text&lt;br /&gt;     print blog_id&lt;br /&gt;     for entry in feed.entry:&lt;br /&gt;         print &quot;\t&quot; + entry.title.text,&lt;br /&gt;         print entry.GetSelfLink().href.split(&quot;/&quot;)[-1]&lt;br /&gt;&lt;br /&gt;def GetBlogFeed(blogger_service):&lt;br /&gt;    query = service.Query()&lt;br /&gt;    query.feed = &quot;/feeds/default/blogs&quot;&lt;br /&gt;   feed = blogger_service.Get(query.ToUri())&lt;br /&gt;   return feed&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;&lt;pre lang=&quot;latex&quot;&gt;&lt;br /&gt;\int_{0}^{1}\frac{x^{4}\left(1-x\right)^{4}}{1+x^{2}}dx&lt;br /&gt;=\frac{22}{7}-\pi&lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;&lt;br /&gt;renders as&lt;br /&gt;&lt;br /&gt;&lt;pre lang=&quot;eq.latex&quot;&gt;&lt;br /&gt;\int_{0}^{1}\frac{x^{4}\left(1-x\right)^{4}}{1+x^{2}}dx&lt;br /&gt;=\frac{22}{7}-\pi&lt;br /&gt;&lt;/pre&gt;
</content>
 </entry>
 
 <entry>
   <title>Getting listed on nature blogs</title>
   <link href="http://partiallyattended.com/2009/04/12/Getting-listed-on-nature-blogs"/>
   <updated>2009-04-12T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/12/Getting-listed-on-nature-blogs</id>
   <content type="html">I&#39;m gittin meself listed on nature blogs. I better whup this blog back into shape first though.
</content>
 </entry>
 
 <entry>
   <title>Adding a tag cloud to blogger</title>
   <link href="http://partiallyattended.com/2009/04/12/Adding-a-tag-cloud-to-blogger"/>
   <updated>2009-04-12T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2009/04/12/Adding-a-tag-cloud-to-blogger</id>
   <content type="html">I&#39;ve been thinking about neat ways to make blogs approach research articles; about how to make some of the core features of a journal be more apparent in a blog, which has led me to think about blogger widgets. That led me to the &lt;a href=&quot;http://phydeaux3.blogspot.com/&quot;&gt;Phydeaux3&lt;/a&gt; blog where there is a kick ass implementation of a &lt;a href=&quot;http://phy3blog.googlepages.com/Beta-Blogger-Label-Cloud.html&quot;&gt;widget to display a tag cloud&lt;/a&gt; for blogger. Hopefully you can see that it works pretty well. Neat plugin. &lt;br /&gt;&lt;br /&gt;Hopefully I&#39;ll be able to dissect this to put in place some of the ideas I have regarding journals.</content>
 </entry>
 
 <entry>
   <title>I woke up today and git-svn was broken.</title>
   <link href="http://partiallyattended.com/2009/03/10/I-woke-up-today-and-git-svn-was-broken."/>
   <updated>2009-03-10T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/03/10/I-woke-up-today-and-git-svn-was-broken.</id>
   <content type="html">Odd, it was working last time I used it. Today I got the following error&lt;br /&gt;&lt;br /&gt;git svn&lt;br /&gt;IO object version 1.22 does not match bootstrap parameter 1.23 at /System/Library/Perl/5.8.8/darwin-thread-multi-2level/XSLoader.pm line 94.&lt;br /&gt;Compilation failed in require at /System/Library/Perl/5.8.8/darwin-thread-multi-2level/IO/Handle.pm line 263.&lt;br /&gt;BEGIN failed--compilation aborted at /System/Library/Perl/5.8.8/darwin-thread-multi-2level/IO/Handle.pm line 263.&lt;br /&gt;Compilation failed in require at /System/Library/Perl/5.8.8/darwin-thread-multi-2level/IO/Seekable.pm line 101.&lt;br /&gt;BEGIN failed--compilation aborted at /System/Library/Perl/5.8.8/darwin-thread-multi-2level/IO/Seekable.pm line 101.&lt;br /&gt;Compilation failed in require at /System/Library/Perl/5.8.8/darwin-thread-multi-2level/IO/File.pm line 133.&lt;br /&gt;BEGIN failed--compilation aborted at /System/Library/Perl/5.8.8/darwin-thread-multi-2level/IO/File.pm line 133.&lt;br /&gt;Compilation failed in require at /usr/local/libexec/git-core//git-svn line 40.&lt;br /&gt;BEGIN failed--compilation aborted at /usr/local/libexec/git-core//git-svn line 40.&lt;br /&gt;&lt;br /&gt;The following blog post http://blog.grogmaster.com/2008/12/notes-about-git-svn-google-code.html seems to reference some kind of git-svn problem on Mac, though whether it is related to the issue that I am having I don&#39;t know. I&#39;ve decided to try to follow the advice there and install through Mac Ports, which involves installing (dmg download available from the site). After that I tried&lt;br /&gt;&lt;br /&gt;sudo port install gs-utils&lt;br /&gt;&lt;br /&gt;For a laugh. I&#39;m now waiting for all of the mac ports dependancies to load and install. I figure I&#39;ve got about a 15% chance of this going through without breaking, given the current state of my system. I&#39;m off for a coffee now, I&#39;ll check back later and see what happens. 
</content>
 </entry>
 
 <entry>
   <title>Rail in the UK is really pretty shitty</title>
   <link href="http://partiallyattended.com/2009/03/09/Rail-in-the-UK-is-really-pretty-shitty"/>
   <updated>2009-03-09T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/03/09/Rail-in-the-UK-is-really-pretty-shitty</id>
   <content type="html">Last month I bought some rail tickets online, and got to London Bridge only to be told that I had to go to Liverpool Street in order to print out the tickets. Five minutes before my train was due to depart. I had to buy a new set of tickets for that days journey, and get up extra early the next day to make it to Liverpool street to print out my tickets.&lt;br /&gt;&lt;br /&gt;This was really annoying me, so I wrote a pretty rude email and got a response saying that if I returned my tickets with a cover letter I would get a full refund, anyway, I&#39;m about to send off for a refund, the cover letter is reproduced below:&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;blockquote&gt;&lt;br /&gt;&lt;br /&gt;09/03/2009&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Dear Madam,&lt;br /&gt;&lt;br /&gt;I am returning the pair of unused tickets for a journey on the &lt;br /&gt;14th of February 2009.&lt;br /&gt;&lt;br /&gt;I purchased these return tickets online for a journey between &lt;br /&gt;London Bridge and Lingfield. When I arrived at London Bridge I &lt;br /&gt;was informed that I had to go to Liverpool Street Station to print&lt;br /&gt;my tickets, and that there was no way to be issued with my tickets &lt;br /&gt;at London Bridge. I was forced to purchase another set of tickets &lt;br /&gt;for journey on that day. &lt;br /&gt;&lt;br /&gt;The following day I had to stop by Liverpool street in order to &lt;br /&gt;print the tickets for travel on the 15th, and in addition I printed&lt;br /&gt;the unused tickets, which I am returning in this letter.&lt;br /&gt;&lt;br /&gt;The idea that you would create a system which allows for purchase&lt;br /&gt;and collection of tickets via a web interface, but at the same &lt;br /&gt;time not provision one of your busiest metropolitan hubs with the means&lt;br /&gt;for retrieval of those tickets is astonishing. I understand that investment&lt;br /&gt;in the ticketing machines may be large, but to roll out a system that &lt;br /&gt;is so patently broken cannot be in the best interest of the consumer.&lt;br /&gt;&lt;br /&gt;At the very least, as an interim measure, providing tickets that may be printed online could be a viable solution. Every rail company that &lt;br /&gt;I have travelled with across Europe has such a system. National Express bus&lt;br /&gt;service has such a system. Even Ryan air uses such a system, which indicates to this mind that it cannot be too expensive to implement.&lt;br /&gt;&lt;br /&gt;Sincerely Yours,&lt;br /&gt;&lt;br /&gt;- Ian Mulvany&lt;br /&gt;&lt;br /&gt;&lt;/blockquote&gt;
</content>
 </entry>
 
 <entry>
   <title>other tips for new york</title>
   <link href="http://partiallyattended.com/2009/03/02/other-tips-for-new-york"/>
   <updated>2009-03-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/03/02/other-tips-for-new-york</id>
   <content type="html">&lt;br /&gt;Also Mona&#39;s bar on 13th and b (a bit of a dive, but all the better for it)&lt;br /&gt;The east village/alphabet street areas have great bars, there used to be one called the drugstore.&lt;br /&gt;&lt;br /&gt;Best Bagel: H&amp;H on 75thish and broadway&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Ah, sure, it&#39;s not a bad wee city.&lt;br /&gt;&lt;br /&gt;Oh, the museums, they are pretty good too.&lt;br /&gt;&lt;br /&gt;The Metropolitan (it&#39;s free)&lt;br /&gt;The Frick Collection&lt;br /&gt;- Guggenheim (depending what&#39;s on)&lt;br /&gt;MOMA&lt;br /&gt;MOMI
</content>
 </entry>
 
 <entry>
   <title>Five places to eat in New York, mmmmm</title>
   <link href="http://partiallyattended.com/2009/03/02/Five-places-to-eat-in-New-York,-mmmmm"/>
   <updated>2009-03-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/03/02/Five-places-to-eat-in-New-York,-mmmmm</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Five places to eat in New York,&lt;/p&gt;&lt;p&gt;I used to live in New York a good few years ago, and now when friends ofmine are about to go there they sometimes ask me about what to do there. Ikeep trying to think of great places to go in the city, so here is a shortlist of five of my favorite places to eat in New York. Not fancy, notexhaustive, just five places that I remember fondly now that I look back onmy time there. Most of these places are on the upper west side, which iswhere I used to live.&lt;/p&gt;&lt;h2&gt;&lt;a href=&quot;http://www.frommers.com/destinations/newyorkcity/D48502.html&quot;&gt;Flor De Mayo&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;.Chinese Cuban fusion. Best half roast chicken in New York. In fact, besthalf roast chicken on the planet. It comes with a big helping of yellow riceand fried platains. It costs about six or seven dollars and it&#39;s on 79th andBroadway, or thereabouts.&lt;/p&gt;&lt;p&gt;&lt;span&gt;Tom&#39;s Restaurant&lt;/span&gt;(a.k.a Tom&#39;s Diner). It has it&#39;s own Wikipedia page, anda &lt;a href=&quot;http://www.flickr.com/search/?q=Tom%27s%20Diner&amp;amp;w=all&quot;&gt;flickrset&lt;/a&gt;. Get the broadway shake. It&#39;s a cappuchino choclate malt shake, it&#39;s amazing.&lt;/p&gt;&lt;h2&gt;&lt;/h2&gt;&lt;h2&gt;Crispy Duck in China Town&lt;/h2&gt;Go eat in china town. Get free helpings of green tea. There is a place downthere that has a menu that includes Chairman Mao&#39;s favorite dishes. I usedto get the chicken in brown sauce. Most of the places down there are dirtcheap. You can get a good lunch for 5 dollars. I went to one place that dida crispy duck with spring onions and pancakes. It was a bit more expensivethe most of the places, but it was one of the most delicious meals that Ihave ever had. It was called &quot;Peking Duck House&quot; (thanks phillip for reminding me of the name!). Oh,and the green tea ice cream that you can get there is great, and so are thelittle egg cakes, look out for the lady in the booth.&lt;h2&gt;Famiglia Pizza&lt;/h2&gt;This is simply the best slice of Pizza in New York, not the biggest, not thefancy schmancyist, just the goddamn best. There are a number of branchesthroughout the city, but the one I used to go to was on 116th and broadway.Incidentally the first pizzeriea in America is also in New York and it&#39;spretty damn good too. It&#39;s called &lt;a href=&quot;http://www.firstpizza.com/&quot;&gt;Lombardi&#39;s&lt;/a&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Any Deli for a Sandwich&lt;/h2&gt;,But specifically broadway market deli where you should get a Sub filled withroast beef, swiss cheese, mayo, and get it heated, mmmm. It&#39;s the archetypalNew York experience. You can get any type of bread and have them stick anytype of anything between the pieces of bread. Bagels are also really reallygood in New York, go to H and H bagels, best bagels in the US, somewherearound 72nd and Broadway. &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>unknown post</title>
   <link href="http://partiallyattended.com/2009/02/18/unnamed"/>
   <updated>2009-02-18T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/18/unnamed</id>
   <content type="html">I want to find out what all of the ISSN&#39;s are for the publications that are printed by Nature Publishing Group. They list all of their publications on the following page &lt;a href=&quot;http://www.nature.com/siteindex/index.html&quot;&gt;http://www.nature.com/siteindex/index.html&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;awk &#39;{print &quot;curl http://www.nature.com&quot;$1&quot;index.html | grep ISSN&quot;}&#39; nature-journal-links.txt &lt;br /&gt;&lt;br /&gt;&lt;br /&gt;
</content>
 </entry>
 
 <entry>
   <title>Training Diary Catchup</title>
   <link href="http://partiallyattended.com/2009/02/18/Training-Diary-Catchup"/>
   <updated>2009-02-18T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/18/Training-Diary-Catchup</id>
   <content type="html">OK, so, I&#39;ve fallen off the wagon in terms of climbing training, or in fact training of any kind.&lt;br /&gt;&lt;br /&gt;Last weekend was interesting. I did the introductory PADI course, but the week leading up to the weekend was swamped with work, and all of the nights of this week have filled up too. I think in order to get my running done I am going to have to transition to a morning run a few times a week.&lt;br /&gt;&lt;br /&gt;I can give this a try tomorrow and see how it goes. I managed to get my bike road worthy again last night, so that will help with the amount of time I have free in the mornings. &lt;br /&gt;&lt;br /&gt;Liowlights: &lt;br /&gt;not finding the time to get any training done.&lt;br /&gt;&lt;br /&gt;Hilights:&lt;br /&gt;So there have been some hilights. &lt;br /&gt;&lt;br /&gt;- Diving for the first time, even if it was only in the pool.&lt;br /&gt;- Last Monday week ago, nearly onsighting a 6c at the wall. My goal is to tick a 6c some time in March, so that was very promising.&lt;br /&gt;- I tried to get back on the fingerboard again this week, but found it very hard. No power, no motivation. This is actually in the hilight column, as if I can actually get some power back in my hands, given how well I was climbing at the wall recently I should see some improvements!! Let&#39;s see how she goes.
</content>
 </entry>
 
 <entry>
   <title>Not a smart way to do this.</title>
   <link href="http://partiallyattended.com/2009/02/18/Not-a-smart-way-to-do-this."/>
   <updated>2009-02-18T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/18/Not-a-smart-way-to-do-this.</id>
   <content type="html">I wanted to find out what all of the 
</content>
 </entry>
 
 <entry>
   <title>Wrangling data from a mysql db</title>
   <link href="http://partiallyattended.com/2009/02/13/Wrangling-data-from-a-mysql-db"/>
   <updated>2009-02-13T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/13/Wrangling-data-from-a-mysql-db</id>
   <content type="html">I am working on a project where I have to pass some data from tables in a MySQL DB over to some people who don&#39;t use a relational database. The question is, how I can best extract the data in a way that is useable to them?&lt;br /&gt;&lt;br /&gt;I&#39;ve decided to prepare the data for them as XML, as this prevents problems with&lt;br /&gt;&lt;br /&gt;My approach uses a hacked together collection of scripts, because, well, as Mark Pilgrim says, because fuck you. &lt;br /&gt;&lt;br /&gt;Actually, what I mean is they were just the fastest set of scripts that I could pull together for the task.&lt;br /&gt;&lt;br /&gt;It&#39;s a mix of perl and python. &lt;br /&gt;&lt;br /&gt;1st off, getting the data out of the DB. 
</content>
 </entry>
 
 <entry>
   <title>Training diary, week 5</title>
   <link href="http://partiallyattended.com/2009/02/10/Training-diary,-week-5"/>
   <updated>2009-02-10T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/10/Training-diary,-week-5</id>
   <content type="html">Saturday 1st&lt;br&gt;Snowboarding&lt;p&gt;Friday 7th&lt;br&gt;Bouldering at the castle&lt;p&gt;OK, I&amp;#39;m a bit late posting this training update. Last week was the&lt;br&gt;snowy week in London, and I was lazy, boo me, however after not&lt;br&gt;climbing for two weeks and given the very poor training week I was&lt;br&gt;uncertain how things would go, which is to say I thought I would not&lt;br&gt;be very good, however my expectations were unfounded and I had a&lt;br&gt;pretty good session. In total 4 5c problems, a 6a problem with an&lt;br&gt;almost flash on another ( got to the last hold). A couple of weeks off&lt;br&gt;were not so bad after all.&lt;p&gt;&lt;br&gt;Highlights:&lt;br&gt;good bouldering session&lt;p&gt;Lowlights:&lt;br&gt;being fuck ass lazy and not getting any running done, shame on me.&lt;p&gt;&lt;br&gt;tags: bouldering, climbing, training
</content>
 </entry>
 
 <entry>
   <title>Converting a mysql schmea into an entity relationship diagram</title>
   <link href="http://partiallyattended.com/2009/02/09/Converting-a-mysql-schmea-into-an-entity-relationship-diagram"/>
   <updated>2009-02-09T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/09/Converting-a-mysql-schmea-into-an-entity-relationship-diagram</id>
   <content type="html">&lt;br /&gt;You will need to install XML support as a ScriptingAddition for script editor. You can get this from &lt;br /&gt;http://www.latenightsw.com/freeware/XMLTools2/. Quit and restart script editor after you have installed the extension. I found that when I was trying to compile the code script editor gave me a syntax error before I installed the extension. The syntax error dissapeard after I installed the extension, but the extensions themselves didn&#39;t work until I restarted script editor. &lt;br /&gt;&lt;br /&gt;http://forums.omnigroup.com/showthread.php?t=1860&lt;br /&gt;
</content>
 </entry>
 
 <entry>
   <title>Even Santa goes to see the rugby</title>
   <link href="http://partiallyattended.com/2009/02/07/Even-Santa-goes-to-see-the-rugby-"/>
   <updated>2009-02-07T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/07/Even-Santa-goes-to-see-the-rugby-</id>
   <content type="html">&lt;p class=&quot;mobile-photo&quot;&gt;&lt;a href=&quot;http://1.bp.blogspot.com/_iEDaPT5RT9U/SY3KsoKv1iI/AAAAAAAAAHU/b46vN-b2jAg/s1600-h/photo-734048.jpg&quot;&gt;&lt;img src=&quot;http://1.bp.blogspot.com/_iEDaPT5RT9U/SY3KsoKv1iI/AAAAAAAAAHU/b46vN-b2jAg/s320/photo-734048.jpg&quot;  border=&quot;0&quot; alt=&quot;&quot; id=&quot;BLOGGER_PHOTO_ID_5300115204530492962&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>weekly training log, week 4</title>
   <link href="http://partiallyattended.com/2009/02/02/weekly-training-log,-week-4"/>
   <updated>2009-02-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/02/weekly-training-log,-week-4</id>
   <content type="html">A week snowboarding in Switzerland, 6 days total with a rest day on&lt;br&gt;the Wed. Pretty fantastic!&lt;p&gt;I didn&amp;#39;t get any running done, and looking at the current weather in&lt;br&gt;London, it is looking like I won&amp;#39;t get any running done this week&lt;br&gt;either.&lt;p&gt;My training summary for January 2009 then is as follows:&lt;p&gt;Number of exercise sessions = 18&lt;br&gt;Number of days with exercise = 17 (54%)&lt;br&gt;Total distance = 49 km&lt;br&gt;Total duration = 54 hrs&lt;p&gt;Overall the 4 week set at stamina training was not great, I just&lt;br&gt;didn&amp;#39;t do enough. I&amp;#39;m going to extend this one week more into the&lt;br&gt;first week of February, and the rest of Feb will be back to power&lt;br&gt;exercises on the fingerboard.
</content>
 </entry>
 
 <entry>
   <title>Weekly training report, week 3</title>
   <link href="http://partiallyattended.com/2009/02/02/Fwd:-Weekly-training-report,-week-3"/>
   <updated>2009-02-02T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/02/02/Fwd:-Weekly-training-report,-week-3</id>
   <content type="html">Saturday 17th&lt;p&gt;Mile end, decided to try power endurance training, picked a 6a to work&lt;br&gt;on. 7 leads, and at the end I was still finding it really easy, which&lt;br&gt;means it was too easy. 6a+ next time. I had a 4 1/2 min rest between&lt;br&gt;leads. Also did some nice bouldering.&lt;p&gt;Sunday 18th&lt;br&gt;ran 12.2 km 80.5 min&lt;br&gt;did this one &lt;a href=&quot;http://www.gmap-pedometer.com/?r=2498524&quot;&gt;http://www.gmap-pedometer.com/?r=2498524&lt;/a&gt;&lt;p&gt;Monday 19th&lt;br&gt;did some chin ups as a warm up and then 3 sets of semi-dead hangs, lasted&lt;br&gt;100s, 80s, 60s respectively with about 4 - 7 min rest between.&lt;br&gt;The last 10 seconds of the first set really fucking started to hurt,&lt;br&gt;which is good.&lt;p&gt;&lt;br&gt;Tuesday 20th&lt;br&gt;4.85 km in 27.5 min, good!&lt;p&gt;Highlights&lt;br&gt;getting in a 12 km run.&lt;p&gt;Lowlights:&lt;br&gt;Picking an endurance set that was too easy, however I know to pick&lt;br&gt;something harder next time!&lt;p&gt;tags: training, climbing
</content>
 </entry>
 
 <entry>
   <title>wrapping c code for python using swig on Mac OS X</title>
   <link href="http://partiallyattended.com/2009/01/21/wrapping-c-code-for-python-using-swig-on-Mac-OS-X"/>
   <updated>2009-01-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/21/wrapping-c-code-for-python-using-swig-on-Mac-OS-X</id>
   <content type="html">from john d cook&lt;br /&gt;http://www.johndcook.com/blog/2009/01/20/using-swig-to-expose-c-code-to-python/&lt;br /&gt;&lt;br /&gt;from &lt;br /&gt;http://www.penzilla.net/tutorials/python/swig/&lt;br /&gt;&lt;br /&gt;and combining the two I came up with a way to get this to work on Mac OS X&lt;br /&gt;&lt;br /&gt;bash$ cat erf.i&lt;br /&gt;&lt;br /&gt;%module erf&lt;br /&gt;#include&lt;br /&gt;double erf(double);&lt;br /&gt;&lt;br /&gt;bash$ swig -o erf_wrap.c -python erf.i&lt;br /&gt;bash$ gcc -o erf_wrap.os -c -fPIC -I/usr/include/python2.4 erf_wrap.c&lt;br /&gt;bash$ gcc -o _erf.so -shared erf_wrap.os&lt;br /&gt;bash$ python&lt;br /&gt;&gt;&gt;&gt; from erf import erf&lt;br /&gt;&gt;&gt;&gt; erf(1)&lt;br /&gt;0.84270079294971489&lt;br /&gt;
</content>
 </entry>
 
 <entry>
   <title>unknown post</title>
   <link href="http://partiallyattended.com/2009/01/21/unnamed"/>
   <updated>2009-01-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/21/unnamed</id>
   <content type="html">&lt;textarea&gt;&lt;br /&gt;&lt;link href=&#39;http://[YOUR HOST]/SyntaxHighlighter.css&#39; rel=&#39;stylesheet&#39; type=&#39;text/css&#39;/&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shCore.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shBrushCpp.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shBrushCSharp.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shBrushCss.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shBrushJava.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shBrushJScript.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shBrushSql.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;script src=&#39;http://[YOUR HOST]/shBrushXml.js&#39; type=&#39;text/javascript&#39;/&gt;&lt;br /&gt;&lt;br /&gt;&lt;script class=&#39;javascript&#39;&gt;&lt;br /&gt;//&lt;![CDATA[&lt;br /&gt;  function FindTagsByName(container, name, Tag)&lt;br /&gt;  {&lt;br /&gt;      var elements = document.getElementsByTagName(Tag);&lt;br /&gt;      for (var i = 0; i &lt; elements.length; i++)&lt;br /&gt;      {&lt;br /&gt;          if (elements[i].getAttribute(&quot;name&quot;) == name)&lt;br /&gt;          {&lt;br /&gt;              container.push(elements[i]);&lt;br /&gt;          }&lt;br /&gt;      }&lt;br /&gt;  }&lt;br /&gt;  var elements = [];&lt;br /&gt;  FindTagsByName(elements, &quot;code&quot;, &quot;pre&quot;);&lt;br /&gt;  FindTagsByName(elements, &quot;code&quot;, &quot;textarea&quot;);&lt;br /&gt;&lt;br /&gt;for(var i=0; i &lt; elements.length; i++) {&lt;br /&gt;if(elements[i].nodeName.toUpperCase() == &quot;TEXTAREA&quot;) {&lt;br /&gt; var childNode = elements[i].childNodes[0];&lt;br /&gt; var newNode = document.createTextNode(childNode.nodeValue.replace(/&lt;br\s*\/?&gt;/gi,&#39;\n&#39;));&lt;br /&gt; elements[i].replaceChild(newNode, childNode);&lt;br /&gt;&lt;br /&gt;}&lt;br /&gt;else if(elements[i].nodeName.toUpperCase() == &quot;PRE&quot;) {&lt;br /&gt; brs = elements[i].getElementsByTagName(&quot;br&quot;);&lt;br /&gt; for(var j = 0, brLength = brs.length; j &lt; brLength; j++) {&lt;br /&gt;  var newNode = document.createTextNode(&quot;\n&quot;);&lt;br /&gt;  elements[i].replaceChild(newNode, brs[0]);&lt;br /&gt; }&lt;br /&gt;}&lt;br /&gt;}&lt;br /&gt;//clipboard does not work well, no line breaks&lt;br /&gt;// dp.SyntaxHighlighter.ClipboardSwf =&lt;br /&gt;//&quot;http://[YOUR HOST]/clipboard.swf&quot;;&lt;br /&gt;dp.SyntaxHighlighter.HighlightAll(&quot;code&quot;);&lt;br /&gt;//]]&gt;&lt;br /&gt;&lt;/script&gt;&lt;br /&gt;&lt;br /&gt;&lt;/body&gt;&lt;br /&gt;&lt;/html&gt;&lt;br /&gt;&lt;/textarea&gt;
</content>
 </entry>
 
 <entry>
   <title>Code Higlighting in Blogger</title>
   <link href="http://partiallyattended.com/2009/01/21/Code-Higlighting-in-Blogger"/>
   <updated>2009-01-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/21/Code-Higlighting-in-Blogger</id>
   <content type="html">&lt;br /&gt;&lt;br /&gt;&lt;pre class=&quot;prettyprint&quot;&gt;&lt;br /&gt;pbl-ian:python-c root# clear&lt;br /&gt;&lt;br /&gt;pbl-ian:python-c root# swig -o erf_wrap.c -python erf.i&lt;br /&gt;pbl-ian:python-c root# gcc -o erf_wrap.os -c -fPIC -I/usr/include/python2.5 erf_wrap.c&lt;br /&gt;pbl-ian:python-c root# ls&lt;br /&gt;erf.i		erf.py		erf_wrap.c	erf_wrap.os&lt;br /&gt;pbl-ian:python-c root# gcc -c erf_wrap.c -I/usr/include/python2.5 -I/usr/lib/python2.5&lt;br /&gt;pbl-ian:python-c root# ls&lt;br /&gt;erf.i		erf.py		erf_wrap.c	erf_wrap.o	erf_wrap.os&lt;br /&gt;pbl-ian:python-c root# python &lt;br /&gt;Python 2.5.1 (r251:54863, Apr 15 2008, 22:57:26) &lt;br /&gt;[GCC 4.0.1 (Apple Inc. build 5465)] on darwin&lt;br /&gt;Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&lt;br /&gt;&gt;&gt;&gt; from erf import erf&lt;br /&gt;Traceback (most recent call last):&lt;br /&gt;  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;&lt;br /&gt;  File &quot;erf.py&quot;, line 7, in &lt;module&gt;&lt;br /&gt;    import _erf&lt;br /&gt;ImportError: No module named _erf&lt;br /&gt;&gt;&gt;&gt; &lt;br /&gt;[3]+  Stopped(SIGTSTP)        python&lt;br /&gt;pbl-ian:python-c root# ld -bundle -flat_namespace -undefined suppress -o _erf.so erf_wrap.o&lt;br /&gt;pbl-ian:python-c root# python&lt;br /&gt;Python 2.5.1 (r251:54863, Apr 15 2008, 22:57:26) &lt;br /&gt;[GCC 4.0.1 (Apple Inc. build 5465)] on darwin&lt;br /&gt;Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&lt;br /&gt;&gt;&gt;&gt; from erf import erf&lt;br /&gt;&gt;&gt;&gt; &lt;br /&gt;&lt;/pre&gt;&lt;br /&gt;
</content>
 </entry>
 
 <entry>
   <title>Weekly training report, week 2</title>
   <link href="http://partiallyattended.com/2009/01/17/Weekly-training-report,-week-2"/>
   <updated>2009-01-17T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/17/Weekly-training-report,-week-2</id>
   <content type="html">Friday 9th&lt;br&gt;2 hours at the castle, top roping with 5kg extra for&lt;p&gt;&lt;br&gt;Sunday 11th&lt;br&gt;57 min 8.75 km&lt;br&gt;&lt;a href=&quot;http://www.gmap-pedometer.com/?r=2483095&quot;&gt;http://www.gmap-pedometer.com/?r=2483095&lt;/a&gt;&lt;p&gt;Went bouldering at the Castle, it was good, nothing too heavy, just&lt;br&gt;tried to do laps on a few nice problems to get tired.&lt;p&gt;&lt;br&gt;Monday 12th&lt;br&gt;Westway, lead climbing.&lt;br&gt;Decided to try some stamina sets, kind of. At least I timed how long&lt;br&gt;it took to do the routes. 6a+ 3 min bang on. I then tried a 6b++&lt;br&gt;(wtf?) and that took 2.30 before I was totally shut down, wrong&lt;br&gt;sequence, too hard a route. I finished the night cruising a 6b, not&lt;br&gt;bad for the first week back. Did some traversing too, coming in at 4&lt;br&gt;and 3 min respectively.&lt;p&gt;Tuesday 13th&lt;br&gt;Donated a pint of blood, and that kind of whupped my ass for a couple of days.&lt;p&gt;Friday 16th&lt;br&gt;7.4 km, 47 min min&lt;br&gt;&lt;a href=&quot;http://www.gmap-pedometer.com/?r=2474102&quot;&gt;http://www.gmap-pedometer.com/?r=2474102&lt;/a&gt;&lt;p&gt;This was a clear 3 min faster over the same route. I was listening to&lt;br&gt;Cafe Del Mar.&lt;p&gt;&lt;br&gt;Weekly Overview&lt;p&gt;Highlights&lt;br&gt;6b onsight at Westway on Monday.&lt;br&gt;Getting my milage in by hauling my ass out for a run on Friday night.&lt;p&gt;Lowlights:&lt;br&gt;being too tired during the week to do anything on the fingerboard, boo me.&lt;p&gt;tags: training, climbing
</content>
 </entry>
 
 <entry>
   <title>Is RSS dead, and why is it dying?</title>
   <link href="http://partiallyattended.com/2009/01/14/Is-RSS-dead,-and-why-is-it-dying%3F"/>
   <updated>2009-01-14T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/14/Is-RSS-dead,-and-why-is-it-dying?</id>
   <content type="html">&lt;p&gt;&lt;br /&gt;From &lt;a href=&quot;http://scienceoftheinvisible.blogspot.com/&quot;&gt;Science of the invisible&lt;/a&gt; I picked up the link to the &lt;a href=&quot;http://www.readwriteweb.com/archives/rip_enterprise_rss.php&quot;&gt;Read Write Web&lt;/a&gt; article on death of enterprise RSS. What is going on here? I&#39;m working in the enterprise and I use RSS a hell of a lot. After trying a number of different strategies I now use Google reader, because it has the fastest way for me to get rid of content in the feeds. Why does the enterprise not get it? I think the issue has to be with signal to noise. RSS opens up feeds to a lot of interesting information, but it is hard work to keep up to date with the content coming in through feeds. Reading feeds is rarely directly relevant to tasks at hand within a company. If we think of RSS as a river of information, most people don&#39;t swim in it, but rather go fishing every now and again when they need to find a data point or write a report or something similar. There is a lot of data, but data without insight is of little use.&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;The tools are not currently in place to easily filter and extract intelligence from that information. Best practices currently involve people creating their own personal workflows, and that is probably a step too far for most people. My take is that what is needed is a tool that can do multiple levels of analysis. Google reader, with it&#39;s Trends, is starting to get there, but this only shows reading behavior and does little to highlight interesting things in the content that is being read.&lt;br /&gt;&lt;p&gt;&lt;br /&gt;What one wants to extract are probably interesting events or facts where in this context interest has to be a user defined filter. Here are examples of the kind of analysis that might be interesting. &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;ul&gt;&lt;br /&gt;&lt;li&gt;Key word extraction and time evolution of these keywords, either through TFIDF of some other algorithm.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Key words determined through cues from social tagging.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Pattern burst detection.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Feed Feed term correlations and time evolution of these correlations.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Rare but interesting terms (what is not being talked about).&lt;/li&gt;&lt;br /&gt;&lt;li&gt;Surprising events, where this can be determined through a Bayseian filter looking for changes from a prior distribution within the feed.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;A mechanism for learning based on user preferences.&lt;/li&gt;&lt;br /&gt;&lt;li&gt;A nice visualization of all of this.&lt;/li&gt;&lt;br /&gt;&lt;/ul&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;All of this should be packaged up with filters for doing this analysis on user read items, all items in user subscribed feeds, feeds similar to user subscribed feeds and feeds subscribed or read by the contextual social network of the user, whether that be class mates, friends, or colleagues on a project. &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;There are many people working on this, for sure.&lt;br /&gt;The &lt;a href=&quot;http://blogs.nature.com/&quot;&gt;Nature Blogs&lt;/a&gt; project and &lt;a href=&quot;http://scintilla.nature.com/front&quot;&gt;Scintilla&lt;/a&gt; already do some of these things. Writing this makes me think I should pick up Programing Collective Intelligence again!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Nasty week ahead</title>
   <link href="http://partiallyattended.com/2009/01/12/Nasty-week-ahead"/>
   <updated>2009-01-12T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/12/Nasty-week-ahead</id>
   <content type="html">&lt;p class=&quot;mobile-photo&quot;&gt;&lt;a href=&quot;http://4.bp.blogspot.com/_iEDaPT5RT9U/SWtIDLNKN7I/AAAAAAAAAHM/HpL6SiB-4Z8/s1600-h/photo-764861.jpg&quot;&gt;&lt;img src=&quot;http://4.bp.blogspot.com/_iEDaPT5RT9U/SWtIDLNKN7I/AAAAAAAAAHM/HpL6SiB-4Z8/s320/photo-764861.jpg&quot;  border=&quot;0&quot; alt=&quot;&quot; id=&quot;BLOGGER_PHOTO_ID_5290401406661572530&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>World War II, Science and Springer Authors</title>
   <link href="http://partiallyattended.com/2009/01/09/World-War-II,-Science-and-Springer-Authors"/>
   <updated>2009-01-09T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/09/World-War-II,-Science-and-Springer-Authors</id>
   <content type="html">&lt;p class=&quot;mobile-photo&quot;&gt;&lt;a href=&quot;http://2.bp.blogspot.com/_iEDaPT5RT9U/SWdpOHNY60I/AAAAAAAAAG8/_jYmZQNvVIo/s1600-h/scienceAndWorldWarII-712471.jpg&quot;&gt;&lt;img src=&quot;http://2.bp.blogspot.com/_iEDaPT5RT9U/SWdpOHNY60I/AAAAAAAAAG8/_jYmZQNvVIo/s320/scienceAndWorldWarII-712471.jpg&quot; border=&quot;0&quot; alt=&quot;&quot; id=&quot;BLOGGER_PHOTO_ID_5289311978544229186&quot; /&gt;&lt;/a&gt;&lt;/p&gt;Springer have just launched a web app that lets you search for&lt;br /&gt;locations of authors, &lt;a href=&quot;http://authormapper.com/search.aspx&quot;&gt;AuthorMapper.&lt;/a&gt; They&lt;br /&gt;have done this by building an XML database with the citation metadata&lt;br /&gt;for all of their papers. You search for terms or authors and it will&lt;br /&gt;generate a google map with the locations for your search terms, or&lt;br /&gt;people. The site also has some other infoporn, including a histogram&lt;br /&gt;for authors published by year for your search term.&lt;p&gt;This box is along the right hand side of the page. From the default&lt;br /&gt;home page there are two things of interest about this little graph.&lt;br /&gt;This first is the rate of increase in the numbers of authors per year.&lt;br /&gt;From a first rough look, it looks somewhat linear from 1948 through to&lt;br /&gt;1980, and then it starts to speed up a bit. No real surprise there.&lt;/p&gt;&lt;p&gt;The other really interesting thing is the presence of two dips in the&lt;br /&gt;numbers, one numbers, one for the First World War and one for the&lt;br /&gt;Second World War. I&#39;ve included a screen shot of the graph below&lt;br /&gt;hi-lighting 1945.&lt;/p&gt;&lt;p&gt;I think that this data is historically quite interesting, as Springer&lt;br /&gt;was founded in Germany in 1842 by Julius Springer, and as a result&lt;br /&gt;their archive for those years is probably a good reflection of the&lt;br /&gt;health of intellectual output from Germany during those times.&lt;/p&gt;&lt;p&gt;Springer also played a role in helping to rebuild science in Germany&lt;br /&gt;after the first world war through the publication of some proceedings.&lt;br /&gt;There is a nice letter of thanks from a number of luminaries in the&lt;br /&gt;scientific community to Springer, you can see an image of &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/149182658/&quot;&gt;the letter&lt;/a&gt;.&lt;/p&gt;</content>
 </entry>
 
 <entry>
   <title>Wekly training report, week 1.</title>
   <link href="http://partiallyattended.com/2009/01/08/Wekly-training-report,-week-1."/>
   <updated>2009-01-08T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2009/01/08/Wekly-training-report,-week-1.</id>
   <content type="html">Sunday 4th of January&lt;br&gt;8 km run, in 53 min, average heart rate about 149 bpm.&lt;br&gt;&lt;a href=&quot;http://www.gmap-pedometer.com/?r=2468786&quot;&gt;http://www.gmap-pedometer.com/?r=2468786&lt;/a&gt;&lt;p&gt;Monday 5th of January.&lt;br&gt;Did a mini endurance set on my fingerboard. I&amp;#39;ve decided to do a 4&lt;br&gt;week set of power endurance training, with a view to improving my&lt;br&gt;sport grade, just 4 weeks and then&lt;br&gt;I&amp;#39;ll switch to finger strength for four weeks. This bascially hurts&lt;br&gt;and sucks, but hey, that&amp;#39;s what you gotta do. I need to be able to&lt;br&gt;hand from my board for from between&lt;br&gt;3 to 4 minutes, my best time, as of today, is 90 seconds, let&amp;#39;s see if&lt;br&gt;we can improve that shall we.&lt;p&gt;Tuesday 6th, 7.4 km, 50.45 min&lt;br&gt;&lt;a href=&quot;http://www.gmap-pedometer.com/?r=2474102&quot;&gt;http://www.gmap-pedometer.com/?r=2474102&lt;/a&gt;&lt;p&gt;Wednesday 7th,&lt;br&gt;Well, I originally wanted to get down to the climbing wall for my&lt;br&gt;first session of the new year, but I was a little wrecked, and decided&lt;br&gt;to have a rest instead.&lt;p&gt;Weekly review,&lt;p&gt;Very happy to have gotten 15km total running in my first week back,&lt;br&gt;and I&amp;#39;m also happy that I&amp;#39;ve decided to try a four week stint just&lt;br&gt;doing Power Endurance, either boulder circuits or exercises on the&lt;br&gt;fingerboard or redpoints. I&amp;#39;ve never had the discipline to keep one&lt;br&gt;format of training going for more than about two weeks before. The&lt;br&gt;goal is also very clear, increase the maximum time that I can hang off&lt;br&gt;of my fingerboard from 90 seconds to more than 90 seconds. This should&lt;br&gt;not be too difficult. The ultimate aim with this is to be able to hang&lt;br&gt;for between three and four minutes, and once I&amp;#39;ve reached that goal,&lt;br&gt;I&amp;#39;ll start adding more resistance to build up a lot of power in that&lt;br&gt;time region.&lt;p&gt;I have decided to recalibrate my training weeks, with day one now&lt;br&gt;being a Saturday, and I&amp;#39;ll be writing up my weekly reports, probably&lt;br&gt;Saturday morning of the new week, so next update a week on Saturday!&lt;p&gt;tags: training, climbing
</content>
 </entry>
 
 <entry>
   <title>Review of Climbing Goals for 2008.</title>
   <link href="http://partiallyattended.com/2008/12/23/Review-of-Climbing-Goals-for-2008"/>
   <updated>2008-12-23T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/23/Review-of-Climbing-Goals-for-2008</id>
   <content type="html">Back in January I set myself some goals for my climbing in 2008. The results at the end of the year were mixed, which means that I succeeded with some of my goals and patently failed with others. The was:&lt;br /&gt;&lt;br /&gt; * Onsight Grit E2&lt;br /&gt; * Redpoint f6c+&lt;br /&gt; * 10 weekende+ trips in UK&lt;br /&gt; * 5 red problems in a day in font&lt;br /&gt; * 80 kg weight&lt;br /&gt; * build climbing wall&lt;br /&gt; * get driving license&lt;br /&gt;&lt;br /&gt;OK, so, I managed to do the following:&lt;br /&gt;&lt;br /&gt; * get driving license&lt;br /&gt;&lt;br /&gt;      This took a lot longer than I had anticipated. 4 tries sucking up a lot of time an money. In the long term I really believe that this is the most important thing for improving my climbing, so it was worth the sacrifice of time and cash to get it completed. That it took more that half a year longer than I had hoped impacted some of my other goals significantly.&lt;br /&gt;&lt;br /&gt; * 5 red problems in a day in font&lt;br /&gt;&lt;br /&gt;     I over achieved on this one, ticked 8 red problems in one day on my trip to font in September. I had only the one trip planned, and it went really well.&lt;br /&gt;&lt;br /&gt; * 80 kg weight&lt;br /&gt;&lt;br /&gt;    OK, this is a bit of a mixed report. I got down to my desired weight by September, and maintained it close to that level, but in November everything went pear shaped, and I&#39;m back up to a little under 85Kg. The lesson though, is that I can get to that weight. I just need to go running more!&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Now, the things I didn&#39;t get to do:&lt;br /&gt;&lt;br /&gt; * Onsight Grit E2&lt;br /&gt; * 10 weekende+ trips in UK&lt;br /&gt;&lt;br /&gt;    These two were basically because I didn&#39;t have time, money or access to a car. A deluge of weddings (6) absorbed much of my free time. I&#39;m not too bummed about this.&lt;br /&gt;&lt;br /&gt; * Redpoint f6c+&lt;br /&gt;&lt;br /&gt;   Ahh, close, so close. I  almost onsighted a 6c indoord. Got to the last hold, fell off trying to hang the last hold. Am confident that a few more trips to the gym would have seen me getting this goal. I actually dropped training for a long swathe in the second part of the year, and only started focussing on this goal towards the end. Earlier focus would have seen me get closer.&lt;br /&gt;&lt;br /&gt; * build climbing wall&lt;br /&gt;&lt;br /&gt; Again, my fingerboard seemed to be doing OK, and I didn&#39;t have the energy to try to build a wall. I will relist this goal for 2009.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;div&gt;So what goals should I set for myself in 2009? My long term goal is to redpoint an 8a by the age of 40. That means I need to improve 7 grades in the next 5 years. I think I&#39;m going to have to get my weight down again, and get my strength up. I&#39;ll also have to take into account that I am going to be getting married, and will have some other time commitments in the new year. &lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Bouldering:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;I&#39;ll have potentially one trip to Font in 2009, in the Spring. I&#39;m going to set a single goal for this trip, climb font 6a. Preferably climb La Marie Rose. This is a major climbing goal for me, and hopefully by focussing specifically on this I can achieve it. It will also mean lots of bouldering in the new year to up my contact strength, which I actually like.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Trad:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Probably getting any trad climbing done would be good. The number of trips last year totally didn&#39;t work out, and if anything the wedding next year will take a bit of time, so let&#39;s say 4 trips over the course of the year, with an E2 onsight. I&#39;m also going to say that if I find myself within distance of Quietus then I&#39;ll have a pop at that.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Indoor/Sport Climbing:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;I need a more refined set of goals. They are going to be:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;6c by March&lt;/div&gt;&lt;div&gt;6c+ by July&lt;/div&gt;&lt;div&gt;7a by November&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Running:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;OK, going running and getting generally fit can really really help, so I&#39;m going to pin my goals at a modest 15km a week. Every week. Except on my honeymoon ;)&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Training:&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;I&#39;m going to keep my training diary up to date on uk climbing.com, but more than that I&#39;ll post a weekly update on this blog. And that should be it!&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>what apps do I want on the iPhone?</title>
   <link href="http://partiallyattended.com/2008/12/21/what-apps-do-I-want-on-the-iPhone%3F"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/what-apps-do-I-want-on-the-iPhone?</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Well, I just read through the engadget report on the iPhone SDK and it&#39;s&lt;br /&gt;&lt;br /&gt;looking pretty good. I&#39;m in the middle of downloading the free SDK, mainly&lt;br /&gt;&lt;br /&gt;so that I can have a virtual iPhone to play around with, but last night I&lt;br /&gt;&lt;br /&gt;got to thinking about what kind of applications I personally would like to&lt;br /&gt;&lt;br /&gt;see on the device.&lt;br /&gt;&lt;br /&gt;I live in London, but I frequently travel to Europe. I have friends that I&lt;br /&gt;&lt;br /&gt;like to keep in contact with in the US as well. Most UK mobile phone&lt;br /&gt;&lt;br /&gt;contracts suck for someone whose social network is evenly distributed across&lt;br /&gt;&lt;br /&gt;the world. Data rates through T-Mobile when I go the the mainland are&lt;br /&gt;&lt;br /&gt;exorbitant, and I only use my N95 as a camera on such occasions cos I can&#39;t&lt;br /&gt;&lt;br /&gt;afford to check email or look at maps. The two main problems with mobile&lt;br /&gt;&lt;br /&gt;tech in Europe at the moment are:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;1. No single european-wide tariff for data and calls. As long as the phone&lt;br /&gt;&lt;br /&gt;companies get away with making pots of cash it&#39;s going to remain this way,&lt;br /&gt;&lt;br /&gt;sigh.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;2. No free WiFi, it exists in patches, but it&#39;s just shit really. One town&lt;br /&gt;&lt;br /&gt;in Ireland was recently blocked from rolling out free municipal wifi by the&lt;br /&gt;&lt;br /&gt;EU on the grounds that it was anti-competitive (phone companies might loose&lt;br /&gt;&lt;br /&gt;revenue). I guess at some point in the future this will change, but for the&lt;br /&gt;&lt;br /&gt;time being it sucks monkeys.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;So the apps I want to see are:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;1. Offline storage of web content, so that I could process, for example,&lt;br /&gt;&lt;br /&gt;feeds or emails, while I am in a high danger zone tariff wise.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;2. Offline access to a google-maps kind of an interface. Apparently for the&lt;br /&gt;&lt;br /&gt;N95 one can download local sheets for areas that you are visiting and browse&lt;br /&gt;&lt;br /&gt;them whilst offline, but the software for doing this is PC only. I could set&lt;br /&gt;&lt;br /&gt;up a copy of MS on my mac, but frankly I don&#39;t have time. I&#39;d like to be&lt;br /&gt;&lt;br /&gt;able to dial in a city that I am about to visit, download maps and related&lt;br /&gt;&lt;br /&gt;info, and then have that on the go while I am tootling around the place.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/what-apps-do-i-want-on-the-iphone.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398e384ef0004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>test a link</title>
   <link href="http://partiallyattended.com/2008/12/21/test-a-link"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/test-a-link</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;test a link &lt;a href=&quot;http://www.guardian.co.uk&quot;&gt;guardian&lt;/a&gt;&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/test-a-link.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398ded3230004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>subprime mortgage crises explained using stick figures</title>
   <link href="http://partiallyattended.com/2008/12/21/subprime-mortgage-crises-explained-using-stick-figures"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/subprime-mortgage-crises-explained-using-stick-figures</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;http://docs.google.com/Present?docid=dtfm9hj_30ccsw79f4&lt;a&gt;&lt;br /&gt;&lt;br /&gt;http://docs.google.com/Present?docid=dtfm9hj_30ccsw79f4&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This is funny, and a little bit scary too.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/subprime-mortgage-crises-explained-using-stick-figures.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48ce0a51e0002?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>star wars</title>
   <link href="http://partiallyattended.com/2008/12/21/star-wars"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/star-wars</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;&amp;quot;The modified tactical standard missile 3 (SM-3) hit the satellite at an&lt;br /&gt;&lt;br /&gt;altitude of 150 miles (247km) while it was travelling at approximately&lt;br /&gt;&lt;br /&gt;17,000 miles per hour.&amp;quot;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I find this somewhat scary.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/star-wars.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398ded3a90004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>social networks</title>
   <link href="http://partiallyattended.com/2008/12/21/social-networks"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/social-networks</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;There is a tension between the providers of social software, and the&lt;br /&gt;&lt;br /&gt;way we behave. When I move from one city to another my social network&lt;br /&gt;&lt;br /&gt;changes as that&#39;s very location dependent, but when I do have that&lt;br /&gt;&lt;br /&gt;network set up for the most part, I don&#39;t expect restrictions on where&lt;br /&gt;&lt;br /&gt;I can go in that city with my friends. For sure, some friends of mine&lt;br /&gt;&lt;br /&gt;might not be caught dead in the palace bar, they only drink in the&lt;br /&gt;&lt;br /&gt;stag&#39;s head, but I could drop in with my palace friends for a quick&lt;br /&gt;&lt;br /&gt;pint and catch up on news.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;On the internet distance only affects us on the scale of timezones,&lt;br /&gt;&lt;br /&gt;and even there our tail of interaction is much broader. Our changing&lt;br /&gt;&lt;br /&gt;activities very much determine the networks we hold on to. I no longer&lt;br /&gt;&lt;br /&gt;practice science, but I&#39;m still in contact with my old climbing&lt;br /&gt;&lt;br /&gt;buddies. However a big change at the moment is that the places we go&lt;br /&gt;&lt;br /&gt;on the internet still don&#39;t play well with each other in the same way&lt;br /&gt;&lt;br /&gt;that they do in real life.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I hope that truly mobile social networks will emerge, and I think they&lt;br /&gt;&lt;br /&gt;will be driven my our address books on our phones. First we will have&lt;br /&gt;&lt;br /&gt;real time tracking of the location of our contacts (to the point that&lt;br /&gt;&lt;br /&gt;mutual permission is granted), and then this will start to seep into&lt;br /&gt;&lt;br /&gt;awareness of location on the web. It&#39;s something that has been faces&lt;br /&gt;&lt;br /&gt;before, with IM and VOIP walled gardens. So far only email and phone&lt;br /&gt;&lt;br /&gt;numbers and physical mail addresses don&#39;t have this problem, and&lt;br /&gt;&lt;br /&gt;perhaps for that reason those will be the media that crack the problem&lt;br /&gt;&lt;br /&gt;first.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/social-networks.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fad690b0750004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>scribed is cool, but</title>
   <link href="http://partiallyattended.com/2008/12/21/scribed-is-cool,-but"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/scribed-is-cool,-but</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;&lt;a href=&quot;http://www.scribd.com/ipaper&quot;&gt;Scribd&lt;/a&gt; has rolled out a very nice&lt;br /&gt;&lt;br /&gt;interface to pdf documents. It is neat and slick, but I think what it is&lt;br /&gt;&lt;br /&gt;missing is support for getting at data or meta-data in the document. It&lt;br /&gt;&lt;br /&gt;would be a great boon to be able to click on a table in a document and have&lt;br /&gt;&lt;br /&gt;that tabular data open either in excel or in some online document tool.&lt;br /&gt;&lt;br /&gt;Likewise for entities in the document that might have associated metadata.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I&#39;m sure such support is possible and it would turn a nice tool into an&lt;br /&gt;&lt;br /&gt;important tool.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/scribed-is-cool-but.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48cfbf3ab0001?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>sadly I've just discovered that vox sucks</title>
   <link href="http://partiallyattended.com/2008/12/21/sadly-I've-just-discovered-that-vox-sucks"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/sadly-I've-just-discovered-that-vox-sucks</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I have been liking using vox to blog, mainly because I can email a blog post&lt;br /&gt;&lt;br /&gt;from any email client. This significantly reduces the&lt;br /&gt;&lt;br /&gt;effort involved in posting a blog post.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I&#39;ve just discovered that vox has enabled snap previews. I don&#39;t like them.&lt;br /&gt;&lt;br /&gt;OK, so, some people may like them, and that&#39;s OK, but I can&#39;t turn them off&lt;br /&gt;&lt;br /&gt;on my blog. That&#39;s not good.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;In addition, when I email a link the link is now broken in vox, so if I type&lt;br /&gt;&lt;br /&gt;http://www.google.com you can see that link text but when I embed it in a &lt;a href=&quot;http://www.google.com&quot;&gt;link&lt;/a&gt; the link does not work. boo.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I also like being able to blog pictures directly from flickr, I guess I am&lt;br /&gt;&lt;br /&gt;going to have to roll my own solution for a blog again at some point in the&lt;br /&gt;&lt;br /&gt;future when I have some time that will allow the bloggy thing to do what I&lt;br /&gt;&lt;br /&gt;want.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Ahh well.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;tags: blog, suckiness, vox&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/sadly-ive-just-discovered-that-vox-sucks.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398ded8e00005?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>question of the day, evil vice presidents</title>
   <link href="http://partiallyattended.com/2008/12/21/question-of-the-day,-evil-vice-presidents"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/question-of-the-day,-evil-vice-presidents</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;So the question of the day is if Hillary Clinton becomes&lt;br /&gt;&lt;br /&gt;Vice-President, would she be more or less evil than Dick Cheney?&lt;br /&gt;&lt;br /&gt;Now Dick Cheney is evil Inc. but the guy has never really pretended to&lt;br /&gt;&lt;br /&gt;be anything that he isn&#39;t, whereas Hillary would obviously&lt;br /&gt;&lt;br /&gt;lie and make policy in any way possible to win votes, which means that&lt;br /&gt;&lt;br /&gt;though she might not be as intrinsically as evil as Dick Cheney, she&lt;br /&gt;&lt;br /&gt;might make as bad a VP as him.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I think that she probably wouldn&#39;t be as actively evil as Dick Cheney,&lt;br /&gt;&lt;br /&gt;but sadly she is beginning to point in that direction.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/question-of-the-day-evil-vice-presidents.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398f807080005?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>progress</title>
   <link href="http://partiallyattended.com/2008/12/21/progress"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/progress</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;If you are interested in the progress of my bet you can follow here:&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://www.bellygraph.com/graph/overview/300&quot;&gt; &lt;img /&gt; &lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;br class=&quot;webkit-block-placeholder&quot; /&gt;&lt;/p&gt;&lt;p&gt;hmm, my embedded image is not showing up here, shame, well, the link is here:&amp;#160;&lt;a href=&quot;http://www.bellygraph.com/graph/view/300&quot;&gt;http://www.bellygraph.com/graph/view/300&lt;/a&gt;&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/progress.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48cdd426c0003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>perl and again,</title>
   <link href="http://partiallyattended.com/2008/12/21/perl-and-again,"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/perl-and-again,</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Ever since Ian Clarke mentioned the potential delights of python to me&lt;br /&gt;&lt;br /&gt;whilst passing me in a corridor back in 1999 I&#39;ve been tinkering around with&lt;br /&gt;&lt;br /&gt;that language.&lt;br /&gt;&lt;br /&gt;Christ, that&#39;s almost 10 years. I like python, it gave a great sense of&lt;br /&gt;&lt;br /&gt;freedom after spending a heavy five years working with various flavours of&lt;br /&gt;&lt;br /&gt;FORTRAN, from&lt;br /&gt;&lt;br /&gt;FORTRAN 90, through to High Performance Fortran. Well, now here I am&lt;br /&gt;&lt;br /&gt;tackling perl. It&#39;s a gem of a language, but by christ it&#39;s scary. The power&lt;br /&gt;&lt;br /&gt;that it gives you&lt;br /&gt;&lt;br /&gt;in it&#39;s ability to interpret so freely is also it&#39;s danger.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;From the end of the introductory chapter from Programming Perl we have:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&amp;quot;But in the end, you must create you own view of Perl. It&#39;s your privilege&lt;br /&gt;&lt;br /&gt;as an artist to inflict the pain of creativity on yourself. We can teach you&lt;br /&gt;&lt;br /&gt;how we paint, but we can&#39;t teach you how your paint. There&#39;s More Than One&lt;br /&gt;&lt;br /&gt;Way To Do It. Have the appropriate amount of fun.&amp;quot;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;For writing code at the speed of thought I can see how this is going to be a&lt;br /&gt;&lt;br /&gt;beguilling language, however for large structured projects it worries me&lt;br /&gt;&lt;br /&gt;that this language is going to slip out and away from the instantly&lt;br /&gt;&lt;br /&gt;comprehensible. Perlhaps that&#39;s not the case, I guess I&#39;ll just have to find&lt;br /&gt;&lt;br /&gt;out.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/perl-and-again.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398d9e8660004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>nice idea for improving the six nations rugby tournament</title>
   <link href="http://partiallyattended.com/2008/12/21/nice-idea-for-improving-the-six-nations-rugby-tournament"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/nice-idea-for-improving-the-six-nations-rugby-tournament</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;&lt;span class=&quot;Apple-style-span&quot;&gt;Shaun Edwards &amp;lt;a href=&amp;quot;&lt;a href=&quot;http://blogs.guardian.co.uk/sport/2008/02/22/bonus_is_the_carrot_that_leads.html&quot; target=&quot;_blank&quot;&gt;http://blogs.guardian.co.uk/sport/2008/02/22/bonus_is_the_carrot_that_leads.html&lt;/a&gt;&amp;quot;&amp;gt;writes&amp;lt;/a&amp;gt; in The Guardian today&lt;br /&gt;that introducing the bonus points system to the Six Nations rugby tournament could help make it more entertaining (not that it needs much help in that regard, as it is a fantastic tournament as it is). I&amp;#160;wholeheartedly&amp;#160;agree. At the moment you get 2 points if you win a game, and 1 point if you draw. Under the bonus system you get an extra point if you score 4 tries and you get a bonus point if you are a losing team and you hold you opposition to a gap of 7 points or less. I think you also get more points for a win. I have only one improvement on this formula. You should get a bonus point if you are wearing green. I fear that this last rule enhancement is likely to be the only way Ireland will win the championship in the near future.&lt;/span&gt;&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/nice-idea-for-improving-the-six-nations-rugby-tournament.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48cfc3e870001?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>networks; head to head</title>
   <link href="http://partiallyattended.com/2008/12/21/networks-head-to-head"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/networks-head-to-head</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;The second talk in the evening CREEN parallel session is from J. Holyst&lt;br /&gt;&lt;br /&gt;about phase transitions in coupled complex networks where the network&lt;br /&gt;&lt;br /&gt;properties are different in the two groups.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;In one group there are a smaller number of members, but they are tightly&lt;br /&gt;&lt;br /&gt;coupled. The second group is larger, but less tightly coupled. The model&lt;br /&gt;&lt;br /&gt;uses an Ising model. The less coupled group has higher fluctuation in&lt;br /&gt;&lt;br /&gt;opinion, and when it is brought into contact with the smaller group the&lt;br /&gt;&lt;br /&gt;larger group undergoes a phase transition. To reverse the process if you&lt;br /&gt;&lt;br /&gt;can find a hub in the tightly coupled system then when you convince them&lt;br /&gt;&lt;br /&gt;their opinions gain traction.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This is a really nice paper and there are obvious tendancies to draw&lt;br /&gt;&lt;br /&gt;parallels with real communities, such as for example two scientific&lt;br /&gt;&lt;br /&gt;communities, or an immigrant community, but I am fairly certain that&lt;br /&gt;&lt;br /&gt;this would at the moment be too simplistic.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;He goes on to show a face off between ER graphs vs BA graphs, and this&lt;br /&gt;&lt;br /&gt;shows that network structure has signifigant effect on the suseptability&lt;br /&gt;&lt;br /&gt;of the community to opinion change.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;One big application could be to look at these results in the context of&lt;br /&gt;&lt;br /&gt;the new vote that Ireland will probably undergo early next year to&lt;br /&gt;&lt;br /&gt;re-ratify the Lison treaty (I mean, I assume that is what is going to&lt;br /&gt;&lt;br /&gt;happen in Ireland next year).&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/networks-head-to-head.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fae8c6339f000b?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>network branching, netsci08</title>
   <link href="http://partiallyattended.com/2008/12/21/network-branching,-netsci08"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/network-branching,-netsci08</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;m really torn by the number of great talks on today. There are three&lt;br /&gt;&lt;br /&gt;parallel sessions, and for each time slot I want to be in at least two&lt;br /&gt;&lt;br /&gt;places at once. I&#39;m going to try to pick out talks that have some&lt;br /&gt;&lt;br /&gt;relation to online social networks, community detection and scientific&lt;br /&gt;&lt;br /&gt;networks, but some of the talks on the theory of clustering are&lt;br /&gt;&lt;br /&gt;conflicting directly with some use cases of looking at some online&lt;br /&gt;&lt;br /&gt;social networks. Ahh, what a dilemma.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The opening talk of this session was from Stwphen Uzzo talking about the&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The next talk was by M.C Gonzales looking at the network of travel&lt;br /&gt;&lt;br /&gt;patterns. This was the paper that made the cover of Nature.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The big question is trying to find out what the travel patterns of&lt;br /&gt;&lt;br /&gt;people are. Thhe big problem is that getting data is apparently quite&lt;br /&gt;&lt;br /&gt;hard.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The solution is to follow mobile phone signals, following 10^5 people over&lt;br /&gt;&lt;br /&gt;10^6 locations over six months.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I&#39;m looking at the movie of their data, and it is clear that many people&lt;br /&gt;&lt;br /&gt;don&#39;t move very much, and other people move a lot. Of course one wants&lt;br /&gt;&lt;br /&gt;to know some information about the people to see what effect like age,&lt;br /&gt;&lt;br /&gt;wealth and occupation will have on these results. Again I&#39;m looking for&lt;br /&gt;&lt;br /&gt;something surprising.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is a nice graph showing corellation over time, it is hugly spiked&lt;br /&gt;&lt;br /&gt;on 24 hours. Not surprising, but a good reality check on the data.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I&#39;m going to head to one of the other sessions after this talk.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This talk, though, is very nice. Once again there is evedence that our&lt;br /&gt;&lt;br /&gt;behaviour is depressingly regular. Also the longer a journey the more likely&lt;br /&gt;&lt;br /&gt;that a journey is going to be linear.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/network-branching-netsci08.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fa968233e80003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>netsci08 opening keynote</title>
   <link href="http://partiallyattended.com/2008/12/21/netsci08-opening-keynote"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/netsci08-opening-keynote</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Nicholas Christakis, Harvard, &amp;quot;eat drink and be merry, the spread of&lt;br /&gt;&lt;br /&gt;health phenomena in social networks&amp;quot;.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This talk is looking at the spread of desies throgh social interactions,&lt;br /&gt;&lt;br /&gt;rather than other types of interactins. The main study was looking at&lt;br /&gt;&lt;br /&gt;obesity using the Framingham Heart Study Social Network. This seems like&lt;br /&gt;&lt;br /&gt;a very famouse social network health related study, so I&#39;m not going to&lt;br /&gt;&lt;br /&gt;go into detail about that, but the bottom line is that they were able to&lt;br /&gt;&lt;br /&gt;construct the social interactions from this study by digging through the&lt;br /&gt;&lt;br /&gt;huge paper archive. They were able to look at friend, relative and&lt;br /&gt;&lt;br /&gt;co-worker ties.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The main study was looking at about 5k individuals out of 12k, taken&lt;br /&gt;&lt;br /&gt;from 1973 onwards.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Nice, node ssize is related to a person&#39;s weight!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is clear clustering of obese nodes in the network, now is this&lt;br /&gt;&lt;br /&gt;clustering random or structured?&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Well, it&#39;s more clustered than random.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There are a couple of reasons why this might be the case. It could be&lt;br /&gt;&lt;br /&gt;that obese people like each other, people might be susceptible to local&lt;br /&gt;&lt;br /&gt;factors, or there might be some kind of peer pressure.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;By looking at time evolution the hope is that they might be able to find&lt;br /&gt;&lt;br /&gt;&#39;patient 0&#39; for the obesity epedmic. OK, video is coming up now ...!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;OK, looking at people getting fatter all over america from 1972 onwards,&lt;br /&gt;&lt;br /&gt;I&#39;m going for a run later!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The effect is not centered in one location, but it seems that it&#39;s an&lt;br /&gt;&lt;br /&gt;epidemic that had multiple starting points in the network.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Looking at the directionality of ties of friendship helps you make&lt;br /&gt;&lt;br /&gt;inferences about causes. Wow, if you are friends with someone who is&lt;br /&gt;&lt;br /&gt;friends with you, and they get obese, you have 300% greater chance to&lt;br /&gt;&lt;br /&gt;gain weight. Stay friends with thin people!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It looks like much of this is driven by social norms.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;They also have gwo data from the network, that is really cool.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;They can convert location to wealth, and can take this into account when&lt;br /&gt;&lt;br /&gt;looking at the evolution of the network.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This data is really really cool.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;No drop off in effect with distance, it is really the social tie that is&lt;br /&gt;&lt;br /&gt;important.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;They also looked at the effect of smoking, and were able to take this&lt;br /&gt;&lt;br /&gt;into account.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;So their working hyppothesis is that it might be the spread of behaviour&lt;br /&gt;&lt;br /&gt;and habit, perticluarly shared behaviour, going runnning vs going for a&lt;br /&gt;&lt;br /&gt;beer.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It might be the spread of an idea, the spread of what an acceptable body&lt;br /&gt;&lt;br /&gt;size might be.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;OK, that&#39;s pretty amazing, and you can tease a hugh amount of&lt;br /&gt;&lt;br /&gt;information out of this study. Liklihood of quitting smoking, of how&lt;br /&gt;&lt;br /&gt;that is effected by education, and friendship tie.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I have to say, there is not a lot of results that are amazingly&lt;br /&gt;&lt;br /&gt;astonishing. They have food networks, like the bannana network and the&lt;br /&gt;&lt;br /&gt;friend chicken network.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;They are also looking at emotions. We know that emotions can spread&lt;br /&gt;&lt;br /&gt;through groups, on diads. Could emotions spread hyper-diadically, and&lt;br /&gt;&lt;br /&gt;over longer time frames?&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is strong clustering of happienss, and your happiness seems&lt;br /&gt;&lt;br /&gt;coreelated with people who are outside of your direct social horizon.&lt;br /&gt;&lt;br /&gt;Interestingly happiness does not spread in the workplace (I think that&lt;br /&gt;&lt;br /&gt;was the point), but happy people have higher clustering and better&lt;br /&gt;&lt;br /&gt;centrality in the network.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There seems to be a half life for catching happiness from your network,&lt;br /&gt;&lt;br /&gt;this is about 6 months. There is also a strong local effect, you need&lt;br /&gt;&lt;br /&gt;happy people to be within about two miles of you, and to be having happy&lt;br /&gt;&lt;br /&gt;events happening to them every six months or so.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Ahh, you can look at smiling on facebook. Right, I gotta put up some&lt;br /&gt;&lt;br /&gt;happy pictures on my profiles!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Ahh, thiness also spreads, but the reason they have been looking at&lt;br /&gt;&lt;br /&gt;obesity is that this study is looking at the obesity epidemic. The&lt;br /&gt;&lt;br /&gt;network shows you the magnification of the phenomena, not the cause or&lt;br /&gt;&lt;br /&gt;origin of the phonomenon.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Interesting question, if you wanted to hire flight attendants who you&lt;br /&gt;&lt;br /&gt;didn&#39;t want to gain weight, should you hire them based on the bmi of&lt;br /&gt;&lt;br /&gt;their friends? Well, the answer is that in a workplace if a certain&lt;br /&gt;&lt;br /&gt;behaviour begins to spread it is likely to have a network effect. The&lt;br /&gt;&lt;br /&gt;flpiside is that you can use these network effects to more economic&lt;br /&gt;&lt;br /&gt;effect by trying to promote certain behaviour through targeting core&lt;br /&gt;&lt;br /&gt;groups in the workplace.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/netsci08-opening-keynote.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fa96818cc60002?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>netsci08 blogging</title>
   <link href="http://partiallyattended.com/2008/12/21/netsci08-blogging"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/netsci08-blogging</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;m in Norwich all this week attending Netsci08&lt;br /&gt;&lt;br /&gt;http://www.ifr.ac.uk/netsci08/, the internatinal workshop and conference&lt;br /&gt;&lt;br /&gt;on network science. It&#39;s a week long event, and broadly speaking it&lt;br /&gt;&lt;br /&gt;looks like there are three types themes that are being discussed here:&lt;br /&gt;&lt;br /&gt;biological networks, pure networks science and community detection in&lt;br /&gt;&lt;br /&gt;networks, principlaly emergent networks of the kind we see in the&lt;br /&gt;&lt;br /&gt;internet.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I&#39;m twittering about the meeting using the tag #netsci08, but it seems&lt;br /&gt;&lt;br /&gt;that I&#39;m the only one out there in the twitterverse who is also at this&lt;br /&gt;&lt;br /&gt;meeting. Not enough power in the lecture hall, and wifi is a little&lt;br /&gt;&lt;br /&gt;ropey, but the conference is pretty good so far.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;The talks on Monday were about some basics on network mathematics, and&lt;br /&gt;&lt;br /&gt;on network science in the social sciences. I&#39;ll go back over my notes&lt;br /&gt;&lt;br /&gt;and give a quick report on them when I get a chance to catchup, but the&lt;br /&gt;&lt;br /&gt;discussion in the evening was pretty interesting, and the talk in the&lt;br /&gt;&lt;br /&gt;morning touced on some very important topics.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The Tuesday morning tutorial is on economics and networks. The morning&lt;br /&gt;&lt;br /&gt;model was very simple, and I think that&#39;s fair enough, but I got the&lt;br /&gt;&lt;br /&gt;feeling that the level of the audience, at least on the side of the room&lt;br /&gt;&lt;br /&gt;that I am sitting on, was high enough to have taken a bit more robust&lt;br /&gt;&lt;br /&gt;model, so I got the feeling that there was some discomfot with the model&lt;br /&gt;&lt;br /&gt;presented.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The after-coffee section is focussing on social influencers, now this is&lt;br /&gt;&lt;br /&gt;interesting.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;How is it that information flow is highly assymetric in the world?&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The model is a mmulti-state model with differeing outcomes. Individuals&lt;br /&gt;&lt;br /&gt;don&#39;t know the true state of the system, but they have beliefs about the&lt;br /&gt;&lt;br /&gt;states. Sounds like a hidden markov model.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The model is stationary, and we want to see how the choices we make&lt;br /&gt;&lt;br /&gt;change the beliefs that we have. Could be a bayseian network? Let&#39;s see.&lt;br /&gt;&lt;br /&gt;What I am hoping to see from this model is how reccomendations can&lt;br /&gt;&lt;br /&gt;travel throgh a network. There is a network of communication between the&lt;br /&gt;&lt;br /&gt;network. The model can integrate dynamics, the dynamics of belief.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is also feedback between actions and beliefs. The main result is&lt;br /&gt;&lt;br /&gt;that as time goes by new information has less effect, and so beliefs&lt;br /&gt;&lt;br /&gt;converge in the network. This is a consequence of Martingale&#39;s theorm.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The big question is whether we get optimal actions, and the big result&lt;br /&gt;&lt;br /&gt;is that the ability to explore the action space and find the best action&lt;br /&gt;&lt;br /&gt;is depenant upon the structure of the network. That is really&lt;br /&gt;&lt;br /&gt;interesting.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Oh my God, someone has an OLPC machine in the audience, how cool is&lt;br /&gt;&lt;br /&gt;that!!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Anyway, back to the talk. So this is indeed a Bayseian network. The&lt;br /&gt;&lt;br /&gt;anti-intutive outcome from this model is that if you have to build a one&lt;br /&gt;&lt;br /&gt;time only network that can&#39;t be changed later, then you have the best&lt;br /&gt;&lt;br /&gt;chance of getting optimal behaviour if no one person has undue&lt;br /&gt;&lt;br /&gt;influence, hoever I think that for online social networks there is a lot&lt;br /&gt;&lt;br /&gt;of dunamics going on that can pull you out of local sub-optimal minima.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/netsci08-blogginh.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fad693bf6d0005?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>mozy backup service</title>
   <link href="http://partiallyattended.com/2008/12/21/mozy-backup-service"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/mozy-backup-service</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;ve been trying the free account this week. I&#39;ve backed up 1.6 GB of data.&lt;br /&gt;&lt;br /&gt;It took, with given interruptions of a normal work day, about 4 days to&lt;br /&gt;&lt;br /&gt;backup this amount of Data.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I am beginning to think that the world of offline remote backups is still a&lt;br /&gt;&lt;br /&gt;little bit away!&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/mozy-backup-service.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48cddaedc0003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>incentives</title>
   <link href="http://partiallyattended.com/2008/12/21/incentives"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/incentives</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;So after reading about some economists who decided to use economic theory to&lt;br /&gt;&lt;br /&gt;loose weight I have decided to follow suit. They both decided to loose a&lt;br /&gt;&lt;br /&gt;certain amount of weight by a certain time and places $5000 in a bond.&lt;br /&gt;&lt;br /&gt;Whoever didn&#39;t make the weight lost their portion of the money to the other&lt;br /&gt;&lt;br /&gt;person. The idea was to affect behavior through an incentive that&lt;br /&gt;&lt;br /&gt;was significant. Well, I&#39;m not a well paid economist, but I have decided to&lt;br /&gt;&lt;br /&gt;follow their example.&lt;br /&gt;&lt;br /&gt;A couple of years ago, back in 2004, my weight had leveled out at 80kg. I&lt;br /&gt;&lt;br /&gt;kept a daily record as part of a climbing training log, and it actually&lt;br /&gt;&lt;br /&gt;varied over the year between 77.4 and 80.6 depending on how much climbing&lt;br /&gt;&lt;br /&gt;i&#39;d been doing.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Then I moved to The Netherlands and within 18 months had put on 15 kg.&lt;br /&gt;&lt;br /&gt;Welll, I&#39;m back down to 85, but those last 5kg have been hell to get rid of,&lt;br /&gt;&lt;br /&gt;so tonight I made a bet with my girlfriend. If I don&#39;t lose those 5kg within&lt;br /&gt;&lt;br /&gt;5 months then I pay her 400 british pounds sterling. That gives me until the&lt;br /&gt;&lt;br /&gt;1st of August.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I reckon I need to run/walk about 100 kms a month to hit the target. I&#39;m&lt;br /&gt;&lt;br /&gt;already walking 3km a day to work, and 3 back again. If I were to walk to&lt;br /&gt;&lt;br /&gt;work every day that would already be close to 120 km, so it&#39;s within the&lt;br /&gt;&lt;br /&gt;realm of possibility. Even more so if I can stop having those sneaky beers&lt;br /&gt;&lt;br /&gt;in the evening.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Spurred on by this new motivation I just went for a 6.6 km run, phew.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/incentives.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398deb0e40004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>ikea is like a biological machine</title>
   <link href="http://partiallyattended.com/2008/12/21/ikea-is-like-a-biological-machine"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/ikea-is-like-a-biological-machine</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;We are just unpacking some more furniture and we have discovered that the&lt;br /&gt;&lt;br /&gt;spacers inside the boxes were made up of cut up pieces of IKEA furniture,&lt;br /&gt;&lt;br /&gt;probably items that had been returned. It reminded my of the cells ability&lt;br /&gt;&lt;br /&gt;to recycle old components.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/ikea-is-like-a-biological-machine.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48d0658700001?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>iPhone prediction market</title>
   <link href="http://partiallyattended.com/2008/12/21/iPhone-prediction-market"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/iPhone-prediction-market</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Well, a prediction about a new market that will spring up (perhaps it&lt;br /&gt;&lt;br /&gt;already has) around the iPhone. So it costs $99 dollars to get an app that&lt;br /&gt;&lt;br /&gt;you have built onto the phone through the App Store. If I design a vanity&lt;br /&gt;&lt;br /&gt;app I&#39;m not going to want to pay that much, but I might pay 5, 10 or even 15&lt;br /&gt;&lt;br /&gt;dollars to see the child of my creativity bouncing around on the little&lt;br /&gt;&lt;br /&gt;device. Some dev shop is going to offer to use their app key to load other&lt;br /&gt;&lt;br /&gt;people&#39;s apps to the App store for sure.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/iphone-prediction-market.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48ce1f01e0002?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>how to learn python</title>
   <link href="http://partiallyattended.com/2008/12/21/how-to-learn-python"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/how-to-learn-python</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;In response to a query that popped up on Friend Feed:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I taught myself years ago with O&#39;Reilly&#39;s Learning Python. The web&lt;br /&gt;&lt;br /&gt;book &#39;Dive into Python&#39; is essential, and the blog posts on&lt;br /&gt;&lt;br /&gt;respectively &#39;How to Code like a Pythonista&#39; and &#39;How to think like a&lt;br /&gt;&lt;br /&gt;Pythonista&#39; will get you a long way towards familiarizing yourself&lt;br /&gt;&lt;br /&gt;with common idoms in the language.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/how-to-learn-python.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fad6901f400004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>getting married and buying an iPhone are probably incompatible.</title>
   <link href="http://partiallyattended.com/2008/12/21/getting-married-and-buying-an-iPhone-are-probably-incompatible."/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/getting-married-and-buying-an-iPhone-are-probably-incompatible.</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Having just gotten engaged and begun to look at the relative costs&lt;br /&gt;&lt;br /&gt;involved in organising a wedding I woke up this morning with the&lt;br /&gt;&lt;br /&gt;unavoidable realisation that the need to save for the wedding is going&lt;br /&gt;&lt;br /&gt;to make purchasing an iPhone, while I have a perfectly normal&lt;br /&gt;&lt;br /&gt;n95 that works rather well (especially since the broken key unstuck&lt;br /&gt;&lt;br /&gt;and started working again) untenable. My cunning plan had been&lt;br /&gt;&lt;br /&gt;to wait until the end of my current contract, at which point the new&lt;br /&gt;&lt;br /&gt;iPhone would be available, but the need to actually pay for the device&lt;br /&gt;&lt;br /&gt;in addition with my desire to invite rather a lot of people to my&lt;br /&gt;&lt;br /&gt;wedding means that I ought rather probably wait until after the&lt;br /&gt;&lt;br /&gt;wedding before&lt;br /&gt;&lt;br /&gt;I think about getting a new flashy gadget.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/getting-married-and-buying-an-iphone-are-probably-incompatible.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398f93c530004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>further confustion</title>
   <link href="http://partiallyattended.com/2008/12/21/further-confustion"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/further-confustion</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;So, after a little more investigation it is clear that earlier links are&lt;br /&gt;&lt;br /&gt;broken and new links have the snap preview.&lt;br /&gt;&lt;br /&gt;Well, I guess I am just going to have to write links as plain text until&lt;br /&gt;&lt;br /&gt;they get this thing sorted out.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;tags: vox sucks&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/further-confustion.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398ded9470005?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>drowning in the streamosphere</title>
   <link href="http://partiallyattended.com/2008/12/21/drowning-in-the-streamosphere"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/drowning-in-the-streamosphere</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;ve been thinking about the streamosphere (as coined by Euan Adie),&lt;br /&gt;&lt;br /&gt;and how I am starting to get dragged down in it again. I&#39;m getting&lt;br /&gt;&lt;br /&gt;daily notifications from pounce, twitter, friendfeed, linked in (I&#39;ve&lt;br /&gt;&lt;br /&gt;been ignoring facebook for ages, facebook, you bite my ass). What I&lt;br /&gt;&lt;br /&gt;really need is a way to manage my notifications and communications in&lt;br /&gt;&lt;br /&gt;the way that I now manage my rss feeds, through a bespoke piece of&lt;br /&gt;&lt;br /&gt;aggregation kit.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/drowning-in-the-streamosphere.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fad68a8f590004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>digital archeology, finding traces in the bits</title>
   <link href="http://partiallyattended.com/2008/12/21/digital-archeology,-finding-traces-in-the-bits"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/digital-archeology,-finding-traces-in-the-bits</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;&lt;a href=&quot;http://www.guardian.co.uk/technology/2008/mar/06/research.bbc&quot;&gt;This&lt;br /&gt;&lt;br /&gt;article in Guardian&lt;/a&gt; today is describing a method of restoring colour to&lt;br /&gt;&lt;br /&gt;some original BBC tv shows whose master tapes were wiped in a purge of the&lt;br /&gt;&lt;br /&gt;BBC archives.&lt;br /&gt;&lt;br /&gt;The shows were originally made in colour, then the master tapes were&lt;br /&gt;&lt;br /&gt;destroyed to make more room in the BBC archive, however black and white&lt;br /&gt;&lt;br /&gt;copies were made for distribution to countries which didn&#39;t have colour TV&lt;br /&gt;&lt;br /&gt;capability. The black and white versions were on a smaller format (16 mm)&lt;br /&gt;&lt;br /&gt;and of a lower resolution.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The method of recording was the following, the colour shows were displayed&lt;br /&gt;&lt;br /&gt;on a large screen and this was re-recorded onto the 16mm tape.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;During this process owing to an artifact from the colour, on the black and&lt;br /&gt;&lt;br /&gt;white film there is a speckled fingeing error.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It describes this problem in the article as follows: &amp;quot;However, there is a&lt;br /&gt;&lt;br /&gt;more relevant problem. Any black and white telerecording of a colour&lt;br /&gt;&lt;br /&gt;programme is prone to pick up interference from the colour encoded video&lt;br /&gt;&lt;br /&gt;signal. This manifests itself as a pattern of small grey dots, called&lt;br /&gt;&lt;br /&gt;chroma-dots, across the picture.&amp;quot;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;A filter used in the re-recording process could eliminate this error, but at&lt;br /&gt;&lt;br /&gt;the time of the recordings the error was considered so minor that often the&lt;br /&gt;&lt;br /&gt;filter was omitted. Back then TV was throwaway and space in a basement was&lt;br /&gt;&lt;br /&gt;considered more valuable than any idea of cultural heritage. Now we look&lt;br /&gt;&lt;br /&gt;back at the decision to scrap the original recordings as somwhat akin to the&lt;br /&gt;&lt;br /&gt;burning of the library of Alexandria. Storage, especially digital, is&lt;br /&gt;&lt;br /&gt;bountiful.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;However, owing to what was then considered to be noise, an error, an&lt;br /&gt;&lt;br /&gt;imperfection in the process, James Insell has devised a technique to map&lt;br /&gt;&lt;br /&gt;back from these chroma-dots to the original colour. And so by looking at the&lt;br /&gt;&lt;br /&gt;finest structure of the current artifact through HD recordings of the 16mm&lt;br /&gt;&lt;br /&gt;film we can recapture  a state of the past that might have been lost to us.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Digging in the digital detritus has uncovered gold.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The formats of our cultural heritage are changing, and there is ever the&lt;br /&gt;&lt;br /&gt;danger that we might loose large chunks of our past when the ability read a&lt;br /&gt;&lt;br /&gt;certain format disappears. For specialist cases, such as the BBC archive,&lt;br /&gt;&lt;br /&gt;there will be, for some time to come, the likes of James Insell who will be&lt;br /&gt;&lt;br /&gt;willing to do the archeology needed to reconstruct from the remnants, but&lt;br /&gt;&lt;br /&gt;looking at the growing sprawl of media in my home I have a number of digital&lt;br /&gt;&lt;br /&gt;cards that can&#39;t be read any more, a zip drive that may or may not contain&lt;br /&gt;&lt;br /&gt;code from a summer of astrophysics, and some very personal movies on&lt;br /&gt;&lt;br /&gt;betamax, that lie in their boxes, becoming more tomb-like as the years roll&lt;br /&gt;&lt;br /&gt;by.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Aside from the personal onus to maintain my own history, I was really&lt;br /&gt;&lt;br /&gt;excited by this guardian article. I loved the idea of recovery from&lt;br /&gt;&lt;br /&gt;the minutia. It is an interesting example for the need for losses&lt;br /&gt;&lt;br /&gt;compression techniques.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/digital-archeology-finding-traces-in-the-bits.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398e3451b0004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>collaborative intelligence and the pidgeonhole problem</title>
   <link href="http://partiallyattended.com/2008/12/21/collaborative-intelligence-and-the-pidgeonhole-problem"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/collaborative-intelligence-and-the-pidgeonhole-problem</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;O&#39;Reilly are hosting a Collaborative Intelligence foo camp this coming&lt;br /&gt;&lt;br /&gt;weekend. There is some discussion bubbling out already on crowdvine at a &lt;a href=&quot;http://cifoo.crowdvine.com/&quot;&gt;group&lt;/a&gt; that has been created for this&lt;br /&gt;&lt;br /&gt;meeting.&lt;br /&gt;&lt;br /&gt;One of the participants, Greg Linden, says the following:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&amp;quot;Hi, Cass. Absolutely, this is called the pigeonhole problem and can be an&lt;br /&gt;&lt;br /&gt;issue if personalization is done poorly.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Done right, personalization enhances discover by helping you find things you&lt;br /&gt;&lt;br /&gt;could not easily have found on your own. Discovery in vast quantities of&lt;br /&gt;&lt;br /&gt;data is what personalization is designed to do. The key is to make sure the&lt;br /&gt;&lt;br /&gt;personalization reaches beyond the obvious and into the surprising. If you&lt;br /&gt;&lt;br /&gt;do that, personalization reveals the full breadth of the data and enhances&lt;br /&gt;&lt;br /&gt;serendipity.&amp;quot;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;and then&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&amp;quot;Hi, Cass. Sure, I think there are things that can be done. Most of this&lt;br /&gt;&lt;br /&gt;depends on the technique used for personalization. For example, if you&lt;br /&gt;&lt;br /&gt;implement recommendations by showing people items that match on keywords or&lt;br /&gt;&lt;br /&gt;from the same fine-grained subject category, you tend to get nearly&lt;br /&gt;&lt;br /&gt;identical items and little diversity. If you use user behavior, such as what&lt;br /&gt;&lt;br /&gt;people tend to buy together, you can often get more interesting patterns&lt;br /&gt;&lt;br /&gt;out, especially if you tune the system to try to reach further afield (at&lt;br /&gt;&lt;br /&gt;the risk of more spurious recommendations).&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It&#39;s a great question and one that troubles all of us when thinking about&lt;br /&gt;&lt;br /&gt;personalization. We are filtering, but trying to do it in a way that focuses&lt;br /&gt;&lt;br /&gt;attention on interesting things, not that limits what people see.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I look forward to talking with you more about this at the conference!&amp;quot;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;It brings to mind the idea that there exists a landscape in the search&lt;br /&gt;&lt;br /&gt;space, and what one wants to do is avoid local minima, but explore enough of&lt;br /&gt;&lt;br /&gt;the space to find related results that are not directly in&lt;br /&gt;&lt;br /&gt;the neighborhood of the item of concern. This means there must be a&lt;br /&gt;&lt;br /&gt;correspondence to the temperature of the system. Getting out of local minima&lt;br /&gt;&lt;br /&gt;can be achieved through an annealing process.&lt;br /&gt;&lt;br /&gt;Balancing relevance and serendipity through some&lt;br /&gt;&lt;br /&gt;constrained minimization process, like the one set out in the information&lt;br /&gt;&lt;br /&gt;bottleneck. How much better performance will you get out of these approaches&lt;br /&gt;&lt;br /&gt;over simple algorithms and what will be the relative computational cost?&lt;br /&gt;&lt;br /&gt;Does anyone know of any literature about this?&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/collaborative-intelligence-and-the-pidgeonhole-problem.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48cfbf4b70001?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>climbing milestone</title>
   <link href="http://partiallyattended.com/2008/12/21/climbing-milestone"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/climbing-milestone</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Last night I got my first UK 6a boulder problem at the Castle climbing wall,&lt;br /&gt;&lt;br /&gt;it&#39;s been a while since I was making progress with my climbing, so that was&lt;br /&gt;&lt;br /&gt;great.My climbing diary is here: http://jottit.com/h94hx/&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/climbing-milestone.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398e7ba690005?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>chasing cars</title>
   <link href="http://partiallyattended.com/2008/12/21/chasing-cars"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/chasing-cars</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;This morning as I was leaving Shoreditch park a guy in a black masarti&lt;br /&gt;&lt;br /&gt;with the top down passed my on my bike.&lt;br /&gt;&lt;br /&gt;I continued along the canal as usual and as I came past sainsbury&#39;s in&lt;br /&gt;&lt;br /&gt;islington saw the same guy in the same car, as I passed him!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Bike 1, Masarati + London Traffic 0.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/chasing-cars.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48cf5781c0003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>bus podcast idea</title>
   <link href="http://partiallyattended.com/2008/12/21/bus-podcast-idea"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/bus-podcast-idea</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I had a great idea yesterday while I was engaged on a personal odyssey on&lt;br /&gt;&lt;br /&gt;London buses. I was on the top deck of, I think it was the 176, heading down&lt;br /&gt;&lt;br /&gt;past Old Street into the square mile, round St Paul&#39;s (with a quick glimpse&lt;br /&gt;&lt;br /&gt;of millennium bridge, and then on into the strand. The bus went past so many&lt;br /&gt;&lt;br /&gt;statues, churches and historical buildings, but I knew only a few of them.&lt;br /&gt;&lt;br /&gt;It struck me that a podcast that could be used as an audio guide for great&lt;br /&gt;&lt;br /&gt;bus routes. You could chapter the audio guide by street so that it was easy&lt;br /&gt;&lt;br /&gt;to navigate according to different traffic conditions.&lt;br /&gt;&lt;br /&gt;The Dublin Tourist Office does something like this already for walks around&lt;br /&gt;&lt;br /&gt;the city &lt;a&gt;&lt;br /&gt;&lt;br /&gt;http://www.visitdublin.com/multimedia/DublinPodcasts/iwalk.aspx?id=275&lt;/a&gt;,&lt;br /&gt;&lt;br /&gt;but with London, or other big cities, providing same for bus routes seems&lt;br /&gt;&lt;br /&gt;like a good idea.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;tags: podcast, idea, cool, london, tourism.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/bus-podcast-idea.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48ce2db730002?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>blogging darwin</title>
   <link href="http://partiallyattended.com/2008/12/21/blogging-darwin"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/blogging-darwin</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;One of my friends is writing a series of blogs about Darwin.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It looks like a very nice series of blog posts, and I look forward to the&lt;br /&gt;&lt;br /&gt;rest.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;You can read it &lt;a&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;Of course as a physicist I disagree with one comment in this first post:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&amp;quot;From an intellectual point of view, the Origin is the most significant work&lt;br /&gt;&lt;br /&gt;of the millennium, and the most important work of non-fiction ever.&amp;quot;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;I would vote the atomic hypothesis into that position, with, in addion, a&lt;br /&gt;&lt;br /&gt;nod to deep time and the extragalactic distance scale, but we each have our&lt;br /&gt;&lt;br /&gt;own scientific peccadilloes so I won&#39;t argue too much on the point.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/blogging-darwin.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398dbec120003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>a great presentation about books and community</title>
   <link href="http://partiallyattended.com/2008/12/21/a-great-presentation-about-books-and-community"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/a-great-presentation-about-books-and-community</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;&lt;span class=&quot;Apple-style-span&quot;&gt;My colleague Gavin Bell just uploaded a great presentation about creating communities of readers out of readers of books. You can see his presentation &amp;lt;a href=&amp;quot;&lt;a href=&quot;http://www.slideshare.net/gavin/gavin-bell-from-readers-of-books-to-a-community-of-readers-oreilly-toc08/&quot; target=&quot;_blank&quot;&gt;http://www.slideshare.net/gavin/gavin-bell-from-readers-of-books-to-a-community-of-readers-oreilly-toc08/&lt;/a&gt;&amp;quot;&amp;gt;here on slideshare&amp;lt;/a&amp;gt;. He gave this talk at the Tools Of Change conference in New York earlier this month.&lt;/span&gt;&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/a-great-presentation-about-books-and-community.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398df1fac0004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Your Brightkite Invite</title>
   <link href="http://partiallyattended.com/2008/12/21/Your-Brightkite-Invite"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Your-Brightkite-Invite</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I just got the following Yay!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&amp;quot;Hi,&lt;br /&gt;&lt;br /&gt;Somebody has sent you a Brightkite invite. Brightkite is a&lt;br /&gt;&lt;br /&gt;location-based social network, currently in private beta.&lt;br /&gt;&lt;br /&gt;Personal message:&lt;br /&gt;&lt;br /&gt;The wait is over! Here&#39;s your Brightkite beta invite. Enjoy!&amp;quot;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Then on sign up discovered that it is only supported by a number of US&lt;br /&gt;&lt;br /&gt;carriers, boo.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/your-brightkite-invite.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fad68800090004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Why the LHC is not really that impressive</title>
   <link href="http://partiallyattended.com/2008/12/21/Why-the-LHC-is-not-really-that-impressive"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Why-the-LHC-is-not-really-that-impressive</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Yesterday the Guardian had a special pull out section dedicated to the&lt;br /&gt;&lt;br /&gt;LHC. If you browse through the articles you find lots of comments along&lt;br /&gt;&lt;br /&gt;the lines of&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&amp;quot;temple to mystery and imagination&amp;quot;, &amp;quot;a journey to the edge of&lt;br /&gt;&lt;br /&gt;understanding&amp;quot;. &amp;quot;a modern cathedral to our relationship with the&lt;br /&gt;&lt;br /&gt;universe&amp;quot;, and so on. From the superlatives that are being written one&lt;br /&gt;&lt;br /&gt;would think that the LHC is the best thing to happen to enlightenment&lt;br /&gt;&lt;br /&gt;since some fat chinese guy sat beneath a tree, and that it is the summit&lt;br /&gt;&lt;br /&gt;of human imagination, achievement and art. Well, I just don&#39;t buy all&lt;br /&gt;&lt;br /&gt;of that crap.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Reading these articles got me thinking about what the LHC is, and&lt;br /&gt;&lt;br /&gt;fundamentally it&#39;s just a larger detector than what we already had&lt;br /&gt;&lt;br /&gt;before. As I see it, it&#39;s an inevitable extension of what you do if you&lt;br /&gt;&lt;br /&gt;want to measure something that we already know how to measure (particle&lt;br /&gt;&lt;br /&gt;tracks), with better precision over a higher energy range.&lt;br /&gt;&lt;br /&gt;The bottom line is that we have been doing this since the 1920&#39;s.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;If you look at it as just being an artifact then it is neat, but there&lt;br /&gt;&lt;br /&gt;are many other piece of artistry that required as much imagination,&lt;br /&gt;&lt;br /&gt;effort, skill and chutzpah to bring together. The moon landings are one,&lt;br /&gt;&lt;br /&gt;the regularity of probes landing on mars another. The engineering&lt;br /&gt;&lt;br /&gt;required to make a large city like New York work always blows my mind,&lt;br /&gt;&lt;br /&gt;and that emerged from a bottom up self organization of 15 million souls&lt;br /&gt;&lt;br /&gt;trying to find a way to survive in an area of land a little too small&lt;br /&gt;&lt;br /&gt;for them all.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;As we look around the world at the things we as a species have built&lt;br /&gt;&lt;br /&gt;there are many such artifacts that can inspire our awe and wonder. I&lt;br /&gt;&lt;br /&gt;don&#39;t think that the LHC can lay a claim to be at the pinnacle, though&lt;br /&gt;&lt;br /&gt;no doubt it is a good example of a big complicated object that make&lt;br /&gt;&lt;br /&gt;people look small when they stand beside it.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is something to wonder at in all of this, and that is the idea&lt;br /&gt;&lt;br /&gt;behind the inevitability of something like the LHC. That idea is the&lt;br /&gt;&lt;br /&gt;atomic and quantum electrodynamical nature of the world. In that there&lt;br /&gt;&lt;br /&gt;is something to be proud of as a species. I don&#39;t see the LHC as being a&lt;br /&gt;&lt;br /&gt;radical departure from this idea, but rather an object whose existence&lt;br /&gt;&lt;br /&gt;is quintessentially rooted in that idea.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;One could almost argue that the LHC represents a failure of the&lt;br /&gt;&lt;br /&gt;imagination. We are faced with limits to our ability to test the&lt;br /&gt;&lt;br /&gt;mathematics that we have written down against the atoms that we write&lt;br /&gt;&lt;br /&gt;with. We cannot tease apart the Fynemann diagrams to tell us more about&lt;br /&gt;&lt;br /&gt;the world, and so we resort to a bigger hammer rather than a more subtle&lt;br /&gt;&lt;br /&gt;approach that might look to other ways to coax the mysteries of the&lt;br /&gt;&lt;br /&gt;universe out of their hiding places.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There have been some papers that have come out recently looking for&lt;br /&gt;&lt;br /&gt;connections in the physics of super fluids with the imagined state of&lt;br /&gt;&lt;br /&gt;the early universe, the idea being that looking at the behavior of&lt;br /&gt;&lt;br /&gt;vortices in super cooled liquids could demonstrate identical physics to&lt;br /&gt;&lt;br /&gt;the phases of matter at the point of various decouplingings in energy&lt;br /&gt;&lt;br /&gt;scales. It&#39;s pretty clear that these models are yet toy models, but&lt;br /&gt;&lt;br /&gt;perhaps they point out an orthogonal direction to building massive atom&lt;br /&gt;&lt;br /&gt;smashers.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I want to be clear that I do applaud the work of the thousands of people&lt;br /&gt;&lt;br /&gt;working at Cern, and I do think that the billions of euro that something&lt;br /&gt;&lt;br /&gt;like this costs is more than worth the investment. I appreciate how hard&lt;br /&gt;&lt;br /&gt;it is to deal with systematics on something of this scale, and it is a&lt;br /&gt;&lt;br /&gt;minor miracle, but I just don&#39;t think that the artifact deserves unconstrained&lt;br /&gt;&lt;br /&gt;adulation over the ideas that is reflects.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/why-the-lhc-is-not-really-that-impressive.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fae8c80373000b?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>We have been nominated for a webby</title>
   <link href="http://partiallyattended.com/2008/12/21/We-have-been-nominated-for-a-webby"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/We-have-been-nominated-for-a-webby</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;br /&gt;        &lt;br /&gt;            &lt;br /&gt;            &lt;p&gt;Nature, the company I work for, has been nominated for a Webby, woot!.&lt;br /&gt;&lt;br /&gt;OK, so we are up against Nasa&#39;s earth observatory, and some other&lt;br /&gt;&lt;br /&gt;great sites in the science field, but it&#39;s really nice to get a nod&lt;br /&gt;&lt;br /&gt;and see that some other people out there like the kind of work that we&lt;br /&gt;&lt;br /&gt;are doing. If you want to go and vote you can at this link here&lt;a href=&quot;http://pv.webbyawards.com/ballot/home/1&quot;&gt;http://pv.webbyawards.com/ballot/home/1&lt;/a&gt;.&lt;/p&gt;&lt;br /&gt;        &lt;br /&gt;    &lt;br /&gt;                &lt;p&gt;&lt;br /&gt;&lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/we-have-been-nominated-for-a-webby.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; | &lt;br /&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398ef07320004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Upcoming.org Founder Creates Fireball (Fire Eagle + DodgeBall + Twitter)</title>
   <link href="http://partiallyattended.com/2008/12/21/Upcoming.org-Founder-Creates-Fireball-Fire-Eagle--DodgeBall-Twitter"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Upcoming.org-Founder-Creates-Fireball-Fire-Eagle--DodgeBall-Twitter</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;br /&gt;        &lt;br /&gt;            &lt;br /&gt;            &lt;p&gt;Ahh, convergence, ahh, the ability to pinpoint your friends on your&lt;br /&gt;&lt;br /&gt;mobile phone. I&#39;ve been waiting for this to happen.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Sent to you by Ian Mulvany via Google Reader: Upcoming.org Founder&lt;br /&gt;&lt;br /&gt;Creates Fireball (Fire Eagle + DodgeBall + Twitter) via TechCrunch by&lt;br /&gt;&lt;br /&gt;Erick Schonfeld on 4/22/08&lt;br /&gt;&lt;br /&gt;Remember DodgeBall, the early social mobile network that languished&lt;br /&gt;&lt;br /&gt;after Google bought it? So does Leonard Lin, a founding member of&lt;br /&gt;&lt;br /&gt;Upcoming.org who recently left Yahoo, where he organized Hack Days. He&lt;br /&gt;&lt;br /&gt;helped write the code for FireBall, a clever mobile geo-location app&lt;br /&gt;&lt;br /&gt;that brings back the promise of DodgeBall using only other existing&lt;br /&gt;&lt;br /&gt;services with public APIs.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;FireBall is a way for people to keep track of where their friends are&lt;br /&gt;&lt;br /&gt;on your mobile phone. It uses Yahoo’s Fire Eagle as a geo-location&lt;br /&gt;&lt;br /&gt;broker and Twitter. It is basically mashup of the two services, plus&lt;br /&gt;&lt;br /&gt;some functionality from Upcoming.org. People add all of their contacts&lt;br /&gt;&lt;br /&gt;on Twitter and authorize Fire Eagle to share their location with&lt;br /&gt;&lt;br /&gt;Fireball. “Instead of creating a new service that forces you to add all&lt;br /&gt;&lt;br /&gt;of your friends,” says Lin, “we end up using Twitter for messaging,”&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;When you want to find out where your friends are who have also signed&lt;br /&gt;&lt;br /&gt;up for FireBall, you send a message to a Fireball account on Twitter.&lt;br /&gt;&lt;br /&gt;You get back a text message with a Tiny URL link. When you click on the&lt;br /&gt;&lt;br /&gt;link, it opens up a KML file that launches Google Maps on your cell&lt;br /&gt;&lt;br /&gt;phone and hows you all your Twitter friends as pinpoints on the map. So&lt;br /&gt;&lt;br /&gt;your Twitter contacts serve as your mobile social network. You can also&lt;br /&gt;&lt;br /&gt;Twitter in your location. Simply mention a room at a conference, for&lt;br /&gt;&lt;br /&gt;instance, and it can pinpoint exactly where you are through integration&lt;br /&gt;&lt;br /&gt;with Upcoming.org,&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;FireBall launches today in a private beta for attendees to the Web 2.0&lt;br /&gt;&lt;br /&gt;Expo. The first 100 TechCrunch readers who are attending Web 2.0 Expo&lt;br /&gt;&lt;br /&gt;and send an email to “Fireballme+TechCrunch [at] gmail [dot] com” will&lt;br /&gt;&lt;br /&gt;recieive an invite. Right now, the service only works in San Francisco.&lt;br /&gt;&lt;br /&gt;CrunchBase Information Fire Eagle Twitter Upcoming Information provided&lt;br /&gt;&lt;br /&gt;by CrunchBase&lt;br /&gt;&lt;br /&gt;Crunch Network: MobileCrunch Mobile Gadgets and Applications, Delivered&lt;br /&gt;&lt;br /&gt;Daily.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Things you can do from here:&lt;br /&gt;&lt;br /&gt;- Subscribe to TechCrunch using Google Reader&lt;br /&gt;&lt;br /&gt;- Get started using Google Reader to easily keep up with all your&lt;br /&gt;&lt;br /&gt;favorite sites&lt;/p&gt;&lt;br /&gt;        &lt;br /&gt;    &lt;br /&gt;                &lt;p&gt;&lt;br /&gt;&lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/upcomingorg-founder-creates-fireball-fire-eagle-dodgeball-twitter.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; | &lt;br /&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48d0f94850001?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Ubigraph</title>
   <link href="http://partiallyattended.com/2008/12/21/Ubigraph"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Ubigraph</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Ubigraph (http://ubietylab.net/ubigraph/) &lt;a href=&quot;http://ubietylab.net/ubigraph/&quot;&gt;Ubigraph&lt;/a&gt; (sorry for the&lt;br /&gt;&lt;br /&gt;fucked up formatting, I think my blog host vox is still being shitty&lt;br /&gt;&lt;br /&gt;at recognising simple html formatting in input, mixed with line&lt;br /&gt;&lt;br /&gt;breaks, it&#39;s just a frickin url link for god&#39;s sake) is a nicely&lt;br /&gt;&lt;br /&gt;implemented engine for making 3-D graphs and plots. I installed it and&lt;br /&gt;&lt;br /&gt;got the default python interface up and running in about 5 minutes. My&lt;br /&gt;&lt;br /&gt;initial reaction was &amp;quot;this is cool&amp;quot;. It runs on a server that you&lt;br /&gt;&lt;br /&gt;communicate with using an XML-RPC interface. Then I had a moment and&lt;br /&gt;&lt;br /&gt;realised that I couldn&#39;t think of anything, other than trying to plot&lt;br /&gt;&lt;br /&gt;graph relationships in citations, to do with it. I want to look at the&lt;br /&gt;&lt;br /&gt;graphing of these relationships, but need to find the time to mine&lt;br /&gt;&lt;br /&gt;some data first, so I&#39;ll just have to put this on the shelf for a&lt;br /&gt;&lt;br /&gt;moment. Before I do, I wanted to spin off a quick blog post to remind&lt;br /&gt;&lt;br /&gt;myself that this really was very easy to work with. You just create a&lt;br /&gt;&lt;br /&gt;graph object G. one could use this in conjunction with &lt;a href=&quot;https://networkx.lanl.gov/wiki&quot;&gt;NetworkX&lt;/a&gt; and subclass the&lt;br /&gt;&lt;br /&gt;ubigraph object from the networkx object and as you wrangled you&lt;br /&gt;&lt;br /&gt;networkx object you would see it appear in ubigraph, that would be&lt;br /&gt;&lt;br /&gt;cool.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/ubigraph.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fae8bb26a6000b?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>The gap between Open Access and Editorial Quality</title>
   <link href="http://partiallyattended.com/2008/12/21/The-gap-between-Open-Access-and-Editorial-Quality"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/The-gap-between-Open-Access-and-Editorial-Quality</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;m reading a great article by Joe Esposito on Open Access. You can read&lt;br /&gt;&lt;br /&gt;the article&lt;br /&gt;&lt;br /&gt;here:http://quod.lib.umich.edu/cgi/t/text/text-idx?c=jep;cc=jep;rgn=main;view=text;idno=3336451.0011.203.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The article&#39;s main claim is that attention is the barrier to&lt;br /&gt;&lt;br /&gt;disemination rather than access. Another claim of this article is that&lt;br /&gt;&lt;br /&gt;paid for publishing platforms are good for readers in that they act as&lt;br /&gt;&lt;br /&gt;an attention filter.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;One of the main claims of the article is that Open Content in a sea of&lt;br /&gt;&lt;br /&gt;other content will exist beyond the scope of peer review and editorial&lt;br /&gt;&lt;br /&gt;review. That is certainly the case at the moment for the most part.&lt;br /&gt;&lt;br /&gt;Beyond Google&#39;s search rank, there are few other effective ways of using&lt;br /&gt;&lt;br /&gt;machines to rank the quality of content, and certainly none at the&lt;br /&gt;&lt;br /&gt;moment that apply specifically to academic content.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I think that one of the issues is that the volume of signals about the&lt;br /&gt;&lt;br /&gt;quality of data that can be data mined compared to the data that needs&lt;br /&gt;&lt;br /&gt;to be mined is still tiny, and the tools to do this mining almost non&lt;br /&gt;&lt;br /&gt;existant. Social signals from tools such as Connotea are only just&lt;br /&gt;&lt;br /&gt;beginnig to create traces, but they are still small.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is a hope that automatic data mining of sources will push out the&lt;br /&gt;&lt;br /&gt;need for manual editorial control, and there are platforms out there&lt;br /&gt;&lt;br /&gt;with enough computational power to do this, it&#39;s just that these&lt;br /&gt;&lt;br /&gt;platforms at the moment have much more important jobs to do.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Even when hardware and storage really are commodotized (and the&lt;br /&gt;&lt;br /&gt;existence of S3, EC2, AppEngine should leave no doubt in our minds that&lt;br /&gt;&lt;br /&gt;this is the way things are going), who is going to write the algorithms&lt;br /&gt;&lt;br /&gt;to review papers for us. Perhaps we only need a few people to do this,&lt;br /&gt;&lt;br /&gt;and so I shouldn&#39;t worry too much about that, but I still don&#39;t see this&lt;br /&gt;&lt;br /&gt;kind of thing happening for a few years yet.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is another interesting aspect of Open Access that springs to&lt;br /&gt;&lt;br /&gt;mind while reading this paper.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The article does not address the machine redability of published work,&lt;br /&gt;&lt;br /&gt;and how restrictions on that type of access can hinder auto-mining of&lt;br /&gt;&lt;br /&gt;facts and figures, the aggregate results of which may command&lt;br /&gt;&lt;br /&gt;signifigantly more attention than the individual componenets.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Finally Joe has a nice little analysis of the kinds of costs associated&lt;br /&gt;&lt;br /&gt;with building new publshing platforms to market.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Alltogether I really liked this paper.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/the-gap-between-open-access-and-editorial-quality.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fad69023ff0004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Testing out a new blog platform</title>
   <link href="http://partiallyattended.com/2008/12/21/Testing-out-a-new-blog-platform"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Testing-out-a-new-blog-platform</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;br /&gt;        &lt;br /&gt;            &lt;br /&gt;            &lt;p&gt;So, I&#39;ve been having some problems with the Vox service for some time,&lt;br /&gt;&lt;br /&gt;and now I have a twine invitation, so I am going to test out Twine as&lt;br /&gt;&lt;br /&gt;a platform for blogging.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The way I blog is that I tend to write up my blog posts in a mail&lt;br /&gt;&lt;br /&gt;client and then mail these to the blog engine, but so far Vox as a&lt;br /&gt;&lt;br /&gt;service has been soso.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;For the next while I am going to try posting the same content to both&lt;br /&gt;&lt;br /&gt;locations and I&#39;ll see which one I like most. Ultimately I want to&lt;br /&gt;&lt;br /&gt;mirror this content on my own domain/site.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;One of the problems that it has been having is mis-rendering html,&lt;br /&gt;&lt;br /&gt;let&#39;s see if I can get a link to my home page working in this post,&lt;br /&gt;&lt;br /&gt;&lt;a href=&quot;http://www.mulvany.net&quot;&gt;mulvany.net&lt;/a&gt;&lt;/p&gt;&lt;br /&gt;        &lt;br /&gt;    &lt;br /&gt;                &lt;p&gt;&lt;br /&gt;&lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/testing-out-a-new-blog-platform.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; | &lt;br /&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398f4f9450004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Soft peer review</title>
   <link href="http://partiallyattended.com/2008/12/21/Soft-peer-review"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Soft-peer-review</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;The following paper &amp;quot;Soft peer review: Social software and distributed&lt;br /&gt;&lt;br /&gt;scientific evaluation&amp;quot; was passed along to me by alf today. I think&lt;br /&gt;&lt;br /&gt;another copy has been haunting my file system for a few days, but this&lt;br /&gt;&lt;br /&gt;seemed like a good reason to sit down again with it.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It&#39;s by &lt;a href=&quot;http://nitens.org/taraborelli/home&quot;&gt;Dario&lt;br /&gt;&lt;br /&gt;Taraborelli&lt;/a&gt; and  the abstract is as follows:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Abstract: The debate on the prospects of peer-review in the Internet age and the&lt;br /&gt;&lt;br /&gt;increasing criticism leveled against the dominant role of impact factor&lt;br /&gt;&lt;br /&gt;indicators are calling for new measurable criteria to assess&lt;br /&gt;&lt;br /&gt;scientific quality.&lt;br /&gt;&lt;br /&gt;Usage-based metrics offer a new avenue to scientific quality assessment but&lt;br /&gt;&lt;br /&gt;face the same risks as first generation search engines that used unreliable&lt;br /&gt;&lt;br /&gt;metrics (such as raw traffic data) to estimate content quality. In&lt;br /&gt;&lt;br /&gt;this article I&lt;br /&gt;&lt;br /&gt;analyze the contribution that social bookmarking systems can provide to the&lt;br /&gt;&lt;br /&gt;problem of usage-based metrics for scientific evaluation. I suggest that&lt;br /&gt;&lt;br /&gt;collaboratively aggregated metadata may help fill the gap between traditional&lt;br /&gt;&lt;br /&gt;citation-based criteria and raw usage factors. I submit that bottom-up,&lt;br /&gt;&lt;br /&gt;distributed evaluation models such as those afforded by social bookmarking&lt;br /&gt;&lt;br /&gt;will challenge more traditional quality assessment models in terms of coverage,&lt;br /&gt;&lt;br /&gt;efficiency and scalability. Services aggregating user-related quality indicators&lt;br /&gt;&lt;br /&gt; for online scientific content will come to occupy a key function in&lt;br /&gt;&lt;br /&gt;the scholarly&lt;br /&gt;&lt;br /&gt;communication system&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;and I get a mention in the acknowledgments, which is cool.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It is a very nice essay on the potential of social bookmarking as a tool for ran&lt;br /&gt;&lt;br /&gt;king academic articles, in addition to adding metadata to scientific articles. D&lt;br /&gt;&lt;br /&gt;ario discusses the issue of ranking the expertese of people who are bookmarking&lt;br /&gt;&lt;br /&gt;and proposes a really nice method to get over the scaling problem that is inherr&lt;br /&gt;&lt;br /&gt;ent when we try to intoduce manual methods to rank people. He suggestes that a u&lt;br /&gt;&lt;br /&gt;sers notes and annotations could be made available about a bookmark on an anonom&lt;br /&gt;&lt;br /&gt;ous basis. Others would have the option to copy these annotations, or rate them.&lt;br /&gt;&lt;br /&gt; This would be a form of soft peer review on the annotations, which would in tur&lt;br /&gt;&lt;br /&gt;n effect the standing of the person creating these annotations.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There would be ways to cheat this system, but with enough signal, one hopes that&lt;br /&gt;&lt;br /&gt; such noise could be drowned out.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The paper also pointed out &lt;a href=&quot;http://www.naboj.com/&quot;&gt;http://www.naboj.com/&lt;/a&gt; which I&#39;d not&lt;br /&gt;&lt;br /&gt;seen before and which is&lt;br /&gt;&lt;br /&gt;pretty amazing.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I really like this paper. Thanks Dario!&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/soft-peer-review.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fae8bdc438000b?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Predictably Irrational</title>
   <link href="http://partiallyattended.com/2008/12/21/Predictably-Irrational"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Predictably-Irrational</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I was in, of all places, Godalming, at the weekend and ended up&lt;br /&gt;&lt;br /&gt;browsing in a book store for a few moments. I saw what looked like a&lt;br /&gt;&lt;br /&gt;very interesting book, &lt;br /&gt;href=&amp;quot;http://www.amazon.co.uk/Predictably-Irrational-Hidden-Forces-Decisions/dp/0007256523/ref=sr_1_1?ie=UTF8&amp;amp;s=books&amp;amp;qid=1211186399&amp;amp;sr=8-1&amp;quot;&amp;gt;Predictably&lt;br /&gt;&lt;br /&gt;Irrational. The book looks at the processes behind bad or&lt;br /&gt;&lt;br /&gt;irrational decisions. The author is an economist and it seems the aim&lt;br /&gt;&lt;br /&gt;of the book is to help us to see the emotional effects that influence&lt;br /&gt;&lt;br /&gt;our decisions, and that lead us to poor decision making. This is a&lt;br /&gt;&lt;br /&gt;theme that is dear to my heart, as it is closely related to the way&lt;br /&gt;&lt;br /&gt;that science policy gets determined, insofar as the facts about&lt;br /&gt;&lt;br /&gt;specific scientific domains are often swamped by emotional reactions&lt;br /&gt;&lt;br /&gt;to what people think the science is about.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I didn&#39;t buy the book yesterday, as I have a very large current&lt;br /&gt;&lt;br /&gt;reading list, but not wanting to feel that I was costing myself some&lt;br /&gt;&lt;br /&gt;opportunity I actually remembered the name of the book. I was&lt;br /&gt;&lt;br /&gt;delighted this morning when I found that the author has a great &lt;br /&gt;href=&amp;quot;http://www.predictablyirrational.com/&amp;quot;&amp;gt;site about the book&lt;br /&gt;&lt;br /&gt;which includes a &lt;br /&gt;href=&amp;quot;http://www.predictablyirrational.com/?page_id=17&amp;quot;&amp;gt;blog. The&lt;br /&gt;&lt;br /&gt;author Dan Ariely also has a &lt;br /&gt;href=&amp;quot;http://en.wikipedia.org/wiki/Dan_Ariely&amp;quot;&amp;gt;wikipedia page.&lt;br /&gt;&lt;br /&gt;From the site and the blog there are links to some papers that seem to&lt;br /&gt;&lt;br /&gt;form the basis of the book, so now I can get some small chunks to read&lt;br /&gt;&lt;br /&gt;to satisfy my curiosity about the subject.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/predictably-irrational.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fa9676d5220003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Networks in Space, Mark Newman, netsci08</title>
   <link href="http://partiallyattended.com/2008/12/21/Networks-in-Space,-Mark-Newman,-netsci08"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Networks-in-Space,-Mark-Newman,-netsci08</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;Mark Newman, Networks in Space,&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This is about networks in geographic space.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Mark is looking at properties of networks that are tied to geography.&lt;br /&gt;&lt;br /&gt;Transport networks are a good example, and we are looking at the&lt;br /&gt;&lt;br /&gt;difference between road and air networks.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The road and air networks are very different, even though you use both&lt;br /&gt;&lt;br /&gt;of them for getting from A to B.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is different bahviour, could I say &#39;driving&#39; the use of these&lt;br /&gt;&lt;br /&gt;networks. For roads we want to minimze the length of our journey, but&lt;br /&gt;&lt;br /&gt;that&#39;s not such an important factor in flight journeys. When we fly we&lt;br /&gt;&lt;br /&gt;like to take direct flights, and minimize the number of flight hops that&lt;br /&gt;&lt;br /&gt;we take.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;If you model this behviour you get out networks that look a lot like&lt;br /&gt;&lt;br /&gt;road and flight networks.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Their first model looked at connecting randomly distributed nodes.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;In order not to get influenced by population density they made a map&lt;br /&gt;&lt;br /&gt;that is rescaled by population density. This is called a cartogram.&lt;br /&gt;&lt;br /&gt;You can see some really nice election cartograms that Newmann and&lt;br /&gt;&lt;br /&gt;Gastern made here: http://www.cscs.umich.edu/~crshalizi/election/&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There is a really nice historical example from Raisz from the&lt;br /&gt;&lt;br /&gt;Geographical REview from 1943.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;It looks like most recent attempts have been hand-drawn, but they look&lt;br /&gt;&lt;br /&gt;pretty shit.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Newman and Gastner made a difffusion algorithm that allows you to do&lt;br /&gt;&lt;br /&gt;this quickly.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;OK, it looks like this started off as a network talk, but segwayed into&lt;br /&gt;&lt;br /&gt;a demo of this mapping technique. Ahh, no, we are back to looking at&lt;br /&gt;&lt;br /&gt;airports.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The interesting result from this talk is that the best covering fro&lt;br /&gt;&lt;br /&gt;utilities such as airports or post offices does not grow lineraly with&lt;br /&gt;&lt;br /&gt;popultaion, but to the power of 2/3.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This was also a pretty nice talk.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/networks-in-space-mark-newman-netsci08.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fa968230600003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Max OS X does not have gethrtime and as a result cannot load Time::HR</title>
   <link href="http://partiallyattended.com/2008/12/21/Max-OS-X-does-not-have-gethrtime-and-as-a-result-cannot-load-TimeHR"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Max-OS-X-does-not-have-gethrtime-and-as-a-result-cannot-load-TimeHR</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I just discovered this after poking around for an inordinate amount of time.&lt;br /&gt;&lt;br /&gt;The trick is to use Time::HiRes instead.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Now someone should write a bridge function that overloads the Time::HR&lt;br /&gt;&lt;br /&gt;functions with Time::HiRes functions which would make a code change as easy&lt;br /&gt;&lt;br /&gt;as loading the overload module.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/max-os-x-does-not-have-gethrtime-and-as-a-result-cannot-load-timehr.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48d02a6d80001?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>I didn't expect lock in so quickly</title>
   <link href="http://partiallyattended.com/2008/12/21/I-didn't-expect-lock-in-so-quickly"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/I-didn't-expect-lock-in-so-quickly</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;ve just signed up for an account with twidox, which is a start up&lt;br /&gt;&lt;br /&gt;that is collecting shared documents of interest to scientists, I&lt;br /&gt;&lt;br /&gt;believe. They are in the private beta stage, but had a link on their&lt;br /&gt;&lt;br /&gt;homepage for requesting an account. I got the following message when I&lt;br /&gt;&lt;br /&gt;hit the verification link:&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;&lt;br /&gt;&lt;br /&gt;Registration is taking place!&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Many thanks for you interest in twidox. Your account has been activated.&lt;br /&gt;&lt;br /&gt;We will send you your private-beta lock-in details very soon.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;We thank you for your support.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Your twidox-team&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/i-didnt-expect-lock-in-so-quickly.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fad69152480005?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>How I learned to stop worrying and love RSS</title>
   <link href="http://partiallyattended.com/2008/12/21/How-I-learned-to-stop-worrying-and-love-RSS"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/How-I-learned-to-stop-worrying-and-love-RSS</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;br /&gt;        &lt;br /&gt;            &lt;br /&gt;            &lt;p&gt;I am, one might say, a bit of an RSS junkie. It has been the main source of&lt;br /&gt;&lt;br /&gt;news and information for me for about the last year or so, but I began to&lt;br /&gt;&lt;br /&gt;feel as if I was drowning in it. I subscribe to something over 80 feeds,&lt;br /&gt;&lt;br /&gt;some of which, like techcrunch, spit out over 40 or 50 items a day. A few&lt;br /&gt;&lt;br /&gt;days away from my feed reader and there could be well over 1000 entries&lt;br /&gt;&lt;br /&gt;waiting when I got back. I had them split down into lots of different&lt;br /&gt;&lt;br /&gt;folders, based on interest, but it was just all getting too much, so I&#39;ve&lt;br /&gt;&lt;br /&gt;adopted a simple strategy which has totally gotten over the problem. I could&lt;br /&gt;&lt;br /&gt;have just dropped all&lt;br /&gt;&lt;br /&gt; I now only have 3 folders. Work Important, Personal Imortant and everything&lt;br /&gt;&lt;br /&gt;else. I&#39;ll read everything in the first two folders, but the threshold for&lt;br /&gt;&lt;br /&gt;getting into the first is very high, and the threshold for getting into the&lt;br /&gt;&lt;br /&gt;second is basically personal blogs from close friends. Everything else goes&lt;br /&gt;&lt;br /&gt;into the 3rd folder and if something doesn&#39;t jump out at me when I scan&lt;br /&gt;&lt;br /&gt;quickly through this folder then I just delete everything. Now the time to&lt;br /&gt;&lt;br /&gt;process all of these feeds is about 10 minutes.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;I do have ideas about how to viksualise this river of information, but&lt;br /&gt;&lt;br /&gt;perhaps I&#39;ll leave those ideas until I get a Google App account.&lt;/p&gt;&lt;br /&gt;        &lt;br /&gt;    &lt;br /&gt;                &lt;p&gt;&lt;br /&gt;&lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/how-i-learned-to-stop-worrying-and-love-rss.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; | &lt;br /&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398ef94740004?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Efficient Name Disambiguation for Large-Scale Databases</title>
   <link href="http://partiallyattended.com/2008/12/21/Efficient-Name-Disambiguation-for-Large-Scale-Databases"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Efficient-Name-Disambiguation-for-Large-Scale-Databases</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;ve been interested for a while now in entity disambiguation,&lt;br /&gt;&lt;br /&gt;particularly where the e&lt;br /&gt;&lt;br /&gt;ntities are the names of authors in academic journals.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Jian Huang, Seyda Ertekin and C Lee Giles have a paper from 2006 in&lt;br /&gt;&lt;br /&gt;which they describe&lt;br /&gt;&lt;br /&gt; the method that they used to diambiguate the CiteSeer data set of&lt;br /&gt;&lt;br /&gt;over 700,000 article&lt;br /&gt;&lt;br /&gt;s. The paper is &amp;quot;Efficient Name Disambiguation for Large-Scale Databases&amp;quot;.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;They were able to use this algorithim to disambiguate this data set&lt;br /&gt;&lt;br /&gt;over three days int&lt;br /&gt;&lt;br /&gt;o just under half a million unique authors (though I didn&#39;t see a&lt;br /&gt;&lt;br /&gt;mention of the hardware nor of whether they used a linear or parallel&lt;br /&gt;&lt;br /&gt;computing approach).&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Their approach seems to be to create an online SVM to bootstap a&lt;br /&gt;&lt;br /&gt;distance funtion. This&lt;br /&gt;&lt;br /&gt; distance funtion can be trained using a number of types of&lt;br /&gt;&lt;br /&gt;information, names, meta da&lt;br /&gt;&lt;br /&gt;ta such as emails, and terms extracted from the associated papers.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;They then block author names into groups based on name similarity, use&lt;br /&gt;&lt;br /&gt;the distance fun&lt;br /&gt;&lt;br /&gt;vtion found with the SVM and find groups of names associated with the&lt;br /&gt;&lt;br /&gt;same person by sc&lt;br /&gt;&lt;br /&gt;anning over the data using DBSCAN, which is a clustering algorithm&lt;br /&gt;&lt;br /&gt;that creates cluster&lt;br /&gt;&lt;br /&gt;s based on a minimal distance and minimal number of members. By&lt;br /&gt;&lt;br /&gt;slicing up the paramate&lt;br /&gt;&lt;br /&gt;r space based on minimal distance, rather than on an a-priori number&lt;br /&gt;&lt;br /&gt;of clusters, the a&lt;br /&gt;&lt;br /&gt;lgorithim is insensitive to a change in the number of points in the&lt;br /&gt;&lt;br /&gt;parameter space. Th&lt;br /&gt;&lt;br /&gt;is means you can use this method in an iterative way and it can be&lt;br /&gt;&lt;br /&gt;adopted to new data&lt;br /&gt;&lt;br /&gt;as it arrives. I&#39;m remined of some papers in astrophysics that did&lt;br /&gt;&lt;br /&gt;clustering based on&lt;br /&gt;&lt;br /&gt;voroni volumes, but only in so far as the voroni method is vaguley&lt;br /&gt;&lt;br /&gt;related to a density&lt;br /&gt;&lt;br /&gt; method.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;All in all this looks like a nice approach to the problem, and the&lt;br /&gt;&lt;br /&gt;authors got 90% accu&lt;br /&gt;&lt;br /&gt;racy with their method, which is probably enough to bootstap a&lt;br /&gt;&lt;br /&gt;solution into existence.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/efficient-name-disambiguation-for-large-scale-databases.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fae8bdef7a000b?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Creationism as Science,</title>
   <link href="http://partiallyattended.com/2008/12/21/Creationism-as-Science,"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Creationism-as-Science,</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;p&gt;I&#39;m at the netsci08 conference and there is a really delightful talk&lt;br /&gt;&lt;br /&gt;about the network of papers published in the creationisim/evolution&lt;br /&gt;&lt;br /&gt;debate.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;The group looked at key people in the ID debate and people who acted as&lt;br /&gt;&lt;br /&gt;strong defenders of evolution. One can then make a graph of the links&lt;br /&gt;&lt;br /&gt;between the groups and intra-groups based on citation and co-citation.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Now one area of social science that is pretty interesting in this debate&lt;br /&gt;&lt;br /&gt;is looking at triads, as there are clearly going to be antagonitic&lt;br /&gt;&lt;br /&gt;relationships in this debate.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;In the graph evolutionists are blue, creationists are yellow and Dawkins&lt;br /&gt;&lt;br /&gt;is red on his own.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;From the graph it is clear that there are some people who are opinion&lt;br /&gt;&lt;br /&gt;leaders.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;Ok, what is interesting is that there are far more mixed triples than&lt;br /&gt;&lt;br /&gt;similar triples in the graph, meaning that people from both sides seem&lt;br /&gt;&lt;br /&gt;to be spending more time slagging each other off than agreeing with&lt;br /&gt;&lt;br /&gt;their friends.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;This is the first time that I would be tempted to say that the study of&lt;br /&gt;&lt;br /&gt;creationisim could be considered science.&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/creationism-as-science.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00fa968244010003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Cloverfield</title>
   <link href="http://partiallyattended.com/2008/12/21/Cloverfield"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/Cloverfield</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;        &lt;div&gt;&lt;br /&gt; &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/2241167543/&quot; title=&quot;photo sharing&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;http://farm3.static.flickr.com/2124/2241167543_7954f37eb8_m.jpg&quot; /&gt;&lt;/a&gt;&lt;br /&gt; &lt;br /&gt;&lt;br /&gt; &lt;span&gt;&lt;br /&gt;  &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/2241167543/&quot;&gt;Cloverfield&lt;/a&gt;&lt;br /&gt;  &lt;br /&gt;&lt;br /&gt;  Originally uploaded by &lt;a href=&quot;http://www.flickr.com/people/mulvanynet/&quot;&gt;Ian Mulvany&lt;/a&gt;&lt;br /&gt; &lt;/span&gt;&lt;br /&gt;&lt;/div&gt;&lt;p&gt;&lt;br /&gt;My Work Colleague make a cloverfield diarama in our sandbox today. We will be going into full scale production soon.&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;   &lt;p&gt; &lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/cloverfield.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;   |   &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00e398d94ea20003?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt; &lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>A minor milestone in leisurely reading</title>
   <link href="http://partiallyattended.com/2008/12/21/A-minor-milestone-in-leisurely-reading"/>
   <updated>2008-12-21T00:00:00+00:00</updated>
   <id>http://partiallyattended.com/2008/12/21/A-minor-milestone-in-leisurely-reading</id>
   <content type="html">&lt;div&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;br /&gt;        &lt;br /&gt;            &lt;br /&gt;            &lt;p&gt;Last night I finally finished Neil Stephenson&#39;s Quicksilver. Oh, don&#39;t&lt;br /&gt;&lt;br /&gt;get me wrong, I&#39;ve read it, and the full trilogy, before, but for much&lt;br /&gt;&lt;br /&gt;of the past year I have been re-reading it aloud to my girlfriend. She&lt;br /&gt;&lt;br /&gt;has an eye strain which means that if she reads too much at night she&lt;br /&gt;&lt;br /&gt;gets headaches, and so I&#39;ve been doing the recreational reading for&lt;br /&gt;&lt;br /&gt;the two of us over the past year. We started out with Quicksilver, and&lt;br /&gt;&lt;br /&gt;made steady but slow progress through it. There have been some breaks,&lt;br /&gt;&lt;br /&gt;a small diversion through the worlds of Philip Pullman, a frantic dash&lt;br /&gt;&lt;br /&gt;through the last Harry Potter, but quicksilver has been the constant&lt;br /&gt;&lt;br /&gt;through the journey, a stable rock against which we could navigate.&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;&lt;p&gt;There have been patches which have been hard to read out loud, many&lt;br /&gt;&lt;br /&gt;sections of the book include deep philosophical discourse between&lt;br /&gt;&lt;br /&gt;multiple characters, and when reading making clear who was saying what&lt;br /&gt;&lt;br /&gt;was at times a bit of a challenge, but we finally got to the last page&lt;br /&gt;&lt;br /&gt;just before midnight last night. Now just The Confusion, The System of&lt;br /&gt;&lt;br /&gt;the World and The Cryptonomicon left to get through!&lt;/p&gt;&lt;br /&gt;        &lt;br /&gt;    &lt;br /&gt;                &lt;p&gt;&lt;br /&gt;&lt;br /&gt;    &lt;a href=&quot;http://partiallyattended.vox.com/library/post/a-minor-milestone-in-leisurely-reading.html?_c=feed-atom-full#comments&quot;&gt;Read and post comments&lt;/a&gt;&lt;br /&gt;&lt;br /&gt; | &lt;br /&gt;&lt;br /&gt;    &lt;br /&gt;    &lt;a href=&quot;http://www.vox.com/share/6a00d09e7c9248be2b00f48cf311a30002?_c=feed-atom-full&quot;&gt;Send to a friend&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;&lt;br /&gt;&lt;br /&gt;                &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>weekend grill</title>
   <link href="http://partiallyattended.com/2008/07/14/weekend-grill"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/weekend-grill</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I visited my girlfriend in Germany this weekend, and her father wascelebrating his 60th birthday. A friend of his arranged a full wild boarfrom the German forests. The spit it and slow cooked it for 7 hours, ittasted amazing. I can quite see why Asterix and friends got so excited aboutthis.&lt;/p&gt; &lt;div class=&quot;enclosure enclosure-center enclosure-extra-large photo-enclosure&quot;&gt;&lt;div class=&quot;enclosure-inner&quot;&gt; &lt;div class=&quot;enclosure-list&quot;&gt; &lt;div class=&quot;enclosure-item photo-asset last&quot;&gt; &lt;div class=&quot;enclosure-image&quot;&gt; &lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00e398b2e6520001.html&quot;&gt;&lt;img src=&quot;http://a2.vox.com/6a00d09e7c9248be2b00e398b2e6520001-500pi&quot; alt=&quot;13102007410.jpg&quot; title=&quot;13102007410.jpg&quot; /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;enclosure-meta&quot;&gt; &lt;div class=&quot;enclosure-asset-name&quot;&gt;&lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00e398b2e6520001.html&quot; title=&quot;13102007410.jpg&quot;&gt;13102007410.jpg&lt;/a&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;!-- end enclosure --&gt; &lt;div class=&quot;enclosure enclosure-center enclosure-extra-large photo-enclosure&quot;&gt;&lt;div class=&quot;enclosure-inner&quot;&gt; &lt;div class=&quot;enclosure-list&quot;&gt; &lt;div class=&quot;enclosure-item photo-asset last&quot;&gt; &lt;div class=&quot;enclosure-image&quot;&gt; &lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00e398b2e6530001.html&quot;&gt;&lt;img src=&quot;http://a3.vox.com/6a00d09e7c9248be2b00e398b2e6530001-500pi&quot; alt=&quot;13102007409.jpg&quot; title=&quot;13102007409.jpg&quot; /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;enclosure-meta&quot;&gt; &lt;div class=&quot;enclosure-asset-name&quot;&gt;&lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00e398b2e6530001.html&quot; title=&quot;13102007409.jpg&quot;&gt;13102007409.jpg&lt;/a&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;!-- end enclosure --&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>spreading of meme's behavior driven transmission of an idea</title>
   <link href="http://partiallyattended.com/2008/07/14/spreading-of-meme's-behavior-driven-transmission-of-an-idea"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/spreading-of-meme's-behavior-driven-transmission-of-an-idea</id>
   <content type="html">&lt;div&gt; &lt;p&gt;&lt;a&gt;Thistech blog article&lt;/a&gt; is a charming description of how human behaviour seemsto have spread the name of a particular wireless node across america. Ithink it is a lovely example of the spread of an idea driven by simpleself-interest.&lt;/p&gt; &lt;p&gt;  &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>sometimes, just sometimes a piece of news makes me smile</title>
   <link href="http://partiallyattended.com/2008/07/14/sometimes,-just-sometimes-a-piece-of-news-makes-me-smile"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/sometimes,-just-sometimes-a-piece-of-news-makes-me-smile</id>
   <content type="html">&lt;div&gt; &lt;p&gt;From the Guardian today, a group of ultra-right wing MEP&#39;s were unable toform a group within the European Parliament owing to internal xenophobia.&lt;/p&gt;&lt;p&gt;http://www.guardian.co.uk/farright/story/0,,2211167,00.html?gusrc=rss&amp;amp;feed=12&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>restaurant BAYOU Berlin</title>
   <link href="http://partiallyattended.com/2008/07/14/restaurant-BAYOU-Berlin"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/restaurant-BAYOU-Berlin</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I got the email below a few days ago:&lt;/p&gt;&lt;p&gt;Hello to you all,Please forgive the bulk email!  We hope all is well with you.We will be opening our new restaurant on December 1st.  Please visit our newwebsite at www.bayou-berlin.com  You are able to book hotel reservations onour site using our corporate discount rate.  We hope to see you sometimesoon,All the best,Steve and Brandon&lt;/p&gt;&lt;p&gt;Earlier this year I was on holiday in Nerja in the south of Spain. On one ofthe last nights of the holiday we went to an amazing Cajun restaurant calledCafe New Orleans. I got chatting to the two owners and they told us abouthow they had been trying to sell their place in Spain and open up inGermany. Well the food was great, and the guy&#39;s running the place were superfriendly, so I was delighted to get this message as it&#39;s clear that theyhave finally made their place in Germany happen. If you find yourself inBerlin then you should definitely consider giving this place a try.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>pythonic is a way of thinking</title>
   <link href="http://partiallyattended.com/2008/07/14/pythonic-is-a-way-of-thinking"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/pythonic-is-a-way-of-thinking</id>
   <content type="html">&lt;div&gt; &lt;p&gt;&lt;a&gt;Thistutorial&lt;/a&gt; delves into pythonic ways of coding. I&#39;m learning from it.&lt;/p&gt;&lt;p&gt;tags: python, hoto, tutorial&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Patents and Peer Review, kissing cousins?</title>
   <link href="http://partiallyattended.com/2008/07/14/patents-and-peer-review"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/patents-and-peer-review</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Below follows a long comment that I posted to an article on O&#39;Reilly Radar about patents.&lt;/p&gt;

	&lt;p&gt;The original blog post is &lt;a href=&quot;http://radar.oreilly.com/archives/2007/09/three_vantage_p.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

	&lt;p&gt;There is an interesting compliment to the patent system in the domain of assigning credit to ideas, which is the academic peer-review system.&lt;/p&gt;

	&lt;p&gt;The inventor of the idea in the case of academia is the author. The equivalent to the patent office is the editorial board of the academic journal that the author submits to.&lt;/p&gt;

	&lt;p&gt;There is an idiosyncratic historical connection between the two systems too.Einstein famously worked as a patent clerk in Bern, Switzerland, before becoming a published academic.&lt;/p&gt;

	&lt;p&gt;At the time that Einstein was working the volume of patent applications was probably on a par with the submission rate of academic papers to peer reviewed journals, though I have no figures to back this up. In both cases an idea was submitted, examined by experts for originality and either accepted, granting the creator rights, or rejected, sending them back to the drawing board.&lt;/p&gt;

	&lt;p&gt;Fast forward to today and it seems that on the whole the two systems, work in almost the completely opposite manner from one another.&lt;/p&gt;

	&lt;p&gt;The peer review system continues to work much as it used to. An idea is submitted, reviewed, in most cases rejected initially, tweaked, re-submitted and possibly accepted. Scientists for the most part are looking for peer recognition though publication, and the career rewards that come with that through tenure and increased likelihood of earning academic grants. The micro-bio and nano fields are diverging from this template, but I&#39;ll get back to that at the end. I would classify this system as one in which the interrogation of the idea happens before the laurel is bestowed on the applicant. Contrary claims or claims of prior art appear as new publications in an ongoing conversation, but it is very rare for the reward (the citable paper) to be retracted. Working as a publishing editor for three years managing five academic journals I saw this happen with one paper, and even that that was considered unusual.&lt;/p&gt;

	&lt;p&gt;The patent system currently seems to work in completely the opposite way.The bar for having a patent approved seems quite low, but even after acceptance of a patent the rewards are not guaranteed until after the patent has been challenged in a court. The interrogation happens after the laurel has been bestowed, and only in cases where there is contention that there might actually be money to be made, which seems to be the real reward that drives people to patent their ideas rather than publish them.&lt;/p&gt;

	&lt;p&gt;Now why is this the case? I would offer this idea. Patent offices are essentially national bodies. This means that compared to the growth of academic journals there are relatively few of them. The academic system provides a distributed means of testing the goodness of the ideas, and so as the volume of academic submissions has risen the journal system has been able to scale with the growth and been able to cope.&lt;/p&gt;

	&lt;p&gt;While patent applications remained mainly technical it was possible for a centralized office to cope with the volume, but the advent of software patents has dramatically changed the balance. (I&#39;m not saying that these ideas are essentially less valuable intrinsically, but rather that the explosion of people literate in creating though the medium of computer code has increased dramatically the volume of patents that are being filed). Under this increase in volume the national patent office system has simply broken. Where it now finds it&#39;s scalability is in the court system. There are lots of courts and lots of lawyers versed in patent law. I am not sure that any fix to the patent office, or to the information that is required to submit a patent is going to get rid of the problem of scalability as long as the office remains a centralized organization, but I might well be dead wrong about this.&lt;/p&gt;

	&lt;p&gt;In what could be a worrying parallel to the way that the patent system has gone the peer review system is beginning to experience strain. It is clear that it is key in the scientific process, however the vast numbers of qualified scientists coming out of China and India are beginning to greatly increase the submission rate to academic journals. The peer review system is beginning to creak under the weight. I hasten to add that it is working just fine at the moment, but consequences can be seen in the growing importance of various citation indices. A publication on its own is no longer sufficient for the advancement of most academic careers. It usually has to come with additional properties, such as being in a popular journal, being cited a certain number of times.&lt;/p&gt;

	&lt;p&gt;Another interesting development is that in some scientific areas patents are replacing peer-reviewed publications. I know of a few groups working on nanotechnology where they have results that could be published in a peer reviewed journal, but to do so might infringe on IP. In other cases the revenue from industry that the groups are attracting mean that at the moment they don&#39;t have the time to commit to writing up their results for peer-review.&lt;/p&gt;

	&lt;p&gt;Are the two systems getting closer again?&lt;/p&gt;

	&lt;p&gt;Could the patent system benefit from having different levels of quality in the way that the peer-review system has different quality journals? A gold-standard patent requiring full code disclosure and bug-free running program, with a bronze-standard patent being equivalent to the current level?&lt;/p&gt;

	&lt;p&gt;How can both systems utilize collective intelligence to alleviate the numerical and informational pressure that surrounds the act of review?&lt;/p&gt;

	&lt;p&gt;Though a word of caution, if you have answerers to the above questions you should probably patent them, shhh now.&lt;/p&gt; &lt;p&gt;
&lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>open science</title>
   <link href="http://partiallyattended.com/2008/07/14/open-science"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/open-science</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I just posted the below as a comment on a blog, but it was good so I thoughtI&#39;d repost here&lt;/p&gt;&lt;p&gt;What is open science and what is the system? Well I am sure that there aremany viewpoints on this, so I am going to just put forward one here.&lt;/p&gt;&lt;p&gt;At a fundamental level &#39;the system&#39; is how we ascribe credit toparticipation in science. The credit is converted to grant money, thedollars keep the food on the plate. The decision makers for the grantsgenerally lie at national funding level. These people are busy and have alot of applications to process, but that is not to say that they aredisinterested in the state of the scientific funding ecosystem. However aslong as there are too many decisions and not enough time then metrics suchas a measure based on journal related factors will dominate. If it is easyto measure and to see how credit can be assigned for contributions that lieoutside the traditional publication at the end of the research cycle then Iam confident that such criteria will be taken into account, but it is veryearly days at the moment and I don&#39;t think we can expect to see an overnightrapid transition, especially when the tools for measuring such contributionsare in their infancy.&lt;/p&gt;&lt;p&gt;What is open science, and why might it be important to funding agencies tosee it being utilized? Again, just one viewpoint. Well, there is a lot ofdata out there, and I expect that a lot of good science could be done onsecond hand data. This is already common in Astronomy. This should help toutilize efficiencies of scale. In addition with better information aboutwhat is happening, and more eyeballs working together, the amount ofredundant work can hopefully be minimized. As the open source adage goes,with many eyeballs all bugs are shallow.&lt;/p&gt;&lt;p&gt;There are also a lot of published papers out there, and the scaling time foran individual to get to the data resource that they need is only going toget longer when there is more information to process. I recall hearing thatin 2005 something along the lines of 600,000 people graduated in China witha degree in engineering. If you talk to any academic journal editor most ofthem will tell you that the rate of submission of papers from the pool ofChinese scientists is growing year on year.&lt;/p&gt;&lt;p&gt;I see a function of open science as being a way to help the flow ofinformation in an open system that maximizes the efficiency for the rightpiece of information to get to the right person, whether that be a piece ofdata for analysis, a protocol for an experiment or a contact for acollaboration.&lt;/p&gt;&lt;p&gt;We have a prerogative to make this happen as a consequence of excess ofinformation that we are faced with.&lt;/p&gt;&lt;p&gt;There is however the very important need to be able to credit people whoparticipate in an open way. As someone working for an academic publisher Ifeel that part of my job to help create systems that can help to moreaccurately measure broader contributions to the scientific enterprise. As Isaid earlier, these systems are in their infancy, but it is a very excitingtime to be involved with this.&lt;/p&gt;&lt;p&gt;tags: science, science2.0, open science&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>mozy backup service</title>
   <link href="http://partiallyattended.com/2008/07/14/mozy-backup-service"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/mozy-backup-service</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I&#39;ve been trying the free account this week. I&#39;ve backed up 1.6 GB of data.It took, with given interruptions of a normal work day, about 4 days tobackup this amount of Data.&lt;/p&gt;&lt;p&gt;I am beginning to think that the world of offline remote backups is still alittle bit away!&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>live blogging from BarCamp Cambridge, Matt's talk</title>
   <link href="http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,-Matt's-talk"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,-Matt's-talk</id>
   <content type="html">&lt;div&gt; &lt;p&gt; Matt talking about semanitic web for science, an introductionXML, URI, namespaces, RDL OWL,standards are often argued about but it;s just XML&lt;/p&gt;&lt;p&gt;we are supposed to be able to publish semantis data easily,at the moment it&#39;s not just an extension but a whole other world,people won&#39;t learn sapqrl&lt;/p&gt;&lt;p&gt;Matt believes that we can get the benifits of semantic now, but withoutin any case, it&#39;s hard to get funding&lt;/p&gt;&lt;p&gt;should consider semantic web, rather than Semantic Web,&lt;/p&gt;&lt;p&gt;how do we add sematic value to existing dcuments,enemble is the public interface originally to hte human genome project, butthere are lots of other gnese in there nowset up to fight against the patenting of genescontains microformat in web output now!enembleit&#39;s open source and open data&lt;/p&gt;&lt;p&gt;people understand how to look at a html source, so it&#39;s easy to add, thevalue is there without the overheadjust add standard html classes, and let people do what they want to do withit.Q - will this lead to islands of parsing?&lt;/p&gt;&lt;p&gt;The idea is enseble is a big resource, and hope that people will follow socreate a defacto-standard&lt;/p&gt;&lt;p&gt;Can style it,Parse it&lt;/p&gt;&lt;p&gt;can the website be the API?&lt;/p&gt;&lt;p&gt;can use a standard uri to access the data&lt;/p&gt;&lt;p&gt;cut down on the amount of code that gets written&lt;/p&gt;&lt;p&gt;there is more data on the web, then is available through the api(we are not the only ones)&lt;/p&gt;&lt;p&gt;Q - What if your api is just your searchFlickr and Yahoo do this&lt;/p&gt;&lt;p&gt;Why not a pipes fo biology?&lt;/p&gt;&lt;p&gt;see microformats.org&lt;/p&gt;&lt;p&gt;have started abioformats.org&lt;/p&gt;&lt;p&gt;the microformats approach is slow, they have the idea of the process,then you have to go through a standard, and it goes round after round,we should just get started(see operator plugin, the browser becomes the broker for data)&lt;/p&gt;&lt;p&gt;slideshare.net/mza&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>live blogging from BarCamp Cambridge, Matt's discussion</title>
   <link href="http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,-Matt's-discussion"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,-Matt's-discussion</id>
   <content type="html">&lt;div&gt; &lt;p&gt; discussionQ Gridle is raised along with RDFa &lt;/p&gt;&lt;p&gt;if you don&#39;t like the way that the xslt is workin you can make your own.however most domain exprts can&#39;t write xslt&lt;/p&gt;&lt;p&gt;if you just let the domain experts create microformats you may leave theontologicaldefinitions to people who are creating the xslt&lt;/p&gt;&lt;p&gt;AG says that there may be two different problems, address to addressbookfrom page vs data harvesting&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>live blogging from BarCamp Cambridge, Laura James</title>
   <link href="http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,-Laura-James"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,-Laura-James</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Laura JamesAlert Me.Com&lt;/p&gt;&lt;p&gt;might get too corporate.&lt;/p&gt;&lt;p&gt;trying to do the internet of things, internet access to small devicesthey are implimetning today, and will be shipping later this year.comes from R&amp;amp;D, but working in a shipping&lt;/p&gt;&lt;p&gt;they are going to ship a home security system, but they are actuallybuilding a platofrmthat can connect anything that does not require full audio and video&lt;/p&gt;&lt;p&gt;using a mesh network that connect to a hub using a &#39;zigby&#39;output can be things like a lamp that has a color dependant state&lt;/p&gt;&lt;p&gt;the hub runs on linux with python on toprun by xml doc&lt;/p&gt;&lt;p&gt;can do things like tell you what day is bin day&lt;/p&gt;&lt;p&gt;is mains powered with battery backup&lt;/p&gt;&lt;p&gt;plugs in to ethernet&lt;/p&gt;&lt;p&gt;sounds just too cool&lt;/p&gt;&lt;p&gt;connects to a hubserver&lt;/p&gt;&lt;p&gt;they have gprs to connect to the internet if the router goes outtalks to a dialog server and a DB&lt;/p&gt;&lt;p&gt;there is data from loads of sensors in the homegoes to the hub,the hub has a logic enginego to the website and set it up to let you know&lt;/p&gt;&lt;p&gt;can send you a twitter when your doorbell rings&lt;/p&gt;&lt;p&gt;there are two really big trade offssecurity vs usabilityneed to make sure that your home can not get hackedand that your data does not get leaked&lt;/p&gt;&lt;p&gt;e.g. don&#39;t want people to have to type in the mac address of every entity inthe network&lt;/p&gt;&lt;p&gt;reliability vs extensabililyt&lt;/p&gt;&lt;p&gt;networ at home is based on zigby, low powered wireless networkopen standards&lt;/p&gt;&lt;p&gt;smallet item is a zigby tile, about 2cm square. range will be about 300mwith one tile.ca n cover a standard home with ome base station.&lt;/p&gt;&lt;p&gt;Q- could you set this up for a wet lab or other lab?&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>live blogging from BarCamp Cambridge,</title>
   <link href="http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/live-blogging-from-BarCamp-Cambridge,</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I am at Bar Camp Cambridge,&lt;/p&gt;&lt;p&gt;We have had the three word introductions and are just running through themorning talks now. It&#39;s pretty cool.&lt;/p&gt;&lt;p&gt;The coffee is good, and cookies are great.&lt;/p&gt;&lt;p&gt;Let&#39;s see how the day goes.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>google reader now has search</title>
   <link href="http://partiallyattended.com/2008/07/14/google-reader-now-has-search"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/google-reader-now-has-search</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Well, OK, this is probably not news, but I guess what is interesting for meis that this is a feature that I didn&#39;t really notice until today when Iwent looking for it, and hey, though that little search box had probablybeen there for weeks now, I only &amp;quot;saw&amp;quot; it today when I looked for it.&lt;/p&gt; &lt;p&gt;  &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>getting started</title>
   <link href="http://partiallyattended.com/2008/07/14/getting-started"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/getting-started</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Well, i&#39;m starting out my mob-blogging life waiting in que for a flight to milan, and i discover that my predictive text thinks i&#39;m a clogger! An interesting, if somewhat disturbing begining. Tags: moblog, txt, travel&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>get addicted, feed the world</title>
   <link href="http://partiallyattended.com/2008/07/14/get-addicted,-feed-the-world"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/get-addicted,-feed-the-world</id>
   <content type="html">&lt;div&gt; &lt;p&gt;at &lt;a href=&quot;http://www.freerice.com&quot;&gt;http://www.freerice.org&lt;/a&gt;&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>friends of mine of TV</title>
   <link href="http://partiallyattended.com/2008/07/14/friends-of-mine-of-TV"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/friends-of-mine-of-TV</id>
   <content type="html">&lt;div&gt; &lt;p&gt;A friend of mine set up her own business a few years ago, at the same timeas having a baby. It was really tough for Ais for the first couple of years,but it is looking like things are really working out for her now. She wasrecently featured on TV in Ireland, and she has posted a link to the clipfrom her blog. For a really inspirational view on managing business withchildcare have a loot at the vid:&lt;/p&gt;&lt;p&gt;this link:http://chewingpaper.typepad.com/chewing_paper_confessions/2007/10/tv-fame.html&lt;/p&gt;&lt;p&gt;tags: business, cool, inspirational&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>comment on climbing goals</title>
   <link href="http://partiallyattended.com/2008/07/14/comment-on-climbing-goals"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/comment-on-climbing-goals</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I find that having a cool trip planned every now and again is key forkeeping me motivated. I&#39;ve been doing a lot of job and country hopping overthe past 10 years, and this has had a signifigant detrimental impact on theamount of climbing that I could do, but hey, I&#39;m doing a job that I love,and those are the rolls we choose to take.&lt;/p&gt;&lt;p&gt;One thing that has kept me motivated to get of my arse and actually try abit harder when I am down in the gym is having a few cool trips planned inthe year. I&#39;m not a major road-trip warrior, so I can only usually manage afew long weekends a year, and maybe one longer trip, but the motivation itgives is powerful stuff. I&#39;m about to head to font for a week att hebeginning of September and that has me well primed right now.&lt;/p&gt;&lt;p&gt;These trips generally are my short-term goals, and I keep track of mypersonal bests. I know which problems I sent last time I was in font, andmore importantly which ones I nearly sent (oh yes, they will be mine!!).&lt;/p&gt;&lt;p&gt;Long term goals I must admit to having a problem with. My mid term goal forclimbing is to try to stay in one country for a few years and to get adriving license. Funny, but it seems that this is just the way a lot of mygood friends got better.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>and while we are at it here are the references from that article</title>
   <link href="http://partiallyattended.com/2008/07/14/and-while-we-are-at-it-here-are-the-references-from-that-article"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/and-while-we-are-at-it-here-are-the-references-from-that-article</id>
   <content type="html">&lt;div&gt; &lt;p&gt; References&lt;/p&gt;&lt;p&gt;   - &amp;quot;Python Objects&amp;quot;, Fredrik Lundh,   http://www.effbot.org/zone/python-objects.htm   - &amp;quot;How to think like a Pythonista&amp;quot;, Mark Hammond,   http://python.net/crew/mwh/hacks/objectthink.html   - &amp;quot;Python main() functions&amp;quot;, Guido van Rossum,   http://www.artima.com/weblogs/viewpost.jsp?thread=4829   - &amp;quot;Python Idioms and Efficiency&amp;quot;,   http://jaynes.colorado.edu/PythonIdioms.html   - &amp;quot;Python track: python idioms&amp;quot;,   http://www.cs.caltech.edu/courses/cs11/material/python/misc/python_idioms.html   - &amp;quot;Be Pythonic&amp;quot;, Shalabh Chaturvedi,   http://shalabh.infogami.com/Be_Pythonic2   - &amp;quot;Python Is Not Java&amp;quot;, Phillip J. Eby,   http://dirtsimple.org/2004/12/python-is-not-java.html   - &amp;quot;What is Pythonic?&amp;quot;, Martijn Faassen,   http://faassen.n--tree.net/blog/view/weblog/2005/08/06/0   - &amp;quot;Sorting Mini-HOWTO&amp;quot;, Andrew Dalke,   http://wiki.python.org/moin/HowTo/Sorting   - &amp;quot;Python Idioms&amp;quot;, http://www.gungfu.de/facts/wiki/Main/PythonIdioms   - &amp;quot;Python FAQs&amp;quot;, http://www.python.org/doc/faq/&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>agile programming</title>
   <link href="http://partiallyattended.com/2008/07/14/agile-programming"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/agile-programming</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I work for a department where we try to do agile development. I liked this&lt;a&gt;Dilbert&lt;/a&gt;about the subject.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Why Do All Of The Science Fiction Authors Have All Of The Really Goodideas Already?</title>
   <link href="http://partiallyattended.com/2008/07/14/Why-do-all-of-the-science-fiction-authors-have-all-of-the-really-goodideas-already%3F"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Why-do-all-of-the-science-fiction-authors-have-all-of-the-really-goodideas-already?</id>
   <content type="html">&lt;div&gt; &lt;p&gt;My friend Gavin has been increasingly interested in the singularity, wherebythe quiddity of humanness is uploaded into a computer, to reside there. Ithink the definition of the singularity has something to do reaching themoment where the boundary between a human individual entity and thetechnology that surrounds them becomes transparent, or disappearsaltogether.&lt;/p&gt;&lt;p&gt;It struck me this weekend that if you can upload an intelligence , a person,a being, a soul, into a peice of technology, then you would probably beliving at a moment when technology was advanced enough to be able to build abody from the amino acid&#39;s up. You would also probably have solved the meatto storage device transfer problem and the reverse. You upload a person,grow a body and download the person into the new body.&lt;/p&gt;&lt;p&gt;You could probably grow the body without utilizing breeding women (I thinkthis theme is described in the later Dune novels). This would also bedifferent from quantum teleportation, which is a ground up build from thequantum qubuits of a large structure, and due to decoherence it is a hardproblem to resolve. Molecules are more stable than quantum states, and soyou just need to knit a bunch of them together to build up a human body.&lt;/p&gt;&lt;p&gt;We can&#39;t travel faster than light. We just can&#39;t. So you upload yourpopulation, ship em off, and rebuild them when you find a suitable location.It might take a while, so you can send out multiple copies to increase thelikelihood of finding a nice new home.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Weddings make you fat</title>
   <link href="http://partiallyattended.com/2008/07/14/Weddings-make-you-fat"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Weddings-make-you-fat</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I just got back from a wedding and bier festival thing in Munich. I&#39;ve been tracking my weight on and off for the past year and a half with the ultimate goal of getting back to my climbing fit weight of about 80kgs. From the graph below you can see the spike that was caused by the extertions at the wedding!&lt;/p&gt;&lt;p&gt;(OK, in the vox rendering you can&#39;t really see the spike on the right hand side of the graph, but if you are bothered then click through and you&#39;ll see the original graph. btw the y-axis is a measure of how much weight I want to lose)&lt;/p&gt;&lt;p&gt;&lt;a href=&quot;http://www.bellygraph.com/graph/overview/300&quot;&gt;&amp;#160;&amp;#160; &lt;img src=&quot;http://www.bellygraph.com/graphs/271_300_large.png&quot; /&gt;&lt;/a&gt; &lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Today at lunch duplicators and instantiators</title>
   <link href="http://partiallyattended.com/2008/07/14/Today-at-lunch-duplicators-and-instantiators"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Today-at-lunch-duplicators-and-instantiators</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I work at a pretty innovative place and the discussions that we have atlunch time are pretty mind bending. The last time I can recall having somany interesting discussions over lunch and breaks was way back when I wasin my first undergraduate degree, but the topics of conversation that tendto come up at my current place of employment are really worth trying torecord.&lt;/p&gt;&lt;p&gt;Today we started off having a couple of split conversation, Euan describingchatting to Martha at Sci-Foo and Euan and I talking about Euler, as you do.Then the conversation quite naturally turned to replicators. We werediscussing the pro&#39;s and con&#39;s of owning a replicator. It&#39;s clear from theconversation that two calsses of replicator exist. One would break the lawsof physics and replicate anything out of nothing (possibly dragging theextra matter out of an alterantive universe, vis a vis the lazy gun inagainst a dark background) and the other type the just melds matter into theshape of whatever might be copies.&lt;/p&gt;&lt;p&gt;Brenda wanted one that would not copy living things, but as someone pointedout, if you could copy living things, and you had one kitten, then you couldhave kittens!&lt;/p&gt;&lt;p&gt;Getting a transfer of ownership form when you copied a beamer might be aproblem, and if you copied the earth then you would be in right trouble.&lt;/p&gt;&lt;p&gt;At the end Gavin wanted one that you could just pass science fiction booksto, and it would make stuff from the book not really a replicator then, butan instantiator.&lt;/p&gt;&lt;p&gt;tags: lunch, replicator&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Tips for switching from Windows to Mac</title>
   <link href="http://partiallyattended.com/2008/07/14/Tips-for-switching-from-Windows-to-Mac"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Tips-for-switching-from-Windows-to-Mac</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I&#39;ve written up the short answers to some questions that you might have if this is the first time to use a mac, read through this and if you followthe suggestions you should have the hang to the system pretty quickly. &lt;/p&gt;&lt;p&gt;If it turns out you don&#39;t like it, then at least you will have made an informeddecision!&lt;/p&gt;&lt;p&gt;-- Where is the right mouse button?&lt;/p&gt;&lt;p&gt;This is the biggest obvious first difference. There are four buttons on the bottom left of the keyboard that I am going to call &#39;fn&#39;, &#39;ctr&#39;, &#39;option&#39; and &#39;mac&#39; respctivley. If you need to press two at the same time then I am going to write it like &amp;quot;ctr + fn&amp;quot;, for example.&lt;/p&gt;&lt;p&gt;The right button mouse action equvalent is hoilding down &amp;quot;ctr + mouse button&amp;quot;.To get the mouse to do something you generally have to double click on the thing you are clicking on. One click is a selection, a double click is an action.&lt;/p&gt;&lt;p&gt;-- I double click on an application but I want to find the preferences, or othermenus, and they are not on the application window, how do I do that?&lt;/p&gt;&lt;p&gt;The very top bar of the mac changes with applicaiton. The menu bars are all along there. You will see a small blue apple in the very top left corner. The name of the application that is active is frst, and if you clioc on that you will get the option of the prefereces panel for the application. You canalso try &amp;quot;mac + ,&amp;quot; (yes, that&#39;s the mac button and the comma button together,it tends to work for all mac applications, joy!).&lt;/p&gt;&lt;p&gt;The top right of the bar gives you information about how your system is doing, battery, internet connection, time etc. You can load this baby with all sorts of things. &lt;/p&gt;&lt;p&gt;-- Where are all of my files, where are the application?&lt;/p&gt;&lt;p&gt;The OS is based directly on a UNIX system, and it&#39;s file structure is the same.If you double click on the Macintosh HD in the top right you will see a filebrowser with some directories. This opens a the very botton level of the file structure of the machine. ALL of the applications on the macine are in the Applications folder (actually, there are a host of very loe level system appsthat are not in here, they are in System, best not to go in there!).This machine can host muliple accounts, and these are in the Users directory, double click on this now. You will see a list of account names, yours &amp;quot;John&amp;quot;has a little picture of a home, this is your home directory. Try clicking in the other accounts. Some folders are locked, others you can have a look around, but you can only create files and delete files from your own local folders. Let&#39;s have a look at those now. Amongst the default folders in youraccount the most important is Library. This stores all of your system preferecesfor all of your applications. That means two people on the same machine can usethe same app, but have totally different setups. Your girlfriend on her accountwill never see the porn sites that you were navigating too in the webbrowser, forexample! For the moment it is probably best to stay out of there.&lt;/p&gt;&lt;p&gt;-- What are all of those things on the botton?&lt;/p&gt;&lt;p&gt;That&#39;s the dock. It keeps a ttrack of open stuff, I don&#39;t use it much, but it can be good if you want to keep a few applications to hand that you use a lotrather than going into the applications folder each time. I&#39;ll show you how to customise that later. &lt;/p&gt;&lt;p&gt;-- Some useful quick key commands and window browsing tips.&lt;/p&gt;&lt;p&gt;&amp;quot;mac + s&amp;quot; = Save&amp;quot;mac + c&amp;quot; = copy&amp;quot;mac + x&amp;quot; = cutpaste is &amp;quot;opt + p + ,&amp;quot;. No, kiddind, its &amp;quot;mac + v&amp;quot; of course! (the mac key predates that windows key on PC&#39;s).&lt;/p&gt;&lt;p&gt;Now I want you to open several windows of a document. Double click on any applications. Do it a few times. Make sure to open Safari (it looks like a compass) and when you have&amp;#160; hit &amp;quot;mac + n&amp;quot; a few times. Now you have lotsof applications open on your desktop. Clicking on the orange button will minimse the window and put it in the Dock. Clicking on the mini-windowin the dock will make it pop up. Cool, eh! OK, Now do that again, but keepthe shift key pressed at the smae time. It does it slowly, just so you can show off!. Now try the following key presses:&lt;/p&gt;&lt;p&gt;&amp;quot;mac + `&amp;quot; - cylces through open windows of a given applicaiton&amp;quot;mac + tab&amp;quot; - lets you pick between applications&amp;quot;mac + shift + tab&amp;quot; - same as above, but in the other direction&amp;quot;mac + 1&amp;quot; - unminises. If you have 3 windows of the same app minimsed, then you can do &amp;quot;mac + 3&amp;quot; or &amp;quot;mac + 2&amp;quot; to get the specific window that you want.&amp;quot;mac + h&amp;quot; - hides an app. All of the windows of the app dissapear. They don&#39;t go to the dock. To get them back either click on the app icon in the dock, orcycle to the app using &amp;quot;mac + tab&amp;quot;.&amp;quot;alt + mac + h&amp;quot; hides all windows apart from the one you are working on. &lt;/p&gt;&lt;p&gt;Ok, now for some really cool stuff. &amp;quot;fn + 11&amp;quot; - while you keep these two pressed all your windows head out to the edge of the screen so you can see your desktop.&amp;quot;fn + 10&amp;quot; - exposes all of the windows of a particular app. click on the window you want makes it come to the front.&amp;quot;fn + 9&amp;quot; - exposes all windows. &amp;quot;fn + 12&amp;quot; - opens up the dashboard. This is a applish thing with lots of widgets to choose from. &lt;/p&gt;&lt;p&gt;&amp;quot;mac + q&amp;quot; will quit an application. Using &amp;quot;mac + tab&amp;quot; and keeping mac pressedyou can quickly kill all of the applications that you have running.&amp;quot;mac + delete&amp;quot; will delete a file&amp;quot;mac + w&amp;quot; will close the current window you have open.&lt;/p&gt;&lt;p&gt;-- How do I find something?&lt;/p&gt;&lt;p&gt;&amp;quot;mac + space&amp;quot; - opens the spotlight window. It is really good. Really really good. It means you really don&#39;t have to look for anything with pain any more.I have 250 GB of data indexed by spotlight, and it finds things instantly.&lt;/p&gt;&lt;p&gt;-- No, I&#39;m sorry, this really isn&#39;t cool enough, show me something more.&lt;/p&gt;&lt;p&gt;Ok, Mac now has smart folders. I have included two on your desktop. You define thekind of file that should go in there. As soon as a file anywhere on your computer that matches this criteria gets created it gets listed in the smart folder. &lt;/p&gt;&lt;p&gt;-- kinds of free applications that you can get.&lt;/p&gt;&lt;p&gt;There are loads. My favourite is called Quicksilver. I have set it up torun for you on your account. Another is called Desctop Manager and I have also set that up for you.&lt;/p&gt;&lt;p&gt;The Desktop Manager provides as many virtual desktops as you wnat, I haveset it up for 4 for you here. A virtual destop is just some extra realestate.The four small squares in the bar on top of the screen show you your desktops in minature. The small squre bottom left of the screen is a pager, and it does the same job as the squares on top. I normally only use one or the other, you can set up how you want it in the preferences. Clickingon a different square to the one that you are in will bring you to that desktop.You can also use the key command &amp;quot;alt + mac + -&amp;gt;&amp;quot; (right arrow) or&amp;quot;alt + mac + &amp;lt;-&amp;quot; to cycle through the desktops. &lt;/p&gt;&lt;p&gt;Type &amp;quot;mac + enter&amp;quot;. This is quicksilver. Actually, It&#39;s not working right now, but i can show it to you on my account where it works very well at the moment.&lt;/p&gt;&lt;p&gt;-- Hmm, someone sent me a Microsoft file, how do I open it on this totally bitchin machine,&lt;/p&gt;&lt;p&gt;Chances are that you already can. Try double clicking on it to see what happens.The application NeoOfficeJ does all of the same things that Microsift Officedoes, oh, but it&#39;s free. I have set it up on the machine and on the dock, it&#39;s the one with the sailing ship icon (?)&lt;/p&gt;&lt;p&gt;-- Gah, something really has gone wrong, and I need to force quit an application. &lt;/p&gt;&lt;p&gt;Go to the apple icon top left. One of the menu options is Force Quit, there you go. &lt;/p&gt;&lt;p&gt;-- Oprn iTunes, I dropped some cool tunes from my collection there for you.You can try burning them to a CD if you have one, it&#39;s easy, but I&#39;ll let you figure out how. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>The fruitcakes have a talking form</title>
   <link href="http://partiallyattended.com/2008/07/14/The-fruitcakes-have-a-talking-form"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/The-fruitcakes-have-a-talking-form</id>
   <content type="html">&lt;div&gt; &lt;p&gt;A new creationisim journal &lt;a&gt;ARJ&lt;/a&gt;.GRRRRRRRR&lt;/p&gt; &lt;p&gt;  &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>The Laboratory Website and Video Awards</title>
   <link href="http://partiallyattended.com/2008/07/14/The-Laboratory-Website-and-Video-Awards"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/The-Laboratory-Website-and-Video-Awards</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Attila Csordas sent along links about these awards, looks nice,&lt;/p&gt;&lt;p&gt;http://www.the-scientist.com/lawva/&lt;/p&gt;&lt;p&gt;and a blog link about them:&lt;/p&gt;&lt;p&gt;http://pimm.wordpress.com/2007/10/09/the-laboratory-website-and-video-awards-by-the-scientist&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;tags: science&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Simpsian</title>
   <link href="http://partiallyattended.com/2008/07/14/Simpsian"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Simpsian</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Yesterday one of the guy&#39;s at the office interviewed the producer of TheSimpsons. As a result he had to do quite a lot of research yesterday onSimsonalia, and decided to use the make your own simpson avatar tool on theSimpsons movie page to make all of us our own simpson character, this iswhat I would look like if I were a simpson.&lt;/p&gt;&lt;p&gt;Tags: simpsons, avatar &lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class=&quot;enclosure enclosure-center enclosure-extra-large photo-enclosure&quot;&gt;&lt;div class=&quot;enclosure-inner&quot;&gt; &lt;div class=&quot;enclosure-list&quot;&gt; &lt;div class=&quot;enclosure-item photo-asset last&quot;&gt; &lt;div class=&quot;enclosure-image&quot;&gt; &lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00d4144f937c3c7f.html&quot;&gt;&lt;img src=&quot;http://a4.vox.com/6a00d09e7c9248be2b00d4144f937c3c7f-500pi&quot; alt=&quot;IansSimpson.jpg&quot; title=&quot;IansSimpson.jpg&quot; /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;enclosure-meta&quot;&gt; &lt;div class=&quot;enclosure-asset-name&quot;&gt;&lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00d4144f937c3c7f.html&quot; title=&quot;IansSimpson.jpg&quot;&gt;IansSimpson.jpg&lt;/a&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;!-- end enclosure --&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Sci - foo lurking</title>
   <link href="http://partiallyattended.com/2008/07/14/Sci---foo-lurking"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Sci---foo-lurking</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I&#39;m a Sci-Foo lurker, as I didn&#39;t make the cut to go this year, but I&#39;vebeen lapping up the news seeping out of the meeting. So far my favoriteTwitter post about the meeting comes from Richard Ackerman&#39;s feed:&lt;/p&gt;&lt;p&gt;&amp;quot;Timo and Tim are trying to kill us. Doesn&#39;t cult brainwashing start withsleep deprivation? Fun so far, anyway&amp;quot;&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Potter prediction</title>
   <link href="http://partiallyattended.com/2008/07/14/Potter-prediction"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Potter-prediction</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I wonder how long it&#39;s going to be before we see a children&#39;s TV series setat Hogwarts. I predict within the next 5 years.&lt;/p&gt;&lt;p&gt;tags: Harry Potter, TV&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Open Reviewing</title>
   <link href="http://partiallyattended.com/2008/07/14/Open-Reviewing"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Open-Reviewing</id>
   <content type="html">&lt;div&gt; &lt;p&gt;&lt;a&gt;Arecent blog post on Action Potential&lt;/a&gt; pointed me towards &lt;a&gt;the neuroscience peer review consortium&lt;/a&gt;. Theyhave a description &lt;a href=&quot;http://nprc.incf.org/about&quot;&gt;here&lt;/a&gt; about theconsortium and a &lt;a href=&quot;http://nprc.incf.org/journals&quot;&gt;list ofparticipating journals&lt;/a&gt;. I have no doubt that this is the future of peerreview. At the moment the peer review system is horribly inefficient forpapers that get rejected. Rejection from a journal can occur because a paperis crap, but often it happens for many other reasons, because the journalhas already met it&#39;s pagequota, the journal is publishing a set of special issues on another topic,the editors of the journal are interested in shifting the focus of thejournal, the topic of the paper is slightly away from the main interests ofthe editorial board, the paper is good, but just gets edged out by a set ofbetter papers that come in. The author resubmits, rewrites, reformats thepaper for another journal, the review process happens again, sometimes withthe same reviewers being approached again to re-review the paper. Thismultiple reviewing of the same paper is for the most part a waste of time.There are of course cases where it is good to have the option, but for themost part it wastes the time of communities who are highly trained and busytrying to do important and original work of their own.&lt;/p&gt;&lt;p&gt;I personally always felt that pool reviewing was the natural solution tothis problem, but I never thought I would see it happen owing to thecompeting nature of academic publishers. This attempt to work pool reviewingin one area is very exciting. The issues that need to be overcome includethe issue of private reviewer comments that the Action Potential blog pointsout, but also the questions of a set of editors of one journal being willingto take the rejected papers from another journal. One would like to say thatin a totally equally fair system all journals are equally important to thedevelopment of science, but that is not true. Some journals are just moreimportant for one reason or another. When two journals feel they are betterthan each other are they going to be willing to take the papers rejected bytheir competitors? I hope that the papers will stand up for themselves andthat this system will lead to a more efficient matching of papers to pagesin published journals.&lt;/p&gt;&lt;p&gt;If it works what next? One single format for submission? One passpeer-review with a peer-reviewed preprint publication guaranteed for allpapers? I don&#39;t know, but I&#39;m interested in seeing what happens with this.&lt;/p&gt;&lt;p&gt;tags: science, peer-review, science2.0&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>New Terminal In Mac Os 10.5 Is Nice But Dont Forget That There Is A Bash_profile Out Of The Box</title>
   <link href="http://partiallyattended.com/2008/07/14/New-terminal-in-Mac-OS-10.5-is-nice-but-dont-forget-that-there-is-a-bash_profile-out-of-the-box"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/New-terminal-in-Mac-OS-10.5-is-nice-but-dont-forget-that-there-is-a-bash_profile-out-of-the-box</id>
   <content type="html">&lt;!DOCTYPE html PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/strict.dtd&quot;&gt;
&lt;html&gt;
&lt;head&gt;
  &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt;
  &lt;meta http-equiv=&quot;Content-Style-Type&quot; content=&quot;text/css&quot;&gt;
  &lt;title&gt;&lt;/title&gt;
  &lt;meta name=&quot;Generator&quot; content=&quot;Cocoa HTML Writer&quot;&gt;
  &lt;meta name=&quot;CocoaVersion&quot; content=&quot;1038.32&quot;&gt;
  &lt;style type=&quot;text/css&quot;&gt;
    body {background-color: #000000}
    p.p1 {margin: 0.0px 0.0px 0.0px 0.0px; font: 12.0px Times}
    p.p2 {margin: 0.0px 0.0px 12.0px 0.0px; font: 12.0px Times}
    p.p3 {margin: 0.0px 0.0px 12.0px 0.0px; font: 12.0px Times; min-height: 14.0px}
  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;p class=&quot;p1&quot;&gt;---&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;layout: post&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;title: New terminal in Mac OS 10.5 is nice, but don&#39;t forget that there is a .bash_profile out of the box. categories:&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;- mac&lt;span class=&quot;Apple-converted-space&quot;&gt; &lt;/span&gt;&lt;/p&gt;
&lt;p class=&quot;p1&quot;&gt;---&lt;/p&gt;
&lt;p class=&quot;p2&quot;&gt;The new terminal is very nice, but I did a wipe and re-install and waswondering what had happened to my old terminal settings. Of course thedefault .bash_profile file was being used as the settings file, so I deletedit and now the terminal works as expected.&lt;/p&gt;
&lt;p class=&quot;p2&quot;&gt;******************************************************************************** DISCLAIMER: This e-mail is confidential and should not be used by anyone who isnot the original intended recipient. If you have received this e-mail in errorplease inform the sender and delete it from your mailbox or any other storagemechanism. Neither Macmillan Publishers Limited nor any of its agents acceptliability for any statements made which are clearly the sender&#39;s own and notexpressly made on behalf of Macmillan Publishers Limited or one of its agents.Please note that neither Macmillan Publishers Limited nor any of its agentsaccept any responsibility for viruses that may be contained in this e-mail orits attachments and it is your responsibility to scan the e-mail and attachments (if any). No contracts may be concluded on behalf of Macmillan Publishers Limited or its agents by means of e-mail communication. Macmillan Publishers Limited Registered in England and Wales with registered number 785998 Registered Office Brunel Road, Houndmills, Basingstoke RG21 6XS ********************************************************************************&lt;/p&gt;
&lt;p class=&quot;p3&quot;&gt;&lt;br&gt;&lt;/p&gt;
&lt;/body&gt;
&lt;/html&gt;
</content>
 </entry>
 
 <entry>
   <title>Money Saving Web Sites for Living in the UK</title>
   <link href="http://partiallyattended.com/2008/07/14/Money-Saving-Web-Sites-for-Living-in-the-UK"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Money-Saving-Web-Sites-for-Living-in-the-UK</id>
   <content type="html">&lt;div&gt; &lt;p&gt;The Guardian ran an article this week listing 10. As a placeholder here aresome of them that I might find useful:&lt;/p&gt;&lt;p&gt;https://www.mysupermarket.co.uk/&lt;/p&gt;&lt;p&gt;http://www.saynoto0870.com/&lt;/p&gt;&lt;p&gt;http://www.quidco.com/&lt;/p&gt;&lt;p&gt;http://www.energysavingtrust.org.uk/&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Mining social data, what Flickr tells us about place</title>
   <link href="http://partiallyattended.com/2008/07/14/Mining-social-data,-what-Flickr-tells-us-about-place"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Mining-social-data,-what-Flickr-tells-us-about-place</id>
   <content type="html">&lt;div&gt; &lt;div&gt; &lt;a href=&quot;http://www.flickr.com/photos/drremulac/725476164/&quot; title=&quot;photo sharing&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;http://farm2.static.flickr.com/1307/725476164_13f735a9cd_m.jpg&quot; /&gt;&lt;/a&gt; &lt;span&gt; &lt;a href=&quot;http://www.flickr.com/photos/drremulac/725476164/&quot;&gt;toscany activity spikes with R&lt;/a&gt;    Originally uploaded by &lt;a href=&quot;http://www.flickr.com/people/drremulac/&quot;&gt;fgirardin&lt;/a&gt; &lt;/span&gt;&lt;/div&gt;&lt;p&gt;Web 2.0 is a buz word. At a conference that I attended last week it came up frequently as being one of the most over-hyped terms around at the moment, but there is substance behind it, and how that substance appears is fully up to the creativity of people who are willing to get their hands dirty with the actual data that is being produced by social web sites. I came across this example today and it exemplifies the type of thing that can be done. &lt;/p&gt;&lt;p&gt;These researchers are looking at time traces of pictures of locations uploaded to flickr and pulling information about those places out of this data. The image here shows activity in and around tuscany. They are also looking at routing through contries and heat-maps of tourist visits to cities. &lt;/p&gt;&lt;p&gt;You can read more here:&lt;/p&gt;&lt;p&gt;http://www.girardin.org/fabien/tracing/&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Liam dropping by london</title>
   <link href="http://partiallyattended.com/2008/07/14/Liam-dropping-by-london"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Liam-dropping-by-london</id>
   <content type="html">&lt;div&gt; &lt;div class=&quot;enclosure enclosure-center enclosure-extra-large photo-enclosure&quot;&gt;&lt;div class=&quot;enclosure-inner&quot;&gt; &lt;div class=&quot;enclosure-list&quot;&gt; &lt;div class=&quot;enclosure-item photo-asset last&quot;&gt; &lt;div class=&quot;enclosure-image&quot;&gt; &lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00cd973f07c64cd5.html&quot;&gt;&lt;img src=&quot;http://a6.vox.com/6a00d09e7c9248be2b00cd973f07c64cd5-500pi&quot; alt=&quot;10072007136&quot; title=&quot;10072007136&quot; /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class=&quot;enclosure-meta&quot;&gt; &lt;div class=&quot;enclosure-asset-name&quot;&gt;&lt;a href=&quot;http://partiallyattended.vox.com/library/photo/6a00d09e7c9248be2b00cd973f07c64cd5.html&quot; title=&quot;10072007136&quot;&gt;10072007136&lt;/a&gt;&lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;!-- end enclosure --&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Installing Python Image Library on a Mac</title>
   <link href="http://partiallyattended.com/2008/07/14/Installing-Python-Image-Library-on-a-Mac"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Installing-Python-Image-Library-on-a-Mac</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I spent about half an hour trying to install the excellent Python ImageLibrary on my mac. It&#39;s one of those things that is more annying than itshould be. You get libjpeg from herehttp://www.ijg.org/files/jpegsrc.v6b.tar.gz follow the instructions here onhow to patch the makefile and how to install libjpeg:http://www.kyngchaos.com/macosx/install/libjpeg (all this after installingthe developer tools on mac), only to fail and then discover that there is aprebuilt binary package here:http://pythonmac.org/packages/py25-fat/index.html which works perfectly. GoLena!&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>If programming is magic, then the old languages are strong</title>
   <link href="http://partiallyattended.com/2008/07/14/If-programming-is-magic,-then-the-old-languages-are-strong"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/If-programming-is-magic,-then-the-old-languages-are-strong</id>
   <content type="html">&lt;div&gt; &lt;p&gt;The similarity between magic and programming is never more apparent thanwhen you sit down and watch someone who is truly good on the command line.By virtue of having secret knowledge they can quickly accomplish theapparently impossible. If you start out in the unix world you begin bylearning some simple incantations such as &#39;cd&#39;, &#39;ls&#39; and &#39;top&#39; and &#39;kill&#39;.If you persevere with the art eventually you may master the hidden runesthat bring &#39;sed&#39; and &#39;awk&#39; to life.&lt;/p&gt;&lt;p&gt;These sorts of commands work at the very root of the operating system, hardwired into the c++ code that built up the universe in which you are walking.In a way this is the fundamental elemental magic of programming. And what Ifind so pleasant about wandering in this landscape is that findingdocumentation on these building blocks is so easy. They have been around forsuch a long time that much of the documentation was written when blue links,plain text and white backgrounds were not just a style issue for html, therewas simply no better way to do it back then.&lt;/p&gt;&lt;p&gt;I often think that there is still no better way to do it.&lt;/p&gt;&lt;p&gt;tags: programming, magic&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Great places to hang out in Den Haag</title>
   <link href="http://partiallyattended.com/2008/07/14/Great-places-to-hang-out-in-Den-Haag"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Great-places-to-hang-out-in-Den-Haag</id>
   <content type="html">&lt;div&gt; &lt;p&gt;I have a good friend who lives in Den Haag and passed on the followingadvice about places to go and eat if you have a small child. This is reallygreat advice so I thought I should post it here:&lt;/p&gt;&lt;p&gt;Hi Victoria,&lt;/p&gt;&lt;p&gt;Very sad to hear your friend has such a lousy experience in my country. AsIan can confirm, it&#39;s not a very easy place for &#39;outsiders&#39;... The upside isthat if you are not at fancy free and footloose as my friend Ian is- andwith a little boy that age she will have moderated her dancing ambitions-The Hague can be quite a nice place to hang out.&lt;/p&gt;&lt;p&gt;Here are a couple of my personal favorites:&lt;/p&gt;&lt;p&gt;- Ziani: italian restaurant espically great with children.  There is even alittle playcorner and no one will mind a couple of screeming children (Ihave experience):http://iens.nl/restaurantsVan/DenHaag/restaurant.htms?r=4240&lt;/p&gt;&lt;p&gt;- De Boterwaag: grand cafe at the center of town (Grote Marktstraat). Goodplace to have a few beers and especially sunday afternoon it is crowded withchildren. Bit smokey but all that will be history after jan 1 when allpublic hangouts will be smoke free. Remnds me that I should quit beforethen.&lt;/p&gt;&lt;p&gt;- Bodega &#39;De Pakschuit&#39;. On the canal on the old part of the center. Goodtapas and again fine place for drinks on sunday afternoon with children. Nottoo crowded.&lt;/p&gt;&lt;p&gt;Plenty of good parks and playgrounds of course. I frenquent the  playgroundon the Scheveningseweg/Kerkhoff laan a lot. Good stuff for kids and daddycan look at the skateboarders when he is bored. She should definately checkout the park &#39;Clingendael&#39;, very classy park and good playground as well. Iam sure she will have discoevered the marvels of the Beach, and it isstarting to become off-season but I highly recomemend strandpavilioen &#39;Zuid&#39;on the &#39;Zuiderstrand&#39;.&lt;/p&gt;&lt;p&gt;Best thing of coursee with children is to get a babysit and have a romanticevening out for mom and dad.&lt;/p&gt;&lt;p&gt;- Pastis: french bistro at the hart of the old center. Decent steakbearnaise and good ambiance:http://iens.nl/restaurantsVan/DenHaag/restaurant.htms?r=21430&lt;/p&gt;&lt;p&gt;- Favorite Thais restaurant is Ponsawan:http://iens.nl/restaurantsVan/DenHaag/restaurant.htms?r=18512 great food andvery frendly people (right around the corner from where Ian used to live butlet&#39;s admit it Ian, you were also a bit shortsighted).&lt;/p&gt;&lt;p&gt;For mom alone, when  she is tired of the whole afair: Wicked Wineshttp://iens.nl/restaurantsVan/DenHaag/restaurant.htms?r=5571&lt;/p&gt;&lt;p&gt;Nice place that women tend to like on wednesday nights for a glas and somegossip.&lt;/p&gt;&lt;p&gt;For Dad, when he just wants to get hammered on Belgian beertasting: Cafe &#39;DePaas&#39; on the Dunne Bierkade. Ask Ian (he still will recall that he beat meby one glass and was very proud of that. Never saw him check in the officethe next day though).&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Getting motivated for climbing</title>
   <link href="http://partiallyattended.com/2008/07/14/Getting-motivated-for-climbing"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Getting-motivated-for-climbing</id>
   <content type="html">&lt;div&gt; &lt;p&gt;A good friend of mine has just hit the 8a mark in climbing. Dave is a greatclimber, and a really nice guy, but what really blew me away is that hisfiancee Caroline led 7b on her first sports climbing trip.&lt;/p&gt;&lt;p&gt;One thing  know about both of them is that they do a lot of running,something like 10 - 15 miles evrey morning.&lt;/p&gt;&lt;p&gt;If this isn&#39;t motivation for me to pick up running then I don&#39;t know whatis.&lt;/p&gt;&lt;p&gt;tags: training, climbing&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Get Slimmer Pets</title>
   <link href="http://partiallyattended.com/2008/07/14/Get-Slimmer-Pets"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Get-Slimmer-Pets</id>
   <content type="html">&lt;div&gt; &lt;div&gt; &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/2186821857/&quot; title=&quot;photo sharing&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;http://farm3.static.flickr.com/2010/2186821857_81b43ae112_m.jpg&quot; /&gt;&lt;/a&gt; &lt;span&gt; &lt;a href=&quot;http://www.flickr.com/photos/mulvanynet/2186821857/&quot;&gt;12/01/2008&lt;/a&gt;    Originally uploaded by &lt;a href=&quot;http://www.flickr.com/people/mulvanynet/&quot;&gt;Ian Mulvany&lt;/a&gt; &lt;/span&gt;&lt;/div&gt;&lt;p&gt;I was shopping at Lidl last weekend and saw this for sale. It might be a bit of a drastic measure, but I think it would work.&lt;/p&gt; &lt;p&gt;  &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>CPANPLUS and Mac OSX</title>
   <link href="http://partiallyattended.com/2008/07/14/CPANPLUS-and-Mac-OSX"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/CPANPLUS-and-Mac-OSX</id>
   <content type="html">&lt;div&gt; &lt;p&gt;OK, so I&#39;m interested in installing the Connotea code base on my mac fordevelopment reasons. It will be the first time that I am going to startplaying around with a largish perl installation on my macine and there are alot of perl dependencies to be installed. Rather than going through CPANmodule by module, and rather than writing a bundle file for the connoteadependancies (because I don&#39;t know how to do that yet) I decided to try touse CPANPLUS, due to the tips  on perl administration withCPANPLUS&lt;/p&gt;&lt;p&gt;My first attempt to instal CPANPLUS didn&#39;t seem to get very far, then I readthat someone had succeeded by installing it into /Useres/Shared as root, sothat&#39;s what I tried and it seems to work. To be safe I ran the followingcommands on the advice of the program itself:&lt;/p&gt;&lt;p&gt;    $ perl bin/cpanp-boxed -s selfupdate dependencies    $ perl bin/cpanp-boxed -s selfupdate enabled_features&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>BarCamp Cambridge Jeff Fates, Drupal</title>
   <link href="http://partiallyattended.com/2008/07/14/BarCamp-Cambridge-Jeff-Fates,-Drupal"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/BarCamp-Cambridge-Jeff-Fates,-Drupal</id>
   <content type="html">&lt;div&gt; &lt;p&gt;OS CMS systems beat the crap out of the free ones for what you get for your money, including support.&lt;/p&gt;&lt;p&gt;If you have a budget then you can get in touch with the authors of the OS systems easily&lt;/p&gt;&lt;p&gt;the only thing they sometimes don&#39;t win on is polish&lt;/p&gt;&lt;p&gt;it is someone&#39;s job to look at each piece and make sure that it is slick&lt;/p&gt;&lt;p&gt;Drupal is free, It upgrades about twice&amp;#160; a year, one major one minor&lt;/p&gt;&lt;p&gt;is built on PHP and MySQLscales pretty well, but perhaps not as well as to the size that sanger would needbut does scale on small hardware to 100s of thousands of items and users&lt;/p&gt;&lt;p&gt;is very modular.&lt;/p&gt;&lt;p&gt;it has lot&#39;s of modulescore modules are very well written&lt;/p&gt;&lt;p&gt;It is very flexible. the core bit of content is a node,any content that you have, if it is a node, then it inherits a lot of featuressuch as getting commenting, revision control, access controlcategorisation, &lt;/p&gt;&lt;p&gt;CCK is the content creation kit&lt;/p&gt;&lt;p&gt;Views module is for making custom lists of pages and custom lists of notes&lt;/p&gt;&lt;p&gt;for example in hte drupal site there is a blog module, but you can make any custom view with the views module&lt;/p&gt;&lt;p&gt;overview of admin pageand module view, the view is quite hard to see as the light is a bit high in the back of the room at the moment.&lt;/p&gt;&lt;p&gt;There is some disagreement about the status of Casablanca as a great movie, suggestion gets derisory snort from Matt, ces&#39;t la vie.&lt;/p&gt;&lt;p&gt;a staging system would be nice, but is not there at the moment&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>BarCamp Cambridge - teacking computers to understand text, Peter Corbett</title>
   <link href="http://partiallyattended.com/2008/07/14/BarCamp-Cambridge---teacking-computers-to-understand-text,-Peter-Corbett"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/BarCamp-Cambridge---teacking-computers-to-understand-text,-Peter-Corbett</id>
   <content type="html">&lt;div&gt; &lt;p&gt;a desk at the computer lab and at the chemistry lab.&lt;/p&gt;&lt;p&gt;computationl lingustic chemistryauto-detect language in chemistry papers to try to recognics chemical andmarkup.&lt;/p&gt;&lt;p&gt;suppliment the mark-up from publishers.&lt;/p&gt;&lt;p&gt;can draw the chemical and annotating them overlayed over the paper&lt;/p&gt;&lt;p&gt;some problems are that there can be new names in papers,comapct names, include extra hyphens, this program can deal with these kindsof things.&lt;/p&gt;&lt;p&gt;also can use systematics parsing.&lt;/p&gt;&lt;p&gt;this is the core technology, you can do things like search for alkloids inyour paper, or document dump&lt;/p&gt;&lt;p&gt;this seems to run within a browser.&lt;/p&gt;&lt;p&gt;run the software over a corpus of about 100 papers, and created a searchengine out of this?? I Might be wrong about that.&lt;/p&gt;&lt;p&gt;can create an svg&lt;/p&gt;&lt;p&gt;can go from plain text to something like a connection layout using aninformation rich markup&lt;/p&gt;&lt;p&gt;the RSC is using this software along with human-clanup to create markup ofchemistry papers.&lt;/p&gt;&lt;p&gt;can then to semantic search over papers.&lt;/p&gt;&lt;p&gt;Small natual languge processing trickimage we were interested in opiates,we could just ask opiates to googleyou can ask a question like &amp;quot;opiates such as&amp;quot; will give you a much betterreturn on results.&lt;/p&gt;&lt;p&gt;I just checkd this ad it works&lt;/p&gt;&lt;p&gt;there are many patterns like this, they are known as hurst patterns.&lt;/p&gt;&lt;p&gt;he did a pass over abstracts on pubmed for these kind of patterns to make anetwork of relationships&lt;/p&gt;&lt;p&gt;there is not a connected graph&lt;/p&gt;&lt;p&gt;dot failes on large graphs, but the demo does show that you can automate thediscovery of reaction networks.&lt;/p&gt;&lt;p&gt;you can do reasoning on structure as well as process (now he mentions lot&#39;sof chemical names that I know nothing about)&lt;/p&gt;&lt;p&gt;a few bits of wisom from this&lt;/p&gt;&lt;p&gt;most of the informaion has come from biochemists rather than chemists,more biologists are into open science, and open databasechemisty has ben mostly captured by commercial interest,hard to get free chemistry data.&lt;/p&gt;&lt;p&gt;next is to define what you are looking for?you want to be able to evaluate how well the software has donehow do you post-annotate the documents?in a lot of text there is a diffeernce between what you think the worldlooks like andhow it is described in the literature, so even when you get people to ..&lt;/p&gt;&lt;p&gt;question about confidence levels,the most recent piece of the software has confidence levels. rare eventsdon&#39;t providegood confidence levels&lt;/p&gt;&lt;p&gt;it could depend on what you are looking for for,&lt;/p&gt;&lt;p&gt;Peter thinkgs that confidence is important for these systems&lt;/p&gt;&lt;p&gt;e.g. &amp;quot;a such has b&amp;quot; if b might be a chemical but you are not sure. if lateryou find in your search that a is indeed a chemical it raises yourconfidence that b is indeed a chemical&lt;/p&gt;&lt;p&gt;Q: is there any way to automate the acronyms of chemicals.turns out that this is not allways nice. you can do some of this.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>BarCamp Cambridge - James talking about HTML5</title>
   <link href="http://partiallyattended.com/2008/07/14/BarCamp-Cambridge---James-talking-about-HTML5"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/BarCamp-Cambridge---James-talking-about-HTML5</id>
   <content type="html">&lt;div&gt; &lt;p&gt;James is just an interested bysander on the HTML 5 mailing list, hey, it&#39;s abarcamp&lt;/p&gt;&lt;p&gt;html5 is th enew verison of html&lt;/p&gt;&lt;p&gt;applemozillaoperaanyone who joins the mailing list&lt;/p&gt;&lt;p&gt;and&lt;/p&gt;&lt;p&gt;w3c (which means MS, which means this is going to work in IE)&lt;/p&gt;&lt;p&gt;if you have ideas, then you can joing hte mailing list and put ideasforwards for the specification&lt;/p&gt;&lt;p&gt;why should we?&lt;/p&gt;&lt;p&gt;lots of information is locked up in HTML, not XML, not SVGL&lt;/p&gt;&lt;p&gt;most of it is invalid&lt;/p&gt;&lt;p&gt;it&#39;s important to know how to parse this invalid html, at the moment all ofthis understanding is locked up in browers, you have to reverse hack mozillaor IE souce, not a good situation to be in&lt;/p&gt;&lt;p&gt;HTML4 is underspecifiedincisistentdoes not match reality&lt;/p&gt;&lt;p&gt;for example the reason when google maps is launced, it didn&#39;t work in Safaribecause no one knows how to parse HTML&lt;/p&gt;&lt;p&gt;another example is video, you need a proprietary plug in to watch videos inyou tube, this is nuts&lt;/p&gt;&lt;p&gt;what of xhtml, this requires XML, and for a lot of people this is also nuts&lt;/p&gt;&lt;p&gt;most browser vendors can&#39;t impliemtnXHTML2 inther browser&lt;/p&gt;&lt;p&gt;what is the proceedure?identify use casesand look for solutions to use cases&lt;/p&gt;&lt;p&gt;this is more contentions than you would think&lt;/p&gt;&lt;p&gt;html 5 looks like html&lt;/p&gt;&lt;p&gt;some changes&lt;/p&gt;&lt;p&gt;doctype is shrtercharset is supported&lt;/p&gt;&lt;p&gt;what interesting features are implimented&lt;/p&gt;&lt;p&gt;things like&lt;/p&gt;&lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt; &lt;/p&gt;&lt;p&gt;nav could be ignored by screen readers&lt;/p&gt;&lt;p&gt;aside is designed for pull out boxes.&lt;/p&gt;&lt;p&gt;some of the reasons for these new items is a google search for favouriteclass names used in htmlthese items closely follow a hughe number of entities that are already inuse&lt;/p&gt;&lt;p&gt;html 5 specifies more algorithms in more details&lt;/p&gt;&lt;p&gt;you can associate a visable caption with an image(is called a legend, not caption for historical reasons)&lt;/p&gt;&lt;p&gt;finally good support for video  multiple encodings supported with source elements  with fallback content&lt;/p&gt;&lt;p&gt;autoplay attribute for audio&lt;/p&gt;&lt;p&gt;lots of DOM support, so you could write a media player in HTML 5&lt;/p&gt;&lt;p&gt;this is working already&lt;/p&gt;&lt;p&gt;new inline elements, e.g. datetime, progress, meter. (specify value throughattributes or get values via program??)&lt;/p&gt;&lt;p&gt;lot&#39;s of support for forms,sample shows many high level form inputs with easy coding.&lt;/p&gt;&lt;p&gt;lots more, canvas element used by yahoo pipes&lt;/p&gt;&lt;p&gt;parsing, HTML privides a detailed parsing algorithim that can deal withmis-formed htmlit is designed with desktop browsers in mind.implimentaion in html5lib (originally written in python, ported to Ruby).you can use this on the web and see how the parser works there.&lt;/p&gt;&lt;p&gt;! Discussion&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Barcamp Cambridge   James Smith Talking About Ensemble, Head Of Theinternet Team For Ensemble</title>
   <link href="http://partiallyattended.com/2008/07/14/BarCamp-Cambridge---James-Smith-talking-about-Ensemble,-head-of-theinternet-team-for-Ensemble"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/BarCamp-Cambridge---James-Smith-talking-about-Ensemble,-head-of-theinternet-team-for-Ensemble</id>
   <content type="html">&lt;div&gt; &lt;p&gt;Ensemble came out of the human genome project about 8 years ago to preventcommercialization of genomic data.&lt;/p&gt;&lt;p&gt;the idea was to have an open source human genome&lt;/p&gt;&lt;p&gt;companies would have to do some work before they could make money off ofsequences.&lt;/p&gt;&lt;p&gt;the ensemble projects takes the raw data from the genes and adds other datato this, such as reference data from other experiments&lt;/p&gt;&lt;p&gt;there is enemble codeand there is the data&lt;/p&gt;&lt;p&gt;there are 41 genomes,&lt;/p&gt;&lt;p&gt;the code is also used elsewhere from this project&lt;/p&gt;&lt;p&gt;everything is OS&lt;/p&gt;&lt;p&gt;there are probably about 100 instaled copies world wide&lt;/p&gt;&lt;p&gt;it is 1.5 milion lines of perl code&lt;/p&gt;&lt;p&gt;major pharma companie use it and layer their hose data on top if the publicdata&lt;/p&gt;&lt;p&gt;there is a public mysql interface&lt;/p&gt;&lt;p&gt;ww.ensembl.org (no e on the end)&lt;/p&gt;&lt;p&gt;there is also an archive system to see old data&lt;/p&gt;&lt;p&gt;everything is in CVS&lt;/p&gt;&lt;p&gt;there are about 40 people involved directly from the gene builders throughto the comparative groupsthere is a funtional annotation of the genomethere is the web team, an outreach team a helpdesk team.a warehouse team.and others ..there is support from the core web team,&lt;/p&gt;&lt;p&gt;scale&lt;/p&gt;&lt;p&gt;35 species in ensemble, human mouse rat zebra fishthen there are random mammallshedgehogs, many mammals from madagascarthe platapus has a poisned claw&lt;/p&gt;&lt;p&gt;they are runing half a million search index queries on one machine, thismakes them about the 5thlargest search index in the world&lt;/p&gt;&lt;p&gt;about 2 million page impression a week100 gb&#39;s of data traffic&lt;/p&gt;&lt;p&gt;they have 20 4 core machines, about 80 cores to run the site&lt;/p&gt;&lt;p&gt;BLAAST SSAHA servers&lt;/p&gt;&lt;p&gt;using 40 TB&#39;s of data at the moment&lt;/p&gt;&lt;p&gt;you expect hardware failure every week, and they don&#39;t let you know&lt;/p&gt;&lt;p&gt;at this point about hardware failure every day&lt;/p&gt;&lt;p&gt;currently on 3rd set of web code&lt;/p&gt;&lt;p&gt;2000 human2001 mouse2001 fly2003 Vegas site2004 archive site started2005 web code v32006 users and groupsin about a month ensembe 50 will be released&lt;/p&gt;&lt;p&gt;also have a number of other sites&lt;/p&gt;&lt;p&gt;they have a two month cycle for releasing data, and code.the day after each release they start building genes again&lt;/p&gt;&lt;p&gt;many data sets take longer than this, for data, the new mouse sequence wasreleased by ncbi 6 months ago,but it has taken this long for sanger to do the annotation and comparativework.&lt;/p&gt;&lt;p&gt;there is a pre-site for data that didn&#39;t quite finish within the two monthcycle&lt;/p&gt;&lt;p&gt;VectorBase  - ensembl for desiese vectorsGramene - esembl for plantsCosmic - uses the drawing code&lt;/p&gt;&lt;p&gt;they are moving over to AJAX because people don&#39;t realize that items in theinterface are buttons or forms.a lot of the interaction is human interactionthey hope they can make ajax that does not break the screen readers, hopethat ajax will offer a web servicesplatform. this leads to issues of display vs data markup.&lt;/p&gt;&lt;p&gt;webcode is extensible by plug-ins.can add code which resides outside the main ensemble CVS tree - butaccessible from within.&lt;/p&gt;&lt;p&gt;and that&#39;s it&lt;/p&gt;&lt;p&gt;Questions:&lt;/p&gt;&lt;p&gt;Q: how does MySQL  cope?&lt;/p&gt;&lt;p&gt;it copes really well, they have 150 GB, about 5GB is in RW DB the rest is inRead only DBthe issue is not the size of the data, but the number of tables.one of the DB&#39;s has 3000 tables, so they have very careful balancing of dataon the serverssome problems come from MySQL  not being able to have keytalbes larger than 4GB,and when you have 60GB of memory then you run into this problem.&lt;/p&gt;&lt;p&gt;the bottlenecks tend to be in the code layer, not in the DB&lt;/p&gt;&lt;p&gt;this is one of the largest MySQL  DB&#39;s in the world&lt;/p&gt;&lt;p&gt;currently using 4.something, keep planning to move to 5, but keep findingother things that are more important.&lt;/p&gt;&lt;p&gt;there are a lot of left joins in some queries.&lt;/p&gt;&lt;p&gt;sometimes it is easier to do these joins in perl rather than inMySQL,millions of times faster than in MySQL &lt;/p&gt;&lt;p&gt;connected to the net via a 1gb net to Janet.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>BarCamp Cambridge, Tom Morris, Semantic Web for hackers</title>
   <link href="http://partiallyattended.com/2008/07/14/BarCamp-Cambridge,-Tom-Morris,-Semantic-Web-for-hackers"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/BarCamp-Cambridge,-Tom-Morris,-Semantic-Web-for-hackers</id>
   <content type="html">&lt;div&gt; &lt;p&gt;what&#39;s cool about microformats web?&lt;/p&gt;&lt;p&gt;is it the stickers?the t-shirtsthe community process&lt;/p&gt;&lt;p&gt;urlb.at/2f&lt;/p&gt;&lt;p&gt;personal information disastertravel  airlines don&#39;t talk to railroads&lt;/p&gt;&lt;p&gt; microformats say, what problem does it solve?&lt;/p&gt;&lt;p&gt; perhaps there is no problem at all&lt;/p&gt;&lt;p&gt;what problem does blogging solve?Twitter for christ&#39;s sake?&lt;/p&gt;&lt;p&gt;no one knows what they do until they are popular&lt;/p&gt;&lt;p&gt;e.g. yahoo pipes is not practical yetit is a user experience nightmareand it doesn&#39;t have a clear defined purpose&lt;/p&gt;&lt;p&gt;useful becasuse there is a lot of data via rss out there&lt;/p&gt;&lt;p&gt;it gives us room to play&lt;/p&gt;&lt;p&gt;microformats is not compatible with this&lt;/p&gt;&lt;p&gt;should be put up data and let people play&lt;/p&gt;&lt;p&gt;adding some richness to the data&lt;/p&gt;&lt;p&gt;if if does not get used then darwin will clear up the mess&lt;/p&gt;&lt;p&gt;the amount of interesting data is greater than the possible number of microformats&lt;/p&gt;&lt;p&gt;this is a mind flip from SQL&lt;/p&gt;&lt;p&gt;RDF is to SQL what dynamic is to static typing&lt;/p&gt;&lt;p&gt;use eRDF&lt;/p&gt;&lt;p&gt;gives an example of sh1 of email address for putting in this data into HTML&lt;/p&gt;&lt;p&gt;if it maps to an RDF schema then you can use it todayif not it is based on URI&#39;s and you can make your own schema&lt;/p&gt;&lt;p&gt;for a free market everyone needs to take part&lt;/p&gt;&lt;p&gt;GRDDL only &lt;a class=&quot;tiddlyLink tiddlyLinkNonExisting&quot; title=&quot;The tiddler &#39;W3C&#39; doesn&#39;t yet exist&quot;&gt;W3C&lt;/a&gt; could come up with a name like that&lt;/p&gt;&lt;p&gt;triplr.org does this&lt;/p&gt;&lt;p&gt;triplr.org will tell you what data your page is putting out&lt;/p&gt;&lt;p&gt;the semantic web is only scary if you make it scary&lt;/p&gt;&lt;p&gt;look at Cwm python tool, closed wold machinecan use with FOAF to make a page of hCardsyou can combine them together to see all of your friends&lt;/p&gt;&lt;p&gt;uses api&#39;s gives you a FOAF docuemtns and HTML page with hCard/XFN for import to for example Dopplr&lt;/p&gt;&lt;p&gt;tommorris.org&lt;/p&gt;&lt;p&gt;homework:&lt;/p&gt;&lt;p&gt;add some rdf data to your sitegetsemantic.com &lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>BarCamp Cambridge, ARM microcontroler</title>
   <link href="http://partiallyattended.com/2008/07/14/BarCamp-Cambridge,-ARM-microcontroler"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/BarCamp-Cambridge,-ARM-microcontroler</id>
   <content type="html">&lt;div&gt; &lt;p&gt;ARM microcontroler dev guy.&lt;/p&gt;&lt;p&gt;hard to use these processors, whanted to make something like this availableto normal peoplewant internet bluetooth connected devices&lt;/p&gt;&lt;p&gt;so they built something&lt;/p&gt;&lt;p&gt;he just plugged in a microcontoler with a wireless sensorhis machine things that it&#39;s a flash drive&lt;/p&gt;&lt;p&gt;he dregged over a binarythe device started blinking, this is the hello world of hardware hacking,cool&lt;/p&gt;&lt;p&gt;what can you do now? well cool stuff obviously!&lt;/p&gt;&lt;p&gt;the other cool thing is that there is a compiler on a websiteso you can talk about things in the context that people imagine themthis is built on top of c++&lt;/p&gt;&lt;p&gt;you can save straigt onto the device, as the computer just thinks that its ahard drive.now he has a flashing light on this&lt;/p&gt;&lt;p&gt;it&#39;s about giving people confidence in the tools that they are working with.there was no software that needed to be installed, reducing the chainbefore you get a response.&lt;/p&gt;&lt;p&gt;if you have a long chain, compiling and so forth,by the time you get a response your confidence that you have done the rightthingcan be low.&lt;/p&gt;&lt;p&gt;low chain, high level of confidence.&lt;/p&gt;&lt;p&gt;he then hacks the light to flash at a vairable rate depending on how totwist a switch. this normally takes about two days to get workingin the usual embeded programming systems.&lt;/p&gt;&lt;p&gt;the difference between this and lego mindstorms is you make this system doanything you wantand it can talk to the internet.&lt;/p&gt;&lt;p&gt;hacked with a gps sensor in his garden, and it told him that he was 2 milesaway from his gardenvia google-maps. It was outputting in degrees and minutes but needed to bein digital.&lt;/p&gt;&lt;p&gt;how does it compare to sunspots?&lt;/p&gt;&lt;p&gt;the main audience for this is people who want to add some control the theirdesign, but that it is not their core competence.For people who want to bridge the physicall world and the internet world.&lt;/p&gt;&lt;p&gt;could put an accelerometer in a rocket, and fly it for school kids. Change&#39;fly&#39; a rocket, and it&#39;s cool, to &#39;fly a rocket, and learn aboutacceleration&#39;.&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Are Academics Prostitutes</title>
   <link href="http://partiallyattended.com/2008/07/14/Are-Academics-Prostitutes"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/Are-Academics-Prostitutes</id>
   <content type="html">&lt;div&gt; &lt;p&gt;A blog post from &lt;a href=&quot;http://www.academicproductivity.com&quot;&gt;AcademicProductivity&lt;/a&gt; trundled across my reader this morning in which the blogpoints to a paper in which the author claims that &lt;a&gt;academicsare prostitutes&lt;/a&gt; because they modify their papers in response to thedemands of reviewers. I got a sense frisson when I read the blog post andsome of the text that is quoted there from the paper, but then I read thecomments to the blog post, and they are very good at, if you like, pointingout that the paper is a bit weak in it&#39;s premise. OK, so I didn&#39;t read thepaper, but it seems to presuppose that all editorial boards work in the sameway and all reviewers and equally mendacious. Academic publishing is anactivity of a community and the reviewing process, whatever it&#39;s faults, ispart of that conversation. To point out the faults in such a way as thispaper does seems like complaining about norms that are accepted and areperhaps not actually as bad as initially laid out.&lt;/p&gt; &lt;p&gt;  &lt;/p&gt; &lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>An idea for an interface for picture search</title>
   <link href="http://partiallyattended.com/2008/07/14/An-idea-for-an-interface-for-picture-search"/>
   <updated>2008-07-14T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2008/07/14/An-idea-for-an-interface-for-picture-search</id>
   <content type="html">&lt;div&gt; &lt;p&gt;A few weeks ago I was a beer festival in Munich, and I was talking tosomeone who was working on something, hey it was a beer festival, but then Ihad an idea about the type of interface that might be really useful fordoing search. We now search for images using text, so somewhere someone hasto build the text to image representation of the images in their database.Arguably this is one area where tagging has made an enormous improvement,ala flickr, but it seems to me that if you could make an interface thatwould allow a user to either draw or assemble a rough draft of the imagethey were searching for then this might offer a powerful and complimentaryapproach. I envisage a system where people would be able to brig together acollage of elements, a car template that could be sized, coloured, a genericperson or child object. By arranging these elements on the search interfacethe seeker could give a lot more information in their search, vis a vis thespatial arrangement of elements.&lt;/p&gt;&lt;p&gt;Well this I heard that there are some people already working on this, Iguess that&#39;s not surprising, I hope that they can make it work, because itwould be really cool.&lt;/p&gt;&lt;p&gt;tags: search, image, tech&lt;/p&gt; &lt;p&gt;   &lt;/p&gt; &lt;/div&gt;</content>
 </entry>
 
 <entry>
   <title>Volvox</title>
   <link href="http://partiallyattended.com/2006/06/29/Volvox"/>
   <updated>2006-06-29T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2006/06/29/Volvox</id>
   <content type="html">&lt;p&gt;“Volvox”:img:img:http://www.mulvany.net/photo/blogPics/volvox&lt;/p&gt;

&lt;p&gt;The very first thing to die on it’s own, without the intervention of an outside agent, 
was an organism called Volvox. The first life that we know of whose cells perish
from old age, rather than misfortune. Before humble Volvox all other 
living things would go on forever, the immortal bacteria, the barely
describable virus. Volvox introduced death by natural causes to
the world, and all living things that came after that were as complex,
or more so, followed suit, and found programmed within them some
pace maker, set to expire after they had done their duty on the earth.
All plants, all animals that sprung from this little algae shared this
little death in common with it, and also the other innovation 
introduced into the vaults of creation by this tumbling capsid, the ability
to combine genetic material from two parents to create a truly new 
individual, the desire to have sex.&lt;/p&gt;

&lt;p&gt;The tale of Adam and Eve bringing death and corruption into
the garden of eden at the same moment as shame
seems to me now to be more than an idle moral play. In the 
evolution of life on this planet sex did herald death, but the garden then
was a poor and simple place before these drivers of change, of need,
took hold and drove the systems of life into a perpetual war
for dominance of resources that somehow and accidentally spat
us breathing and panting onto the shore.&lt;/p&gt;

&lt;p&gt;When I was younger I should have felt immortal, but there was always
a fragility to the world around me. At any moment a sudden shift might take
hold and break down the walls that held together what I thought of 
as my existence. Sitting in the sun looking down at the ants threading 
between blades of grass my brow would tighten as I tried to make 
scrutable their encoded wanderings. &lt;/p&gt;

&lt;p&gt;And now I look about me, and it seems that those same blades of 
light that made clear to me my ignorance when I was a child are now
highlighting again the fragility of the world, and the incredible 
insouciance that other people tread through their lives with. &lt;/p&gt;

&lt;p&gt;We are all rolling along on our own hidden roller-coaster ride.&lt;/p&gt;

&lt;p&gt;In the dark Volvox keeps rolling on, spawning it’s children, suspended in 
waters, like some tiny sun cast adrift in the intergalactic spaces,
 the centre of it’s own epicycle, it’s own birthings and dyings.&lt;/p&gt;

&lt;p&gt;I am four billion years removed from this speck, and at the same time
i could hardly feel closer.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Economics and The New World Order,</title>
   <link href="http://partiallyattended.com/2006/06/26/Economics-and-The-New-World-Order,"/>
   <updated>2006-06-26T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2006/06/26/Economics-and-The-New-World-Order,</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;Economics and The New World Order,

I had a rather detailed and engaging conversation on Friday night
with a couple of good friends of mine about Economics, and it&#39;s
explanatory power. My friend Brain holds that economics explains
everything, except perhaps for the laws of physics. Now I am
also tempted to buy into his arguments, he is quite a persuasive fellow,
however I intrinsically feel some caution in doing so, and I have
been trying to figure out why.

I am not sure whether my arguments hold any weight to them, or
whether I am just being an objectionable fucker for the sake of it,
but I&#39;ll try to lay out my thoughts here in any case. If nothing
else, it should draw a comment from Brain pointing out the error 
of my ways.

I think the argument is that if we want to find an explanation 
for all of the events in History, then the reason that 
some things happened, and others didn&#39;t is that the events
that occurred, and were successful, were the ones that had
an economic advantage over the ones that didn&#39;t. The scope
of what we consider, for this argument, to be economic advantage
is quite broad. Really, it seems to be anything that gives the
actors involved some sense of value. That sense can come from
moral well being, from money, from realization of religious
justification, I think. Certainly it&#39;s not simply money
as money is just one common abstract representation of
value. 
 
Now I think that I have two objections to the economic argument.

The first is that it might not have any predictive power. It 
may be tautological to say that when things happen, then
people to whom they happen feel value,  therefore those things
are the best fit things to happen (oh dear, that&#39;s not very clear
at all, but this is only a blog, and so in the spirit of such
I am not going to worry at all about not making sense). If you
can back fit all circumstances to your explanation, either
your explanation is very good, or it is very bad. If it adds no
predictive power, then it&#39;s not very good. I fear that though the
spirit of taking a truly market capitalist attitude might be 
correct, it might also have no value. In a broad market place 
there are many ideas that compete, but there are also 
a huge number of factors that go to influence success. The landscape
in which events operate (and by landscape here I mean every 
event connected to the event under consideration that has some 
effect on the event, weather, personal motivation, war, time
of year, news, car accidents, and so forth). If one&#39;s position
in the landscape has a great deal to determine whether the outcome
of an event will be a success, then though you could argue that the
even succeeded because economically it was best fit for it&#39;s 
location, I think there is something wrong with that argument.
I think that what you are looking at in economic terms is which 
direction in the landscape you want to be heading in, however
actually looking at the local geography of this abstract space
may tell you more about whether you will succeed than by looking
at where you want to go. It is not inconceivable that the 
only thing that matters is your position in this space, and 
not by any means your intent. The purely economic argument would then 
be a comforting chimera that we can wrap around ourselves to 
protect us from the vagaries of the world.

That&#39;s all well and good, but is there any way to tease these idea
apart and to test them? it&#39;s highly unlikely, but there may be some
option not from looking at the world, but by looking at worlds that
we create. In a simple model the economic argument should work. 
There are many studies of what is known as the prisoners dilemma,
I don&#39;t know much about what the studies say, but I think 
they should be a good test of economic predictive theory.
Therefore in a simple game economics should have a high 
predictive power to give a winner. Add complexity to the 
game and see how predictability changes as a rate of increasing
complexity. Hmm, actually, the stock market is a very good 
example of doing something like this, but we can&#39;t reverse 
engineer the world to see if we can make it more predictable.

Well, that was part one of my argument, which even I have to admit
just comes down to saying &quot;perhaps things are just a bit more complicated&quot;,
and since we all seek simplicity, then perhaps there is not 
much harm in looking to economics (other than being wrong an awful
lot, and retroactively fitting by saying, ahh, but of course we didn&#39;t
factor in economic driver blah blah). Still, it&#39;s in our
nature to be wrong loving mammals, so I shouldn&#39;t worry too much.

The next thing that unsettles me is even if the economic argument
it is wright, and it would be quite nice if it were right, for if
it were it would give us the true power to change the world, 
there may be a temptation to confuse correctness of explanation
with justification for action. Being Irish I have a built-in
distrust of a lazzaiz-fair market, as this was the decision
that contributed to the deaths of many Irish people during the 
great famine of the 1840&#39;s. By saying that the open market
is the best option we forgo our ability to intervene when there
is pressing reason to do so. The best open market for ideas
is evolution, but even in evolution market forces can press
species into extinction, though sexual over-selection. The
same may be happening with America where there is a strong
market drive for light entertainment, cheap credit and cheap oil.
Perhaps these drivers are acting locally and may not be the
best actions that the market could be taking locally. Even though
humans are subject to evolution I believe strongly that we have
the capacity to transcend evolution (that sounds wishy-washy, but
I mean that we have the moral and technological ability to make decisions
that are nut just driven by competition with other species, indeed
our ability to do so almost gives us a moral obligation to do so, 
and that would be fine, as soon as we figure out what morals are).

Well, I have more to say, but for the time being that is enough on this topic 
from me.
&lt;/code&gt;&lt;/pre&gt;

</content>
 </entry>
 
 <entry>
   <title>Economics and The New World Order,</title>
   <link href="http://partiallyattended.com/2006/06/26/Economics-and-The-New-World-Order"/>
   <updated>2006-06-26T00:00:00+01:00</updated>
   <id>http://partiallyattended.com/2006/06/26/Economics-and-The-New-World-Order</id>
   <content type="html">&lt;pre&gt;&lt;code&gt;Economics and The New World Order,

I had a rather detailed and engaging conversation on Friday night
with a couple of good friends of mine about Economics, and it&#39;s
explanatory power. My friend Brain holds that economics explains
everything, except perhaps for the laws of physics. Now I am
also tempted to buy into his arguments, he is quite a persuasive fellow,
however I intrinsically feel some caution in doing so, and I have
been trying to figure out why.

I am not sure whether my arguments hold any weight to them, or
whether I am just being an objectionable fucker for the sake of it,
but I&#39;ll try to lay out my thoughts here in any case. If nothing
else, it should draw a comment from Brain pointing out the error 
of my ways.

I think the argument is that if we want to find an explanation 
for all of the events in History, then the reason that 
some things happened, and others didn&#39;t is that the events
that occurred, and were successful, were the ones that had
an economic advantage over the ones that didn&#39;t. The scope
of what we consider, for this argument, to be economic advantage
is quite broad. Really, it seems to be anything that gives the
actors involved some sense of value. That sense can come from
moral well being, from money, from realization of religious
justification, I think. Certainly it&#39;s not simply money
as money is just one common abstract representation of
value. 
 
Now I think that I have two objections to the economic argument.

The first is that it might not have any predictive power. It 
may be tautological to say that when things happen, then
people to whom they happen feel value,  therefore those things
are the best fit things to happen (oh dear, that&#39;s not very clear
at all, but this is only a blog, and so in the spirit of such
I am not going to worry at all about not making sense). If you
can back fit all circumstances to your explanation, either
your explanation is very good, or it is very bad. If it adds no
predictive power, then it&#39;s not very good. I fear that though the
spirit of taking a truly market capitalist attitude might be 
correct, it might also have no value. In a broad market place 
there are many ideas that compete, but there are also 
a huge number of factors that go to influence success. The landscape
in which events operate (and by landscape here I mean every 
event connected to the event under consideration that has some 
effect on the event, weather, personal motivation, war, time
of year, news, car accidents, and so forth). If one&#39;s position
in the landscape has a great deal to determine whether the outcome
of an event will be a success, then though you could argue that the
even succeeded because economically it was best fit for it&#39;s 
location, I think there is something wrong with that argument.
I think that what you are looking at in economic terms is which 
direction in the landscape you want to be heading in, however
actually looking at the local geography of this abstract space
may tell you more about whether you will succeed than by looking
at where you want to go. It is not inconceivable that the 
only thing that matters is your position in this space, and 
not by any means your intent. The purely economic argument would then 
be a comforting chimera that we can wrap around ourselves to 
protect us from the vagaries of the world.

That&#39;s all well and good, but is there any way to tease these idea
apart and to test them? it&#39;s highly unlikely, but there may be some
option not from looking at the world, but by looking at worlds that
we create. In a simple model the economic argument should work. 
There are many studies of what is known as the prisoners dilemma,
I don&#39;t know much about what the studies say, but I think 
they should be a good test of economic predictive theory.
Therefore in a simple game economics should have a high 
predictive power to give a winner. Add complexity to the 
game and see how predictability changes as a rate of increasing
complexity. Hmm, actually, the stock market is a very good 
example of doing something like this, but we can&#39;t reverse 
engineer the world to see if we can make it more predictable.

Well, that was part one of my argument, which even I have to admit
just comes down to saying &quot;perhaps things are just a bit more complicated&quot;,
and since we all seek simplicity, then perhaps there is not 
much harm in looking to economics (other than being wrong an awful
lot, and retroactively fitting by saying, ahh, but of course we didn&#39;t
factor in economic driver blah blah). Still, it&#39;s in our
nature to be wrong loving mammals, so I shouldn&#39;t worry too much.

The next thing that unsettles me is even if the economic argument
it is wright, and it would be quite nice if it were right, for if
it were it would give us the true power to change the world, 
there may be a temptation to confuse correctness of explanation
with justification for action. Being Irish I have a built-in
distrust of a lazzaiz-fair market, as this was the decision
that contributed to the deaths of many Irish people during the 
great famine of the 1840&#39;s. By saying that the open market
is the best option we forgo our ability to intervene when there
is pressing reason to do so. The best open market for ideas
is evolution, but even in evolution market forces can press
species into extinction, though sexual over-selection. The
same may be happening with America where there is a strong
market drive for light entertainment, cheap credit and cheap oil.
Perhaps these drivers are acting locally and may not be the
best actions that the market could be taking locally. Even though
humans are subject to evolution I believe strongly that we have
the capacity to transcend evolution (that sounds wishy-washy, but
I mean that we have the moral and technological ability to make decisions
that are nut just driven by competition with other species, indeed
our ability to do so almost gives us a moral obligation to do so, 
and that would be fine, as soon as we figure out what morals are).

Well, I have more to say, but for the time being that is enough on this topic 
from me.
&lt;/code&gt;&lt;/pre&gt;

</content>
 </entry>
 
 
</feed>